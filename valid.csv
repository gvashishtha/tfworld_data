50392874,"Only Fan-out (and forget) in Durable Functions <p>I have an existing Function App with 2 Functions and a storage queue. F1 is triggered by a message in a service bus topic. For each msg received  F1 calculates a some sub-tasks (T1 T2 ...) which have to be executed with varying amount of delay. Ex - T1 to be fired after 3 mins  T2 after 5min etc. F1 posts messages to a storage queue with appropriate visibility timeouts (to simulate the delay) and F2 is triggered whenever a message is visible in the queue. All works fine.</p>  <p>I now want to migrate this app to use 'Durable Functions'. F1 now only starts the orchestrator. The orchestrator code is something as follows - </p>  <pre><code>    public static async Task Orchestrator([OrchestrationTrigger] DurableOrchestrationContext context  TraceWriter log)     {         var results = await context.CallActivityAsync&lt;List&lt;TaskInfo&gt;&gt;(\CalculateTasks\""  \""someinput\"");         List&lt;Task&gt; tasks = new List&lt;Task&gt;();         foreach (var value in results)         {             var pnTask = context.CallActivityAsync(\""PerformSubTask\""  value);             tasks.Add(pnTask);         }          //dont't await as we want to fire and forget. No fan-in!         //await Task.WhenAll(tasks);     }      [FunctionName(\""PerformSubTask\"")]     public async static Task Run([ActivityTrigger]TaskInfo info  TraceWriter log)     {          TimeSpan timeDifference = DateTime.UtcNow - info.Origin.ToUniversalTime();          TimeSpan delay = TimeSpan.FromSeconds(info.DelayInSeconds);          var actualDelay = timeDifference &gt; delay ? TimeSpan.Zero : delay - timeDifference;           //will still keep the activity function running and incur costs??          await Task.Delay(actualDelay);           //perform subtask work after delay!      } </code></pre>  <p>I would only like to fan-out (no fan-in to collect the results) and start the subtasks. The orchestrator starts all the tasks and avoids call 'await Task.WhenAll'. The activity function calls 'Task.Delay' to wait for the specified amount of time and then does its work.</p>  <p>My questions</p>  <ul> <li>Does it make sense to use Durable Functions for this workflow?</li> <li>Is this the right approach to orchestrate 'Fan-out' workflow?</li> <li>I do not like the fact that the activity function is running for specified amount of time (3 or 5 mins) doing nothing. It will incurs costs or?</li> <li>Also if a delay of more than 10 minutes is required there is <a href=\""https://docs.microsoft.com/en-us/azure/azure-functions/functions-host-json#functiontimeout\"" rel=\""nofollow noreferrer\"">no way</a> for an activity function to succeed with this approach!</li> <li><p>My earlier attempt to avoid this was to use 'CreateTimer' in the orchestrator and then add the activity as a continuation  but I see only timer entries in the 'History' table. The continuation does not fire! Am I violating the <a href=\""https://docs.microsoft.com/en-us/azure/azure-functions/durable-functions-checkpointing-and-replay#orchestrator-code-constraints\"" rel=\""nofollow noreferrer\"">constraint for orchestrator code</a> - 'Orchestrator code must never initiate any async operation' ?</p>  <pre><code>foreach (var value in results) {         //calculate time to start         var timeToStart = ;         var pnTask = context.CreateTimer(timeToStart   CancellationToken.None).ContinueWith(t =&gt; context.CallActivityAsync(\""PerformSubTask\""  value));         tasks.Add(pnTask); } </code></pre>  <p><strong>UPDATE</strong> : using approach suggested by Chris</p>  <p>Activity that calculates subtasks and delays</p>  <pre><code>[FunctionName(\""CalculateTasks\"")] public static List&lt;TaskInfo&gt; CalculateTasks([ActivityTrigger]string input TraceWriter log) {     //in reality time is obtained by calling an endpoint      DateTime currentTime = DateTime.UtcNow;     return new List&lt;TaskInfo&gt; {         new TaskInfo{ DelayInSeconds = 10  Origin = currentTime }          new TaskInfo{ DelayInSeconds = 20  Origin = currentTime }          new TaskInfo{ DelayInSeconds = 30  Origin = currentTime }      }; }  public static async Task Orchestrator([OrchestrationTrigger] DurableOrchestrationContext context  TraceWriter log) {     var results = await context.CallActivityAsync&lt;List&lt;TaskInfo&gt;&gt;(\""CalculateTasks\""  \""someinput\"");     var currentTime = context.CurrentUtcDateTime;     List&lt;Task&gt; tasks = new List&lt;Task&gt;();     foreach (var value in results)     {         TimeSpan timeDifference = currentTime - value.Origin;         TimeSpan delay = TimeSpan.FromSeconds(value.DelayInSeconds);         var actualDelay = timeDifference &gt; delay ? TimeSpan.Zero : delay - timeDifference;          var timeToStart = currentTime.Add(actualDelay);          Task delayedActivityCall = context              .CreateTimer(timeToStart  CancellationToken.None)              .ContinueWith(t =&gt; context.CallActivityAsync(\""PerformSubtask\""  value));         tasks.Add(delayedActivityCall);     }      await Task.WhenAll(tasks); } </code></pre></li> </ul>  <p>Simply scheduling tasks from within the orchestrator seems to work.In my case I am calculating the tasks and the delays in another activity (CalculateTasks) before the loop. I want the delays to be calculated using the 'current time' when the activity was run. I am using DateTime.UtcNow in the activity. This somehow does not play well when used in the orchestrator. The activities specified by 'ContinueWith' just don't run and the orchestrator is always in 'Running' state. </p>  <p><strong>Can I not use the time recorded by an activity from within the orchestrator?</strong></p>  <p><strong>UPDATE 2</strong></p>  <p>So the workaround suggested by Chris works! </p>  <p>Since I do not want to collect the results of the activities I avoid calling '<code>await Tasks.WhenAll(tasks)</code>' after scheduling all activities. I do this in order to reduce the contention on the control queue i.e. be able to start another orchestration if reqd. Nevertheless the status of the 'orchestrator' is still '<em>Running</em>' till all the activities finish running. I guess it moves to '<em>Complete</em>' only after the last activity posts a 'done' message to the control queue. </p>  <p><strong><em>Am I right? Is there any way to free the orchestrator earlier i.e right after scheduling all activities?</em></strong></p>""",azure-functions
44303809,"Is there any way to set up an alert on low disk space for Azure App Service <p>I'm running an Azure App Service on a Standard App Service Plan which allows usage of max 50 GB of file storage. The application uses quite a lot of disk space for image cache. Currently the consumption level lies at around 15 GB but if cache cleaning policy fails for some reason it will grow up to the top very fast.</p>  <p>Vertical autoscaling (scaling up) is not a common practice as it often requires some service downtime according to this Microsoft article:</p>  <p><a href=\https://docs.microsoft.com/en-us/azure/architecture/best-practices/auto-scaling\"" rel=\""nofollow noreferrer\"">https://docs.microsoft.com/en-us/azure/architecture/best-practices/auto-scaling</a></p>  <p>So the question is:</p>  <p>Is there any way to set up an alert on low disk space for Azure App Service?</p>  <p>I can't find anything related to disk space in the options available under Alerts tab.</p>""",azure-web-app-service
47607802,"How do Azure Durable Functions resume? <p>I'm looking at <a href=\https://github.com/Azure/azure-functions-durable-extension\"" rel=\""nofollow noreferrer\"">Azure Durable Functions extension</a> (and the <a href=\""https://github.com/Azure/durabletask\"" rel=\""nofollow noreferrer\"">Durable Task framework repo</a>) and looking for the technical details of how it handles the following scenario.</p>  <p>Imagine the following orchestration.</p>  <pre><code>var result1 = await client.PostAsync(\""http://some-external-service.com/...\""  input);  var result2 = await context.CallActivityAsync&lt;string&gt;(\""Other Function\"" \""some data\"");  ... do more stuff with result1 and result2 </code></pre>  <p>Imagine the function was resumed after <code>Other Function</code> finished  on a machine that was not the first. How does the framework resume from the second await  without executing the first?</p>  <p>In fact  is there a possibility that the HTTP call can be executed more than once in this case?</p>  <hr>  <p>I looked at the Microsoft Bot Framework which has a <em>similar</em> resuming strategy which serializes and rehydrates <code>Dialog</code> stack. (This forced writing code that does not refer to outer scope  so the function itself can be serialized .etc.)</p>  <p>I'm interested in the core functionality in .NET Tasks (or Durable Tasks) which allows serializing and resuming a <code>Task</code> on a different machine without re-running the part it already executed (potentially on a different machine).</p>""",azure-functions
30020116,"Azure Block Blob Storage file upload strange issue <p>I' m using Azure Block Blob Storage to keep my files. Here is my code to upload file. </p>  <p>I m calling the method twice as below for the same file in the same request; The first call of the method saves the file as expected but the second call saves file as length of 0 so i cant display the image and no error occurs.</p>  <pre><code>    [HttpPost]     public ActionResult Index(HttpPostedFileBase file)     {         UploadFile(file);         UploadFile(file);          return View();     }        public static string UploadFile(HttpPostedFileBase file){          var credentials = new StorageCredentials(\accountName\""  \""key\"");          var storageAccount = new CloudStorageAccount(credentials  true);          var blobClient = storageAccount.CreateCloudBlobClient();          var container = blobClient.GetContainerReference(\""images\"");          container.CreateIfNotExists();          var containerPermissions = new BlobContainerPermissions         {             PublicAccess = BlobContainerPublicAccessType.Blob         };          container.SetPermissions(containerPermissions);          var blockBlob = container.GetBlockBlobReference(Guid.NewGuid().ToString());          blockBlob.Properties.ContentType = file.ContentType;          var azureFileUrl = string.Format(\""{0}\""  blockBlob.Uri.AbsoluteUri);          try         {             blockBlob.UploadFromStream(file.InputStream);         }          catch (StorageException ex)         {             throw;         }         return azureFileUrl ;     } </code></pre>  <p>I just find the below solution which is strange like mine  but it does not help.</p>  <p><a href=\""https://stackoverflow.com/questions/23987351/strange-sudden-error-the-number-of-bytes-to-be-written-is-greater-than-the-spec\"">Strange Sudden Error &quot;The number of bytes to be written is greater than the specified ContentLength&quot;</a></p>  <p>Any idea? Thanks</p>""",azure-storage
47365769,"ListBlobs not available in cloudblobdirectory class? <p>I have installed the latest windows azure nuget packages in my .net core 2.0 project. Installed version : 8.6.0.0</p>  <p>In the 8.1.4 version  i have get the list of items using listblobs method using the below syntax.</p>  <pre><code>CloudBlobDirectory sampleDirectory = container.GetDirectoryReference(path);                 IEnumerable&lt;IListBlobItem&gt; items = sampleDirectory.ListBlobs(false  BlobListingDetails.Metadata); </code></pre>  <p>when is try to use the same code block in .net core 2.0 project with 8.6.0.0 windows azure version  it throws error as </p>  <p>\cloudblobdirectory does not contain a definition for listblobs\"".</p>  <p>How to get the file items in this version? </p>  <p>Similarly   UploadText() method in \""CloudBlockBlob\"" also not available in this version.</p>  <p>any one please suggest the solution for this issue ?</p>""",azure-storage
21852540,"Can I configure Azure diagnostics on IAAS virtual machine? <p>I would like to reuse libraries written for Azure PAAS solution (WebRoles and WorkerRoles) in a specific service running in Azure VM (IAAS). It would be beneficial if I could use the same trace listener (DiagnosticMonitorTraceListener) and let the Azure diagnostics to deliver logs to Azure Storage. Is it possible to install the diagnostics services into Azure VM?</p>  <p>I found basically the same question <a href=\https://stackoverflow.com/questions/13408564/is-it-possible-to-use-azure-diagnostics-without-being-in-a-hosted-service\"">here</a> on SO but it is quite old now. Perhaps there was some progress?</p>""",azure-virtual-machine
25176763,"Launching Apps via RDweb Access not working <p>I have created a Windows Server 2012 VM on Azure in its own Domain  running Active Directory. </p>  <p>It is also the host for:</p>  <ul> <li>RD Gateway</li> <li>RD Licensing</li> <li>RD Web Access</li> <li>RD Connection Broker</li> </ul>  <p>It has been configured for Remote Desktop Session access to launch published apps.</p>  <p>Here is an overview of the deployment: <a href=\http://screencast.com/t/NCn8xGFrnzU5\"" rel=\""nofollow\"">http://screencast.com/t/NCn8xGFrnzU5</a></p>  <p>The issue I am facing is this:</p>  <p>While logged inside the Azure VM that is hosting the applications  I can: Browse to the 'RD Web Access' URL Log in to the RD Web page Successfully launch the published apps</p>  <p>Here is a video of me doing the above while logged onto the Azure VM: <a href=\""http://screencast.com/t/PxZTcXmEl\"" rel=\""nofollow\"">http://screencast.com/t/PxZTcXmEl</a> </p>  <p>However  if I attempt to do the above steps on any other PC  we can browse to the 'RD Web Access' URL and log in to the RD Web page BUT  when I attempt to launch the application  I get the error \""Remote Desktop can’t connect to the remote computer for one of these reasons...........\"" (screenshot)</p>  <p>Here is a video of me doing the above on my local machine: <a href=\""http://screencast.com/t/zjKlPcok9Fn\"" rel=\""nofollow\"">http://screencast.com/t/zjKlPcok9Fn</a></p>  <p>I have run the RD License Diagnoser and everything seems to be OK: <a href=\""http://screencast.com/t/3c6qNfWno1u\"" rel=\""nofollow\"">http://screencast.com/t/3c6qNfWno1u</a> </p>  <p>Can anyone provide any suggestions on what could be the problem  and how to fix it?</p>""",azure-virtual-machine
36121219,"Can we RDP / install third-party software to Azure App Service Web App <p>I have read plenty of literature in this context (see links below). The presence of classic vs new Azure management portal  Roles vs App Services  Azure Website vs Azure Web Apps only complicates the matter. Although I believe I have good understanding of these terms and the latters are more or less improved re-incarnations of the formers in the above comparisons  the literature is written mostly using the former of these and not necessarily depicts the options available in the new Management portal.</p>  <p>So what I am really looking forward to understand very clearly is:</p>  <ol> <li>Can I RDP to Azure App Service Web App underlying compute resource?</li> <li>Can I install custom third party software components (e.g. Crystal Reports) to Azure App Service Web App underlying compute resource?</li> </ol>  <p><a href=\https://www.simple-talk.com/cloud/platform-as-a-service/installing-third-party-software-on-windows-azure-%E2%80%93-what-are-the-options/\"" rel=\""nofollow noreferrer\"">Reference 1</a></p>  <p><a href=\""https://azure.microsoft.com/en-in/documentation/articles/cloud-services-nodejs-enable-remote-desktop/\"" rel=\""nofollow noreferrer\"">Reference 2</a></p>  <p><a href=\""https://stackoverflow.com/questions/26260505/where-is-azure-service-definition-schema-csdef-file-located-in-windows\"">Reference 3</a></p>  <p><a href=\""https://stackoverflow.com/questions/23449900/how-to-rdp-to-my-azure-cloud-service?rq=1\"">Reference 4</a></p>  <p><a href=\""https://stackoverflow.com/questions/12516983/download-uploaded-cspkg-file-from-azure\"">Reference 5</a></p>  <p><a href=\""https://stackoverflow.com/questions/20733275/is-it-possible-to-connect-do-remote-desktop-with-windows-azure-websites\"">Reference 6</a></p>""",azure-web-app-service
43785751,".NET class library as an Azure Function App with ServiceBusTopic trigger does not work <p>I created an Azure function app locally in Visual Studio 2017(Not Azure portal) by following the steps at the following URL.</p>  <p><a href=\https://blogs.msdn.microsoft.com/appserviceteam/2017/03/16/publishing-a-net-class-library-as-a-function-app\"" rel=\""nofollow noreferrer\"">https://blogs.msdn.microsoft.com/appserviceteam/2017/03/16/publishing-a-net-class-library-as-a-function-app</a></p>  <p>I followed the steps exactly to create a function that has a “ServiceBusTopicTrigger”. I added the following to my function.json</p>  <pre><code>{     “disabled”: false      “bindings”: [         {             “name”: “mySbMsg”              “type”: “serviceBusTrigger”              “direction”: “in”              “topicName”: “negotiatedaddcharge_test”              “subscriptionName”: “clientdispatches”              “connection”: “servicebusnac”              “accessRights”: “manage”         }     ] } </code></pre>  <p>My appsenttings.json has the following</p>  <pre><code>{     “IsEncrypted”: true      “Values”: {         “servicebusnac”: “Endpoint=MyCompanyEndPointPlaceHolder”     } } </code></pre>  <p>When I run the function in Visual Studio I keep getting an error message “Microsoft.Azure.WebJobs.ServiceBus: Microsoft Azure WebJobs SDK ServiceBus connection string ‘AzureWebJobsservicebusnac’ is missing or empty.”</p>  <p>Just for the heck of it I added another entry to the values collection with the name “AzureWebJobsservicebusnac” but still the same message shows up. Is there something that I am doing wrong?</p>  <p>Also how do you unit test this function? I cannot Access any function in the csx file in my unit test project.</p>  <p>Thanks.</p>  <p>Edited: I added information to make it clear that I am creating the function in Visual Studio rather than the Azure portal.</p>""",azure-functions
23549994,"Possible to access one Azure Virtual Machine through two DNS names using two Cloud Services? <p>I have purchased a Pay-As-You-Go Azure Subscription with the lowest resources (A0 Basic  shared core and 768 MB RAM) and automatically  four services were created for me: a Storage Account  a Virtual Machine  a Cloud Service and a Directory.</p>  <p>On the Virtual Machine I set up my own HTTP server software written in C# using HttpListener class. I added an HTTP Endpoint connecting the private and public port 80 on TCP. Once I've done that  I was able to access my Cloud Service address (Something.CloudApp.net).</p>  <p>I've created a separate Cloud Service on top of 4 service I already had and now I can't figure out how to make that service use the Virtual Machine so I can access the same HTTP server from both DNS names (Something.CloudApp.net versus SomethingElse.CloudApp.net).</p>  <p>The service status of both services is Created if I investigate in the Microsoft Azure Portal  however  only the first service says Running in Production column in Cloud Service list. The other one doesn't. None of the Cloud Services say anything in the Staging column. </p>  <p>I figure I have to set the other service to run in production too  but when I want to do that  the Portal says \You have nothing deployed to the production environment.\""  \""Upload a new production deployment\""  which opens a dialog prompting me to provide details for a production environment to be newly created.</p>  <p>Is there a way I can make my other Cloud Service use the production environment of the first service?</p>  <p>Is there an alternative way to make my Virtual Machine accessible through two DNS names offered by Azure (CloudApp.net)?</p>""",azure-virtual-machine
50499393,"Windows Azure VM Remote desktop connection issue even from home connection <p>I am not sure what i am doing wrong.</p>  <p>I created a virtual machine with SQL server 2016 with the free subscription and all the default setting but when i try to <strong>RDP</strong> from home where there is no firewall  i get an <strong>error</strong>(see below). Please help. Thanks.</p>  <p><a href=\https://i.stack.imgur.com/m61wQ.gif\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/m61wQ.gif\"" alt=\""enter image description here\""></a></p>""",azure-virtual-machine
26610090,Azure Files not shows as storage option <p>Has anyone had any luck in getting Azure files to work? it does not show as an option even though Azure says I have been accepted for preview</p>,azure-storage
36205611,How to switch off the endpoints of Azure Virtual Machines(VMs) by default  not deletion afterwards? <p>How to configure endpoints of Azure VMs  having them shut down by default  when or before I creating VMs?</p>  <p>In another word  how to create Azure VMs without any endpoints assignment?</p>  <p>Removal after VMs creation does not count as the solution for this question.</p>,azure-virtual-machine
54030154,"twilio c# sdk publish to azure app service <p>Downloaded Twilio C# SDK for chat application and when I run off Visual Studio -- it works fine (localhost:port).</p>  <p>Now I would like to publish this on to Azure App Service.  Running into issues here.  Hope someone can give me pointers.</p>  <pre><code>1&gt;------ Publish started: Project: TwilioSdkStarterDotnetCore.Web  Configuration: Release Any CPU ------ Web App was published successfully http://xxxxxxxxxxxx.azurewebsites.net/ ========== Build: 0 succeeded  0 failed  1 up-to-date  0 skipped ========== ========== Publish: 1 succeeded  0 failed  0 skipped ========== </code></pre>  <p>I think the problem is Twilio has external URL in the code that Azure does not like.  Not sure.  Even if it is  not sure how to fix.</p>  <p>ERROR:<br>     System.ApplicationException: The trace listener AzureBlobTraceListener is disabled. ---> System.InvalidOperationException: The SAS URL for the cloud storage account is not specified. Use the environment variable 'DIAGNOSTICS_AZUREBLOBCONTAINERSASURL' to define it.        at Microsoft.WindowsAzure.WebSites.Diagnostics.AzureBlobTraceListener.RefreshConfig()</p>  <pre><code>From Azure App Service log stream: ------------------------------------------------------------------------- Connecting... 2019-01-03T20:09:36  Welcome  you are now connected to log-streaming service.  2019-01-03T20:09:50  System.ApplicationException: The trace listener AzureBlobTraceListener is disabled. ---&gt; System.InvalidOperationException: The SAS URL for the cloud storage account is not specified. Use the environment variable 'DIAGNOSTICS_AZUREBLOBCONTAINERSASURL' to define it.     at Microsoft.WindowsAzure.WebSites.Diagnostics.AzureBlobTraceListener.RefreshConfig()     --- End of inner exception stack trace ---    2019-01-03T20:09:50  PID[4536] Information VSProjectId: 79a347a8-313a-4d83-8c0c-7fe1cba0aa67  2019-01-03T20:09:50  PID[4536] Information DeploymentComplete  2019-01-03 20:09:54.706 +00:00 [Debug] Microsoft.AspNetCore.Hosting.Internal.WebHost: Hosting starting  2019-01-03 20:09:54.794 +00:00 [Information] Microsoft.AspNetCore.DataProtection.KeyManagement.XmlKeyManager: Azure Web Sites environment detected. Using 'D:\\home\\ASP.NET\\DataProtection-Keys' as key repository; keys will not be encrypted at rest.  2019-01-03 20:09:54.834 +00:00 [Debug] Microsoft.AspNetCore.DataProtection.Repositories.FileSystemXmlRepository: Reading data from file 'D:\\home\\ASP.NET\\DataProtection-Keys\\key-3205a103-24e9-43f7-b49c-c3d6f8f8c36f.xml'.  2019-01-03 20:09:54.959 +00:00 [Debug] Microsoft.AspNetCore.DataProtection.Internal.DataProtectionStartupFilter: Key ring with default key {3205a103-24e9-43f7-b49c-c3d6f8f8c36f} was loaded during application startup.  2019-01-03 20:09:54.987 +00:00 [Debug] Microsoft.AspNetCore.Mvc.MvcJsonOptions: Compatibility switch AllowInputFormatterExceptionMessages in type MvcJsonOptions is using compatibility value True for version Version_2_1  2019-01-03 20:09:55.000 +00:00 [Debug] Microsoft.AspNetCore.Mvc.MvcOptions: Compatibility switch AllowCombiningAuthorizeFilters in type MvcOptions is using compatibility value True for version Version_2_1  2019-01-03 20:09:55.000 +00:00 [Debug] Microsoft.AspNetCore.Mvc.MvcOptions: Compatibility switch AllowBindingHeaderValuesToNonStringModelTypes in type MvcOptions is using compatibility value True for version Version_2_1  2019-01-03 20:09:55.000 +00:00 [Debug] Microsoft.AspNetCore.Mvc.MvcOptions: Compatibility switch AllowValidatingTopLevelNodes in type MvcOptions is using compatibility value True for version Version_2_1  2019-01-03 20:09:55.000 +00:00 [Debug] Microsoft.AspNetCore.Mvc.MvcOptions: Compatibility switch InputFormatterExceptionPolicy in type MvcOptions is using compatibility value MalformedInputExceptions for version Version_2_1   2019-01-03 20:09:55.117 +00:00 [Debug] Microsoft.AspNetCore.Mvc.ModelBinding.ModelBinderFactory: Registered model binder providers  in the following order: Microsoft.AspNetCore.Mvc.ModelBinding.Binders.BinderTypeModelBinderProvider  Microsoft.AspNetCore.Mvc.ModelBinding.Binders.ServicesModelBinderProvider  Microsoft.AspNetCore.Mvc.ModelBinding.Binders.BodyModelBinderProvider  Microsoft.AspNetCore.Mvc.ModelBinding.Binders.HeaderModelBinderProvider  Microsoft.AspNetCore.Mvc.ModelBinding.Binders.FloatingPointTypeModelBinderProvider  Microsoft.AspNetCore.Mvc.ModelBinding.Binders.EnumTypeModelBinderProvider  Microsoft.AspNetCore.Mvc.ModelBinding.Binders.SimpleTypeModelBinderProvider  Microsoft.AspNetCore.Mvc.ModelBinding.Binders.CancellationTokenModelBinderProvider  Microsoft.AspNetCore.Mvc.ModelBinding.Binders.ByteArrayModelBinderProvider  Microsoft.AspNetCore.Mvc.ModelBinding.Binders.FormFileModelBinderProvider  Microsoft.AspNetCore.Mvc.ModelBinding.Binders.FormCollectionModelBinderProvider  Microsoft.AspNetCore.Mvc.ModelBinding.Binders.KeyValuePairModelBinderProvider  Microsoft.AspNetCore.Mvc.ModelBinding.Binders.DictionaryModelBinderProvider  Microsoft.AspNetCore.Mvc.ModelBinding.Binders.ArrayModelBinderProvider  Microsoft.AspNetCore.Mvc.ModelBinding.Binders.CollectionModelBinderProvider  Microsoft.AspNetCore.Mvc.ModelBinding.Binders.ComplexTypeModelBinderProvider  2019-01-03 20:09:55.177 +00:00 [Debug] Microsoft.AspNetCore.Server.Kestrel.Core.KestrelServer: Failed to locate the development https certificate at '(null)'.  2019-01-03 20:09:55.313 +00:00 [Debug] Microsoft.AspNetCore.Hosting.Internal.WebHost: Hosting started  2019-01-03 20:09:55.313 +00:00 [Debug] Microsoft.AspNetCore.Hosting.Internal.WebHost: Loaded hosting startup assembly TwilioSdkStarterDotnetCore.Web  2019-01-03 20:09:55.313 +00:00 [Debug] Microsoft.AspNetCore.Hosting.Internal.WebHost: Loaded hosting startup assembly Microsoft.AspNetCore.AzureAppServices.HostingStartup  2019-01-03 20:09:55.313 +00:00 [Debug] Microsoft.AspNetCore.Hosting.Internal.WebHost: Loaded hosting startup assembly Microsoft.AspNetCore.Server.IISIntegration  2019-01-03 20:09:55.386 +00:00 [Debug] Microsoft.AspNetCore.Server.Kestrel: Connection id \0HLJHMTMRPB3K\"" started.  2019-01-03 20:09:55.501 +00:00 [Debug] Microsoft.AspNetCore.Server.Kestrel.Transport.Sockets: Connection id \""0HLJHMTMRPB3K\"" received FIN.  2019-01-03 20:09:55.511 +00:00 [Debug] Microsoft.AspNetCore.Server.Kestrel: Connection id \""0HLJHMTMRPB3K\"" disconnecting.  2019-01-03 20:09:55.532 +00:00 [Debug] Microsoft.AspNetCore.Server.Kestrel.Transport.Sockets: Connection id \""0HLJHMTMRPB3K\"" sending FIN.  2019-01-03 20:09:55.543 +00:00 [Debug] Microsoft.AspNetCore.Server.Kestrel: Connection id \""0HLJHMTMRPB3K\"" stopped.  2019-01-03 20:09:55.574 +00:00 [Debug] Microsoft.AspNetCore.Server.Kestrel: Connection id \""0HLJHMTMRPB3L\"" started.  2019-01-03 20:09:55.632 +00:00 [Information] Microsoft.AspNetCore.Hosting.Internal.WebHost: Request starting HTTP/1.1 GET http://xxxxxxxxxxxxxxxx.azurewebsites.net/    &lt;!DOCTYPE html PUBLIC \""-//W3C//DTD XHTML 1.0 Strict//EN\"" \""http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd\""&gt;  &lt;html xmlns=\""http://www.w3.org/1999/xhtml\""&gt;  &lt;head&gt;  &lt;title&gt;IIS Detailed Error - 404.0 - Not Found&lt;/title&gt;  &lt;style type=\""text/css\""&gt;  &lt;!--  body{margin:0;font-size:.7em;font-family:Verdana Arial Helvetica sans-serif;}  code{margin:0;color:#006600;font-size:1.1em;font-weight:bold;}  .config_source code{font-size:.8em;color:#000000;}  pre{margin:0;font-size:1.4em;word-wrap:break-word;}  ul ol{margin:10px 0 10px 5px;}  ul.first ol.first{margin-top:5px;}  fieldset{padding:0 15px 10px 15px;word-break:break-all;}  .summary-container fieldset{padding-bottom:5px;margin-top:4px;}  legend.no-expand-all{padding:2px 15px 4px 10px;margin:0 0 0 -12px;}  legend{color:#333333;;margin:4px 0 8px -12px;_margin-top:0px;  font-weight:bold;font-size:1em;}  a:link a:visited{color:#007EFF;font-weight:bold;}  a:hover{text-decoration:none;}  h1{font-size:2.4em;margin:0;color:#FFF;}  h2{font-size:1.7em;margin:0;color:#CC0000;}  h3{font-size:1.4em;margin:10px 0 0 0;color:#CC0000;}  h4{font-size:1.2em;margin:10px 0 5px 0;  }#header{width:96%;margin:0 0 0 0;padding:6px 2% 6px 2%;font-family:\""trebuchet MS\"" Verdana sans-serif;  color:#FFF;background-color:#5C87B2;  }#content{margin:0 0 0 2%;position:relative;}  .summary-container .content-container{background:#FFF;width:96%;margin-top:8px;padding:10px;position:relative;}  .content-container p{margin:0 0 10px 0;  }#details-left{width:35%;float:left;margin-right:2%;  }#details-right{width:63%;float:left;overflow:hidden;  }#server_version{width:96%;_height:1px;min-height:1px;margin:0 0 5px 0;padding:11px 2% 8px 2%;color:#FFFFFF;  background-color:#5A7FA5;border-bottom:1px solid #C1CFDD;border-top:1px solid #4A6C8E;font-weight:normal;  font-size:1em;color:#FFF;text-align:right;  }#server_version p{margin:5px 0;}  table{margin:4px 0 4px 0;width:100%;border:none;}  td th{vertical-align:top;padding:3px 0;text-align:left;font-weight:normal;border:none;}  th{width:30%;text-align:right;padding-right:2%;font-weight:bold;}  thead th{background-color:#ebebeb;width:25%;  }#details-right th{width:20%;}  table tr.alt td table tr.alt th{}  .highlight-code{color:#CC0000;font-weight:bold;font-style:italic;}  .clear{clear:both;}  .preferred{padding:0 5px 2px 5px;font-weight:normal;background:#006633;color:#FFF;font-size:.8em;}  --&gt;  &lt;/style&gt;   &lt;/head&gt;  &lt;body&gt;  &lt;div id=\""content\""&gt;  &lt;div class=\""content-container\""&gt;  &lt;h3&gt;HTTP Error 404.0 - Not Found&lt;/h3&gt;  &lt;h4&gt;The resource you are looking for has been removed  had its name changed  or is temporarily unavailable.&lt;/h4&gt;  &lt;/div&gt;  &lt;div class=\""content-container\""&gt;  &lt;fieldset&gt;&lt;h4&gt;Most likely causes:&lt;/h4&gt;  &lt;ul&gt;    &lt;li&gt;The directory or file specified does not exist on the Web server.&lt;/li&gt;  &lt;li&gt;The URL contains a typographical error.&lt;/li&gt;    &lt;li&gt;A custom filter or module  such as URLScan  restricts access to the file.&lt;/li&gt; &lt;/ul&gt;  &lt;/fieldset&gt;  &lt;/div&gt;  &lt;div class=\""content-container\""&gt;  &lt;fieldset&gt;&lt;h4&gt;Things you can try:&lt;/h4&gt;  &lt;ul&gt;    &lt;li&gt;Create the content on the Web server.&lt;/li&gt;  &lt;li&gt;Review the browser URL.&lt;/li&gt;    &lt;li&gt;Create a tracing rule to track failed requests for this HTTP status code and see which module is calling SetStatus. For more information about creating a tracing rule for failed requests  click &lt;a href=\""http://go.microsoft.com/fwlink/?LinkID=66439\""&gt;here&lt;/a&gt;. &lt;/li&gt; &lt;/ul&gt;  &lt;/fieldset&gt;  &lt;/div&gt;   &lt;div class=\""content-container\""&gt;  &lt;fieldset&gt;&lt;h4&gt;Detailed Error Information:&lt;/h4&gt;  &lt;div id=\""details-left\""&gt;  &lt;table border=\""0\"" cellpadding=\""0\"" cellspacing=\""0\""&gt;  &lt;tr class=\""alt\""&gt;&lt;th&gt;Module&lt;/th&gt;&lt;td&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;AspNetCoreModule&lt;/td&gt;&lt;/tr&gt;  &lt;tr&gt;&lt;th&gt;Notification&lt;/th&gt;&lt;td&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;ExecuteRequestHandler&lt;/td&gt;&lt;/tr&gt;  &lt;tr class=\""alt\""&gt;&lt;th&gt;Handler&lt;/th&gt;&lt;td&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;aspNetCore&lt;/td&gt;&lt;/tr&gt;  &lt;tr&gt;&lt;th&gt;Error Code&lt;/th&gt;&lt;td&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;0x00000000&lt;/td&gt;&lt;/tr&gt;   &lt;/table&gt;  &lt;/div&gt;  &lt;div id=\""details-right\""&gt;  &lt;table border=\""0\"" cellpadding=\""0\"" cellspacing=\""0\""&gt;  &lt;tr class=\""alt\""&gt;&lt;th&gt;Requested URL&lt;/th&gt;&lt;td&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;http://xxxxxxxxxxxxxx:80/&lt;/td&gt;&lt;/tr&gt;  &lt;tr&gt;&lt;th&gt;Physical Path&lt;/th&gt;&lt;td&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;D:\\home\\site\\wwwroot&lt;/td&gt;&lt;/tr&gt;  &lt;tr class=\""alt\""&gt;&lt;th&gt;Logon Method&lt;/th&gt;&lt;td&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;Anonymous&lt;/td&gt;&lt;/tr&gt;  &lt;tr&gt;&lt;th&gt;Logon User&lt;/th&gt;&lt;td&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;Anonymous&lt;/td&gt;&lt;/tr&gt;   &lt;/table&gt;  &lt;div class=\""clear\""&gt;&lt;/div&gt;  &lt;/div&gt;  &lt;/fieldset&gt;  &lt;/div&gt;   &lt;div class=\""content-container\""&gt;  &lt;fieldset&gt;&lt;h4&gt;More Information:&lt;/h4&gt;  This error means that the file or directory does not exist on the server. Create the file or directory and try the request again.  &lt;p&gt;&lt;a href=\""http://go.microsoft.com/fwlink/?LinkID=62293&amp;amp;IIS70Error=404 0 0x00000000 14393\""&gt;View more information &amp;raquo;&lt;/a&gt;&lt;/p&gt;  &lt;p&gt;Microsoft Knowledge Base Articles:&lt;/p&gt;    &lt;/fieldset&gt;  &lt;/div&gt;  &lt;/div&gt;  &lt;/body&gt;  &lt;/html&gt;  2019-01-03 20:09:55.633 +00:00 [Debug] Microsoft.AspNetCore.HostFiltering.HostFilteringMiddleware: Wildcard detected  all requests with hosts will be allowed.  2019-01-03 20:09:55.640 +00:00 [Trace] Microsoft.AspNetCore.HostFiltering.HostFilteringMiddleware: All hosts are allowed.  2019-01-03 20:09:55.659 +00:00 [Warning] Microsoft.AspNetCore.HttpsPolicy.HttpsRedirectionMiddleware: Failed to determine the https port for redirect.  2019-01-03 20:09:55.680 +00:00 [Debug] Microsoft.AspNetCore.StaticFiles.StaticFileMiddleware: The request path / does not match a supported file type  2019-01-03 20:09:55.959 +00:00 [Debug] Microsoft.AspNetCore.Routing.RouteBase: Request successfully matched the route with name 'default' and template '{controller=Home}/{action=Index}/{id?}'.  2019-01-03 20:09:55.999 +00:00 [Information] Microsoft.AspNetCore.Mvc.Internal.ControllerActionInvoker: Route matched with {action = \""Index\""  controller = \""Home\""}. Executing action TwilioSdkStarterDotnetCore.Web.Controllers.HomeController.Index (TwilioSdkStarterDotnetCore.Web)  2019-01-03 20:09:56.005 +00:00 [Debug] Microsoft.AspNetCore.Mvc.Internal.ControllerActionInvoker: Execution plan of authorization filters (in the following order): None  2019-01-03 20:09:56.005 +00:00 [Debug] Microsoft.AspNetCore.Mvc.Internal.ControllerActionInvoker: Execution plan of resource filters (in the following order): Microsoft.AspNetCore.Mvc.ViewFeatures.Internal.SaveTempDataFilter  2019-01-03 20:09:56.005 +00:00 [Debug] Microsoft.AspNetCore.Mvc.Internal.ControllerActionInvoker: Execution plan of action filters (in the following order): Microsoft.AspNetCore.Mvc.Internal.ControllerActionFilter (Order: -2147483648)  Microsoft.AspNetCore.Mvc.ModelBinding.UnsupportedContentTypeFilter  2019-01-03 20:09:56.005 +00:00 [Debug] Microsoft.AspNetCore.Mvc.Internal.ControllerActionInvoker: Execution plan of exception filters (in the following order): None  2019-01-03 20:09:56.005 +00:00 [Debug] Microsoft.AspNetCore.Mvc.Internal.ControllerActionInvoker: Execution plan of result filters (in the following order): Microsoft.AspNetCore.Mvc.ViewFeatures.Internal.SaveTempDataFilter  2019-01-03 20:09:56.007 +00:00 [Trace] Microsoft.AspNetCore.Mvc.Internal.ControllerActionInvoker: Resource Filter: Before executing OnResourceExecuting on filter Microsoft.AspNetCore.Mvc.ViewFeatures.Internal.SaveTempDataFilter.  2019-01-03 20:09:56.007 +00:00 [Trace] Microsoft.AspNetCore.Mvc.Internal.ControllerActionInvoker: Resource Filter: After executing OnResourceExecuting on filter Microsoft.AspNetCore.Mvc.ViewFeatures.Internal.SaveTempDataFilter.  2019-01-03 20:09:56.018 +00:00 [Trace] Microsoft.AspNetCore.Mvc.Internal.ControllerActionInvoker: Action Filter: Before executing OnActionExecutionAsync on filter Microsoft.AspNetCore.Mvc.Internal.ControllerActionFilter.  2019-01-03 20:09:56.027 +00:00 [Trace] Microsoft.AspNetCore.Mvc.Internal.ControllerActionInvoker: Action Filter: Before executing OnActionExecuting on filter Microsoft.AspNetCore.Mvc.ModelBinding.UnsupportedContentTypeFilter.  2019-01-03 20:09:56.027 +00:00 [Trace] Microsoft.AspNetCore.Mvc.Internal.ControllerActionInvoker: Action Filter: After executing OnActionExecuting on filter Microsoft.AspNetCore.Mvc.ModelBinding.UnsupportedContentTypeFilter.  2019-01-03 20:09:56.037 +00:00 [Information] Microsoft.AspNetCore.Mvc.Internal.ControllerActionInvoker: Executing action method TwilioSdkStarterDotnetCore.Web.Controllers.HomeController.Index (TwilioSdkStarterDotnetCore.Web) - Validation state: Valid  2019-01-03 20:09:56.045 +00:00 [Information] Microsoft.AspNetCore.Mvc.Internal.ControllerActionInvoker: Executed action method TwilioSdkStarterDotnetCore.Web.Controllers.HomeController.Index (TwilioSdkStarterDotnetCore.Web)  returned result Microsoft.AspNetCore.Mvc.ViewResult in 0.4307ms.  2019-01-03 20:09:56.045 +00:00 [Trace] Microsoft.AspNetCore.Mvc.Internal.ControllerActionInvoker: Action Filter: Before executing OnActionExecuted on filter Microsoft.AspNetCore.Mvc.ModelBinding.UnsupportedContentTypeFilter.  2019-01-03 20:09:56.045 +00:00 [Trace] Microsoft.AspNetCore.Mvc.Internal.ControllerActionInvoker: Action Filter: After executing OnActionExecuted on filter Microsoft.AspNetCore.Mvc.ModelBinding.UnsupportedContentTypeFilter.  2019-01-03 20:09:56.045 +00:00 [Trace] Microsoft.AspNetCore.Mvc.Internal.ControllerActionInvoker: Action Filter: After executing OnActionExecutionAsync on filter Microsoft.AspNetCore.Mvc.Internal.ControllerActionFilter.  2019-01-03 20:09:56.046 +00:00 [Trace] Microsoft.AspNetCore.Mvc.Internal.ControllerActionInvoker: Result Filter: Before executing OnResultExecuting on filter Microsoft.AspNetCore.Mvc.ViewFeatures.Internal.SaveTempDataFilter.  2019-01-03 20:09:56.046 +00:00 [Trace] Microsoft.AspNetCore.Mvc.Internal.ControllerActionInvoker: Result Filter: After executing OnResultExecuting on filter Microsoft.AspNetCore.Mvc.ViewFeatures.Internal.SaveTempDataFilter.  2019-01-03 20:09:56.048 +00:00 [Trace] Microsoft.AspNetCore.Mvc.Internal.ControllerActionInvoker: Before executing action result Microsoft.AspNetCore.Mvc.ViewResult.  2019-01-03 20:09:56.057 +00:00 [Debug] Microsoft.AspNetCore.Mvc.Razor.RazorViewEngine: View lookup cache miss for view 'Index' in controller 'Home'.  2019-01-03 20:09:56.058 +00:00 [Debug] Microsoft.AspNetCore.Mvc.Razor.Internal.RazorViewCompiler: Initializing Razor view compiler with compiled view: '/Views/Chat/Index.cshtml'.  2019-01-03 20:09:56.058 +00:00 [Debug] Microsoft.AspNetCore.Mvc.Razor.Internal.RazorViewCompiler: Initializing Razor view compiler with compiled view: '/Views/Home/Index.cshtml'.  2019-01-03 20:09:56.058 +00:00 [Debug] Microsoft.AspNetCore.Mvc.Razor.Internal.RazorViewCompiler: Initializing Razor view compiler with compiled view: '/Views/Notify/Index.cshtml'.  2019-01-03 20:09:56.058 +00:00 [Debug] Microsoft.AspNetCore.Mvc.Razor.Internal.RazorViewCompiler: Initializing Razor view compiler with compiled view: '/Views/Shared/_Layout.cshtml'.  2019-01-03 20:09:56.058 +00:00 [Debug] Microsoft.AspNetCore.Mvc.Razor.Internal.RazorViewCompiler: Initializing Razor view compiler with compiled view: '/Views/Shared/_ValidationScriptsPartial.cshtml'.  2019-01-03 20:09:56.058 +00:00 [Debug] Microsoft.AspNetCore.Mvc.Razor.Internal.RazorViewCompiler: Initializing Razor view compiler with compiled view: '/Views/Sync/Index.cshtml'.  2019-01-03 20:09:56.058 +00:00 [Debug] Microsoft.AspNetCore.Mvc.Razor.Internal.RazorViewCompiler: Initializing Razor view compiler with compiled view: '/Views/Video/Index.cshtml'.  2019-01-03 20:09:56.064 +00:00 [Debug] Microsoft.AspNetCore.Mvc.Razor.Internal.RazorViewCompiler: Initializing Razor view compiler with compiled view: '/Views/_ViewImports.cshtml'.  2019-01-03 20:09:56.064 +00:00 [Debug] Microsoft.AspNetCore.Mvc.Razor.Internal.RazorViewCompiler: Initializing Razor view compiler with compiled view: '/Views/_ViewStart.cshtml'.  2019-01-03 20:09:56.065 +00:00 [Trace] Microsoft.AspNetCore.Mvc.Razor.Internal.RazorViewCompiler: Located compiled view for view at path '/Views/Home/Index.cshtml'.  2019-01-03 20:09:56.075 +00:00 [Trace] Microsoft.AspNetCore.Mvc.Razor.Internal.RazorViewCompiler: Could not find a file for view at path '/Views/Home/_ViewStart.cshtml'.  2019-01-03 20:09:56.075 +00:00 [Trace] Microsoft.AspNetCore.Mvc.Razor.Internal.RazorViewCompiler: Located compiled view for view at path '/Views/_ViewStart.cshtml'.  2019-01-03 20:09:56.077 +00:00 [Trace] Microsoft.AspNetCore.Mvc.Razor.Internal.RazorViewCompiler: Could not find a file for view at path '/_ViewStart.cshtml'.  2019-01-03 20:09:56.077 +00:00 [Debug] Microsoft.AspNetCore.Mvc.Razor.RazorViewEngine: Using precompiled view for '/Views/Home/Index.cshtml'.  2019-01-03 20:09:56.084 +00:00 [Information] Microsoft.AspNetCore.Mvc.ViewFeatures.ViewResultExecutor: Executing ViewResult  running view Index.  2019-01-03 20:09:56.085 +00:00 [Debug] Microsoft.AspNetCore.Mvc.ViewFeatures.ViewResultExecutor: The view path '/Views/Home/Index.cshtml' was found in 28.1834ms.  2019-01-03 20:09:56.214 +00:00 [Debug] Microsoft.AspNetCore.Mvc.Razor.RazorViewEngine: View lookup cache miss for view '_Layout' in controller 'Home'.  2019-01-03 20:09:56.214 +00:00 [Trace] Microsoft.AspNetCore.Mvc.Razor.Internal.RazorViewCompiler: Could not find a file for view at path '/Views/Home/_Layout.cshtml'.  2019-01-03 20:09:56.214 +00:00 [Trace] Microsoft.AspNetCore.Mvc.Razor.Internal.RazorViewCompiler: Located compiled view for view at path '/Views/Shared/_Layout.cshtml'.  2019-01-03 20:09:56.215 +00:00 [Debug] Microsoft.AspNetCore.Mvc.Razor.RazorViewEngine: Using precompiled view for '/Views/Shared/_Layout.cshtml'.  2019-01-03 20:09:56.335 +00:00 [Trace] Microsoft.AspNetCore.Mvc.Internal.ControllerActionInvoker: After executing action result Microsoft.AspNetCore.Mvc.ViewResult.  2019-01-03 20:09:56.336 +00:00 [Trace] Microsoft.AspNetCore.Mvc.Internal.ControllerActionInvoker: Result Filter: Before executing OnResultExecuted on filter Microsoft.AspNetCore.Mvc.ViewFeatures.Internal.SaveTempDataFilter.  2019-01-03 20:09:56.336 +00:00 [Trace] Microsoft.AspNetCore.Mvc.Internal.ControllerActionInvoker: Result Filter: After executing OnResultExecuted on filter Microsoft.AspNetCore.Mvc.ViewFeatures.Internal.SaveTempDataFilter.  2019-01-03 20:09:56.336 +00:00 [Trace] Microsoft.AspNetCore.Mvc.Internal.ControllerActionInvoker: Resource Filter: Before executing OnResourceExecuted on filter Microsoft.AspNetCore.Mvc.ViewFeatures.Internal.SaveTempDataFilter.  2019-01-03 20:09:56.336 +00:00 [Trace] Microsoft.AspNetCore.Mvc.Internal.ControllerActionInvoker: Resource Filter: After executing OnResourceExecuted on filter Microsoft.AspNetCore.Mvc.ViewFeatures.Internal.SaveTempDataFilter.  2019-01-03 20:09:56.336 +00:00 [Information] Microsoft.AspNetCore.Mvc.Internal.ControllerActionInvoker: Executed action TwilioSdkStarterDotnetCore.Web.Controllers.HomeController.Index (TwilioSdkStarterDotnetCore.Web) in 330.8858ms  2019-01-03 20:09:56.412 +00:00 [Error] Microsoft.AspNetCore.Diagnostics.ExceptionHandlerMiddleware: An unhandled exception has occurred while executing the request.  System.InvalidOperationException: The following sections have been defined but have not been rendered by the page at '/Views/Shared/_Layout.cshtml': 'Styles'. To ignore an unrendered section call IgnoreSection(\""sectionName\"").     at Microsoft.AspNetCore.Mvc.Razor.RazorPage.EnsureRenderedBodyOrSections()     at Microsoft.AspNetCore.Mvc.Razor.RazorView.RenderLayoutAsync(ViewContext context  ViewBufferTextWriter bodyWriter)     at Microsoft.AspNetCore.Mvc.Razor.RazorView.RenderAsync(ViewContext context)     at Microsoft.AspNetCore.Mvc.ViewFeatures.ViewExecutor.ExecuteAsync(ViewContext viewContext  String contentType  Nullable`1 statusCode)     at Microsoft.AspNetCore.Mvc.ViewFeatures.ViewExecutor.ExecuteAsync(ActionContext actionContext  IView view  ViewDataDictionary viewData  ITempDataDictionary tempData  String contentType  Nullable`1 statusCode)     at Microsoft.AspNetCore.Mvc.ViewFeatures.ViewResultExecutor.ExecuteAsync(ActionContext context  ViewResult result)     at Microsoft.AspNetCore.Mvc.ViewResult.ExecuteResultAsync(ActionContext context)     at Microsoft.AspNetCore.Mvc.Internal.ResourceInvoker.InvokeResultAsync(IActionResult result)     at Microsoft.AspNetCore.Mvc.Internal.ResourceInvoker.InvokeNextResultFilterAsync[TFilter TFilterAsync]()     at Microsoft.AspNetCore.Mvc.Internal.ResourceInvoker.Rethrow(ResultExecutedContext context)     at Microsoft.AspNetCore.Mvc.Internal.ResourceInvoker.ResultNext[TFilter TFilterAsync](State&amp; next  Scope&amp; scope  Object&amp; state  Boolean&amp; isCompleted)     at Microsoft.AspNetCore.Mvc.Internal.ResourceInvoker.InvokeResultFilters()     at Microsoft.AspNetCore.Mvc.Internal.ResourceInvoker.InvokeNextResourceFilter()     at Microsoft.AspNetCore.Mvc.Internal.ResourceInvoker.Rethrow(ResourceExecutedContext context)     at Microsoft.AspNetCore.Mvc.Internal.ResourceInvoker.Next(State&amp; next  Scope&amp; scope  Object&amp; state  Boolean&amp; isCompleted)     at Microsoft.AspNetCore.Mvc.Internal.ResourceInvoker.InvokeFilterPipelineAsync()     at Microsoft.AspNetCore.Mvc.Internal.ResourceInvoker.InvokeAsync()     at Microsoft.AspNetCore.Builder.RouterMiddleware.Invoke(HttpContext httpContext)     at Microsoft.AspNetCore.StaticFiles.StaticFileMiddleware.Invoke(HttpContext context)     at Microsoft.AspNetCore.Diagnostics.ExceptionHandlerMiddleware.Invoke(HttpContext context)  2019-01-03 20:09:56.414 +00:00 [Debug] Microsoft.AspNetCore.StaticFiles.StaticFileMiddleware: The request path /Home/Error does not match a supported file type  2019-01-03 20:09:56.414 +00:00 [Debug] Microsoft.AspNetCore.Routing.RouteBase: Request successfully matched the route with name 'default' and template '{controller=Home}/{action=Index}/{id?}'.  2019-01-03 20:09:56.422 +00:00 [Debug] Microsoft.AspNetCore.Mvc.Internal.ActionSelector: No actions matched the current request. Route values: controller=Home  action=Error  2019-01-03 20:09:56.422 +00:00 [Debug] Microsoft.AspNetCore.Mvc.Internal.MvcRouteHandler: No actions matched the current request. Route values: controller=Home  action=Error  2019-01-03 20:09:56.422 +00:00 [Debug] Microsoft.AspNetCore.Builder.RouterMiddleware: Request did not match any routes.  2019-01-03 20:09:56.425 +00:00 [Debug] Microsoft.AspNetCore.Server.Kestrel: Connection id \""0HLJHMTMRPB3L\"" completed keep alive response.  2019-01-03 20:09:56.441 +00:00 [Information] Microsoft.AspNetCore.Hosting.Internal.WebHost: Request finished in 810.0333ms 404   2019-01-03 20:08:57 xxxxxxxxxxxx GET / X-ARR-LOG-ID=e9cbd7fd-3276-4c70-bf95-0acdd80e637e 80 - 13.13.16.2 Mozilla/5.0+(Windows+NT+10.0;+Win64;+x64)+AppleWebKit/537.36+(KHTML +like+Gecko)+Chrome/58.0.3029.110+Safari/537.36+Edge/16.16299 - - xxxxxxxxxxxxxx.azurewebsites.net 404 0 0 328 999 3533  2019-01-03 20:09:28 ~1xxxxxxxxxxxx GET /api/vfs/site/wwwroot/ _=1546546158817&amp;X-ARR-LOG-ID=e63305a7-9618-48d7-ab3b-2c3c716ff36b 443 - 13.13.137.1 Mozilla/5.0+(Windows+NT+10.0;+Win64;+x64;+rv:64.0)+Gecko/20100101+Firefox/64.0 - https://websites.hosting.portal.azure.net/websites?bundlingKind=PopularPartitioner&amp;cacheability=3&amp;extensionName=WebsitesExtension&amp;l=en&amp;pageVersion=5.12.34.339&amp;trustedAuthority=portal.azure.com xxxxxxxxxxxx.scm.azurewebsites.net 200 0 0 2373 1643 514  2019-01-03 20:09:48 ~1xxxxxxxxxxxx HEAD /msdeploy.axd site=xxxxxxxxxxxx&amp;X-ARR-LOG-ID=4ed97fa0-1c03-4ec2-a2be-0eb145b6841a 443 - 13.13.157.6 - - - xxxxxxxxxxxx.scm.azurewebsites.net 200 0 0 412 1077 19  2019-01-03 20:09:48 ~1xxxxxxxxxxxx HEAD /msdeploy.axd site=xxxxxxxxxxxx&amp;X-ARR-LOG-ID=16d097ec-fb4d-461c-ac12-920ea317561f 443 - 13.13.157.6 - ARRAffinity=69e56d94bc2631bcc7dd44f6f455e6e654512fd223067d328f88fbea76b6ea85 - xxxxxxxxxxxx.scm.azurewebsites.net 200 0 0 412 1165 9  2019-01-03 20:09:48 ~1xxxxxxxxxxxx POST /msdeploy.axd site=xxxxxxxxxxxx&amp;X-ARR-LOG-ID=c55ecae7-4bea-4354-aaad-a5f33679a35e 443 - 13.13.157.6 VSCmdLine:WTE2.1.500.1853;sid=1b9a629a-5f37-4ffb-846d-c2f79ec96757;op=Sync ARRAffinity=69e56d94bc2631bcc7dd44f6f455e6e654512fd223067d328f88fbea76b6ea85 - xxxxxxxxxxxx.scm.azurewebsites.net 200 0 0 767 14711 382  2019-01-03 20:09:48 ~1xxxxxxxxxxxx POST /msdeploy.axd site=xxxxxxxxxxxx&amp;X-ARR-LOG-ID=3b31d177-31c9-4b5e-8004-f3d285bbda0d 443 - 13.13.157.6 - ARRAffinity=69e56d94bc2631bcc7dd44f6f455e6e654512fd223067d328f88fbea76b6ea85 - xxxxxxxxxxxx.scm.azurewebsites.net 200 0 0 503 1273 885  2019-01-03 20:09:49 ~1xxxxxxxxxxxx HEAD /msdeploy.axd site=xxxxxxxxxxxx&amp;X-ARR-LOG-ID=03a0ab1a-c8c9-439b-b7d9-6a0c31f2746f 443 - 13.13.157.6 - ARRAffinity=69e56d94bc2631bcc7dd44f6f455e6e654512fd223067d328f88fbea76b6ea85 - xxxxxxxxxxxx.scm.azurewebsites.net 200 0 0 412 1163 15  2019-01-03 20:09:49 ~1xxxxxxxxxxxx POST /msdeploy.axd site=xxxxxxxxxxxx&amp;X-ARR-LOG-ID=ded7df79-b97b-4405-88b7-50cc17ab652b 443 - 13.13.157.6 - ARRAffinity=69e56d94bc2631bcc7dd44f6f455e6e654512fd223067d328f88fbea76b6ea85 - xxxxxxxxxxxx.scm.azurewebsites.net 200 0 0 957 1275 757 </code></pre>""",azure-web-app-service
44115466,Azure AppService repsonse slow after restart <p>I have an AppService with a WebAPI project on it. After I restart this service or upload new version  each of endpoints I first call are responding very slowly (>15sec). If I click through all the endpoints once  the application works fine. </p>  <p>My Azure has a PayAsYouGo Subscription and I have <code>AlwaysOn</code> feature of <code>AppSercice</code> set to <code>true</code>. In the trace logs I also saw multiple entries with: </p>  <blockquote>   <p>SnapshotHelper::RestoreSnapshot - optout environment variable aspnet:PortableCompilationOutput=true</p> </blockquote>  <p>During compilation I'm using following parameters:</p>  <pre><code>/p:PrecompileBeforePublish=true  /p:UseMerge=true  /p:SingleAssemblyName=AppCode </code></pre>,azure-web-app-service
51176475,"Application Insight data sampling <p>I have an Azure function linked with Application Insights. I log in App Insight several business data and I can have a lot of instances of my function running during a small period of time. I read this post about Data Sampling in App Insight and I want to know if I can lose data because of this data sampling algorithm? (<a href=\https://docs.microsoft.com/en-us/azure/application-insights/app-insights-sampling\"" rel=\""nofollow noreferrer\"">https://docs.microsoft.com/en-us/azure/application-insights/app-insights-sampling</a>) Thanks. </p>""",azure-functions
51937016,Unable to open Json file on Server <p>I published a json file on to my website using ftp. When I tried to access my site using mtsite.com/abc.json it throws the below error.</p>  <p>The resource you are looking for has been removed  had its name changed  or is temporarily unavailable.</p>  <p>My file is on hosted site on azure. Even if file in on server why did it say that file is not found?</p>  <p>Any place in azure portal where I can add or allow Mime type json? I cannot add web.config file as My files are all HTML and Json.</p>,azure-web-app-service
55500388,"Issue creating Azure App Registration with AZ CLI <p>I am trying to create an Azure AD app with an updated manifest that has access to Windows Azure AD. I have been able to successfully create / configure a new App Registration but run into issues when i try to configure the Manifest.</p>  <p>I have tried using the sample code provided my MS (<a href=\https://docs.microsoft.com/en-us/cli/azure/ad/app?view=azure-cli-latest#az-ad-app-create\"" rel=\""nofollow noreferrer\"">https://docs.microsoft.com/en-us/cli/azure/ad/app?view=azure-cli-latest#az-ad-app-create</a>) with an updated 'resourceAppId' from an already existing App Registration however bash throws an error </p>  <pre><code>az ad app create --display-name myTest --homepage https://blah.test.com --reply-urls https://blah.test.com/.auth/login/add/callback --required-resource-accesses @manifest.json(\""manifest.json\"" contains the following content)  [{\""resourceAppId\"": \""00000002-0000-0000-c000-000000000000\""  \""resourceAccess\"": [                     {                      \""id\"": \""a42657d6-7f20-40e3-b6f0-cee03008a62a-test\""                       \""type\"": \""Scope\""                     }                   ] }] </code></pre>  <p>As I've copied the sample code and just updated a few params i would expect it to run. TIA for any suggestions</p>  <p>This is the error i recieve when running via the portal </p>  <p><a href=\""https://i.stack.imgur.com/39D0X.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/39D0X.png\"" alt=\""enter image description here\""></a></p>""",azure-devops
53068672,Mysterious Exception with .net Core on Azure App Service <p>I've had an app hosted on an App Service with a connected Azure SQL Database for the past year. Just over the past week  we've had numerous issues with responses being batched  which has shown some brittleness in our asynchronous code. There was not relevant new code deployed. I suspect that these involve one part of our app  likely our DB  being unallocated until the request processes.</p>  <p>Our stack involves using an ASP.Net Core 2.0 app on Kestrel  navigates a user to a Razor Page  which then instantiates a websocket connection used for what is (essentially) a game. It's a monolith; this all lies in one project deployed to one instance.</p>  <p>The most recent issue involves this error:</p>  <pre><code>System.NullReferenceException: Object reference not set to an instance of an object.   at Microsoft.AspNetCore.Routing.Tree.TreeRouter.&lt;RouteAsync&gt;d__13.MoveNext() --- End of stack trace from previous location where exception was thrown ---   at System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw()   at System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess(Task task)   at Microsoft.AspNetCore.Routing.RouteCollection.&lt;RouteAsync&gt;d__9.MoveNext() --- End of stack trace from previous location where exception was thrown ---   at System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw()   at System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess(Task task)   at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task)   at Microsoft.AspNetCore.Builder.RouterMiddleware.&lt;Invoke&gt;d__4.MoveNext() --- End of stack trace from previous location where exception was thrown ---   at System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw()   at System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess(Task task)   at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task)   at Microsoft.AspNetCore.Builder.Extensions.MapMiddleware.&lt;Invoke&gt;d__3.MoveNext() --- End of stack trace from previous location where exception was thrown ---   at System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw()   at System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess(Task task)   at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task)   at Microsoft.AspNetCore.Diagnostics.ExceptionHandlerMiddleware.&lt;Invoke&gt;d__6.MoveNext() </code></pre>  <p>Our App Service ended up in what looks like a restart loop with this exception being the only error  repeated. Previously in the logs  there are an unreasonable amount of requests being processed within 200ms  which makes me think they were being held and processed virtually simultaneously; the times don't make sense otherwise. </p>  <p>The app was unusable during this period until I manually restarted the App Service  after which there was no issue. This error has proven hard to reproduce. </p>  <p>Any insights on any of these issues and how to make the app service and its DB stay always on or what this error may have been related to?</p>,azure-web-app-service
22087491,"Multiple cloud projects publishing to the same web role <p>Is it possible to have multiple cloud projects independently publish to one web role?</p>  <p>For example  cloud <strong>project A's</strong> <code>ServiceDefinition.csdef</code> would contain:</p>  <pre><code>  &lt;WebRole name=\SomeWebRole\"" vmsize=\""Small\""&gt;     &lt;Sites&gt;       &lt;Site name=\""WebA\""&gt;         &lt;Bindings&gt;           &lt;Binding name=\""Endpoint1\"" endpointName=\""Endpoint1\"" /&gt;         &lt;/Bindings&gt;       &lt;/Site&gt;     &lt;/Sites&gt;     &lt;Endpoints&gt;       &lt;InputEndpoint name=\""Endpoint1\"" protocol=\""http\"" port=\""80\"" /&gt;     &lt;/Endpoints&gt;   &lt;/WebRole&gt; </code></pre>  <p>And <strong>project B</strong>:</p>  <pre><code>  &lt;WebRole name=\""SomeWebRole\"" vmsize=\""Small\""&gt;     &lt;Sites&gt;       &lt;Site name=\""WebB\""&gt;         &lt;Bindings&gt;           &lt;Binding name=\""Endpoint2\"" endpointName=\""Endpoint2\"" /&gt;         &lt;/Bindings&gt;       &lt;/Site&gt;     &lt;/Sites&gt;     &lt;Endpoints&gt;       &lt;InputEndpoint name=\""Endpoint2\"" protocol=\""http\"" port=\""81\"" /&gt;     &lt;/Endpoints&gt;   &lt;/WebRole&gt; </code></pre>  <p>They have different <code>&lt;Site&gt;</code> names and are bound to different endpoints (port 80 and port 81).</p>""",azure-storage
53052388,How will DNS changes affect my azure site? <p>If I change my DNS settings  will my azure website lose the custom domain that is already assigned to it ? </p>,azure-web-app-service
47760543,Install ASP Classic components in Azure Web App <p>I am migrating an big set of old applications from Locaweb server to Microsoft Azure Web Apps. But  there are some ASP Classic applications which uses some server components like SoftArtisans.FileUp and SoftArtisans.SMTPMail.</p>  <p>Is there any chance to install these components in Azure Web Apps?</p>,azure-web-app-service
56173532,"Azure DevOps REST API - How are Picklists associated with Field? <p>I am trying to use rest to create fields and picklists  on the web site I created a field as type picklist String and added some items to the list:  <a href=\https://i.stack.imgur.com/ba7WE.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/ba7WE.png\"" alt=\""custom field as picklist String with some picklist items\""></a></p>  <p>Rest url for field: <a href=\""https://dev.azure.com/\"" rel=\""nofollow noreferrer\"">https://dev.azure.com/</a>{org}/_apis/work/processes/{processId}/workitemtypes/CMMI2.Bug/fields/Custom.AppType?api-version=5.0-preview.2</p>  <p>it is returning this:</p>  <pre><code>{ referenceName: \""Custom.AppType\""  name: \""AppType\""  type: \""string\""  description: \""\""  url: \""https://dev.azure.com/{org}/_apis/work/processes/bd96307e-3d16-44ac-b498-be1a8daff2d5/behaviors\""  customization: \""custom\"" } </code></pre>  <p>Rest URL for picklist: <a href=\""https://dev.azure.com/\"" rel=\""nofollow noreferrer\"">https://dev.azure.com/</a>{org}/_apis/work/processes/lists/{picklistId}?api-version=5.0-preview.1 this returns:</p>  <pre><code>{ items: [ \""All\""  \""Item2\""  \""Item3\"" ]  id: \""{picklistId}\""  name: \""picklist_{diffGuidFromPickListId}\""  type: \""String\""  isSuggested: false  url: \""https://dev.azure.com/{org}/_apis/work/processes/lists/{picklistId}\"" } </code></pre>  <p>Here is documentation for this: <a href=\""https://docs.microsoft.com/zh-cn/rest/api/azure/devops/processes/fields/get?view=azure-devops-rest-5.0#processworkitemtypefield\"" rel=\""nofollow noreferrer\"">https://docs.microsoft.com/zh-cn/rest/api/azure/devops/processes/fields/get?view=azure-devops-rest-5.0#processworkitemtypefield</a></p>  <p>Firstly - why is type of field string when it should be picklistString (as per documentation link)?</p>  <p>Secondly - how is the picklist linked to the field?</p>  <p>thanks</p>""",azure-devops
56034220,"How to call a webhook only when a pull request has been successfully merged into master? <p>We are using <a href=\https://docs.microsoft.com/en-us/azure/devops/service-hooks/services/webhooks?view=azure-devops\"" rel=\""nofollow noreferrer\"">Azure DevOps webhooks</a> to call into our service from our customers projects.</p>  <p>The intention is to seamlessly perform some actions over their repository once they've completed a PR into master branch.</p>  <p>In my tests  I've set up a webhook defined like so: <a href=\""https://i.stack.imgur.com/VsTid.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/VsTid.png\"" alt=\""Event hook subscription settings\""></a></p>  <p>You can see that we've configured our webhook to only be called on \""pull request merge attempted\"" on a specific repo  into \""master\"" branch when the merge is successful.</p>  <p>What I've observed is that this causes our webhook to be hit any time a commit is added to a pull request  instead of only when the pull request has been completed.</p>  <p>What is the correct mechanism to perform an action only on successful completed PRs into a specific branch?</p>  <p>Is there something we should do on our code to validate or is it something we should get our customers to set up differently in the service hooks subscription?</p>""",azure-devops
42536483,"Fix Port Range on Public IP for Azure DevTest Lab <p>Azure DevTest Labs now enable you to use a single public IP to access all your VMs via RDP (see <a href=\https://azure.microsoft.com/en-us/updates/azure-devtest-labs-share-public-ip-address-between-lab-vms/\"" rel=\""nofollow noreferrer\"">here</a>). It appears to work using <a href=\""https://en.wikipedia.org/wiki/Network_address_translation\"" rel=\""nofollow noreferrer\"">NAT</a>  whereby the load balancer will assign a different port number for each VM's RDP port.</p>  <p>Is it possible to define the range of port numbers that the load balancer is allowed to assign to each VM  so I have some idea of the port numbers it will be using?  e.g.  33890-33899</p>""",azure-virtual-machine
11126393,"Cannot point domain name to Windows Azure Website <p>I signed up for an As-You-Go account with Windows Azure  and created an SQL DB and setup 'Websites'. I then successfully deployed my website to my Azure account and read a <em>bunch</em> of articles online that basically said I need to CNAME my domain name to my Windows Azure Websites URL.</p>  <p>So I did that:</p>  <p><img src=\https://i.stack.imgur.com/vaGdn.png\"" alt=\""enter image description here\""></p>  <p>I then stumbled upon another article that said \""for 'Websites' you need to scale the server to 'Reserved' mode.\""</p>  <p>I did that too:</p>  <p><img src=\""https://i.stack.imgur.com/Msc1d.png\"" alt=\""enter image description here\""></p>  <p>But it hasn't worked.</p>  <p>I am getting a 404 on my homepage which is hosted on my previous hosting company's server  <em>even though I've set it up to point to Azure's servers.</em></p>  <p>Can anyone please help shed some light on this? Am I doing something wrong? As you can see  it's been about 72 hours already  and given the information above  to me  it suggest that it still hasn't propagated yet. Is this the case?</p>""",azure-storage
57573376,"Application Gateway's backend health probe says Backend server certificate is not whitelisted with Application Gateway <p>Health probe of Application Gateway says \Backend server certificate is not whitelisted with Application Gateway.\"". How do I fix the certificate issue?</p>  <p>I Had uploaded latest certificate to the web site as well as on Azure (while creating the <code>AppgatewayHttpSettings (crt file)</code> and <code>appGatewayHttpListener (pfx) file</code>. But it still displays the same message.</p>""",azure-web-app-service
40946867,"Visual Studio 2015 does not find existing Web Apps on Azure Cloud during Web Deploy <p>On my <strong>Azure</strong> account I have several <strong>Web Apps</strong>.</p>  <p>I'm trying to deploy my <strong>ASP.NET MVC</strong> project from <strong>Visual Studio 2015</strong> using <strong>Publish</strong>. But it doesn't find any existing Web Apps on my Azure account. I logged in in Visual Studio. Credentials are correct. But list of existing Web Apps in VS is empty:</p>  <p><a href=\https://i.stack.imgur.com/8jO6H.jpg\"" rel=\""noreferrer\""><img src=\""https://i.stack.imgur.com/8jO6H.jpg\"" alt=\""enter image description here\""></a></p>  <hr>  <p>I select <strong>Microsoft Azure Web Apps</strong>:</p>  <p>Then it's loading some time and finally the list of existing Web Apps is empty.  <img src=\""https://i.imgur.com/aGMHxOu.gif\"" alt=\""enter image description here\""></p>  <hr>  <p>I thought that it's my specific project that doesn't work. Then I created new ASP MVC Web Application (template). Still  the list is empty.</p>  <p>My IDE: <strong>MS Visual Studio Professional 2015-U3</strong></p>  <hr>  <p>What might be a reason that VS cannot find existing Web Apps on my Azure cloud account? I tried to reenter my credentials  logout and login. Nothing.</p>""",azure-web-app-service
48520539,Azure + Cassandra certified by Bitnami VM + nodejs app: Cannot connect to cassandra from remote app <p>Using datastax nodejs driver: <code>'cassandra-driver'</code></p>  <p>Connecting to database in my nodejs app server backend as:</p>  <pre><code>const cassandra = require('cassandra-driver'); const client = new cassandra.Client({ contactPoints: [ '${azure_vm_ip}' ] }); </code></pre>  <p>Output log:</p>  <pre><code>{ [Error: All host(s) tried for query failed. First host tried  azure_vm_ip:9042: Error: Connection timeout. See innerErrors.]   innerErrors:    { 'azure_vm_ip:9042':       { [Error: Connection timeout]         message: 'Connection timeout'          info: 'Cassandra Driver Error' } }    info: 'Represents an error when a query cannot be performed because no host is available or could be reached by the driver.'    message: 'All host(s) tried for query failed. First host tried  azure_vm_ip:9042: Error: Connection timeout. See innerErrors.' } </code></pre>  <p>Questions:</p>  <ul> <li><p>Should I edit something on the default <code>cassandra.yaml</code> file? If so  what?</p></li> <li><p>Should I do something with firewall? If so  what?</p></li> <li><p>Should I pass in more options in <code>new cassandra.Client({ contactPoints: [ '${azure_vm_ip}' ] })</code>? If so  What?</p></li> </ul>,azure-virtual-machine
52317396,"Azure Devops: Cannot Build an Image using NPM private registry even after setting NPM Authenticate <p>I am always getting an error on npm install after setting NPM Authenticate. I would like to authenticate to my npm private registry during image build and install all the dependencies I need. Maybe I misunderstood how this authentication process works but this is what I am doing:</p>  <p><strong>Build pipeline</strong></p>  <p><img src=\https://i.stack.imgur.com/IGTNU.png\"" alt=\""\""></p>  <p>I tried establishing a service connection from the project settings page as in <a href=\""https://docs.microsoft.com/en-us/azure/devops/pipelines/library/service-endpoints?view=vsts#use-a-service-connection\"" rel=\""nofollow noreferrer\"">Service connections for builds and releases</a></p>  <p>After that  I also set up my NPM Authentication task following the steps in <a href=\""https://docs.microsoft.com/en-us/azure/devops/artifacts/npm/npmrc?view=vsts&amp;tabs=new-nav#set-up-authentication-in-a-build-task\"" rel=\""nofollow noreferrer\"">With a Task Runner (e.g. make gulp work)</a></p>  <p>But this is not working. These are the errors I am getting:</p>  <p>During 'NPM Authenticate' phase:</p>  <blockquote>   <p>[warning]Found and overrode credentials for the   myregistry.pkgs.visualstudio.com registry in the selected .npmrc file.   Remove credentials from the file and store them in an npm service   connection instead (recommended)  or remove the npm Authenticate task   from your build to use credentials checked into an .npmrc.</p> </blockquote>  <p>During 'Build an Image' phase:</p>  <blockquote>   <p>Step 4/7 : RUN npm install --production ---> Running in 8724f713f1db   [91mnpm ERR! code[0m[91m E404 [0m[91mnpm [0m[91mERR! 404[0m[91m Not   Found: @myregistry/service-logging@latest npm ERR![0m[91m A complete   log of this run can be found in: npm ERR!<br>   /root/.npm/_logs/2018-09-11T04_20_00_513Z-debug.log [0mThe command   '/bin/sh -c npm install --production' returned a non-zero code: 1   [error]The command '/bin/sh -c npm install --production' returned a non-zero code: 1 [error]/usr/local/bin/docker failed with return   code: 1 [section]Finishing: Build an image</p> </blockquote>  <p>This is my .npmrc file:</p>  <pre><code>unsafe-perm=true package-lock=false registry=https://myregistry.pkgs.visualstudio.com/_packaging/myregistry/npm/registry/ always-auth=true //myregistry.pkgs.visualstudio.com/_packaging/myregistry/npm/registry/:_authToken=${NPM_TOKEN} //myregistry.pkgs.visualstudio.com/_packaging/myregistry/npm/:_authToken=${NPM_TOKEN} </code></pre>  <p>And this is my Dockerfile:</p>  <pre><code>FROM node:8.9-alpine  ARG NPM_TOKEN  WORKDIR /usr/src/srv/  COPY package.json package.json  COPY .npmrc .npmrc  RUN npm install --production  RUN rm -f .npmrc  COPY . .  EXPOSE 8080  CMD npm start </code></pre>  <p>Any help to unblock me from this issue will be highly appreciated! Thanks!</p>""",azure-devops
48512865,"Error when running Azure Functions project in Visual Studio with --useHttps <p>I was trying to figure out a way to run azure functions project with https in Visual Studio using AF v1 with C#.</p>  <p>Under Debug section in the project settings  I put \host start --useHttps\"" in Application arguments and then tried running the application.</p>  <p>In the console it shows \""The host is taking longer than expected to start.\""</p>  <p>There are no errors shown. What could be the problem?</p>""",azure-functions
51589697,"Dictionary type input in the VSTS Build/Release Task <p>I have to create a VSTS Build/Release task extension which takes a dictionary as the input type.</p>  <p>I need to pass n number of parameters to the task and also the parameter name and the parameter value should be given dynamically (while configuring the CI and CD).</p>  <p>Is there any input type which is similar to the Variable section where we can specify the Key-Value pair and also we can add n number of variables.</p>  <p><a href=\https://i.stack.imgur.com/ODbQh.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/ODbQh.png\"" alt=\""enter image description here\""></a></p>""",azure-devops
26730649,"System Center Virtual Machine Manager Service Unable to start <p>I have install Virtual Machine Manager on windows server 2012 R2 . it installed sucessfuly but the SCVMM  service can't be started please check the following log for and the error </p>  <p>when i try to start SCVMM service its endup with the following error </p>  <p>\ The System Center Virtual Machine Manager Service on Local Computer started and then stopped. Some services stop automatically if they are not in use by other services or programs. \"" Log Name:      Application Source:        SCVMMService Date:          11/4/2014 7:58:55 AM Event ID:      0 Task Category: None Level:         Error Keywords:      Classic User:          N/A Computer:      HC********** Description:</p>  <pre><code>Service cannot be started. System.Reflection.ReflectionTypeLoadException: Unable to load one or more of the requested types. Retrieve the LoaderExceptions property for more information.    at System.Reflection.RuntimeModule.GetTypes(RuntimeModule module)    at System.Reflection.RuntimeModule.GetTypes()    at System.Reflection.Assembly.GetTypes()    at Microsoft.VirtualManager.Remoting.IndigoSerializableObject.BuildKnownAssemblyTypes(Assembly assembly)    at Microsoft.VirtualManager.Remoting.IndigoSerializableObject.InitializeKnownTypesCache(List`1 assembliesToExamine)    at Microsoft.VirtualManager.Engine.Remoting.IndigoServiceHost.InitializeKnownTypesCache()    at Microsoft.VirtualManager.Engine.VirtualManagerService.TimeStartupMethod(String description  TimedStartupMethod methodToTime)    at Microsoft.VirtualManager.Engine.VirtualManagerService.OnStart(String[] args)    at System.ServiceProcess.ServiceBase.ServiceQueuedMainCallback(Object state) Event Xml: &lt;Event xmlns=\""http://schemas.microsoft.com/win/2004/08/events/event\""&gt;   &lt;System&gt;     &lt;Provider Name=\""SCVMMService\"" /&gt;     &lt;EventID Qualifiers=\""0\""&gt;0&lt;/EventID&gt;     &lt;Level&gt;2&lt;/Level&gt;     &lt;Task&gt;0&lt;/Task&gt;     &lt;Keywords&gt;0x80000000000000&lt;/Keywords&gt;     &lt;TimeCreated SystemTime=\""2014-11-04T07:58:55.000000000Z\"" /&gt;     &lt;EventRecordID&gt;10656&lt;/EventRecordID&gt;     &lt;Channel&gt;Application&lt;/Channel&gt;     &lt;Computer&gt;HC-S*********** &lt;/Computer&gt;     &lt;Security /&gt;   &lt;/System&gt;   &lt;EventData&gt;     &lt;Data&gt;Service cannot be started. System.Reflection.ReflectionTypeLoadException: Unable to load one or more of the requested types. Retrieve the LoaderExceptions property for more information.    at System.Reflection.RuntimeModule.GetTypes(RuntimeModule module)    at System.Reflection.RuntimeModule.GetTypes()    at System.Reflection.Assembly.GetTypes()    at Microsoft.VirtualManager.Remoting.IndigoSerializableObject.BuildKnownAssemblyTypes(Assembly assembly)    at Microsoft.VirtualManager.Remoting.IndigoSerializableObject.InitializeKnownTypesCache(List`1 assembliesToExamine)    at Microsoft.VirtualManager.Engine.Remoting.IndigoServiceHost.InitializeKnownTypesCache()    at Microsoft.VirtualManager.Engine.VirtualManagerService.TimeStartupMethod(String description  TimedStartupMethod methodToTime)    at Microsoft.VirtualManager.Engine.VirtualManagerService.OnStart(String[] args)    at System.ServiceProcess.ServiceBase.ServiceQueuedMainCallback(Object state)&lt;/Data&gt;   &lt;/EventData&gt; &lt;/Event&gt; </code></pre>""",azure-virtual-machine
15791323,"how to link css file to aspx in azure host? <p>I have asp.net app that I am trying to upload to azure host. first I have try to link in the traditional way with Css folder and link to it </p>  <pre><code>&lt;link href=\http://mysite.azurewebsites.net/css/style.css\""        rel=\""stylesheet\"" type=\""text/css\"" /&gt; </code></pre>  <p>NOT WORKING</p>  <p><strong>then i create blob and reference to it :</strong></p>  <pre><code>&lt;link href=\""http://mysite.blob.core.windows.net/scripts/style.css\""        rel=\""stylesheet\"" type=\""text/css\"" /&gt; </code></pre>  <p>NOT WORKING</p>  <p>now I dont get error but nothing happend to the styling (after empty my cache and restart the site) I am not using master pages in my site just normal asp.net page. i saw in some place that they are doing it with master page but there is other way to do it without master page.</p>  <p>Thanks.</p>""",azure-storage
57086503,"Should we be using AspNetCoreHostingModel on Azure App Services for ASP.NET Core 2.2+ web applications? <p>I'm looking at publishing an <strong>ASP.NET Core 2.2</strong> Web API application to Azure App Services. I noticed that in ASP.NET Core 2.2 they have added in the <code>AspNetCoreHostingModel</code> setting.</p>  <p><a href=\https://docs.microsoft.com/en-us/aspnet/core/host-and-deploy/iis/index?view=aspnetcore-2.2#in-process-hosting-model\"" rel=\""nofollow noreferrer\"">The documentation on this</a> says that this setting allows <code>In-process hosting</code>.</p>  <blockquote>   <p>In-process hosting provides improved performance over out-of-process hosting because requests aren't proxied over the loopback adapter.</p> </blockquote>  <p>Question 1: By using Azure App Services on a Windows App Service Plan  does this mean we automatically are forced to use IIS?</p>  <p>Question 2: If that is the case (we are forced)  we should probably set this value to <code>&lt;AspNetCoreHostingModel&gt;InProcess&lt;/AspNetCoreHostingModel&gt;</code> to take advantage of the performance benefits of InProc vs Out-of-proc ?</p>  <p>EDIT:</p>  <ul> <li>My assumption for Linux App Service Plans is that IIS is not available on those  so this setting is ignored.</li> </ul>""",azure-web-app-service
55633294,Azure Storage Blob/File per tenant <p>I'm trying to understand how I can achieve the following in our multi-tenant application: - Have a seperate 'file location' per tenant (guid) - Ability to map this file location to a PC - Make sure that a 'file location' can only be accessed with a single key  meaning  one key should not be allowed to access multiple 'file locations' - Restrict access to pure read-only purposes</p>  <p>I was looking at Azure File Shares  but  when creating a few fileshares  I noticed that  when trying to map the fileshare to my PC  it's using the same key for all these fileshares. That's a problem  I don't want to give any tenant the possibility to map different tenant's file locations using the same key.</p>,azure-storage
12253326,"A Same Name \Cloud Service\"" will be created when create \""Virtual Machine\"" in Azure  can I delete it? <p>A same name \""Cloud Service\"" will be created when create \""Virtual Machine\"" in Azure.</p>  <p>My question is:</p>  <p>A: What is the same name \""Cloud Service\"" for?</p>  <p>B: Can I delete the one exist in \""Cloud Service\""  which is empty  no deployment in neither production nor stage.</p>  <p>C: If I delete it  will it effect \""Virtual Machine\"" I created?</p>  <p>D: If I delete it  can I recreate it with the same name later?</p>""",azure-virtual-machine
53147402,"Strip URLs from querystring in web.config <p>I am using Google to authenticate users through OAuth2. The site is built in Angular 5 and hosted in an Azure App Service (IIS). When google authenticates the user  it sends back an URL which contains some URIs: </p>  <p><code>https://domain.azurewebsites.net/membership/oauth2?code=&lt;authentication code&gt;&amp;scope=openid%20email%20https://www.googleapis.com/auth/plus.me%20https://www.googleapis.com/auth/userinfo.email</code>.</p>  <p>As you can see  after the <code>&amp;scope</code>  there are 2 URIs. azure websites returns an error indicating that </p>  <blockquote>   <p>The resource you are looking for has been removed  had its name changed  or is temporarily unavailable. </p> </blockquote>  <p>If I strip the query string from <code>&amp;scope</code> onwards  it works fine.</p>  <p>I have tried to strip that part in web.config with a rewrite rule:</p>  <pre><code>    &lt;rule name=\Remove paging parameters\"" stopProcessing=\""true\""&gt;         &lt;match url=\""^(.*)\\/membership\\/oauth2(.*)$\"" /&gt;         &lt;conditions trackAllCaptures=\""true\""&gt;             &lt;add input=\""{QUERY_STRING}\"" pattern=\""^(.*)(scope=.+)(.*)$\"" /&gt;         &lt;/conditions&gt;         &lt;action type=\""Redirect\"" url=\""{C:1}{C:3}\"" appendQueryString=\""false\"" /&gt;     &lt;/rule&gt; </code></pre>  <p>However  nothing happens. Any help will be greatly appreciated.</p>  <p>Side Note: everything works fine in localhost  as it is nodejs that serves the Angular site. The problem arouses in the Azure App Service  as it is served by IIS.</p>""",azure-web-app-service
12076029,Allowing only local network connections to a Windows Azure VM? <p>I am trying lock down a virtual machine that acts as an app server for a web application. I have a two VM's: One for the app server and another one running the web server. I have to open a ton of ports to allow the web server talk to some wcf services  but I only want to allow those connections from the web server and no one outside of that network. I have to add endpoints in order for the web server to access the wcf services  but this also makes them accesible to the public IP. How can I only allow this traffic on the </p>,azure-virtual-machine
32328988,"All VM detail Created in a single Day <p>I need to create a PS script which can give me a report how many azure VMs are created today or created on a particular day. I don't find any information in terms of date and time by <code>get-azurevm</code> or <code>get-azurevm -servicename \testservice\"" -name \""testvm\""</code> Can anyone help me on this.</p>""",azure-virtual-machine
47598952,Allow wiki pages to be viewed by non users <p>Is there a way with VSTS Wiki for me to build out Wiki pages that can be viewed by non VSTS users? My use case is this  we have an internal team that develops internal products for our company but there are only about 4-5 of us that are VSTS users. We would like to build out some documentation for the rest of our company to see who are not VSTS users. How would I go about doing this or is this not a feature?</p>,azure-devops
52661214,"Adding files to build package artifacts <p>I'm following a learning course on plural-sight and he shows an artifact with cfg folder and json file within that folder(outside of the packge.zip file) but I cant figure out how he managed to configure his build process to get that file there.</p>  <p><a href=\https://i.stack.imgur.com/jTUVN.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/jTUVN.png\"" alt=\""image\""></a></p>  <p>How do I achieve this and where should i go to learn more about package files how they are made?</p>""",azure-devops
50432269,100 Vm's are suddenly stopped in my Azure portal <p>in my azure portal suddenly 100 vm 's are stopped all are in same region and subscription..please help me ..</p>  <p>am getting below error</p>  <p>Failed to start virtual machine Failed to start the virtual machines </p>,azure-virtual-machine
40480026,Is it possible to seed the release revision for a release plan? <p>We're migrating over from another build tool where relied on the CI to maintain a release version that increments based on a given pattern. In VSTS  the release revision id autoincrements from 1  but we deploy to targets that require a newer version number than the current one.</p>  <p>I'd really rather not create hundreds of fake releases to push the version number up or have to manage the version number myself. </p>  <p>Is there a way to seed the release version with a starting number? Or  alternatively  is it possible for a release to modify a release plan's variable (so that the changed value is available to future releases)?</p>,azure-devops
51298378,Session based service bus with Azure Function <p>I am using session queue on Azure and when I push some data on queue I write one Azure function to trigger.</p>  <p>Please note that I have created statefull/session based queue.</p>  <p>The problem is when I push data to queue at that moment I got error like </p>  <blockquote>   <p>The listener for function 'xxx' was unable to start.   Microsoft.ServiceBus: It is not possible for an entity that requires   sessions to create a non-sessionful message receiver</p> </blockquote>  <p>So my question is am I not able to use function with queue/topic with session?</p>,azure-functions
48663665,"TFS 2018 associating work item with commit without pull request <p>we are using git in our on-premises TFS 2018 <s>RC2</s> RTW</p>  <p>when we checkin our code we assiciate a work item by adding a hash and a number e.g. #8635</p>  <p><a href=\https://i.stack.imgur.com/JG2PY.png\"" rel=\""noreferrer\""><img src=\""https://i.stack.imgur.com/JG2PY.png\"" alt=\""enter image description here\""></a></p>  <p>It is written in the <a href=\""https://blogs.msdn.microsoft.com/devops/2016/03/02/linking-work-items-to-git-branches-commits-and-pull-requests/\"" rel=\""noreferrer\"">docs</a> that this should work with pull-requests. But in our case we do not neccessarly need pull-requests.</p>  <p><strong>Is it possible to link commits with work items without pull-requests?</strong></p>  <p>related: </p>  <ul> <li><a href=\""https://stackoverflow.com/questions/36599939/vsts-how-to-get-all-linked-work-items-since-last-successful-release-to-producti\"">VSTS: How to get all linked work items since last successful release to production?</a></li> <li><a href=\""https://blogs.msdn.microsoft.com/devops/2016/03/02/linking-work-items-to-git-branches-commits-and-pull-requests/\"" rel=\""noreferrer\"">https://blogs.msdn.microsoft.com/devops/2016/03/02/linking-work-items-to-git-branches-commits-and-pull-requests/</a></li> </ul>  <p><strong>Update:</strong></p>  <p>I just tested this on a different git project on the same team project. </p>  <p>Guess what: It's working as expected. Strange there needs to be something with this git project...</p>  <p><a href=\""https://i.stack.imgur.com/eXa9K.png\"" rel=\""noreferrer\""><img src=\""https://i.stack.imgur.com/eXa9K.png\"" alt=\""enter image description here\""></a></p>""",azure-devops
42137407,"Multiple VM's using the same storage accounts in Azure <p>I read on the Azure docs that its a best practice to have 1 storage account per VM storage for performance benefenits  but on another page I read that this doesn't really become an issue untill reaching 20-40 VM in 1 storage account.</p>  <p>see: <a href=\https://gallery.technet.microsoft.com/scriptcenter/Azure-Count-VHDs-Per-6a44ecbd\"" rel=\""nofollow noreferrer\"">https://gallery.technet.microsoft.com/scriptcenter/Azure-Count-VHDs-Per-6a44ecbd</a></p>  <p>I'm planning on using 2-3 VM's with 2 SSD disks/Premium Storage each using the same storage account  my argument to keep them in the same storage account is that less resource to manage is easier management. Will I hit performance limits when using SSD's?</p>""",azure-storage
22880633,"Azure Storage - download file and put into Storage <p>I am using Azure Mobile Service API as a backend. I need to store a file from an URL to the Azure Storage in Azure Mobile Service API script.</p>  <p>Really I have no idea how to do it :(</p>  <p>There are some readings in Storage subject  but not from Azure Mobile Sevice API.</p>  <p>Please help.</p>  <p>------- After comments------</p>  <p>Well I'm quite there. It's all going in the right direction.  Can download the file  I can store it in Storage container  but on my way I am doing something wrong  because when I view the file from Sotrage  it is corrupted.</p>  <p><a href=\http://screencast.com/t/evBpmAVHQrbb\"" rel=\""nofollow\"">http://screencast.com/t/evBpmAVHQrbb</a> <a href=\""http://screencast.com/t/H5Z0xzzsaH\"" rel=\""nofollow\"">http://screencast.com/t/H5Z0xzzsaH</a></p>  <pre><code>var requestImageCallback = function (err  resp2  body) { if (err || resp2.statusCode !== 200) {     console.error('Error sending data to the provider: '  err);     response.send(statusCodes.INTERNAL_SERVER_ERROR  body); } else {     var type = resp2.headers[\""content-type\""]          prefix = \""data:\"" + type + \"";base64 \"";      resp2.setEncoding('binary');     var base64 = new Buffer(body  'binary').toString('base64')          item = prefix + base64;     console.log(item);       var blobService = azure.createBlobService(accountName  accountKey  host);     blobService.createContainerIfNotExists(\""avatars\""  {         publicAccessLevel: 'blob'     }  function (error) {         if (!error) {             var sharedAccessPolicy = {                 AccessPolicy: {                     Permissions: azure.Constants.BlobConstants.SharedAccessPermissions.WRITE                      Expiry: new Date(new Date().getTime() + 5 * 60 * 1000)                 }             };             var now = new Date();             var filename = now.getTime() + \"".jpg\"";             var sasQueryUrl =                 blobService.generateSharedAccessSignature(\""avatars\""                      filename  sharedAccessPolicy);              console.log(qs.stringify(sasQueryUrl.queryString));              console.log(sasQueryUrl.baseUrl + sasQueryUrl.path);              var options = {                 contentType: type                  contentTypeHeader: type             };             blobService.createBlockBlobFromText('avatars'  filename  item  options     function (error) {                 if (!error) {                     // Blob uploaded                 }             });         } else {             console.error(error);         }     });      } }  var http = require('request'); var reqOptions = {     uri: userData.picture.data.url      headers: {         Accept: \""image/jpeg  image/png\""     } }; http(reqOptions  requestImageCallback); </code></pre>""",azure-storage
38189154,Diverting web traffic from one Azure Web app to another without downtime <p>I have two Azure web apps:</p>  <ul> <li>webapp1.azurewebsites.net</li> <li>webapp2.azurewebsites.net</li> </ul>  <p>webapp1 is my live website  which is configured with a custom domain  www.example.com.</p>  <p>I want to divert all incoming traffic so that it goes to webapp2  rather than webapp1.</p>  <p>My plan to do this was:</p>  <ol> <li>Add the custom domain 'www.example.com' to webapp2.</li> <li>Change the DNS CNAME record for www.example.com so that it points to webapp2.azurewebsites.net (instead of webapp1.azurewebsites.net).</li> </ol>  <p>However  this approach doesn't work; When I try to add the custom domain name to webapp2 using portal.azure.com  I get the error: 'The host name www.example.com' is already assigned to another Azure website'.</p>  <p>It's important to ensure that there is no downtime in this transition  so removing the custom domain name from webapp1 before adding it to webapp2 isn't an option.</p>  <p>Any ideas on how I can solve this problem?</p>,azure-web-app-service
55747205,"How to get the complete URL of a Azure Function from a different function inside the same App Service? <p>In Azure Functions  when you create a function  this one gets a unique GET code for calling it. Using a App Service that has two or more functions  I want to  from one of those functions  access the complete URL with the GET code of a different function.</p>  <p><strong>My example sceneraio</strong></p>  <p>I have two functions:</p>  <ul> <li>PreSomethingHook</li> <li>PostSomethingHook</li> </ul>  <p>When \something\"" happens  <code>/api/PreSomethingHook?code=ew12e12ew2e</code> should be called. I want <code>PreSomethingHook</code> to start a long process in an external API which  one of the parameters it receives  is a callback url for when the process finishes. Now  when the process finishes  <code>PostSomethingHook</code> should be called and handle the result.</p>  <p>My problem is that I don't know how to obtain the <em>PostSomethingHook complete url</em> dynamically  without setting it inside a DB or an environment variable. (Which is what I don't want to do)</p>  <p>To conclude </p>  <p>How can I obtain a function's URL with it's GET code from a different function inside the same App Service?</p>""",azure-functions
40664377,"How to handle secret files on Azure App Services with Git <p>We have an PHP app  where for encryption of the connection with database we need to provide 3 files that shouldn't be publicly accessible  but should be present on the server to make the DB connection (<a href=\https://www.cleardb.com/developers/ssl_connections\"" rel=\""nofollow noreferrer\"">https://www.cleardb.com/developers/ssl_connections</a>)</p>  <p>Obviously we don't want to store them in the SCM with the app code  so the only idea that comes to my mind is using post-deploy action hook and fetch those files from storage account (with keys and URIs provided in the app parameters).</p>  <p>Is there a nicer/cleaner way to achieve this? :)</p>  <p>Thank you </p>""",azure-web-app-service
55246212,"Deploy Vue CLI on Azure App Service with History mode <p>Hi is there anyone who has deployed there application to azure app service and got the history mode to work?  I have been trying on and off  and cant get it work :S</p>  <p>Im using connect-history-api-fallback and my package.json lookslike this:</p>  <pre><code>{   \name\"": \""wbo\""    \""version\"": \""0.1.0\""    \""private\"": true    \""scripts\"": {     \""serve\"": \""vue-cli-service serve\""      \""build\"": \""vue-cli-service build\""      \""lint\"": \""vue-cli-service lint\""      \""start\"": \""node server.js\""   }    \""dependencies\"": {     \""axios\"": \""^0.18.0\""      \""buefy\"": \""^0.7.3\""      \""connect-history-api-fallback\"": \""^1.6.0\""      \""express\"": \""^4.16.4\""      \""js-cookie\"": \""^2.2.0\""      \""lodash\"": \""^4.17.11\""      \""nprogress\"": \""^0.2.0\""      \""vue\"": \""^2.6.6\""      \""vue-router\"": \""^3.0.1\""      \""vuelidate\"": \""^0.7.4\""      \""vuex\"": \""^3.0.1\""      \""vuex-persistedstate\"": \""^2.5.4\""   }    \""devDependencies\"": {     \""@vue/cli-plugin-babel\"": \""^3.5.0\""      \""@vue/cli-plugin-eslint\"": \""^3.5.0\""      \""@vue/cli-service\"": \""^3.5.0\""      \""@vue/eslint-config-prettier\"": \""^4.0.1\""      \""babel-eslint\"": \""^10.0.1\""      \""eslint\"": \""^5.8.0\""      \""eslint-plugin-vue\"": \""^5.0.0\""      \""node-sass\"": \""^4.9.0\""      \""sass-loader\"": \""^7.1.0\""      \""vue-cli-plugin-buefy\"": \""^0.3.5\""      \""vue-template-compiler\"": \""^2.5.21\""   } } </code></pre>  <p>And i have a server.js file in root like this:</p>  <pre><code>const express = require('express') const history = require('connect-history-api-fallback') const port = process.env.PORT || 8080 const app = express()  app.use(history())  app.use(express.static(__dirname + '/dist/')) app.get('/*'  function(req  res) {   res.sendFile(__dirname + '/dist/html.html') }) app.listen(port)  console.log('Server started....') </code></pre>  <p>Does anyone know if theres something more i need todo  or can see the problem somewhere :S </p>  <p>Best regards Daniel</p>""",azure-web-app-service
53738487,"Azure Web Services [Web App for Containers (linux)] - how to prevent timeout periodically <p>There is error log in Web Services periodically:</p>  <blockquote>   <p>ERROR - Container XXX for site YYY did not start within expected time limit. Elapsed time = 230.3790706 sec</p> </blockquote>  <p>I set below settings already mention in <a href=\https://blogs.msdn.microsoft.com/waws/2017/09/08/things-you-should-know-web-apps-and-linux/\"" rel=\""nofollow noreferrer\"">Microsoft's blog</a> but still failed:</p>  <pre><code>1. Use the EXPOSE instruction in your Dockerfile to expose port 3000. 2. Use the WEBSITES_PORT app setting with a value of \""3000\"" to expose that port. </code></pre>  <p>How to config to prevent this error?</p>""",azure-web-app-service
38698112,"How to scale out VMs in Azure Container Service Docker? <p>I created Docker(+swarm) with Azure Container Service template.</p>  <p>1 master and 1 agent created  but how can I scale out agent VMs? The template generates agent VMSS(scale sets) but not found to add more VMs in Portal UI.</p>  <p>Found <a href=\https://azure.microsoft.com/en-us/documentation/articles/virtual-machine-scale-sets-autoscale-overview/\"" rel=\""nofollow\"">template documentation</a> but it seems not handy.</p>  <p>Is there any way to do it only with a few clicks like Azure Worker Role?</p>""",azure-virtual-machine
41018810,How to update Azure webApp slot configuration in Visual Studio Online continuous integration? <p>When releasing the build in VSO  I would like to release it in a webapp staging slot. I'm using NewRelic  so I have to stop the staging environment  and set AlwaysOn option to false  before deployment  then put it on and start after deployment.</p>  <p>This is what I'm doing using Azure CLI task before the deployment task :</p>  <pre><code>call azure webapp config set --slot staging Default-Web-WestEurope instanceName  --alwayson false call azure webapp stop --slot staging Default-Web-WestEurope instanceName </code></pre>  <p>It works well when I launch these commands on Azure CLI on my own desktop. But when I put this script on Azure CLI Task on VSO  it works... <strong>but on the production slot.</strong></p>  <p>It's very annoying because it put the production down.</p>  <p>Do you know how to update WebApp <strong>slot</strong> configuration in VSO continuous integration ?</p>,azure-devops
20107701,What are the big differences between TFVC (TFS Version Control) and Git for source control when using Visual Studio 2013? <p>There are tons of questions and answers about Git versus TFVC Source Control  but no current answers cover the integration of Git into Team Foundation Server/Service that I can find.   </p>  <p>I'm starting green pasture development using a wide variety of languages (C#  C++  PHP  Javascript  MySSQL) using Visual Studio 2013. In the future  there will be some iOS development. I'm very familiar with SVN  VSS and TFVC for source control. However  I have never used Git. I prefer TFS for process management/agile development... It's not perfect  but it integrates well into Visual Studio.</p>  <p>So  to help me decide between these two systems...</p>  <h3>What are the big differences between TFVC and Git for source control when using Visual Studio 2013?</h3>  <ul> <li>Is the only benefit in my case a local repository (not saying that it's insignificant) and iOS development support?</li> <li>Is the only drawback to Git the command line interface (some would argue that's not a drawback ;-P).</li> <li>Have you experienced in the Visual Studio 2013 GUI for Git? Is that enough to support basic branching/merging without the command line interface?</li> <li>Is there a detailed start-up guide for Git that shows Git being used with Visual Studio 2013? Microsoft has a video for integrating an existing Git repository into Visual Studio 2013  but I'm looking for a start from scratch with Git and VS 2013.</li> </ul>  <p>I am not looking for a book here  but just a few bullet points and maybe some relevant links from folks that have used both TFVC and Git.</p>,azure-devops
51486665,"My Inherited Process Template named SCRUMUA in my one VSTS account didn't get exported to my another VSTS Account <p>I installed the NP M through the “node-v8.11.3-x64” from your link and it installed successfully.<br> Then I create the PAT from both the Source VSTS account and from the Target VSTS account.<br> Then I manually created the Configuration.json file. The Configuration.json file is in the attachments for your review  I changed the PATs from it for security reason.<br> Then I ran the Node.Exe file. Command Prompt open and there I ran the command  </p>  <pre><code> process-migrator [--mode=&lt;migrate(default)/import/export&gt; [--config=]   </code></pre>  <p>Which I ran on my machine like this:-</p>  <pre><code>process [export [--config=C:\\Users\\uabbasi\\Documents\\configuration.json] </code></pre>  <p>But the TFS Process Template named SCRUMUA didn’t get exported to Target VSTS account.</p>  <p>I think the command I am running is incorrect so can you please let me know how to correct this command And if something else is missing or incorrect then can you please do let me know that.</p>  <p>If possible can you please share any video or stepbystep guide regarding how to use this process migrator which shall by very helpful for us.</p>  <p>The node.exe command prompt image present below and command that i ran which didn't work.</p>  <p>process-migrator_command_running_through_node exe_on_comand_prompt</p>  <p><img src=\https://i.stack.imgur.com/tWZEq.png\"" alt=\""enter image description here\""></p>  <p>Configuration.json file image that i have created and using it :</p>  <p><img src=\""https://i.stack.imgur.com/7KTbC.png\"" alt=\""enter image description here\""></p>  <p>YOU CAN ALSO SEE MY POST THAT I FIRST POSTED ON THE \""MICROSOFT / PROCESS-MIGRATOR SITE.  Its link is also present below :</p>  <p><a href=\""https://github.com/Microsoft/process-migrator/issues/18\"" rel=\""nofollow noreferrer\"">https://github.com/Microsoft/process-migrator/issues/18</a></p>  <p>Thanks  Umair Abbasi.</p>""",azure-devops
56457072,Azure Functions  how to have multiple .json config files <p>So I have written an azure function that works locally just fine. I believe this is down to having the <code>local.setting.json</code> file. But when I publish it to azure the function does not work as it can't find the settings values that I had defined. Coming from a web app and console driven approach  we would have different config files that would be associated with each environment. How can I get this to work so I can have multiple <code>settings.json</code> files  e.g. one for dev  stag and prod environments? The end result is to get this deployed with octopus deploy  but at this point  if I cant event get it working with a publish then there is no chance of doing this.</p>  <p>I'm rather confused why this information is not easily available  as would presume it is a common thing to do?</p>,azure-functions
53580661,"Unable clone repository using VSTS plugin in IntelliJ installed in linux Azure VM <p>1.Imported repository <a href=\https://github.com/nwcadence/MyShuttle2.git\"" rel=\""nofollow noreferrer\"">https://github.com/nwcadence/MyShuttle2.git</a> in Azure. 2.Created a linux VM in Azure. 3.Installed IntellJ 4.Installed Microsoft Teams plugin and tried to clone the git repository from my Azure account to Intellij. 5.It was able to list the repository post entering my Microsoft credentials. 6.But when i clone the repository it again ask me for Microsoft credentials and says invalid credentials </p>  <p>Please let me know what is the issues   </p>""",azure-virtual-machine
45307612,"Create an Azure VM with an unmanaged disk <p>I'm trying to <strong>create an Azure VM with an unmanaged disk via PowerShell</strong> since managed disks aren't supported in Azure Government yet.</p>  <p>None of the <a href=\https://docs.microsoft.com/azure/virtual-machines/windows/quick-create-powershell\"" rel=\""nofollow noreferrer\"">documentation</a> I could find for PowerShell VM creation references managed or unmanaged disks and the default seems to be managed disks. My VM creation fails with the following error:</p>  <blockquote>   <p>New-AzureRmVM : Managed Disks are not supported in this region. </p>      <p>ErrorCode: BadRequest</p> </blockquote>  <p>Here's the script I'm using:</p>    <pre><code>$location = \""USGovTexas\""  New-AzureRmResourceGroup -Name myResourceGroup -Location $location  # Create a subnet configuration $subnetConfig = New-AzureRmVirtualNetworkSubnetConfig -Name mySubnet -AddressPrefix 192.168.1.0/24  # Create a virtual network $vnet = New-AzureRmVirtualNetwork -ResourceGroupName myResourceGroup -Location $location `     -Name MYvNET -AddressPrefix 192.168.0.0/16 -Subnet $subnetConfig  # Create a public IP address and specify a DNS name $pip = New-AzureRmPublicIpAddress -ResourceGroupName myResourceGroup -Location $location `     -AllocationMethod Static -IdleTimeoutInMinutes 4 -Name \""mypublicdns$(Get-Random)\""  # Create an inbound network security group rule for port 3389 $nsgRuleRDP = New-AzureRmNetworkSecurityRuleConfig -Name myNetworkSecurityGroupRuleRDP  -Protocol Tcp `     -Direction Inbound -Priority 1000 -SourceAddressPrefix * -SourcePortRange * -DestinationAddressPrefix * `     -DestinationPortRange 3389 -Access Allow  # Create an inbound network security group rule for port 80 $nsgRuleWeb = New-AzureRmNetworkSecurityRuleConfig -Name myNetworkSecurityGroupRuleWWW  -Protocol Tcp `     -Direction Inbound -Priority 1001 -SourceAddressPrefix * -SourcePortRange * -DestinationAddressPrefix * `     -DestinationPortRange 80 -Access Allow  # Create a network security group $nsg = New-AzureRmNetworkSecurityGroup -ResourceGroupName myResourceGroup -Location $location `     -Name myNetworkSecurityGroup -SecurityRules $nsgRuleRDP $nsgRuleWeb  # Create a virtual network card and associate with public IP address and NSG $nic = New-AzureRmNetworkInterface -Name myNic -ResourceGroupName myResourceGroup -Location $location `     -SubnetId $vnet.Subnets[0].Id -PublicIpAddressId $pip.Id -NetworkSecurityGroupId $nsg.Id  # Define a credential object $cred = Get-Credential  # Create a virtual machine configuration $vmConfig = New-AzureRmVMConfig -VMName myVM -VMSize Standard_DS2_v2 | `     Set-AzureRmVMOperatingSystem -Windows -ComputerName myVM -Credential $cred | `     Set-AzureRmVMSourceImage -PublisherName MicrosoftWindowsServer -Offer WindowsServer `     -Skus 2016-Datacenter -Version latest | Add-AzureRmVMNetworkInterface -Id $nic.Id  # Create the virtual machine New-AzureRmVM -ResourceGroupName myResourceGroup -Location $location -VM $vmConfig </code></pre>""",azure-virtual-machine
47704892,Can I run a Azure function once on a specific date triggered by my asp.net mvc site? <p>I know I can create a scheduled Azure function to run on a schedule. But what I want is to be able to run a Azure function once given a specific date/time I pass it  along with some data parameters.</p>  <p>Ex. I'm scheduling classes in my site and I want to email out all students when the class is over. So when the class is created for Monday October 9th @ 4:00PM I want to send a message to trigger my Azure function on that same day  but like 1 hour later at 5:00PM. And I want to pass it some info like the class id or something. I also want to be able to remove this queued trigger if the class is canceled. </p>  <p>Is this possible in Azure and my ASP.Net MVC site?</p>,azure-functions
43169602,Connect to Azure Virtual machine from Mobile App locally <p>I'm using Azure Mobile App and classic Virtual Machine on Azure Portal.</p>  <p>There is a great tool on Mobile App - API. I use it for different tasks.  My question is -can I somehow connect to server from mobile app API using local interface?</p>  <p>For instance  I want to deploy web server on virtual machine and restrict connections only from local subnet? And I will use mobile app API to communicate with it.  Thank you.</p>,azure-virtual-machine
54232224,rsyslogd-3000: omazuremds error at connect(). errno=No such file or directory <p>I'm receiving the following error after cloning a Linux VM from one region to another:</p>  <pre><code>rsyslogd-3000: omazuremds error at connect(). errno=No such file or directory </code></pre>  <p>The source VM was connected to the OMS workspace in the other region. Since cloning  I have stopped any OMS related services on the box but the error persists. </p>  <p>Are there any other files/services I should remove to stop this error?</p>,azure-virtual-machine
49422387,"Function App Time trigger not working <p>I have a function App. type is Timetrigger. I have given the time trigger expression <code>0 0 * * * *</code>   as my requirement it to run with 1 Hour interval. I have refereed the <a href=\https://codehollow.com/2017/02/azure-functions-time-trigger-cron-cheat-sheet/\"" rel=\""nofollow noreferrer\"">TimeTrigger Cheat Sheet</a> </p>  <p>But Unfortunetly its triggering in each 5 min. Somehow it's not working. Help me regarding this. </p>  <p><strong>target--> Run the function App in the interval of 1 Hour.</strong> </p>""",azure-functions
56804099,"Where do i see Python print function output <p>I am using azure web services  for my Python Django web app   where can i see  the output of : print (\strating \""+str(datetime.now()))</p>  <p>Thanks </p>  <p>Nir</p>""",azure-web-app-service
55236659,"Semicolon in password in azure function application setting connection string value <p>Bonjour</p>  <p>Ive created a azure function which does not work in the Azure Portal. </p>  <p>The problem is that the password of the connnection string value contains a semicolon.</p>  <p>It works great locally when using '{Password}' in local.settings. This does not work when i enter this in the connection string value in the Application Settings of the function  I get the error Login failed for user '{User}'.</p>  <p>Without using ' ' it breaks the connection string value at the wrong place.</p>  <p>How do I use a password with semicolon in the Connection String value in Application Settings for Azure Function?</p>  <p>The connection string is built like this: <a href=\https://i.stack.imgur.com/MUhy4.png\"" rel=\""nofollow noreferrer\"">ConnectionStringValue</a></p>  <p>Thank you!</p>""",azure-functions
56443104,Azure: Add existing Virtual Machines to new Application Gateway in same region <p>We already have created two virtual machines in the North Europe region. Now  I want to add these two machines in Application Gateway  but as per Azure documents while creating an Application gateway one cannot use a virtual network with existing VMs in it.  Is there a way around to create an Application gateway in the same network as VMs?</p>,azure-virtual-machine
16321608,"Windows Azure VM RDP issue <p>I followed this </p>  <p><a href=\http://blogs.technet.com/b/keithmayer/archive/2013/04/17/step-by-step-build-a-free-sharepoint-2013-lab-in-the-cloud-with-windows-azure-31-days-of-servers-in-the-cloud-part-7-of-31.aspx#.UX_iF7XvvQI\"" rel=\""nofollow\"">http://blogs.technet.com/b/keithmayer/archive/2013/04/17/step-by-step-build-a-free-sharepoint-2013-lab-in-the-cloud-with-windows-azure-31-days-of-servers-in-the-cloud-part-7-of-31.aspx#.UX_iF7XvvQI</a></p>  <p>I created a VM using the datacentre Image it created successfully and the status shows Its running. I am trying to RDP It says </p>  <p>Remote Desktop cant connect to the remote computer for one of these reasons: 1) Remote access to the server is not enabled 2) The remote computer is turned off 3) The remote computer is not available on the network</p>  <p>make sure the remote computer is turned on and conencted to the network and that remote access is enabled.</p>  <p>I did check the endpoints the public port is open and also 3389 private port is open too. I did try with different release one with latest patch and the other with the second latest OS patch but I am still not able to RDP.</p>  <p>Thanks</p>""",azure-virtual-machine
41767899,"Getting \Entity already exists\"" error writing aggregates to Azure Table Storage (with Azure Function) <p>In an Azure Function  I'm trying to aggregate some data and write the aggregations into a Table.</p>  <p>I have a query that summarises data:</p>  <pre><code>var query = recs             .GroupBy(r =&gt; new { r.Category  r.Account  r.Record })             .Select(r =&gt; new ts_webhitaggregate_account                     {                         PartitionKey = partition   // Constant                         RowKey = $\""{r.Key.Category}:{r.Key.Account}:{r.Key.Record}\""  // Group By                          rawDate = intervaldate    // Constant                         epochDate = intervalepoch  // Constant                         Category = r.Key.Category  // Group By                          Account = r.Key.Account  // Group By                          Record = r.Key.Record  // Group By                          Hits = r.Count()  // Aggregate                         Users = r.Select(t =&gt; t.User).Distinct().Count()  // Aggregate                         Devices = r.Select(t =&gt; t.Device).Distinct().Count() // Aggregate                     }); </code></pre>  <p>I then attempt to pass these records to the ICollector bound Table</p>  <pre><code>foreach (ts_webhitaggregate_account a in query.ToList()) {     webhitsAggAccount.Add(a); } </code></pre>  <p>I'm frequently encountering an \""Entity already exists\"" error like:</p>  <blockquote>   <p>Exception has been thrown by the target of an invocation. Microsoft.WindowsAzure.Storage: 82:The specified entity already exists.</p> </blockquote>  <p>If I was writing a comparable SQL statement to the C# I wouldn't expect duplicates of the compound key to be possible as every value being written is the key  a constant  or an aggregation. I also have no pre-existing data in the Table which could be causing the conflict.</p>  <p><strong>What am I doing wrong to be generating duplicates in my query?</strong></p>""",azure-functions
45083875,"Microsoft Graph API result is not treated as a JSON object in AngularJS <p>I'm fetching group information from the Microsoft Graph API and it returns results as:</p>  <pre><code>{   \@odata.context\"": \""https://graph.microsoft.com/v1.0/$metadata#groups(id displayName description)\""    \""value\"": [     {       \""id\"": \""00000000-0000-0000-0000-000000000000\""        \""description\"": \""Admin\""        \""displayName\"": \""Admin\""     }      {       \""id\"": \""00000000-0000-0000-0000-000000000000\""        \""description\"": \""End user\""        \""displayName\"": \""EndUser\""     }      {       \""id\"": \""00000000-0000-0000-0000-000000000000\""        \""description\"": \""Administrator\""        \""displayName\"": \""Administrator\""     }      {       \""id\"": \""00000000-0000-0000-0000-000000000000\""        \""description\"": \""XXX\""        \""displayName\"": \""XXX\""     }   ] } </code></pre>  <p>I return this string from the server as:</p>  <pre><code>return req.CreateResponse(HttpStatusCode.OK  groups); </code></pre>  <p>In AngularJS 1.6 at the client side it is treated as a string  not as a JSON object.  Does anyone know what might be wrong?</p>""",azure-functions
48003552,"Azure Log analytics : Error while configuring custom data <p>I am trying to configure collection of custom logs using log analytics in azure. I connected my linux VM to OMS workspace and also installed Linux agent in my VM. but after this Whenever I try to go to  \CustomData\"" menu under  Log Analytics workspace\\Advance Settings following error pops up  </p>  <p>Accessed JArray values with invalid key value: \""value\"". Array position index expected.</p>  <p>Any help is appreciated.</p>""",azure-virtual-machine
48411359,GetAppendBlobReference is removed from Microsoft.WindowsAzure.Storage.Blob.CloudBlobContainer <p>What is the alternative to get an appendblob from a container? </p>,azure-storage
54120011,Is it possible to specify function sub directories / paths? <p>I'm writing my first azure function project in node.js. I have my project directory  in which exists the <code>host.json</code> and local settings files. As far as I understand it  my individual function folders  in which <code>function.json</code> and my function code exists  must reside as a sibling to the <code>hosts.json</code> file. So  project folders must look something like ...</p>  <pre><code>project-root/   package.json   host.json   function-a/     function.json     index.js   function-b/     function.json     index.js </code></pre>  <p>But  is it possible to have a project structure with those function folders nested deeper? Something like the following  perhaps ...</p>  <pre><code>project-root/   package.json   host.json   src/     function-a/       function.json       index.js     function-b/       function.json       index.js </code></pre>  <p>This might be useful if I were to be using TypeScript and would need to the function host to execute out of a <code>dist</code> folder  like below ...</p>  <pre><code>project-root/   package.json   host.json   src/     function-a/       function.json       index.js     function-b/       function.json       index.js   dist/     function-a/     function-b/ </code></pre>  <p>I can't seem to get the function host to look into nested directories  though.</p>  <p>Is this possible?</p>,azure-functions
48311141,How to open a custom port for the Azure Container (Swarm) agent? <p>I have an Azure Container Service (Swarm). I am running a docker-compose with multiple http aspi and websites in it's definition. How can I configure the the swarm agent to allow inbound traffic to those apis? (they are running on different ports). By default I can access an api or a website under the 80 port only.</p>,azure-virtual-machine
15708045,"Where is the Azure Storage library changelog? <p>I'm using the official <a href=\http://nuget.org/packages/WindowsAzure.Storage\"" rel=\""nofollow\"">nuget package</a> of Windows Azure Storage Client Library to retrieve items of my Azure tables.</p>  <p>Recently I updated the package from version 2.0.2.0 to 2.0.5.0 and my app stopped working because the results returned by my storage query are different with the new version.</p>  <p>I'm looking for the library changelog in order to understand how to fix the issue. </p>  <p>Do you know where can I find it ?</p>  <p>The <a href=\""http://msdn.microsoft.com/en-us/library/windowsazure/jj721952.aspx\"" rel=\""nofollow\"">link</a> provided on the <a href=\""http://nuget.org/packages/WindowsAzure.Storage\"" rel=\""nofollow\"">nuget page</a> seems to be outdated (it's a changelog between 1.x and 2.x  not between 2.0.2 and 2.0.5 !). Also  the Windows Azure Storage team's <a href=\""http://blogs.msdn.com/b/windowsazurestorage/\"" rel=\""nofollow\"">blog</a> is not updated.</p>""",azure-storage
15104480,"Access internet from Azure VM not working <p>I've created an Azure DNS server with Address 192.168.0.4<br> I've created a Virtual Network with address space 192.168..  I changed the Subnet-1 to be  </p>  <pre><code> starting IP 192.168.10.0  Address Count 64    Address Range 192.168.10.0 - 192.168.10.63   </code></pre>  <p>I've created 3 virtual machine images in a single cloud service using powershell.</p>  <pre><code>$ADVM = New-AzureVMConfig -Name $ADVMName -InstanceSize Small -ImageName $ADVMImageName.ImageName |             Add-AzureProvisioningConfig -Windows -Password $AdminPassword |             Add-AzureDataDisk -CreateNew -DiskSizeInGB 10 -DiskLabel 'datadisk2' -LUN 0  |             Add-AzureEndpoint -Protocol tcp -LocalPort 80 -PublicPort 80 -Name 'web' -LBSetName 'lbweb' -ProbePort 80 -ProbeProtocol http -ProbePath '/'  $SQLVM = New-AzureVMConfig -Name $SQLVMName -InstanceSize Medium -ImageName $SQLImageName.ImageName |             Add-AzureProvisioningConfig -Windows -Password $AdminPassword |             Add-AzureDataDisk -CreateNew -DiskSizeInGB 50 -DiskLabel 'datadisk2' -LUN 0 |             Add-AzureEndpoint -Protocol tcp -LocalPort 80 -PublicPort 80 -Name 'web' -LBSetName 'lbweb' -ProbePort 80 -ProbeProtocol http -ProbePath '/'  $APPVM = New-AzureVMConfig -Name $APPVMName -InstanceSize Large -ImageName $AppImageName.ImageName |             Add-AzureProvisioningConfig -Windows -Password $AdminPassword |             Add-AzureDataDisk -CreateNew -DiskSizeInGB 50 -DiskLabel 'datadisk2' -LUN 0 |             Add-AzureEndpoint -Protocol tcp -LocalPort 80 -PublicPort 80 -Name 'web' -LBSetName 'lbweb' -ProbePort 80 -ProbeProtocol http -ProbePath '/'  #CreateService                    New-AzureVM -ServiceName $CloudServiceName -VMs $ADVM $SQLVM $APPVM -AffinityGroup $AffinityGroup -VNetName $VirtualNetworkName </code></pre>  <p>All the VM's and cloud service get created as expected. (although the IP addresses of the new VM's are not sequential)</p>  <p>I get these 3 IP addresses</p>  <p>192.168.0.4 for $ADVMName<br> 192.168.0.12 for $SQLVMName<br> 192.168.0.20 for $APPVMName   </p>  <p>When I RDP to $ADVMName and try to access <a href=\http://www.google.com\"" rel=\""noreferrer\"">http://www.google.com</a> it is not successful  clicking <code>Fix connection problems</code> says <code>The DNS Server isn't responding</code>.  </p>  <p>Why cant I access google from this machine? How can the DNS server (set at 192.168.0.4) be unavailable when I'm on that machine?</p>""",azure-virtual-machine
44950638,"Pick list items in VSTS gets auto sorted <p>I'm trying to add some items (strings) to a pick list in VSTS. The items get auto sorted alphabetically (ascending order).</p>  <p>Below is the scenario:</p>  <p><img src=\https://i.stack.imgur.com/54QUd.png\"" alt=\""Link for the Pick list\""></p>  <p>I entered 'test' then 'abc' and then 'xyz'  but it auto sorts and displays 'abc' then 'test' and then 'xyz'.</p>  <p>Is there any way to avoid this sorting and the items should be inserted in the order they were entered?</p>  <p>And I want to achieve this without writing an extension.</p>""",azure-devops
54039467,"Bind SSL Certificate from KeyVault to webapp using Azure CLI <p>We are currently using the following ARM template to bind the an SSL certificate to a WebApp  but we want to migrate to Azure CLI  but cannot find a way to do this without downloading the certificate.</p>  <pre><code>{   \type\"": \""Microsoft.Web/certificates\""    \""name\"": \""[variables('certificateName')]\""    \""apiVersion\"": \""2016-03-01\""    \""location\"": \""[resourceGroup().location]\""    \""properties\"": {     \""keyVaultId\"": \""[resourceId(parameters('existingKeyVaultResourceGroup')  'Microsoft.KeyVault/vaults' parameters('existingKeyVaultId'))]\""      \""keyVaultSecretName\"": \""[parameters('existingKeyVaultSecretName')]\""      \""serverFarmId\"": \""[resourceId('Microsoft.Web/serverFarms' variables('hostingPlanName'))]\""   } }  {   \""type\"": \""Microsoft.Web/sites/hostnameBindings\""    \""name\"": \""[concat(variables('webAppName')  '/'  variables('hostname'))]\""    \""apiVersion\"": \""2016-03-01\""    \""location\"": \""[resourceGroup().location]\""    \""properties\"": {     \""sslState\"": \""SniEnabled\""      \""thumbprint\"": \""[reference(resourceId('Microsoft.Web/certificates'  variables('certificateName'))).Thumbprint]\""   }    \""dependsOn\"": [     \""[concat('Microsoft.Web/certificates/' variables('certificateName'))]\""   ] } </code></pre>""",azure-web-app-service
48060503,"Cant find System.Runtime when I add async <p>I'm making an Azure Function  and I need it to do some async work. But I get this strange error it can't load assembly <code>System.Runtime</code> once I call a awaited method:</p>  <pre><code>[FunctionName(\MyTestFunction\"")] async public static void Run(     [ServiceBusTrigger(\""testtopic\""  \""testsubscription\""  AccessRights.Listen  Connection = \""MyServiceBusConnection\"")]     string mySbMsg      TraceWriter log) {     client = new DocumentClient(new System.Uri(ENDPOINT)  ENDPOINT_KEY);     await client.CreateDocumentAsync(UriFactory.CreateDocumentCollectionUri(DATABASE  COLLECTION_ID)  string.Format(\""{ \\\""newmessage\\\"": {0} }\""  mySbMsg));      log.Info($\""C# ServiceBus topic trigger function processed message: {mySbMsg}\""); } </code></pre>  <p>What am I missing here?</p>""",azure-functions
32411628,"Unauthorized error when accessing SharePoint REST API after Azure subscription change <p>Since we canceled our Azure Free Trial subscription a couple of days ago and are using our Azure Pass subscription we are sporadically getting the following error when trying to access the SharePoint REST API:</p>  <p>401 Unauthorized</p>  <p>Reason given in HTTP response:</p>  <pre><code>\The access token has expired. It's valid from '9/4/2015 3:51:21 PM' and to '9/4/2015 4:56:21 PM'.\"";category=\""invalid_client\"" </code></pre>  <p>Sometimes  retrying helps  sometimes we have to <code>reauthenticate</code>.</p>  <p>Is this somehow caused by the change of the <strong>Azure</strong> subscription?</p>""",azure-web-app-service
48049943,How to serialize VSTS CI branch builds <p>VSTS allows you to select which branches automatically trigger a CI build by specifying a branch pattern.</p>  <p>However  my unit tests are using a real database which causes a problem when more than one build triggers e.g. master and feature-123 as they will clash on the database tests.</p>  <p>Is there a way of specifying that only one such build should be run at at time; I don't want to go away from executing tests against a real database as there are significant differences between an in-memory database and SQL Azure.</p>,azure-devops
53723534,"Azure Redis Cache with HTTP Trigger Function App? <p>My problem right now is pretty straightforward: I have some data inside a CosmosDB instance and  when I receive an HTTP request containing a date range  I want to move some data from CosmosDB to a Redis Cache instance.</p>  <p>Right now I use Azure Function Apps only and they worked great but I can't find an output binding for Azure Redis Cache. I'm currently using Javascript. If the only way to connect and send data to a Redis Cache is through a \backend\""  should I just switch to it and avoid Azure Functions?</p>  <p>Am I missing something obvious? Thanks in advance for the help!</p>""",azure-functions
52826203,Is it possible to use more than 1.5 Gb of memory with an Azure Function App V2 <p>I'm currently using v2 of Azure Function Apps.  I've set the environment to be 64 bit and am compiling to .Net Standard 2.0.  Host Json specifies version 2.</p>  <p>I'm reading in a .csv and it works fine for smaller files.  But when I read in a 180MB .csv into a List of string[] it's ballooning to over a GB on read and when I try to parse it  it's up over 2 GB but then throws the 'Out of Memory' Exception.  Even running on an app service plan with more than 3.5 GB hasn't solved the issue.  </p>  <p>Edit:  I'm using this:</p>  <pre><code>Uri blobUri = AppendSasOnUri(blobName); _webClient = new WebClient();  Stream sourceStream = _webClient.OpenRead(blobUri);  _reader = new StreamReader(sourceStream); </code></pre>  <p>However  since It's a csv  I'm splitting out entire columns of data.  It's pretty hard to get away from this: </p>  <pre><code>internal async Task&lt;List&lt;string[]&gt;&gt; ReadCsvAsync() {      while (!_reader.EndOfStream) {          string[] currentCsvRow = await ReadCsvRowAsync();          _fullBlobCsv.Add(currentCsvRow);      }  return _fullBlobCsv; } </code></pre>  <p>Goal is to store json into blob when alls said and done.</p>,azure-functions
16059405,Performance with MS SQL in Azure Virtual Machine <p>I installed <strong>SQL Server</strong> in <strong>Azure Virtual Machine</strong>. Open port 1433  create rule in the firewall. </p>  <p>After that  I created <strong>Web-role</strong> and connect to SQL Server via <strong>Azure Connect</strong>. </p>  <p>All works. But performance is very bad: ping 500-900 ms between Virtual Machine and Web-role  simple stored procedures worked 5-7 seconds. </p>  <ul> <li>How increase performance?</li> <li>Will performance increase if I will use virtual network?</li> </ul>  <p><strong>SOLUTION</strong></p>  <p>I created virtual netwotk and result is the BEST!</p>,azure-virtual-machine
39835124,"Azure AD Application not appearing in existing AD App list for an Azure web application <p>I was just going through some walkthrough where I created an Azure AD App to use it as an authorization/authentication in my Azure web application. </p>  <p><strong>Now when I go to select existing AD app for my Azure website (App Services) it doesn't appear in my Azure AD Applications list.</strong> </p>  <p>The path to add existing AD app is \App Services > MyAzureApp > Authentication/Authorization > Auzre Active Directory > Express > Select existing AD App\""</p>  <p>I have used following settings for my Azure AD app:  </p>  <p><strong>Sign-on URL:</strong><br> <a href=\""https://login.windows.net\"" rel=\""noreferrer\"">https://login.windows.net</a>  </p>  <p><strong>Reply URLs:</strong><br> <a href=\""https://msmanaged-na.consent.azure-apim.net/redirect\"" rel=\""noreferrer\"">https://msmanaged-na.consent.azure-apim.net/redirect</a></p>  <p><strong>Required permissions:</strong><br> Azure Service Management API > Access Azure Service Management as organization users  </p>  <p><strong>Keys:</strong><br> Added a key and set it's expiration date to 1 year</p>  <p>Help please.</p>  <p><strong>Update (@dstrockis):</strong><br> I pasted this in the browser  <a href=\""https://login.microsoftonline.com/(tenantname).onmicrosoft.com/oauth2/authorize?client_id=(API\"" rel=\""noreferrer\"">https://login.microsoftonline.com/(tenantname).onmicrosoft.com/oauth2/authorize?client_id=(API</a> Acces-Keys-GeneratedKey)=&amp;redirect_uri=(<a href=\""https://azuresitename.azurewebsites.net/.auth/login/aad/callback)&amp;response_mode=query&amp;response_type=code+id_token&amp;scope=openid&amp;nonce=12345\"" rel=\""noreferrer\"">https://azuresitename.azurewebsites.net/.auth/login/aad/callback)&amp;response_mode=query&amp;response_type=code+id_token&amp;scope=openid&amp;nonce=12345</a></p>  <p>And I got a bad request. See image below</p>  <p><a href=\""https://i.stack.imgur.com/R5EMf.png\"" rel=\""noreferrer\""><img src=\""https://i.stack.imgur.com/R5EMf.png\"" alt=\""enter image description here\""></a></p>""",azure-web-app-service
37756130,"Error re-adding a user to Visual Studio Team Services (was Visual Studio Online) <p>Can't add a user who was previously linked to a project  then I removed it and now I'm trying to add him again  getting the following error :</p>  <blockquote>   <p>\Could not add user Microsoft.TeamFoundation.BindPendingIdentity;upn:92a19a0b-ae59-4d7c-b7ae-be71ce46bd82\\xxxxxx@hotmail.com in tenant 92a19a0b-ae59-4d7c-b7ae-be71ce46bd82 to group Microsoft.TeamFoundation.Identity;S-1-9-1551374245-781684931-2852341834-2908411269-2087932524-1-2951360343-342954306-2166683068-3335447427 in account da851b74-db4a-42d3-b619-962e5b1a61b2 in tenant 00000000-0000-0000-0000-000000000000\""   Session Id: 2c95c6b8-0dfe-415f-962c-3eafbb0a5a7e</p> </blockquote>  <p>Details:</p>  <p><img src=\""https://i.stack.imgur.com/jlHLb.png\"" alt=\""1. Error\""> <img src=\""https://i.stack.imgur.com/4NEUY.png\"" alt=\""2. Error\""></p>  <p>Thank you for your help.</p>""",azure-devops
54718654,"Azure Functions + nodejs + vscode: launch config to debug multiple azure function funcs? <p>In all the tutorials using http triggers  the .vscode launch file has this:</p>  <pre><code>    {       \name\"": \""Attach to Javascript Functions\""        \""type\"": \""node\""        \""request\"": \""attach\""        \""port\"": 9229        \""preLaunchTask\"": \""func: host start\""     } </code></pre>  <p>So now I've added a second function in the same function app. It uses a service bug trigger. I'd like to test it locally before deploying to azure. So now <strong>how do I extend the launch configurations</strong>? I can copy the block and change the name but how will the debugger know which func to kick off? Thanks!</p>""",azure-functions
20913668,Azure table storage - where clause on column that may not exist <p>I am adding a new column to my azure table. For ex.  the table is called 'User' and the new column is called 'ComputationDate'. The 'User' table already exists with rows that do not have this new column 'ComputationDate'. I have a query over it as follows </p>  <p><code>var usersDue = from user in Table.Query                            where user.ComputationDate != &lt;somedate&gt;                            select user;</code></p>  <p>I want this query to return all user rows that do not have ComputationDate set to 'somedate' and also user rows that do not have this new 'ComputationDate' column defined.  But the query doesn't return the latter set of users. It only returns rows that have 'ComputationDate' set and where the value is not equal to 'somedate'. Is there any way to get the results I desire without having to get all users and filter it on the client?</p>,azure-storage
33644327,"Azure Storage account doesn't have \Europe\"" Affinity / Location group? <p>I just created a web app on North EU Azure datacenter.</p>  <p>When I try to add an affinity group on the Settings on manage.windowsazure.com page I only see: <br><strong>South &amp; Central &amp; East US  Southeast Asia  Japan West.</strong></p>  <p>I see the same list when I am trying to create a Storage Account or trying to create a VM.</p>  <p>When creating a Mobile Service I see North EU  creating a Cloud Service the same previous list without EU and with Batch Service I see a long list of data centers.</p>  <p>But when I go to portal.azure.com I was able to create a storage account in North EU. Then now I can't see this in the manage.windowsazure.com.</p>  <p>I am really confused. Is this how it should be?</p>  <p>Thanks</p>""",azure-storage
55809597,where to download file from selenium script in azure pipeline. And how to compare it with uploadingfile <p>im writing a selenium webdriver C# script to upload a file on a then download this file. I am doing it locally and it  upoload file from my computer than download in my computer. But after continous integration when my code will run in azure pipeline build.(for upload file i put the files in a folder of project will upload from there)but on downloading where  my file will download. And how my code for compare with upload file will work??</p>,azure-devops
51759015,Azure Active Directory: Add Service Principal to Directory Readers Role with PowerShell <ul> <li>The command <code>(Get-AzureRmADUser -Mail $user).Id</code> in a Azure PowerShell Task returned null when running on a self-hosted agent in VSTS</li> <li>The problem was that the Service Principal needs to have the permission to read from the Active Directory</li> </ul>  <p>How can I give the the Service Principal the correct permissions to read from the Azure Active Directory?</p>,azure-devops
49300564,"Change resourcegroup when the 'from' resourcegroup-subscription is no longer active (ie disabled) <p>I signed up for a Microsoft 'Developer Program Benefit' subscription for Azure  besides my normal paid account.</p>  <p>Now this account suddenly expired (at least suddenly for me  I now read that it only lasts a year).</p>  <p>My situation is that I have some storage accounts which are coupled to 2 resource groups which are attached to the 'Developer Program Benefit' subscription.</p>  <p>So what I thought I had to do was create 2 new resource groups attached to my paid subscription and then change the resource group for the storage accounts to these new resource groups.</p>  <p>So I am in the storage account <a href=\https://i.stack.imgur.com/iMky0.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/iMky0.png\"" alt=\""enter image description here\""></a></p>  <p>And choose 'change'</p>  <p>However  I get this message:</p>  <p><a href=\""https://i.stack.imgur.com/MTEbN.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/MTEbN.png\"" alt=\""enter image description here\""></a></p>  <p>So now I'm kind of stuck. I don't want to re-create all my storage accounts  but I can't reassign them to the new resource groups either.</p>""",azure-storage
52158101,Limit Azure Blob Access to WebApp <p><strong>Situation:</strong> We have a web-app on azure  and blob storage  via our web-app we write data into the blob  and currently read that data back out returning it as responses in the web-app.</p>  <p><strong>What we're trying to do:</strong> Trying to find a way to restrict access to the blob so that only our web-app can access it. Currently setting up an IP address in the firewall settings works fine if we have a static IP (we often test running the web app locally from our office and that lets us read/write to the blob just fine). However when we use the IP address of our web app (as read from the cross domain page of the web app) we do not get the same access  and get errors trying to read/write to the blob.</p>  <p><strong>Question:</strong> Is there a way to restrict access to the blob to the web app without having to set up a VPN on azure (too expensive)? I've seen people talk about using SAS to generate time valid links to blob content  and that makes sense for only allowing users to access content via our web-app (which would then deliver them the link)  but that doesn't solve the problem of our web-app not being able to write to the blob when not publicly accessible.</p>  <p>Are we just trying to miss-use blobs? or is this a valid way to use them  but you have to do so via the VPN approach?</p>,azure-web-app-service
48708311,"SonarQube not able to record the coverage <p>I am using SonarQube 6.7 and TFS Plugin Sonar version 4.0.  Before the upgrade from of both the server and plugin I am able to get the coverage but now not no coverage is recorded from the MSTest. The same code with coverage is recorded when used with dot cover.  Sonar is able to record the number of tests and the coverage in TFS Build is also recorded yet it doesn't work. I have checked for the trx and the coverage files as well which is available but only *.coverage file is available not the coveragexml file. Is there any solution for this. <a href=\https://i.stack.imgur.com/wecBM.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/wecBM.png\"" alt=\""enter image description here\""></a></p>  <p><a href=\""https://i.stack.imgur.com/2XomY.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/2XomY.png\"" alt=\""enter image description here\""></a></p>  <p><a href=\""https://i.stack.imgur.com/Rztrg.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/Rztrg.png\"" alt=\""enter image description here\""></a></p>""",azure-devops
56394615,"How to display the Project Version as Release name in Azure DevOps <p>I have the release version in <code>pom.xml</code>. For Example  <strong>xyz-0.0.1</strong> is the version in my <code>pom.xml</code>. Azure Build creating the package.</p>  <p>I want to use the version <strong>xyz-0.0.1</strong> as a release name in the release pipeline. How can I pass the version to release pipeline and set \Release name format\"" in options?</p>  <p><a href=\""https://i.stack.imgur.com/6ppeX.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/6ppeX.png\"" alt=\""enter image description here\""></a></p>""",azure-devops
53904141,"Incorrect result is returned in the callback <p>Hi I want to combine the two collections and send the combined result. I did the following. I am using the mongoclient.</p>  <pre><code>&gt; module.exports = function (context  req) { &gt;  &gt;     //making the connection &gt;     var response; &gt;     //check for the request method &gt;  &gt;     if (req.method !== 'GET') { &gt;         response = { &gt;             status: 500  &gt;             body: { &gt;                 \code\"": 500  &gt;                 \""message\"": \""Invalid request. Please check the request method or parameter\"" &gt;             }  &gt;             headers: { &gt;                 'Content-Type': 'application/json' &gt;             } &gt;         } &gt;         context.done(null  response); &gt;         return; &gt;     } //end of if &gt;  &gt;     mongoClient.connect(dbUrl  function (err  client) { &gt;         assert.equal(null  err); &gt;         var database = client.db(databaseConfig.mLabDbName); &gt;         var response; &gt;         var getUserIdParams = req.query.userId &gt;         var index = req.query.index; &gt;         var noOfResults = mapResultsWithIndex(index) &gt;  &gt;  &gt;         getSubByUId(database  context  getUserIdParams  function (res  err) { &gt;  &gt;             // console.log(\""response from the callback\""  res) &gt;  &gt;  &gt;         getForms(database  context  res  function (result) { &gt;                 console.log(\""response from secondcallback\""  result) &gt;  &gt;  &gt;                 //closing the connection &gt;                 client.close(); &gt;  &gt;                 if (err) { &gt;                     console.log(\""an error in getting the result\""); &gt;                     response = { &gt;                         status: 500  &gt;                         body: { &gt;                             code: 500  &gt;                             message: \""Error in getting the forms\"" &gt;                         }  &gt;                         headers: { &gt;                             'Content-Type': 'application/json' &gt;                         } &gt;                     } &gt;                 } //end of error &gt;                 else { &gt;                     if (result.length &gt; 0) { &gt;                         console.log(\""got the data\""); &gt;                         response = { &gt;                             status: 200  &gt;                             body: { &gt;                                 code: 200  &gt;                                 result: result &gt;                             }  &gt;                             headers: { &gt;                                 'Content-Type': 'application/json' &gt;                             } &gt;                         } &gt;                     } else { &gt;                         console.log(\""did not get the data\""); &gt;                         response = { &gt;                             status: 204  &gt;                             body: { &gt;                                 code: 204  &gt;                                 message: \""No submissions found for the user id\"" &gt;                             }  &gt;                             headers: { &gt;                                 'Content-Type': 'application/json' &gt;                             } &gt;                         } &gt;                     } &gt;  &gt;                 } &gt;  &gt;                  context.done(null  response) &gt;             }) &gt;             &gt;  &gt;         }) //end of subId &gt;  &gt;     }) //closing mongodb connection }; //closing function &gt;  </code></pre>  <p>My main functions are:</p>  <pre><code>var getForms = function (db  context  array  callback) {     let newArray = [];     // console.log(\""array uuuuu\""  array)     for (let i = 0; i &lt; array.length; i++) {         db.collection('forms').find({_id:ObjectID(array[i].formId)}).toArray(function (err  res) {             console.log(\""rskkkk\"" res.length)             res.forEach(doc =&gt; {                 newArray.push({                     \""subId\"": array[i]._id                      \""formId\"": array[i].formId                      \""userId\"": array[i].userId                      \""formDescription\"": array[i].formDescription                      \""formFields\"": array[i].formFields                      \""createdAt\"": array[i].createdAt                      \""data\"": array[i].data                      \""imageformedarray\"": doc.imageUploadedarray                 })              })             callback(newArray);             console.log(\""new array is\""  newArray.length);          })       }    }  var getSubByUId = function (db  context  getUserIdParams  callback) {     let arr = []          type;     var getSubmissions = db.collection('user-submission').find({         userId: getUserIdParams     });     getSubmissions.toArray(function (err  res) {         res.forEach(doc =&gt; {             var value = doc.createdAt             if (doc.hasOwnProperty(\""updatedAt\"")) {                 value = doc.updatedAt             }             if ((typeof (doc.formFields)) === \""string\"") {                 console.log(\""string\"")                 type = JSON.parse(doc.formFields)                 // type = doc.data().formFields             } else {                 type = doc.formFields             }              arr.push({                 \""subId\"": doc._id                  \""formId\"": doc.formId                  \""userId\"": doc.userId                  \""formDescription\"": doc.formDescription                  \""formFields\"": type                  \""createdAt\"": value                  \""data\"": doc              })         });         // console.log(\""arr is\""  arr);         callback(arr  err)      })  } </code></pre>  <p>I want to return the entire array  but it only returns the result in the first loop. When i moved this callback of the <strong>getForms</strong> where it is present  it returns the result with null value.     Please help.</p>""",azure-functions
17677449,"inserting data to table located in windows azure <p>This is the very first time  i am working with Windows Azure. So  please ignore my silly mistake if found.</p>  <p>I am having problem with inserting record to the database located at windows azure. This is my java code:</p>  <pre><code>import java.net.MalformedURLException;  import com.microsoft.windowsazure.mobileservices.MobileServiceClient; import com.microsoft.windowsazure.mobileservices.MobileServiceTable; import com.microsoft.windowsazure.mobileservices.ServiceFilterResponse; import com.microsoft.windowsazure.mobileservices.TableOperationCallback;  import android.app.Activity; import android.os.Bundle; import android.util.Log; import android.view.View; import android.view.View.OnClickListener; import android.widget.Button; import android.widget.EditText;  public class HomeScreen extends Activity {      EditText et_id  et_acc_mas_id  et_amount  et_sender_id  et_borrower_id              et_entry_date  et_cancel_flag;     Button btn_save  btn_clear;     EditText[] et;     private MobileServiceClient mClient;     private MobileServiceTable&lt;AccountLiner&gt; mToDoTable;      @Override     protected void onCreate(Bundle savedInstanceState) {         super.onCreate(savedInstanceState);         setContentView(R.layout.activity_home_screen);          try {             mClient = new MobileServiceClient(                     \https://xxxxxxxx.azure-mobile.net/\""                      \""XXXXXXXXXXXXXXXXXXXXXXXXX\""  this);              mToDoTable = mClient.getTable(AccountLiner.class);          } catch (MalformedURLException e) {             // TODO Auto-generated catch block             e.printStackTrace();         }          et_id = (EditText) findViewById(R.id.editText1);         et_acc_mas_id = (EditText) findViewById(R.id.editText2);         et_amount = (EditText) findViewById(R.id.editText3);         et_sender_id = (EditText) findViewById(R.id.editText4);         et_borrower_id = (EditText) findViewById(R.id.editText5);         et_entry_date = (EditText) findViewById(R.id.editText6);         et_cancel_flag = (EditText) findViewById(R.id.editText7);          et = new EditText[] { et_id  et_acc_mas_id  et_amount                  et_sender_id  et_borrower_id  et_entry_date  et_cancel_flag };          btn_save = (Button) findViewById(R.id.button1);         btn_save.setOnClickListener(new OnClickListener() {              @Override             public void onClick(View v) {                 // TODO Auto-generated method stub                 addItem();                 for (EditText e : et) {                     e.setText(\""\"");                 }             }         });          btn_clear = (Button) findViewById(R.id.button2);         btn_clear.setOnClickListener(new OnClickListener() {              @Override             public void onClick(View v) {                 // TODO Auto-generated method stub                  for (EditText e : et) {                     e.setText(\""\"");                 }             }         });     }      public void addItem() {         if (mClient == null) {             return;         }          Log.i(\""add item\""  \""add item\"");         // Create a new item //      AccountLiner item = new AccountLiner(Integer.parseInt(et_id.getText() //              .toString().trim())  Integer.parseInt(et_acc_mas_id.getText() //              .toString().trim())  Float.parseFloat(et_amount.getText().toString().trim())  //              Integer.parseInt(et_sender_id.getText().toString().trim())  //              Integer.parseInt(et_borrower_id.getText().toString().trim())  //              et_entry_date.getText().toString().trim()  false);          AccountLiner item = new AccountLiner(Integer.parseInt(et_acc_mas_id.getText()                 .toString().trim())  Float.parseFloat(et_amount.getText().toString().trim())                  Integer.parseInt(et_sender_id.getText().toString().trim())                  Integer.parseInt(et_borrower_id.getText().toString().trim())                  et_entry_date.getText().toString().trim()  false);          // Insert the new item         mToDoTable.insert(item  new TableOperationCallback&lt;AccountLiner&gt;() {              public void onCompleted(AccountLiner entity  Exception exception                      ServiceFilterResponse response) {                  if (exception == null) {                     Log.i(\""insert\""  \""insert\"");                  } else {                     exception.printStackTrace();                 }             }         });     } } </code></pre>  <p>When i check  i don't find any records and i get an exception caught through printing stack trace:</p>  <pre><code>06-11 18:15:34.318: W/KeyCharacterMap(25959): No keyboard for id 0 06-11 18:15:34.318: W/KeyCharacterMap(25959): Using default keymap: /system/usr/keychars/qwerty.kcm.bin 06-11 18:15:49.558: I/add item(25959): add item 06-11 18:15:49.798: D/dalvikvm(25959): GC_FOR_MALLOC freed 6889 objects / 339584 bytes in 68ms 06-11 18:15:51.118: W/System.err(25959): com.microsoft.windowsazure.mobileservices.MobileServiceException: Error while processing request. 06-11 18:15:51.118: W/System.err(25959):    at com.microsoft.windowsazure.mobileservices.MobileServiceConnection$1.onNext(MobileServiceConnection.java:122) 06-11 18:15:51.118: W/System.err(25959):    at com.microsoft.windowsazure.mobileservices.MobileServiceClient$7.handleRequest(MobileServiceClient.java:728) 06-11 18:15:51.118: W/System.err(25959):    at com.microsoft.windowsazure.mobileservices.MobileServiceConnection.start(MobileServiceConnection.java:93) 06-11 18:15:51.118: W/System.err(25959):    at com.microsoft.windowsazure.mobileservices.RequestAsyncTask.doInBackground(RequestAsyncTask.java:77) 06-11 18:15:51.118: W/System.err(25959):    at com.microsoft.windowsazure.mobileservices.RequestAsyncTask.doInBackground(RequestAsyncTask.java:1) 06-11 18:15:51.118: W/System.err(25959):    at android.os.AsyncTask$2.call(AsyncTask.java:185) 06-11 18:15:51.118: W/System.err(25959):    at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:305) 06-11 18:15:51.118: W/System.err(25959):    at java.util.concurrent.FutureTask.run(FutureTask.java:137) 06-11 18:15:51.118: W/System.err(25959):    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1068) 06-11 18:15:51.118: W/System.err(25959):    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:561) 06-11 18:15:51.118: W/System.err(25959):    at java.lang.Thread.run(Thread.java:1096) 06-11 18:15:51.118: W/System.err(25959): Caused by: javax.net.ssl.SSLException: Not trusted server certificate 06-11 18:15:51.118: W/System.err(25959):    at org.apache.harmony.xnet.provider.jsse.OpenSSLSocketImpl.startHandshake(OpenSSLSocketImpl.java:371) 06-11 18:15:51.118: W/System.err(25959):    at android.net.SSLCertificateSocketFactory.verifyHostname(SSLCertificateSocketFactory.java:199) 06-11 18:15:51.148: W/System.err(25959):    at android.net.SSLCertificateSocketFactory.createSocket(SSLCertificateSocketFactory.java:256) 06-11 18:15:51.148: W/System.err(25959):    at org.apache.http.conn.ssl.SSLSocketFactory.createSocket(SSLSocketFactory.java:375) 06-11 18:15:51.148: W/System.err(25959):    at org.apache.http.impl.conn.DefaultClientConnectionOperator.openConnection(DefaultClientConnectionOperator.java:164) 06-11 18:15:51.148: W/System.err(25959):    at org.apache.http.impl.conn.AbstractPoolEntry.open(AbstractPoolEntry.java:164) 06-11 18:15:51.148: W/System.err(25959):    at org.apache.http.impl.conn.AbstractPooledConnAdapter.open(AbstractPooledConnAdapter.java:119) 06-11 18:15:51.148: W/System.err(25959):    at org.apache.http.impl.client.DefaultRequestDirector.execute(DefaultRequestDirector.java:348) 06-11 18:15:51.148: W/System.err(25959):    at org.apache.http.impl.client.AbstractHttpClient.execute(AbstractHttpClient.java:555) 06-11 18:15:51.148: W/System.err(25959):    at org.apache.http.impl.client.AbstractHttpClient.execute(AbstractHttpClient.java:487) 06-11 18:15:51.148: W/System.err(25959):    at org.apache.http.impl.client.AbstractHttpClient.execute(AbstractHttpClient.java:465) 06-11 18:15:51.148: W/System.err(25959):    at android.net.http.AndroidHttpClient.execute(AndroidHttpClient.java:243) 06-11 18:15:51.148: W/System.err(25959):    at com.microsoft.windowsazure.mobileservices.ServiceFilterRequestImpl.execute(ServiceFilterRequestImpl.java:71) 06-11 18:15:51.148: W/System.err(25959):    at com.microsoft.windowsazure.mobileservices.MobileServiceConnection$1.onNext(MobileServiceConnection.java:102) 06-11 18:15:51.148: W/System.err(25959):    ... 10 more 06-11 18:15:51.148: W/System.err(25959): Caused by: java.security.cert.CertificateException: java.security.cert.CertPathValidatorException: TrustAnchor for CertPath not found. 06-11 18:15:51.148: W/System.err(25959):    at org.apache.harmony.xnet.provider.jsse.TrustManagerImpl.checkServerTrusted(TrustManagerImpl.java:168) 06-11 18:15:51.148: W/System.err(25959):    at org.apache.harmony.xnet.provider.jsse.OpenSSLSocketImpl.startHandshake(OpenSSLSocketImpl.java:366) 06-11 18:15:51.148: W/System.err(25959):    ... 23 more 06-11 18:15:51.158: W/System.err(25959): Caused by: java.security.cert.CertPathValidatorException: TrustAnchor for CertPath not found. 06-11 18:15:51.158: W/System.err(25959):    at org.bouncycastle.jce.provider.PKIXCertPathValidatorSpi.engineValidate(PKIXCertPathValidatorSpi.java:149) 06-11 18:15:51.158: W/System.err(25959):    at java.security.cert.CertPathValidator.validate(CertPathValidator.java:202) 06-11 18:15:51.158: W/System.err(25959):    at org.apache.harmony.xnet.provider.jsse.TrustManagerImpl.checkServerTrusted(TrustManagerImpl.java:164) 06-11 18:15:51.158: W/System.err(25959):    ... 24 more </code></pre>  <p>Please help me finding my problem.</p>""",azure-storage
55968545,"Firewall access from Azure app service to blob storage <p>I am trying to lock down access to blob storage to an app service. I have the following powershell code which gets the possible outgoing ip addresses from an app service I run and then limits access to blob storage to those ip addresses:</p>  <pre><code>Write-Host (\Setting blob storage access restrictions\"") $appServiceIPAddresses = (Get-AzureRmWebApp -ResourceGroupName $resourceGroupName -name $webSiteName).PossibleOutboundIpAddresses.Split(\"" \"") $currentStorageAccessRules = (Get-AzureRmStorageAccountNetworkRuleSet -ResourceGroupName $resourceGroupName -Name $storageAccountName).IpRules  $currentStorageAccessRules = {$currentStorageAccessRules}.Invoke() # Convert to modifiable list foreach($ipAddress in $appServiceIPAddresses) {     if (($currentStorageAccessRules | Where-Object { $_.IPAddressOrRange -eq $ipAddress }) -ne $null) {         Write-Host(\""IP $ipAddress already has access to blob storage $storageAccountName\"")     } else {         Write-Host(\""Allowing IP $ipAddress access to blob storage $storageAccountName\"")         $ipRule = New-Object -TypeName Microsoft.Azure.Commands.Management.Storage.Models.PSIpRule         $ipRule.Action = 'Allow'         $ipRule.IPAddressOrRange = $ipAddress         $currentStorageAccessRules.Add($ipRule)     } } Update-AzureRmStorageAccountNetworkRuleSet -ResourceGroupName $resourceGroupName -Name $storageAccountName -IPRule $currentStorageAccessRules -DefaultAction Deny Write-Host (\""Updated blob storage access restrictions\"") </code></pre>  <p>This sets all of the ip addresses I would expect correctly  however I now get a 403 Forbiden when the app service tries to access blob storage. All containers are private so there should be no url access to the blobs I just access them programmatically from the app service. Can anyone see why the above approach does not work?</p>""",azure-storage
47587469,"Cannot open port on Azure VM <p>I have an Azure VM running Ubuntu 16.04. I'm developing a Django app hosted by Apache  so the production site is hosted on port 80 but the dev server is on 8000 or whatever.</p>  <p>At first I could access neither with my VM's public DNS; then I followed <a href=\https://docs.microsoft.com/en-us/azure/virtual-machines/windows/nsg-quickstart-portal?toc=%2Fazure%2Fvirtual-machines%2Fwindows%2Ftoc.json\"" rel=\""nofollow noreferrer\"">this blog</a> to set up the inbound security rules for both 80 and 8000. I was able to access the production site on 80 but still cannot get past 8000.</p>  <p>I'm thinking it's a firewall rule so I went and used ufw commands to allow port 8000. Nothing changed. Can somebody please tell me what I missed? I tried googling around but didn't find anything helpful.</p>""",azure-virtual-machine
55105752,"Read secret stored in Key Vault from an App Service running a container <p>I've created an App Service that is running a container running Identity Server. This container needs a certificate that I'm loading from Key Vault. To get the content of the certificate what I've done is:</p>  <ul> <li>Upload the certificate into Key Vault</li> <li>Access the content accessing the secret endpoint of the Key Vault (<a href=\https://mykeyvault.vault.azure.net/secrets/IdentityCert\"" rel=\""nofollow noreferrer\"">https://mykeyvault.vault.azure.net/secrets/IdentityCert</a>)</li> </ul>  <p>In my first attempt  I was storing just the URI of the secret in the App Settings and try to get the value using the following code:</p>  <pre><code>var azureServiceTokenProvider = new AzureServiceTokenProvider(); var keyVaultClient = new KeyVaultClient(                     new KeyVaultClient.AuthenticationCallback(azureServiceTokenProvider.KeyVaultTokenCallback));  var cert = keyVaultClient     .GetSecretAsync(         Env.GetString(\""CERTIFICATE_KEY_VAULT_KEY\""))     .ConfigureAwait(false).GetAwaiter().GetResult();  identityServerBuilder.AddSigningCredential(new X509Certificate2(Convert.FromBase64String(cert.Value)));  </code></pre>  <p>This works if I deploy the code into a VM. But it doesn't if I deploy the code into an App Service running a container. So I decided to try another option which is to use the Key Vault reference thing. So  I've created a new App Settings like this:</p>  <pre><code>CERTIFICATE_CONTENT = @Microsoft.KeyVault(SecretUri=https://mykeyvault.vault.azure.net/secrets/IdentityCert/5221036c6b734d5fa69cba29976a8592) </code></pre>  <p>And then just use this value inside my code:</p>  <pre><code>var certificateContent = Env.GetString(\""CERTIFICATE_CONTENT\"");  identityServerBuilder.AddSigningCredential(new X509Certificate2(Convert.FromBase64String(certificateContent))); </code></pre>  <p>But this doesn't work either.</p>  <p>I've enabled the managed identity in the App Service and added it to the Access Policies in the Key Vault.</p>  <p>How can I get the value from Key Vault? Is there anything I'm missing? </p>""",azure-web-app-service
48569126,"How does Azure Function Continuous Deployment handle environment-specific transforms? <p>I have a set of functions  some of which require environment-specific connections to Event Hubs  i.e.  Function App A connects to Event Hub A  Function App B connects to Event Hub B. Given that the CD model uses branch-per-environment  how can I maintain the separate copies of function.json that drive that integration?</p>  <p>The dumb answer is  obviously  maintain a separate copy of function.json on each branch. This is dumb because that means \be really careful not to accidentally merge over top of your environment-specific copy and be really sorry when you forget\"". Ideally  there'd be something like maintaining environment specific copies  like function.DEV.json and function.QA.json. But this does not appear to be the case.</p>  <p>My function.json looks like this:</p>  <pre><code>{       \""bindings\"": [         {           \""type\"": \""eventHubTrigger\""            \""name\"": \""myEventHubMessage\""            \""direction\"": \""in\""            \""path\"": \""iot-e1-ehub-dev-deviceevents-01\""            \""connection\"": \""iot-e1-ehub-dev-deviceevents-01_iothubroutes_iot-e1-iot-dev-01_EVENTHUB\""         }       ]        \""disabled\"": false } </code></pre>  <p>So  those path and connection elements need to be different for each environment. If there's a way to manage that binding outside of function.json  I don't know about it.</p>  <p>Is there a better solution?</p>""",azure-functions
45234346,Unable to access my .net website from internet <p>I am new to networking and routing.</p>  <p>I have hosted my website (enabled https) in azure vm having firewall settings. Have opened the ports for the websites.</p>  <p>But still unable to access my website from internet.</p>  <p>I have 2 sites running. the main website which is running on port 443. To access this site   it is directed to openid oauth2 identity site running on port 44300. Both the ports are opened. The site is running perfect when i access from the hosted server and also other servers.</p>  <p>I am trying to access this main site from my home internet. It is not working.I want to access this site from internet as well.</p>  <p>additional info:</p>  <p>Main website hosted in server which is connected to internet with a Connection which has got a IPv4 Default Gateway - eg; A</p>  <p>My own pc connected to internet with a different connection with different IPv4 Default Gateway.</p>  <p>With this above setup  it is possible to achieve my requirement?</p>  <p>Can anyone help what has to be done to access my website from outside world?</p>  <p>Thanks</p>,azure-virtual-machine
29598383,"Sql instance is not opening in Windows azure <p>I've deployed my version in windows azure.</p>  <p>After that I've added sql database. When I trying to connect  it doesn't allow from local. So I've clicked on <strong>\Set up Windows Azure firewall rules for this IP address\""</strong> and added ip address. Now working fine when I run from local.</p>  <p>But When I tried to access from the iis8  I got an isssue is </p>  <p><strong>A network-related or instance-specific error occurred while establishing a connection to SQL Server. The server was not found or was not accessible. Verify that the instance name is correct and that SQL Server is configured to allow remote connections. (provider: TCP Provider  error: 0 - No such host is known.) .Net SqlClient Data Provider</strong>.</p>  <p>In local  the same functionality is working fine.</p>""",azure-storage
53518077,CS0433: The type 'X' exists in both 'A' and 'B' - Clear Temporary ASP.NET Files from Azure AppService as part of Azure Devops release pipeline? <p>When I try to reach for the site I'm getting the error on the title. Web Application project running on an App Services on Azure. Being deployed through Azure Devops.</p>  <p>When On premises I used to manually delete the Temporary ASP.NET Files and the site would recompile and this problem would no longer occurr. But now I'm trying to create a release pipeline on Azure Devops and reaching this error  so if I had in fact to clear those files every deploy  then it shoul be a part of my pipepline. Is this the correct approach? If so  how it can be done?</p>,azure-devops
54620800,"Azure Event Hub/Azure Function - Singleton <p>Is it possible for an Azure Function to read messages from an Azure Event Hub by a single thread?</p>  <p>I'm trying to perform in-order processing as the article below shows but I think a second Azure Function thread is picking up event hub message data causing data issues.</p>  <p><a href=\https://medium.com/@jeffhollan/in-order-event-processing-with-azure-functions-bb661eb55428\"" rel=\""nofollow noreferrer\"">https://medium.com/@jeffhollan/in-order-event-processing-with-azure-functions-bb661eb55428</a></p>""",azure-functions
53425806,How to get whole code deployment history in Azure WebApp? <p>Need to get the code deployment data for my Azure WebApp. Since the App has been accessed by multiple team members and I am unable to trace When   Who(Name or email if of the person) has done the deployment with timestamp.</p>,azure-web-app-service
48791242,"How to migrate to a non-SQL Server virtual machine <p>I provisioned an Azure VM with SQL Server pre-installed on Azure  but the decision has been made to re-install SQL Server with a different license. According to <a href=\https://docs.microsoft.com/en-us/azure/virtual-machines/windows/sql/virtual-machines-windows-sql-server-iaas-faq\"" rel=\""nofollow noreferrer\"">Azure documentation</a> that means that I need to \""deploy a new virtual machine and migrate the data and applications to the new virtual machine\"". Can I back up the OS VHD and migrate that to a new Azure VM without losing the applications and other prep work that's already been done and as a result drop the extra costs associated with using a SQL Server VM? How would I go about doing that?</p>""",azure-virtual-machine
16958910,"Set metadata in REST request to put blob in AZURE <p>i am able to upload file to azure blob using REST api provided by Azure.</p>  <p>i want to set metadata at the time i am doing request for put blob  when i am setting it into header as shown <a href=\http://msdn.microsoft.com/en-us/library/windowsazure/dd179362.aspx\"" rel=\""nofollow noreferrer\"">here</a> i am unble to upload file and getting following exception <code>org.apache.http.client.ClientProtocolException</code>.</p>  <p>from the last line of the code below</p>  <pre><code>    HttpPut req = new HttpPut(uri);     req.setHeader(\""x-ms-blob-type\""  blobType);     req.setHeader(\""x-ms-date\""  date);     req.setHeader(\""x-ms-version\""  storageServiceVersion);     req.setHeader(\""x-ms-meta-Cat\""  user);     req.setHeader(\""Authorization\""  authorizationHeader);      HttpEntity entity = new InputStreamEntity(is blobLength);     req.setEntity(entity);      HttpResponse response = httpClient.execute(req); </code></pre>  <p>regarding the same  i have two questions.</p>  <ol> <li><p>can setting different metadata  avoid overwriting of file? <a href=\""https://stackoverflow.com/q/16958629/2381006\"">See my question for the same here</a></p></li> <li><p>if Yes for first question  how to set metadata in REST request to put blob into Azure?</p></li> </ol>  <p>please help</p>""",azure-storage
30410040,Can I install MySQL on the VMs provided in Azure Cloud Services? <p>From what I gather  the only way to use a MySQL database with Azure websites is to use Cleardb but can I install MySQL on VMs provided in Azure Cloud Services. And if so how?</p>,azure-virtual-machine
56422176,Azure CosmosDB Trigger to update a Collection based on Value in another Collection <p>I have to update a cosmosDB Collection(let be collection-1) based on value of a column in another cosmosDB Collection(let be collection-2). The collection-1 should be updated with values from other collections like collection-3 and collection-4. i have tried with writing post trigger in Collection-2 but stuck while writing function inside trigger.</p>  <p>Please suggest whether it is possible with CosmosDB Trigger or suggest If there Is any alternative way to achieve this.</p>  <p>I have created a new trigger function for cosmos DB. </p>,azure-functions
33386280,"How to start a azure deallocated vm? <p>I needed to do a vm backup and I followed this article: <a href=\https://azure.microsoft.com/en-us/documentation/articles/virtual-machines-linux-capture-image/\"" rel=\""nofollow noreferrer\"">https://azure.microsoft.com/en-us/documentation/articles/virtual-machines-linux-capture-image/</a></p>  <p>So  I executed: azure vm shutdown vm-1</p>  <p>But now I really need to start the deallocated vm but I don't know how to do it.</p>  <p>When I try to execute this command: Start-AzureVM -ServiceName \""vm-1\"" -Name \""vm-1\""</p>  <p>I'm getting this message: No deployment found in service: 'vm-1'.</p>  <p>And when I try to list all my vm  I don't see vm-1</p>  <p>Any idea of how to start a deallocated vm?</p>  <p>Thanks</p>""",azure-virtual-machine
53489071,Azure Functions Cannot access a disposed of object <p>I am converting HTML to pdf using NReco in azure functions. It used to work properly but when I deployed in another slot I am getting below error. </p>  <pre><code>Assembly reference changes detected. Restarting host... Environment shutdown has been triggered. Stopping host and signaling shutdown. completed successfully Function completed (Success  Id=d5042f25-18d9-489a-81fe-05ae07607012  Duration=10921ms) Executed 'AzureBillFunc' (Succeeded  Id=d5042f25-18d9-489a-81fe-05ae07607012) The host started (12276ms) A ScriptHost error has occurred Microsoft.Azure.WebJobs.Host: Cannot access a disposed of object. Stopping Host </code></pre>  <p>can I know what's happening in the above steps? </p>,azure-functions
52958046,"How to connect ASP.NET Web Api project with hosted mySQL database? <p>I am working with an api web application that is connected to mysql database using Visual Studio for Mac  my problem is that when I try to connect with hosted mysql db in the server I got the following exception \Unable to connect to any of the specified MySQL hosts.\"" However  when you connect to the local db mysql by using XAMPP  the connection works well and successfully.</p>  <p>here is my code.</p>  <p>in Program.cs</p>  <pre><code>  public static MySqlConnection Conn(){           var connection_string = \""Data Source=MYSQL5015.site4now.net;Initial Catalog=db_a42078_holzqp;User ID=xxxxxx;Password=xxxxxxx\"";          var conn = new MySqlConnection(connection_string);          return conn;     } </code></pre>  <p>in ValuesController.cs</p>  <pre><code>public string Get(int id){          conn = Program.Conn();         try         {             conn.Open();         }         catch (MySqlException ex)         {             return \""Failure: \"" + ex.Message.ToString();         }         if(conn.State == System.Data.ConnectionState.Open){             return \""opened\"";         }else{             return \""closed\"";         }} </code></pre>  <p><strong>Note</strong> : i also tried the standard mysql connection string like \""SERVER:XXX;DATABASE=XXX;UID=XXXX;PWD=XXXX\"" and i got the same exception.</p>  <p>please help and thanks for all </p>""",azure-web-app-service
53673801,Docker: Error starting userland proxy: Bind for 0.0.0.0:50000: unexpected error Permission denied on Azure VM <p>I'm new to Docker so please be kind but I am testing it out on a Windows 10 image on Azure (I know I could run it directly but I wanted to try it in a VM first).</p>  <p>I have a fresh Windows 10 image that I have installed Docker for Windows 2.0.0 on. Note:  I did not tick the option to use Windows containers instead of linux containers.</p>  <p>Once it installed (and rebooted) I was prompted to install Hyper-V and Containers features (causing restarts).</p>  <p>Once it was all installed I open an Administrative PowerShell window to download Jenkins:</p>  <pre><code>docker run -p 8080:8080 -p 50000:50000 -v jenkins_home:/var/jenkins_home jenkins/jenkins:lts </code></pre>  <p>This gave me the error:</p>  <pre><code>C:\Program Files\Docker\Docker\Resources\bin\docker.exe: Error response from daemon: driver failed programming external connectivity on endpoint goofy_lederberg (deaba2deeea0486c92ba8a1a32740295f03859b1b5829d39e39eff0b24613ebf): Error starting userland proxy: Bind for 0.0.0.0:50000: unexpected error Permission denied. </code></pre>  <p>I thought this was strange as 50000 wasn't a port that I expected to be in use  changing this to different ports (50001) produced the same error.</p>  <p>Running:</p>  <pre><code>netstat -a -n -o </code></pre>  <p>Showed that the port was not in use.</p>  <p>If I remove -p 50000:50000 from the command it can bind and start Jenkins but I assume it needs this port mapping to work correctly.</p>  <p>Previous posts have suggested stopping the World Wide Web Publishing service but that isn't installed.</p>  <p>There are no other running Docker containers.</p>  <p>I assume the port is in use or something is stopping the port mapping.</p>  <p>Assuming a user has permission to create a port binding from their terminal are there any other techniques beside netstat to determine if something is bound to a port - either something internal to docker's own checking process or something at the host OS level?</p>,azure-virtual-machine
52823650,"Selenium screenshots in VSTS (Azure DevOps) <p>According to my searches  it should \just work\"". <a href=\""https://docs.microsoft.com/en-us/azure/devops/test/collect-screenshots-and-video?view=vsts\"" rel=\""nofollow noreferrer\"">This</a> is the best article I found. I've followed the steps  but nowhere in the VSTS (Azure DevOps) interface does it indicate there are any screenshots attached.</p>  <p>I am running this on a privately hosted build server and I have verified the following:</p>  <ol> <li>Screenshots are being created and saved to disk</li> <li>The resulting TRX file (I'm using MSTEST framework) does have a ResultFile reference (a path to the image file)</li> <li>The TRX file is uploaded to VSTS and I can download it and see that the ResultFile is still in the TRX.</li> </ol>  <p>I'm not sure what I am missing in order to get this to work. Any help would be appreciated.</p>""",azure-devops
45567836,"SQLVDI error when backing up to Azure Storage BLOB <p>I'm running a patched SQL 2014 trying to backup a database to one of our Azure Storage BLOBs  using:</p>  <pre><code>BACKUP DATABASE [DB] TO URL = N'https://storage.blob.core.windows.net/server-mssqlserver/DB.bak' WITH CREDENTIAL = N'AzureCredential'      NOFORMAT      NOINIT      NAME = N'DBA_DB-Full Database Backup'      NOSKIP      NOREWIND      NOUNLOAD      COMPRESSION      STATS = 5 GO </code></pre>  <p>but the query throws the following error:</p>  <blockquote>   <p>Msg 3292  Level 16  State 9  Line 1<br>   A failure occurred while attempting to execute Backup or Restore with a URL device specified. Consult the Windows Event Log for details.<br>   Msg 3013  Level 16  State 1  Line 1<br>   BACKUP DATABASE is terminating abnormally.</p> </blockquote>  <p>Checking the server's Event Logs shows the actual error as:</p>  <blockquote>   <p>SQLVDI: Loc=IdentifySQLServer. Desc=MSSQLSERVER. ErrorCode=(5)Access is denied.<br>   . Process=4668. Thread=6596. Client. Instance=MSSQLSERVER. VD=.</p> </blockquote>  <p>I have made sure that the <strong>SQL Server Agent</strong> service's account has the <strong>Create global objects</strong> policy  and also made sure the <strong>SQL VSS Writer</strong> service is running under the <strong>Local System</strong> account. The error keeps happening!</p>  <p>Is there something I can do to fix it  or just log some more detailed error messages than the \SQLVDI: Loc=IdentifySQLServer\"" one above?</p>""",azure-storage
11140588,"Processing a Message Queue and Using Async <p>I wrote a small test node app that loops and adds messages to a queue (azure storage queue)  something like this:</p>  <pre class=\lang-js prettyprint-override\""><code>var queueService = azure.createQueueService(); var queueName = 'taskqueue';  // other stuff like check if created  // loop called after queue is confirmed  for (i=0;i&lt;1000;i++){   queueService.createMessage(queueName  \""Hello world!\""  null  messageCreated); }  // messageCreated does nothing at the moment  just logs to console </code></pre>  <p>I'm trying to rewrite that to handle say 1 million create's using async to control the number of worker functions that are run in parallel.  This is a learning exercise more than anything.</p>  <p><a href=\""https://github.com/caolan/async#queue\"" rel=\""nofollow\"">https://github.com/caolan/async#queue</a></p>  <p>This is the basic setup for async's queue and I'm kind of at a loss as to what I need to change. I don't think the below will work:</p>  <pre class=\""lang-js prettyprint-override\""><code>var q = async.queue(function (task  callback) {    queueService.createMessage(queueName  task.msg  null  messageCreated);     callback(); }  100);   // assign a callback.  Called when all the queues have been processed q.drain = function() {     console.log('all items have been processed'); }  // add some items to the queue for(i=0;i&lt;1000000;i++) {   q.push({msg: 'Hello World'}  function (err) {     console.log('finished processing foo');   });     console.log('pushing: ' + i); } </code></pre>  <p>I'm not quite grasping how to pull it all together with async.</p>""",azure-storage
50650676,Use Virtual Machine Extension against multiple VMs <p>With Terraform  is it possible to create a single Virtual Machine Extension and use it against multiple VMs?  What happens when I destroy (using Terraform) one of the VMs that I used the extension on?</p>  <p>UPDATE: I was able to determine that you can't do what I was wanting to which is to create a single CSE and use it against multiple machines.  One of the properties of the a CSE is the name of the computer and if you were to change that after the CSE is created  it will re-create the CSE.  Not the behavior I was looking for.</p>,azure-virtual-machine
38379129,TeamCity Build Agent name is not picked up from config file <p>I have recently setup a VM on azure to use as my build agent. When the agent is started its name is calculated based on the azure instance name (_myservername) and the name I provide in the <code>buildAgent.properties</code> file is ignored completely.</p>  <p>This is particularly problematic when I have a second agent and the same name is chosen which will result in name conflict.</p>  <p>looking at the <code>teamcity-agent.log</code> I can see the following lines:</p>  <pre><code>[2016-07-14 15:33:04 745]   WARN - ds.azure.AzurePropertiesReader - Unable to set self port. Azure integration will experience problems  [2016-07-14 15:33:04 745]   INFO - ds.azure.AzurePropertiesReader - Added alternative address is set to   [2016-07-14 15:33:04 745]   INFO - ds.azure.AzurePropertiesReader - Instance name and agent name are set to _myservername ... </code></pre>  <p>Question is:</p>  <ul> <li>Why is the name I provide via config file is not taking precedence over any other place it reads the name from? -- should it?</li> <li>How can I possibly force a name on it? </li> </ul>,azure-virtual-machine
51712866,"Add MSDN subscribers to Visual Studio Team Services account <p>Can a MSDN Visual Studio Professional subscriber be added as user to two or more TFS and/or VSTS accounts? I am setting up our own VSTS account and I want to add a contractor as a user with MSDN VS Professional subscription but he also uses it to access his company's TFS. Thanks.</p>  <p>This <a href=\https://docs.microsoft.com/en-us/vsts/organizations/security/add-users-team-project?view=vsts\"" rel=\""nofollow noreferrer\"">MS document</a> does not answer my question explicitly. </p>""",azure-devops
56980969,Best way to download many images into Azure App Service .Net Core app for processing <p>I have over 500 large image files that I need to process in my .NET Core app hosted in an Azure App Service. That said  I need to download all of the images and run them through a machine learning categorization function in my code. I currently use blob storage as my mechanism for storing the images  but downloading all those images via blob rest api is slow. Is there a better architecture in Azure that I should be making use of to greatly increase performance of processing these images? Perhaps a storage mechanism much faster than blob storage?</p>,azure-web-app-service
54348395,"source link will download from the internet <p>I have an existing Azure functions(Version 1 V1).I want to migrate them to Version 2 (V2). Azure Function V1 (.NET 4.61 / WebAPI 2). Azure Function V2 (ASP.NET Core / MVC 6).</p>  <p>I created the AF-V2 and tried to call(class library .dll written in .NET 4.61) from AF-V2: it built successfully.</p>  <pre><code>[FunctionName(\MyFunctionV2\"")]     public static async Task&lt;IActionResult&gt; Run(         [HttpTrigger(AuthorizationLevel.Function  \""post\""  Route = \""MyFunctionV2\"")] HttpRequest req          ILogger log)     {         MyDllClass.InitializeSomething(parameter1  parameter2);//exception encountered here.         //my codes </code></pre>  <p>When I debug the code  it(<strong><em>MyDllClass.InitializeSomething(parameter1  parameter2);</em></strong>) encountered the following popup stating <strong><em>source link will download from the internet</em></strong>. <a href=\""https://i.stack.imgur.com/Yve74.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/Yve74.png\"" alt=\""enter image description here\""></a></p>  <p>I have few questions related:</p>  <ol> <li>What exactly does <strong><em>source link will download from the internet</em></strong> mean?</li> <li>How can I call .NET 4.61 classLibrary dll from AF-V2?</li> <li>I am stuck to google out the exact issue  much appreciated yours help. </li> </ol>""",azure-functions
35713239,"Azure Scheduler Job Collection integration with Resource Manager Deployment Model Storage Queue <p>I am attempting to create a new <code>Azure Scheduler Job</code> that has a <code>Storage queue</code> action  but the only Storage Accounts that I am able to select from my Azure Subscription are \Classic\"" Storage Accounts  I can not select a \""Resource Manager\"" Storage Account.</p>  <p>Are <code>Azure Scheduler Job</code>s not compatible with \""Resource Management\"" Storage Accounts?</p>""",azure-storage
55012229,Azure JavaScript Function Out to Service Bus Queue <p>I have a Service Bus Queue which is has duplicate detection set on.</p>  <p>A Function is triggered via CosmosDb in which it needs to then create a message in the Service Bus Queue; however  each attempt fails with a duplicate message error requiring MessageId.</p>  <p>Is there a Javascript SDK the function can access to create a new valid message payload?</p>  <p>If not  what is the message payload supposed to look like?</p>,azure-functions
52259592,"How to handle Outage images in Azure WebApp <p>We are hosting our website in Azure. During the deployment(TFS) we will do the below Steps as the part of the deployment pipeline.</p>  <ol> <li>Stop the WebApp</li> <li>Deploy Web App Service</li> <li>Start the WebApp</li> </ol>  <p>After the 1st step  if anyone tries to access our website  then by default Azure will return the below page</p>  <p><a href=\https://i.stack.imgur.com/zXQzr.jpg\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/zXQzr.jpg\"" alt=\""enter image description here\""></a></p>  <p>We really don't want our users to show this page during the outage. We are planning to show our own outage image/page in such case.</p>  <p>Is there is any way to achieve this?</p>  <p>Since Azure Web Apps in a Paas model  I'm wondering how to do this?</p>  <p>Any inputs Appreciated!</p>""",azure-web-app-service
8427162,"How to fetch the Group of files placed in azure storage container to local machine using SSIS <p>The link mentioned below explains clearly how to fetch single file  <a href=\https://stackoverflow.com/questions/6684317/making-an-http-request-from-ssis/6684780#6684780\"">enter link description here</a></p>  <p>What changes i need to make to my SSIS script task to fetch the group of files placed in my azure container </p>""",azure-storage
46382973,"How to run npm install during VSTS Build <p>I have setup a VSTS build for a .NET Core application and am having a problem getting the node_modules included in the generated artifact.  Below is the Build Pipeline <a href=\https://i.stack.imgur.com/0HaDl.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/0HaDl.png\"" alt=\""enter image description here\""></a></p>  <p>As I watch the build run I see it go through and do the restore of the node_modules  but after it finishes the build successfully I look in the artifact that it generates and I do see the node_modules directory.  </p>  <p>What am I missing?</p>""",azure-devops
33109611,Can't connect to remote desktop on azure virtual machine <p>I uploaded a hyper-v VHD file to storage.  I then created a Windows VM from disk and specified that it contains the operating system.   Azure says the machine is running and the remote desktop and powershell endpoints are configured.    However  When I click connect I get the standard rdp error.</p>  <p>I have resized the VM and restarted the VM a few times to no avail.  </p>  <p>Clicking Reset Remote Connection has failed in the Azure Preview Portal.   This button is now disabled.</p>  <p>When I run (Get-AzureVM -ServiceName XXXXXX -Name XXXXXX).GuestAgentStatus  it returns:</p>  <pre><code>ProtocolVersion   : 1.0 TimestampUtc      : 10/13/2015 2:02:29 PM GuestAgentVersion : Unknown Status            : NotReady Code              : Message           : FormattedMessage  : Microsoft.WindowsAzure.Commands.ServiceManagement.Model.GuestAgentFormattedMessage ExtensionData     : </code></pre>,azure-virtual-machine
25455085,"Powershell Connect to VSO <p>I'm trying to use Powershell to connect to VSO. Here is my code:</p>  <pre><code>$tfsServer = New-Object System.Uri(\the server is here\"") $creds = [System.Net.CredentialCache]::DefaultNetworkCredentials $tfsCollection = New-Object Microsoft.TeamFoundation.Client.TfsTeamProjectCollection($tfsServer $creds) $tfsCollection.Authenticate() </code></pre>  <p>When it reaches the Authenticate line  it pops up a box for me to enter my credentials. I need it to not pop up this box  as this script will be scheduled  and I can't keep entering the credentials. How can I pass the current user's credentials to the TFS object?</p>""",azure-devops
54514585,"Running JaCoCo in Azure DevOps for Android : Could not find method jacocoTestReport() <p>We have implemented Jacoco in our Android Kotlin project which we can call locally via <strong>./gradlew  clean build jacocoTestReport</strong></p>  <p>However  when we deploy to VSTS/Azure DevOps it errors with:</p>  <pre><code>2019-02-04T09:37:35.5760285Z BUILD SUCCESSFUL in 12s 2019-02-04T09:37:35.5760428Z 1 actionable task: 1 executed 2019-02-04T09:37:35.5801607Z SYSTEMVSSCONNECTION exists true 2019-02-04T09:37:35.5816653Z [command]C:\\Windows\\system32\\cmd.exe /D /S /C \C:\\vstsagent\\A1\\_work\\2\\s\\ApolloClient\\gradlew.bat clean build jacocoRootReport\"" 2019-02-04T09:37:36.7652264Z  2019-02-04T09:37:36.7653533Z FAILURE: Build failed with an exception. 2019-02-04T09:37:36.7653767Z  2019-02-04T09:37:36.7653947Z * Where: 2019-02-04T09:37:36.7654401Z Build file 'C:\\vstsagent\\A1\\_work\\2\\s\\ApolloClient\\build.gradle' line: 44 2019-02-04T09:37:36.7654582Z  2019-02-04T09:37:36.7654768Z * What went wrong: 2019-02-04T09:37:36.7654952Z A problem occurred evaluating root project 'ApolloClient'. 2019-02-04T09:37:36.7655191Z &gt; Could not find method jacocoTestReport() for arguments [build_abtyecjstjhjqmdmcxnlw2kq0$_run_closure4$_closure8@50246031] on project ':app' of type org.gradle.api.Project. 2019-02-04T09:37:36.7655365Z  2019-02-04T09:37:36.7655547Z * Try: 2019-02-04T09:37:36.7655747Z Run with --stacktrace option to get the stack trace. Run with --info or --debug option to get more log output. Run with --scan to get full insights. 2019-02-04T09:37:36.7655931Z  2019-02-04T09:37:36.7656098Z * Get more help at https://help.gradle.org 2019-02-04T09:37:36.7656242Z  2019-02-04T09:37:36.7656585Z BUILD FAILED in 1s 2019-02-04T09:37:37.1999815Z Error: C:\\vstsagent\\A1\\_work\\2\\s\\ApolloClient\\gradlew.bat failed with return code: 1 2019-02-04T09:37:37.1999996Z     at ChildProcess.&lt;anonymous&gt; (C:\\vstsagent\\A1\\_work\\_tasks\\Gradle_8d8eebd8-2b94-4c97-85af-839254cc6da4\\2.143.2\\node_modules\\vsts-task-lib\\toolrunner.js:639:25) 2019-02-04T09:37:37.2000102Z     at emitTwo (events.js:106:13) 2019-02-04T09:37:37.2000154Z     at ChildProcess.emit (events.js:191:7) 2019-02-04T09:37:37.2000226Z     at maybeClose (internal/child_process.js:886:16) 2019-02-04T09:37:37.2000286Z     at Process.ChildProcess._handle.onexit (internal/child_process.js:226:5) </code></pre>  <p>What I don't understand is  is it looking for a task called <strong>jacocoRootReport</strong> or <strong>jacocoTestReport</strong>?</p>""",azure-devops
32304661,How to upload files into azure media services directly from client(azure website)? <p>How to upload files into azure media services directly from client browser using (azure hosted website) ?and also to azure blob storage using azure website  without using any intermediate server.</p>,azure-storage
45452899,Azure VM to Ubuntu 16.04 <p>I am setting up a Ubuntu remotely  but instead of seeing the desktop version of it I been told to use this Power Shell  since I am out to office  I am trying to put some command to this Ubuntu VM as I use Chrome Remote Desktop to access it from my iPhone  can it be possible that I am not allowed to do it from my iPhone?</p>,azure-virtual-machine
53536436,How to open Hive Port 10001 on HDInsight cluster on Azure without creating VM <p>I have my cluster connection string (xxxxx.azurehdinsight.net) however when I try to connect to it I am getting time out.</p>  <p>I believe this is due to the fact that I have not opened port 10001 to public. How can I do this as under the cluster I only have Hadoop Services and username  I don't want to deploy any VM on azure.</p>,azure-virtual-machine
46425322,Get Message metadeta for queue trigger azure webjob <p>We have below code to QueueTrigger and we want to have message metadata(ie: dequequecount  lastretrival) at ProcessQueueMessage. Is there way to achive it?</p>  <pre><code> public static void ProcessQueueMessage([QueueTrigger(AppConstants.AzureBlobQueue)] string message  TextWriter log  ExecutionContext context)     {         try         {             //Do Something             log.WriteLine(message);         }         catch (Exception ex)         {             if(message.DequeueCount == 1)             {               //Logic 1 to notify              }              if(message.DequeueCount == 2)             {               //Logic 2 to notify              } if(message.DequeueCount == 3)             {               //Logic 3 to notify              } if(message.DequeueCount == 4)             {               //Logic 4 to notify              } if(message.DequeueCount == 5)             {               //Logic 5 to notify              }         }      } </code></pre>  <p>We have different logic for dequeue count == 5 we want to move message to db  we can achive it via queue-poison but just does not want to add another webjob/function for same.</p>,azure-functions
39287865,"SonarQube analysis failed in VSTS with Remote Agent <p>SonarQube analysis failed in VSTS with Remote Agent but working fine in hosted agent. Java path is set correctly in my remote machine where the agent is installed  \C:\\Program Files\\Java\\jre1.8.0_92\"" ... still facing the same issue</p>  <pre><code>&gt; SONAR_RUNNER_OPTS is not configured. Setting it to the default value &gt; of -Xmx1024m Calling the SonarQube Scanner... ERROR: JAVA_HOME exists &gt; but does not point to a valid Java home folder. No \""\\bin\\java.exe\"" &gt; file can be found there. The SonarQube Scanner did not complete &gt; successfully 08:21:27.994  Creating a summary markdown file... &gt; Post-processing failed. Exit code: 1 System.Exception: Unexpected exit &gt; code received from batch file: 1 at &gt; Microsoft.TeamFoundation.DistributedTask.Task.Internal.PowerShell.InvokeBatchScriptCmdlet.ProcessRecord() &gt; at System.Management.Automation.CommandProcessor.ProcessRecord() &gt; Waiting on the SonarQube server to finish processing in order to &gt; determine the quality gate status. &gt; System.Management.Automation.RuntimeException: Cannot determine if the &gt; analysis has finished. Possible cause: your SonarQube server version &gt; is lower than 5.3 - for more details see &gt; https://go.microsoft.com/fwlink/?LinkId=722407 ---&gt; &gt; System.Management.Automation.RuntimeException: Cannot determine if the &gt; analysis has finished. Possible cause: your SonarQube server version &gt; is lower than 5.3 - for more details see &gt; https://go.microsoft.com/fwlink/?LinkId=722407 &gt; --- End of inner exception stack trace --- at System.Management.Automation.Runspaces.PipelineBase.Invoke(IEnumerable &gt; input) at &gt; System.Management.Automation.PowerShell.Worker.ConstructPipelineAndDoWork(Runspace &gt; rs  Boolean performSyncInvoke) at &gt; System.Management.Automation.PowerShell.Worker.CreateRunspaceIfNeededAndDoWork(Runspace &gt; rsToUse  Boolean isSync) at &gt; System.Management.Automation.PowerShell.CoreInvokeHelper[TInput TOutput](PSDataCollection`1 &gt; input  PSDataCollection`1 output  PSInvocationSettings settings) at &gt; System.Management.Automation.PowerShell.CoreInvoke[TInput TOutput](PSDataCollection`1 &gt; input  PSDataCollection`1 output  PSInvocationSettings settings) at &gt; Microsoft.TeamFoundation.DistributedTask.Handlers.PowerShellHandler.Execute(ITaskContext &gt; context  CancellationToken cancellationToken  Int32 timeoutInMinutes) &gt; at &gt; Microsoft.TeamFoundation.DistributedTask.Worker.JobRunner.RunTask(ITaskContext &gt; context  TaskWrapper task  CancellationTokenSource tokenSource) &gt; ****************************************************************************** Finishing task: SonarQubePostTest &gt; ****************************************************************************** System.Exception: Task SonarQubePostTest failed. This caused the job &gt; to fail. Look at the logs for the task for more details. at &gt; Microsoft.TeamFoundation.DistributedTask.Worker.JobRunner.Run(IJobContext &gt; jobContext  IJobRequest job  IJobExtension jobExtension  &gt; CancellationTokenSource tokenSource) &gt; ****************************************************************************** Finishing Build &gt; ****************************************************************************** </code></pre>""",azure-devops
10742719,"How to estimate Windows Azure Table storage query performance? <p>I'd like to evaluate how my Windows Azure Table store queries scale. For this purpose  I've put together a simple test environment  where I can increase the amount of data in my table  and measure the execution times of the queries. And based on the times I'd like to define a cost function that could be used to evaluate the performance of future queries.</p>  <p>I've evaluated the following queries: </p>  <ol> <li>Query with PartitionKey and RowKey</li> <li>Query with PartitionKey and an attribute</li> <li>Query with PartitionKey and two RowKeys</li> <li>Query with PartitionKey and two attributes</li> </ol>  <p>For the last two queries I've checked the following two patterns:</p>  <ol> <li>PartitionKey == \...\"" &amp;&amp; (RowKey == \""...\"" || RowKey == \""...\"")</li> <li>(PartitionKey == \""...\"" &amp;&amp; RowKey == \""...\"") || (PartitionKey == \""...\"" &amp;&amp; RowKey == \""...\"")</li> </ol>  <p>To minimize the transfer delay  I've executed the test on an Azure instance. From the measurements  I can see that </p>  <ul> <li>query 1 (not surprisingly  as the table is indexed based on those fields) is extremely fast  it's about 10-15ms if I have about 150000 entries in the table.  </li> <li>query 2 requires a partition scan  so the execution time is increasing linearly with the stored data. </li> <li>query 3.1 performs almost exactly as query 2. So this query is also executed with a full partition scan  which for me seems a bit odd.</li> <li>query 4.1 is a bit more than two times slower than query 3.1. So it seems like it is evaluated with two partition scans.</li> <li>and finally  query 3.2 and 4.2 performs almost exactly 4 times slower than query 2.  </li> </ul>  <p>Can you explain the internals of the query/filter interpreter? Even if we accept that query 3.1 needs a partition scan  query 4.1 could also be evaluated with the same logic (and under the same time). Query 3.2 and 4.2 seems like a mystery for me. Any pointers on those?</p>  <p>Obviously the whole point to this is that I'd like to query distinct elements within one query to minimize cost meanwhile not losing performance. But it seems like using separate queries (with Task Parallel Library) for each element is the only real fast solution. What is the accepted way of doing this?</p>""",azure-storage
56635520,"Uploading a file to a blob container seems to leak channels <p>I am new to Azure  and I am using azure-storage-blob v11.0.0 for java and trying to upload a file by following the sample here <a href=\https://github.com/Azure-Samples/storage-blob-java-getting-started\"" rel=\""nofollow noreferrer\"">https://github.com/Azure-Samples/storage-blob-java-getting-started</a></p>  <p>This is upload as expected  but I my application is kept alive  there seems to be a remote socket timeout that will lead to generate and exception :</p>  <pre><code>18:16:46.528 23751 [nioEventLoopGroup-1-1] INFO  com.microsoft.azure.storage.blob.LoggingFactory$LoggingPolicy - Successfully Received Response Request try:'1'  request duration:'1271' ms  operation duration:'1271' ms PUT: https://REDACTED.blob.core.windows.net/REDACTED/REDACTED.wav Authorization: REDACTED Content-Length: 275244 x-ms-version: 2018-11-09 x-ms-date: Mon  17 Jun 2019 16:16:45 GMT host: REDACTED.blob.core.windows.net Content-Type: application/octet-stream connection: keep-alive x-ms-client-request-id: c78bf188-f604-40da-b5a9-340eaad045bd x-ms-blob-type: BlockBlob User-Agent:  Azure-Storage/11.0.0 (JavaJRE 1.8.0_212; Linux 4.19.49-1-MANJARO)  18:16:46.540 23763 [nioEventLoopGroup-1-1] DEBUG AzureCopy - Completed upload request. : 201 18:16:46.541 23764 [nioEventLoopGroup-1-1] DEBUG com.microsoft.rest.v2.http.SharedChannelPool - Channel released to pool: 77156491 18:19:48.496 205719 [nioEventLoopGroup-1-2] WARN  com.microsoft.rest.v2.http.NettyClient$AcquisitionListener - Error emitted on channel 8afa7171. Message: Connexion ré-initialisée par le correspondant 18:19:48.500 205723 [nioEventLoopGroup-1-2] DEBUG com.microsoft.rest.v2.http.NettyClient$AcquisitionListener - Stack trace:  java.lang.Exception: null     at com.microsoft.rest.v2.http.NettyClient$AcquisitionListener.emitError(NettyClient.java:427)     at com.microsoft.rest.v2.http.NettyClient$HttpClientInboundHandler.exceptionCaught(NettyClient.java:890)     at io.netty.channel.AbstractChannelHandlerContext.invokeExceptionCaught(AbstractChannelHandlerContext.java:297)     at io.netty.channel.AbstractChannelHandlerContext.invokeExceptionCaught(AbstractChannelHandlerContext.java:276)     at io.netty.channel.AbstractChannelHandlerContext.fireExceptionCaught(AbstractChannelHandlerContext.java:268)     at io.netty.channel.CombinedChannelDuplexHandler$DelegatingChannelHandlerContext.fireExceptionCaught(CombinedChannelDuplexHandler.java:426)     at io.netty.channel.ChannelHandlerAdapter.exceptionCaught(ChannelHandlerAdapter.java:92)     at io.netty.channel.CombinedChannelDuplexHandler$1.fireExceptionCaught(CombinedChannelDuplexHandler.java:147)     at io.netty.channel.ChannelInboundHandlerAdapter.exceptionCaught(ChannelInboundHandlerAdapter.java:143)     at io.netty.channel.CombinedChannelDuplexHandler.exceptionCaught(CombinedChannelDuplexHandler.java:233)     at io.netty.channel.AbstractChannelHandlerContext.invokeExceptionCaught(AbstractChannelHandlerContext.java:297)     at io.netty.channel.AbstractChannelHandlerContext.invokeExceptionCaught(AbstractChannelHandlerContext.java:276)     at io.netty.channel.AbstractChannelHandlerContext.fireExceptionCaught(AbstractChannelHandlerContext.java:268)     at io.netty.handler.ssl.SslHandler.exceptionCaught(SslHandler.java:1098)     at io.netty.channel.AbstractChannelHandlerContext.invokeExceptionCaught(AbstractChannelHandlerContext.java:297)     at io.netty.channel.AbstractChannelHandlerContext.invokeExceptionCaught(AbstractChannelHandlerContext.java:276)     at io.netty.channel.AbstractChannelHandlerContext.fireExceptionCaught(AbstractChannelHandlerContext.java:268)     at io.netty.channel.DefaultChannelPipeline$HeadContext.exceptionCaught(DefaultChannelPipeline.java:1375)     at io.netty.channel.AbstractChannelHandlerContext.invokeExceptionCaught(AbstractChannelHandlerContext.java:297)     at io.netty.channel.AbstractChannelHandlerContext.invokeExceptionCaught(AbstractChannelHandlerContext.java:276)     at io.netty.channel.DefaultChannelPipeline.fireExceptionCaught(DefaultChannelPipeline.java:918)     at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.handleReadException(AbstractNioByteChannel.java:125)     at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:174)     at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:682)     at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:617)     at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:534)     at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:496)     at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:906)     at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)     at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)     at java.lang.Thread.run(Thread.java:748) 18:19:48.501 205724 [nioEventLoopGroup-1-2] INFO  com.microsoft.rest.v2.http.SharedChannelPool - ---- com.microsoft.rest.v2.http.SharedChannelPool@fbece82: size 768  keep alive (sec) 60 ---- 18:19:48.502 205725 [nioEventLoopGroup-1-2] INFO  com.microsoft.rest.v2.http.SharedChannelPool - Channel    State   For Age URL 18:19:48.504 205727 [nioEventLoopGroup-1-2] INFO  com.microsoft.rest.v2.http.SharedChannelPool - 77156491   AVAIL   181s    182s    https://REDACTED.blob.core.windows.net:443 18:19:48.504 205727 [nioEventLoopGroup-1-2] INFO  com.microsoft.rest.v2.http.SharedChannelPool - 8afa7171   AVAIL   182s    182s    https://REDACTED.blob.core.windows.net:443 </code></pre>  <p>I can still use the application and perform other upload  but I am not really sure if I have to clean any unused connection of anything. Or if I can ignore these errors.</p>  <p>Edit : added code sample used</p>  <pre><code>public class AzureCopy {     private final ContainerURL containerURL;      public AzureCopy() throws InvalidKeyException  MalformedURLException     {         final String accountName = ConfHelper.getString(\""AZURE_ACCOUNT\"");         final String accountKey = ConfHelper.getString(\""AZURE_KEY\"");          final SharedKeyCredentials creds = new SharedKeyCredentials(accountName  accountKey);          final ServiceURL serviceURL = new ServiceURL(new URL(\""https://\"" + accountName + \"".blob.core.windows.net\"")  StorageURL.createPipeline(creds  new PipelineOptions()));          containerURL = serviceURL.createContainerURL(ConfHelper.getString(\""AZURE_CONTAINER\""));     }      public void upload(final File toUpload)     {         if(toUpload != null)         {             final BlockBlobURL blobURL = containerURL.createBlockBlobURL(toUpload.getName());              try             {                 uploadFile(blobURL  toUpload);             }             catch(final IOException e)             {                 e.printStackTrace();             }         }     }      private static void uploadFile(final BlockBlobURL blob  final File sourceFile) throws IOException     {         final AsynchronousFileChannel fileChannel = AsynchronousFileChannel.open(sourceFile.toPath());          TransferManager.uploadFileToBlockBlob(fileChannel  blob  8 * 1024 * 1024  null  null).subscribe(response -&gt; System.out.println(\""Completed upload request. : \"" + response.response().statusCode()));     } } </code></pre>  <p>As you can see this is mainly the sample code that is available on the github without the interactive menu. This class is instantiated at the start of the application  and the upload method is called when we need to upload a file. Nothing more. We don't create a new instance each time  we re-use the same instance when needed.</p>""",azure-storage
56785668,How do I modify unified group custom attributes immediately post creation? <p>I create a unified group using the graph api through a queue-triggered azure function (C#). When created  I want to tag some information on custom attributes and do other exchange-related stuff like hide from GAL. How is this best done?</p>  <p>I have tried using yet another queue-triggered function in order to connect to exchange online with powershell  although I have a hard time getting the credentials right having only clientid  secret and certificate thumbprint in the functions configuration. To run exchange online commandlets it seems like you have to go with actual user credentials (username  password).</p>  <p>I have also explored the possibilities of doing this kind of settings directly from the graph API but it seems limited in this case.</p>,azure-functions
48770322,Configure Self-Signed certificate in azure virtual machine <p>I have a asp.net webapplication which is ssl enabled. I would like to host this in one of the Azure VM. On my local iis   i can create a self-signed certificate. But dont know how to achieve the same on IIS in an azure VM</p>  <p>Can anyone help how to create self-signed certificate and configure the iis in azure VM to use this self-signed cert?</p>  <p>Thanks</p>,azure-virtual-machine
46117177,Azure App Service - Slot swapping files get locked <p>The erorr occurs when there is an acctive traffic to the service 1. Deploy o staging 2. Swap slot with prod 3. application return 502</p>  <p>logs shows</p>  <blockquote>   <p>Microsoft.AspNetCore.DataProtection.Abstractions  Version=1.1.2.0  Culture=neutral  PublicKeyToken=adb9793829ddae60' or one of its dependencies. The process cannot access the file because it is being used by another process. (Exception from HRESULT: 0x80070020)</p> </blockquote>  <p>The error message is not consistent  it could be Swagger DLL was locked or System.IdentityModel.Tokens.Jwt.JwtSecurityTokenHandler.</p>  <p>the big question is. Are slots sharing same files ? how does exactly works ? I ssume that each slot is a separate App .</p>,azure-web-app-service
33494648,"Internet gateway with azure vnet <p>I would like to create an internet gateway in an azure vnet but I don't know what is the better way of do it. I mean when I create a new vm  by default  all the internet requests go throught his own ip address. And I would like that those requests go throught the same ip addrees.</p>  <p>One possibility is to create a linux vm with NAT that works as a internet gateway. And then  I could set all the new vms with that vm as the gateway. But I wonder if there is a better solution. </p>  <p>For example  I've read the following article and it seems that I need: <a href=\https://azure.microsoft.com/en-gb/documentation/articles/virtual-network-create-udr-classic-ps/\"" rel=\""nofollow\"">https://azure.microsoft.com/en-gb/documentation/articles/virtual-network-create-udr-classic-ps/</a></p>  <p>Any ideas?</p>  <p>Thanks!</p>""",azure-virtual-machine
36125930,"Error fetching vm list using azure cli tools <p>I'm using azure tools on mac OS X.  I did run following commands :</p>  <pre><code>1. $ azure login 2. $ azure account download 3. $ azure import .publishsettings 4. $ azure account set \subscription id\"" </code></pre>  <p>But now when I run </p>  <blockquote>   <p>$ azure vm list</p> </blockquote>  <p>it shows following error :</p>  <pre><code>{ [Error: The server failed to authenticate the request. Verify that the certificate is valid and is associated with this subscription.] code: 'ForbiddenError'  statusCode: 403 } Error: The server failed to authenticate the request. Verify that the certificate is valid and is associated with this subscription.     at Function.ServiceClient._normalizeError (/usr/local/lib/node_modules/azure-cli/node_modules/azure-common/lib/services/serviceclient.js:815:23)     at /usr/local/lib/node_modules/azure-cli/node_modules/azure-common/lib/services/filters/errorhandlingfilter.js:44:29     at Request._callback (/usr/local/lib/node_modules/azure-cli/node_modules/azure-common/lib/http/request-pipeline.js:109:14)     at Request.self.callback (/usr/local/lib/node_modules/azure-cli/node_modules/azure-common/node_modules/request/request.js:199:22)     at Request.emit (events.js:98:17)     at Request.&lt;anonymous&gt; (/usr/local/lib/node_modules/azure-cli/node_modules/azure-common/node_modules/request/request.js:1160:14)     at Request.emit (events.js:117:20)     at IncomingMessage.&lt;anonymous&gt; (/usr/local/lib/node_modules/azure-cli/node_modules/azure-common/node_modules/request/request.js:1111:12)     at IncomingMessage.emit (events.js:117:20)     at _stream_readable.js:944:16 </code></pre>""",azure-virtual-machine
46718838,"azure function in java configure using function.json <p>I'm trying to create an Azure Function written in Java and configured using a function.json file (rather than using annotations).</p>  <p>To get started I followed the MS <a href=\https://docs.microsoft.com/en-gb/azure/azure-functions/functions-create-first-java-maven\"" rel=\""nofollow noreferrer\"">tutorial</a> (which works ok).</p>  <p>Next  I tried to modify the class to remove the Function annotations and add a function.json as indicated <a href=\""https://docs.microsoft.com/en-gb/azure/azure-functions/functions-reference-java\"" rel=\""nofollow noreferrer\"">here</a> in the section \""The same function written without annotations\"".</p>  <p>The class source code is now:</p>  <pre><code>public class Function {      public static String hello(String req  ExecutionContext context) {         return String.format(\""Hi  %s!\""  req);     }  } </code></pre>  <p>My function.json file is</p>  <pre><code>{     \""scriptFile\"": \""ServiceBusQueueMsgToLogWriter-1.0-SNAPSHOT.jar\""      \""entryPoint\"": \""com.oneadvanced.adv365.mgdsvc.azure.func.test1.Function.hello\""      \""bindings\"": [     {         \""type\"": \""httpTrigger\""          \""name\"": \""req\""          \""direction\"": \""in\""          \""authLevel\"": \""anonymous\""          \""methods\"": [ \""post\"" ]     }      {         \""type\"": \""http\""          \""name\"": \""$return\""          \""direction\"": \""out\""     }     ] } </code></pre>  <p>The output of running the command:</p>  <pre><code>mvn clean package </code></pre>  <p>Includes the output:</p>  <pre><code>AI: INFO 12-10-2017 21:50  1: Configuration file has been successfully found as resource AI: INFO 12-10-2017 21:51  1: Configuration file has been successfully found as resource [INFO] [INFO] Step 1 of 6: Searching for Azure Function entry points [INFO] Reflections took 33 ms to scan 1 urls  producing 0 keys and 0 values [INFO] 0 Azure Function entry point(s) found. [INFO] [INFO] Step 2 of 6: Generating Azure Function configurations [INFO] No Azure Functions found. Skip configuration generation. </code></pre>  <p>This makes me wonder if the function.json file isn't in the right place...</p>  <p>Does anyone know where the correct place to put the function.json file for an Azure Function written in Java?</p>  <p>I've tried:</p>  <ul> <li>in the root of the project</li> <li>in src/main/resources (which I think would be the standard place for this kind of thing in a typical Java/Maven project)</li> <li>in the same folder as the Java source file</li> </ul>  <p>Same outcome in every case :(</p>  <p>I'd be grateful for any pointers on what I should be doing.</p>  <p>Thanks  Andy</p>""",azure-functions
57466149,Architecture recommendation - Azure Webjob <p>I have a webjob that subscribes to an Azure service Bus topic. The webjob automates a very important business process. For the Service bus  it is Premium SKU and have Geo-Recovery configured. My question is about the best practice to setup High Availability for my webjob (to ensure that the process runs always). I already have the App Service Plan deployed in two regions  and the webjob is installed in both the regions. However  I would like my webjob in the secondary region to run only if the primary region is down - maybe temporarily due to an outage. How can this be implemented? If I run both the webjob in parallel  that will create some serious duplication issues. Is there any architectural pattern I can refer to  or use any features within App Service or Azure to implement this?</p>,azure-web-app-service
50108597,"Shared config file for various VSTS roles <p>I know how to make a shared config file for traditional projects and adding them to each project with the following tag:  <code>&lt;appSettings file=\../other_project/foo.config\""&gt;</code>.</p>  <p>How do I share application settings in VSTS  ensuring every role can access the shared config settings? I assume you can't directly reference other projects' config files using relative path names  like in my example above. </p>  <p>I would like to centralize my configuration and make my config transform file relatively short  as there are a lot of projects. </p>""",azure-devops
56170100,Azure Web App on Linux I change Scale Up and down then i reveice Application Error on website <p>Website error message is: </p>  <p>:( Application Error If you are the application administrator  you can access the diagnostic resources.</p>  <p>What i did</p>  <p>Restart Web App ( Still same error) Restart Mysql  ( Still same error) I search lots of pages can't find it right solutions </p>,azure-web-app-service
35644788,"Continuous deployment to Azure VM <p>I have set up a Git hook in Azure. However  whenever I try to push to Azure VM  I am stuck with this screen  and it freezes. I am using the same keys that SSH into the azure virtual machine.</p>  <p><a href=\https://i.stack.imgur.com/a2jP5.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/a2jP5.png\"" alt=\""stucked here. \""></a></p>""",azure-virtual-machine
42785617,Auto-scaling of agent/worker nodes in Azure Container Service [Kubernetes] <p>I am working with windows + kubernetes cluster on ACS (Azure Container Service). I have few queries about the auto-scaling of agents/worker nodes in ACS. </p>  <p>Suppose I have a cluster of 1 master and 5 worker nodes. I have 200 running pods and these pods are distributed along the 5 worker nodes and the resources of these 5 nodes are used. Now  if I deploy a new pod or scale the running pods which will requires more resources  so is there any way ACS can auto-scale the worker nodes to like 7 worker nodes based on the resource usage?</p>  <p>Same case  if resource usage is reduced  can ACS descale the worker nodes to 3 worker nodes from 7 nodes?</p>  <p>My question is not related to auto-scaling of pods as provided by kubernetes  I am talking about auto-scaling of worker/agent nodes which are managed by ACS.</p>,azure-virtual-machine
46354060,Disable a Triggered Azure WebJob <p>I've got a webhook-triggered Azure WebJob. For... reasons  I do not have control over the system that is sending the webhooks. One webhook per day is sent. It is the only WebJob hosted by the WebApp.</p>  <p>During testing I wanted to disable this WebJob  so I stopped the WebApp. Much to my surprise  the WebJob ran even though the WebApp was disabled. </p>  <p>So my question is two-fold:</p>  <ol> <li>Is the ability to trigger a WebJob while a WebApp is disabled intentional  or did I encounter some sort of bug?</li> <li>If this is intentional  is there a way to disable this job being triggered via the Azure portal?</li> </ol>  <p>If the only solution to my problem is to have the WebJob check a config value to determine whether to run or not  that will do. I just think there has to be a way to disable a WebJob through the portal that I'm missing. </p>,azure-web-app-service
45444942,"Serializing in Azure Function <p>I'm running into a strange issue with Azure Function Apps. Newtonsoft Json.NET deserialization is not liking the <code>$type</code> annotations. My deserialization code looks like:</p>  <pre><code>return JsonConvert.DeserializeObject&lt;T&gt;(json  new JsonSerializerSettings {     TypeNameHandling = TypeNameHandling.Auto }); </code></pre>  <p>The json looks like:</p>  <pre><code>{   \$type\"": \""Trading.Control.Json.TradingConfig  Trading\""    \""Config\"": {     \""$type\"": \""Trading.Control.Json.Config  Trading\""      \""Optimize\"": false   }    \""Trading\"": {     \""$type\"": \""System.Collections.Generic.Dictionary`2[[System.String  mscorlib] [Trading.Platforms.Credentials  Trading]]  mscorlib\""  ... </code></pre>  <p>And is serialized with:</p>  <pre><code>return JsonConvert.SerializeObject(o  new JsonSerializerSettings {     TypeNameHandling = TypeNameHandling.All      Formatting = Formatting.Indented }); </code></pre>  <p>The error is: </p>  <pre><code>2017-08-01T17:32:46.395 Type specified in JSON  'Trading.Control.Json.TradingConfig  Trading  Version=1.0.0.0  Culture=neutral  PublicKeyToken=null' is not compatible with  'Trading.Control.Json.TradingConfig  Trading  Version=1.0.0.0  Culture=neutral  PublicKeyToken=null'. Path '$type'  line 2  position 56. </code></pre>  <p>As you can see  the types appear to be identical. This code is well tested locally and works as expected. It will fail in Azure on the first <code>$type</code> annotation encountered  regardless of how many I remove.</p>  <p>I would like to keep using the annotations  as I need them for deserializing objects derived from an abstract class.</p>  <p>This is compiled in x64  .NET 4.7  Json.NET v10.0.3  Azure Function Apps v1.0.11027.0 (~1). I have the Newtonsoft.Json.dll file in the bin folder  with <code>#r \""Newtonsoft.Json.dll\""</code> to reference it. Any ideas? Much appreciated.</p>  <p>Edit: I have also tried adding a project.json file looking like:</p>  <pre><code>{   \""frameworks\"": {     \""net47\"":{       \""dependencies\"": {         \""Newtonsoft.Json\"": \""10.0.3\""       }     }    } } </code></pre>  <p>which successfully installed. I removed the assembly file I uploaded  and the <code>#r</code> import. The error is now:</p>  <pre><code>2017-08-01T18:30:18.971 Error resolving type specified in JSON 'Trading.Control.Json.TradingConfig  Trading'. Path '$type'  line 2  position 56. </code></pre>  <p>I suspect there is a \""base namespace\"" or somesuch lookup error.</p>  <p>The filesystem of the function looks like: <code>/site/wwwroot/TimerTriggerCSharp3/</code> with assemblies in a bin folder. They are all loaded with <code>#r</code> imports  which work fine.</p>""",azure-functions
45370503,Microsoft.WindowsAzure.Storage update to V8.2.1.0 has broken my code <p>I've created a WebJob that places items in a queue  this process worked perfectly well until I updated <strong>Microsoft.WindowsAzure.Storage</strong> to <strong>v8.2.1.0</strong> and I'm now getting this error</p>  <blockquote>   <p>'Invalid storage account 'devstoreaccount1'. Please make sure your   credentials are correct.'</p> </blockquote>  <p>It was working perfectly well until the update  is this an issue? whats the fix?</p>,azure-storage
46414162,"How to trigger a failure in an azure function http trigger  WITH a custom error response <p>I cannot find a way to fail a http call to a nodejs azure function  and include a custom error response. </p>  <p>Calling context.done() allows for a custom response (but not indicated as a failure in Application Insights)</p>  <p>Calling context.done(true  XXX) does create a failure  but returns a generic error to the user (no matter what I put in XXX):</p>  <pre><code>{\id\"":\""b6ca6fb0-686a-4a9c-8c66-356b6db51848\"" \""requestId\"":\""7599d94b-d3f2-48fe-80cd-e067bb1c8557\"" \""statusCode\"":500 \""errorCode\"":0 \""message\"":\""An error has occurred. For more information  please check the logs for error ID b6ca6fb0-686a-4a9c-8c66-356b6db51848\""} </code></pre>  <p>This is just the latest headache I have ran into in trying to get a fast web api running on Azure funcs. If you cant track errors  than it should hardly be called \""Application Insights\"". Any ideas? </p>""",azure-functions
27789360,"Azure table Storage throws exception : Unable to read data from the transport connection: <p>I'm running a long Azure table storage query for 6-7 hrs after 5-6 hrs of time  Azure table storage throws exception has \Unable to read data from the transport connection: An existing connection was forcibly closed by the remote host.An existing connection was forcibly closed by the remote host \"" **</p>  <pre><code>    \""Exception : Unable to read data from the transport connection: An existing connection was forcibly closed by the remote host.  Stack Trace :    at Microsoft.WindowsAzure.Storage.Core.Executor.Executor.ExecuteSync[T](RESTCommand`1 cmd  IRetryPolicy policy  OperationContext operationContext)        at Microsoft.WindowsAzure.Storage.Table.TableQuery`1.&lt;&gt;c__DisplayClass7.&lt;ExecuteInternal&gt;b__6(IContinuationToken continuationToken)        at Microsoft.WindowsAzure.Storage.Core.Util.CommonUtility.&lt;LazyEnumerable&gt;d__0`1.MoveNext()        at System.Collections.Generic.List`1..ctor(IEnumerable`1 collection)        at System.Linq.Enumerable.ToList[TSource](IEnumerable`1 source)\""  ** </code></pre>  <p>There is no clue what is causing problem   Can any one help me out reason for this error.</p>  <pre><code> ServicePointManager.DefaultConnectionLimit = 48;             ServicePointManager.Expect100Continue = false;             ServicePointManager.UseNagleAlgorithm = false; </code></pre>  <p>I'm using A7 (8 CPU core  56 GB RAM)  even with high configuration also it is failing. </p>  <p>Also included Retry logic on Table Storage suring execution of Query   but no luck.</p>  <pre><code> var DefaultRequestOptions = new TableRequestOptions                             {                                 RetryPolicy =new ExponentialRetry(TimeSpan.FromSeconds(3)  3)                                  //PayloadFormat = TablePayloadFormat.JsonNoMetadata                             };  AzureTableQuery.Execute(DefaultRequestOptions).ToList(); </code></pre>  <p>I also check Network IN : it is showing has 100 GB. Is there any limit on Network bandwith. I request any one help on this.  Thanks in advance</p>""",azure-storage
42319675,Mapping to 2 or more projects with common source <p>I am trying to upload my projects in TFS. Below is my scenario.</p>  <ol> <li>I have a common project  which will be common to all my clients.</li> <li>Then there are few projects with are specific to each client.</li> <li>My requirement is  when i load one of my client project  all the common projects should also come along with it.</li> <li>When i do checkin  changes in common projects should be reflected on all my client projects and changes in client specific project should be independent of other clients.</li> </ol>  <p>Below is an example:</p>  <p>Lets say I have a projects X and Y. In X and Y some piece of codes will be exactly the same.  So I am uploading those common codes to separate project(Lets call it BASE). Some piece of codes are specific to X or Y  Which i will upload in separately.(Lets call it X-Spec or Y-Spec) So when i load my X-Spec or Y-Spec  it has to fetch the BASE codes also into my system.</p>  <p>Hope it's detailed  Let me know if any more explanation required.</p>,azure-devops
57282882,Drupal Docker compose mount Azure File share as volumes <p>I am trying to mount Azure File share as a volume for Drupal in Docker compose</p>  <p>I am looking for an answer to how to mount the Azure Volumes</p>  <pre><code>version: '3' services:   drupal:     image: drupal:latest     ports:       - 80:80     volumes:       - drupal_modules:/var/www/html/modules       - drupal_profiles:/var/www/html/profiles       - drupal_themes:/var/www/html/themes       - drupal_sites:/var/www/html/sites     restart: always    postgres:     image: postgres:10     environment:       POSTGRES_PASSWORD: your_postgres_password     volumes:         - db_data:/var/lib/postgresql/data     restart: always  volumes:   drupal_modules:   drupal_profiles:   drupal_themes:   drupal_sites:   db_data: </code></pre>,azure-storage
46367630,"spark specify multiple jars for azure <p>Im trying to access azure blobs from my spark-shell but get the following error- </p>  <pre><code>scala&gt; sc.textFile(\wasb://mycontainer@test.blob.core.windows.net/testfolder/txtfile\"").count() java.lang.NoClassDefFoundError: com/microsoft/azure/storage/StorageException   at org.apache.hadoop.fs.azure.NativeAzureFileSystem.createDefaultStore(NativeAzureFileSystem.java:1064)   at org.apache.hadoop.fs.azure.NativeAzureFileSystem.initialize(NativeAzureFileSystem.java:1035)   at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2397)   at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:89)   at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2431)\\ </code></pre>  <p>multiple jar in the jars directive</p>  <pre><code>Ps-M:spark-2.1.1-bin-hadoop2.7 p$ bin/spark-shell --jars \""/Users/p/Documents/ba/spark-tutorial/spark-2.1.1-bin-hadoop2.7/jars/hadoop-azure-2.7.0.jar\"" \""/Users/p/Documents/ba/spark-tutorial/spark-2.1.1-bin-hadoop2.7/jars/azure-storage-2.0.0.jar\"" </code></pre>  <p>I would like to know how to specify multiple jars in the --jars directive  right now I mentioned as \""jar1\"" \""jar2\""</p>""",azure-storage
47112509,"How to Deploy an Isolated App Service Environment with ARM Template <p>Does anyone know what values need to be used in an ARM template to deploy an Isolated (e.g I3) App Service Environment. I can deploy manually through the portal and then deploy I series service plans but I can only get P series ASEs through an ARM template  looking at resource manager doesn't enlighten me. Here is the ASE section of my template:</p>  <pre><code>{   \type\"": \""Microsoft.Web/hostingEnvironments\""    \""name\"": \""ase1\""    \""apiVersion\"": \""2016-09-01\""    \""location\"": \""North Europe\""    \""dependsOn\"": []    \""properties\"": {     \""name\"": \""ase1\""      \""location\"": \""North Europe\""      \""ipSslAddressCount\"": 0      \""internalLoadBalancingMode\"": \""Web\""      \""dnsSuffix\"": \""somedns.co.uk\""      \""virtualNetwork\"": {       \""Id\"": \""someVNetId\""        \""Subnet\"": \""somesubnetName\""     }      \""multiSize\"": \""Standard_D1_V2\""      \""multiRoleCount\"": 2      \""workerPools\"": [       {         \""workerSizeId\"": 0          \""workerSize\"": \""Small\""          \""workerCount\"": 0       }        {         \""workerSizeId\"": 1          \""workerSize\"": \""small\""          \""workerCount\"": 0       }        {         \""workerSizeId\"": 2          \""workerSize\"": \""small\""          \""workerCount\"": \""0\""       }     ]   } } </code></pre>""",azure-web-app-service
47245347,Can I make VSTS URL accessible only within my office network? <p>I am using VSTS to host my source code and a private agent(on-prem) to build it. Can I make <code>https://******.visualstudio.com</code> this URL private so that it is only accessible within my office network?</p>,azure-devops
57666808,"Unable to save JSON config file updates in Azure Portal <p>I have deployed a .NET Core app services to Azure.  From time to time I want to go in and update the JSON config file but it doesn't save</p>  <p>It always gets a 409 error </p>  <p><a href=\https://i.stack.imgur.com/ozhuI.jpg\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/ozhuI.jpg\"" alt=\""Error\""></a></p>  <p>This has only recently started occurring.  It is quite annoying to have to build and deploy to test a simple config change</p>  <p>Does anyone know how to resolve this?</p>""",azure-devops
50765346,IP throttling on web app (app service) <p>We have a few webpages (aspx) hosted in the Azure web app (app service)  this is already in production. We observed that appeared to be some abnormal activities that seems hacker access that accessing the app intensively between milliseconds. How can we avoid this kind of activities  by introducing IP rate throttling (e.g. traffic from a single IP can only allow to access the page 1 time per minute).</p>  <p>Is this something could be done by app service alone or have to introduce other azure services? We have an azure API Management service  we also think to put it behind there but that seems overkill..</p>  <p>Thanks for help in advance</p>,azure-web-app-service
21175293,"How to track progress of async file upload to azure storage <p>Is there way to track the file upload progress to an Azure storage container?  I am trying to make a console application for uploading data to Azure using C#.  </p>  <p>My current code looks like this:  </p>  <pre><code>using System; using System.Collections.Generic; using System.Linq; using System.Text; using Microsoft.WindowsAzure.Storage; using Microsoft.WindowsAzure.Storage.Auth; using Microsoft.WindowsAzure.Storage.Blob; using System.Configuration; using System.IO; using System.Threading;  namespace AdoAzure {     class Program     {         static void Main(string[] args)         {             CloudStorageAccount storageAccount = CloudStorageAccount.Parse(             ConfigurationManager.ConnectionStrings[\StorageConnectionString\""].ConnectionString);             CloudBlobClient blobClient = storageAccount.CreateCloudBlobClient();             CloudBlobContainer container = blobClient.GetContainerReference(\""adokontajnerneki\"");             container.CreateIfNotExists();             CloudBlobClient myBlobClient = storageAccount.CreateCloudBlobClient();             CloudBlockBlob myBlob = container.GetBlockBlobReference(\""racuni.adt\"");             CancellationToken ca = new CancellationToken();             var ado = myBlob.UploadFromFileAsync(@\""c:\\bo\\racuni.adt\""  FileMode.Open  ca);             Console.WriteLine(ado.Status); //Does Not Help Much             ado.ContinueWith(t =&gt;             {                 Console.WriteLine(\""It is over\""); //this is working OK             });             Console.WriteLine(ado.Status); //Does Not Help Much             Console.WriteLine(\""theEnd\"");             Console.ReadKey();         }     } } </code></pre>  <p>This piece of code works well  but I'd love to have some kind of progress bar  so users can see that there are running tasks. Is there something built into WindowsAzure.Storage.Blob namespace that I can use  like a rabbit from a hat?</p>""",azure-storage
53811111,"Azure DevOps Build Xamarin.IOS with IOS 12 as target <p>I have an Application written with Xamarin and a buildpipline on Azure Devops. This builds fine when I target IOS 11.x. However I would like to update to SDK 12 since Apple starts to enforce this starting in march 2019:</p>  <blockquote>   <p>SDK Version Issue - This app was built with the iOS 11.4 SDK. Starting   March 2019  all iOS apps submitted to the App Store must be built with   the iOS 12.1 SDK or later  included in Xcode 10.1 or later.</p> </blockquote>  <p>But when I build I always get this error in my Azure Devops pipeline:</p>  <pre><code>MTOUCH : error MT0074: Xamarin.iOS 11.14.0 does not support a deployment target of 12.0 for iOS (the maximum is 11.4). Please select an older deployment target in your project's Info.plist or upgrade to a newer version of Xamarin.iOS. </code></pre>  <p>Based on this <a href=\https://docs.microsoft.com/en-us/azure/devops/pipelines/agents/hosted?view=vsts&amp;tabs=yaml#how-can-i-manually-select-versions-of-tools-on-the-hosted-macos-agent\"" rel=\""noreferrer\"">article</a> I tried to set the SDK Version with this script:</p>  <pre><code> /bin/bash -c \""sudo $AGENT_HOMEDIRECTORY/scripts/select-xamarin-sdk.sh 5_12_0\"" </code></pre>  <p>Unfortunately it still uses the 11 SDK instead of 12. Did I choose the wrong Mono Version or is that the wrong approach to select the Xamarin.IOS SDK?</p>  <p>My complete build YAML for the IOS Job:</p>  <pre><code>queue:   name: Hosted macOS   demands:    - xcode   - Xamarin.iOS  steps: - bash: |    echo \""Select Xamarin Version\""     /bin/bash -c \""sudo $AGENT_HOMEDIRECTORY/scripts/select-xamarin-sdk.sh 5_12_0\""   displayName: 'Select Xamarin Version'  - task: InstallAppleCertificate@2   displayName: 'Install an Apple certificate'   inputs:     certSecureFile: '6f1c094d-c147-41e0-9bc6-c9fe9a40b2e6'      certPwd: '$(P12password)'   - task: InstallAppleProvisioningProfile@1   displayName: 'Install an Apple provisioning profile'   inputs:     provProfileSecureFile: 'a883a983-6027-4382-afd4-94b52736323c'   - task: NuGetToolInstaller@0   displayName: 'Use NuGet'   inputs:     versionSpec: 4.x   - task: NuGetCommand@2   displayName: 'NuGet restore'   inputs:     restoreSolution: '$(Parameters.solution)'   - task: XamariniOS@2   displayName: 'Build Xamarin.iOS '   inputs:     solutionFile: Src/MoneyFox.Ios/MoneyFox.iOS.csproj      configuration: '$(BuildConfiguration)' </code></pre>""",azure-devops
53227780,"how to host .net core 2.1 generic host in azure <p>Have several services written using the new generic Ihost in .NET CORE 2.1: <a href=\https://docs.microsoft.com/en-us/aspnet/core/fundamentals/host/generic-host?view=aspnetcore-2.1\"" rel=\""nofollow noreferrer\"">https://docs.microsoft.com/en-us/aspnet/core/fundamentals/host/generic-host?view=aspnetcore-2.1</a></p>  <p>I can't find any documentation on how to host these in Azure  I've tried hosting them in App Service but they don't seem to be recogniced as they don't start. How am I supposed to host these in Azure?</p>""",azure-web-app-service
51103897,Increase startup timeout for Azure WebApp for Containers <p>We run Java Spring Boot app in a Docker on Azure WebApp for Containers. Single B1 instance is enough for the app to run  however Spring Boot is pretty slow at startup and might take over 240 seconds for the app to start.</p>  <p>As the result Azure WebApp for Containers kills the container after 240 seconds not giving it enough time to start.</p>  <p>Is there any way to change the default 240 seconds startup timeout?</p>,azure-web-app-service
43790752,"Excel to SQL Table(s) <p>I am trying to take data that is in an Excel workbook which lives in Azure Blob Storage (also  the Excel file is updated manually every day and then exported to Blob Storage via MS Flow) and then export that data into some tables in Azure SQL database. I cannot use SSIS packages as that would be too costly. Anyone know of a way to get this done without SSIS? I've looked into OPENROWSET and linked servers  but both are \not supported in my version of SQL server.\"" I've also considered converting the Excel file to CSV and then using ADF  but I can't figure out how to convert it to CSV in the blob... (without uploading manually)</p>""",azure-storage
41740705,Azure ApiApp - listen for ServiceBus msg <p>Say a have a <code>CreateOrder</code> method inside a ApiApp project. </p>  <p>Now I need to also trigger the <code>CreateOrder</code> when I receive a <code>CreateOrderMessage</code> from a ServiceBus queue.</p>  <p>I understand that this could be easily done using Azure Functions with a queue trigger. But that adds more complexity (introduces another concepts  will require a new repository  docs etc) So my question is simply:</p>  <p>Could I listen for queue messages inside of a WebApi project? (I know spinning up a new thread involves some problems)</p>  <p>Thanks for any suggestions</p>  <p>Larsi</p>,azure-functions
57463075,HTTP Error 500.50 - URL Rewrite Module Error on Azure app service <p>We are trying to handle URL redirects by using FileMapProvider on Azure app service  however we get the following error:</p>  <blockquote>   <p>System.IO.FileNotFoundException: Could not load file or assembly   'Microsoft.Web.Iis.Rewrite.Providers  Version=7.1.761.0    Culture=neutral  PublicKeyToken=0545b0627da60a5f' or one of its   dependencies. The system cannot find the file specified.</p> </blockquote>  <p>Does anybody know if Azure anyhow supports FileMapProvider?</p>,azure-web-app-service
56652707,"How to show error on POST action in an ActionCard? <p>I'm facing a problem I don't know how to solve. I developed an Azure Function that posts a message on a Teams channel with some information about issues. I've also added some action buttons for allowing Teams users to perform an automatic action like assign responsible to that issue. This button  the assign responsible one  is defined to make an \HttpPOST\"" action to another Azure Function.</p>  <p><a href=\""https://i.stack.imgur.com/CW4ti.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/CW4ti.png\"" alt=\""Action Card code\""></a></p>  <p>As you can imagine  <code>assignResponsibleUrl</code> variable contains the URL of the target Azure Function. The problem comes when the user hits the button that returns an error but without any kind of description to understand what is wrong on this call. I tried the Azure Function target url with several tools like <em>Postman</em> and <em>RESTer</em> and works fine so  I don't know how to trace the error.</p>  <p>Here you have the error screenshot (sorry about the message but it's in spanish):</p>  <p><a href=\""https://i.stack.imgur.com/X7yxO.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/X7yxO.png\"" alt=\""Error screenshot\""></a></p>  <p>As you can see  the message says: \""The requested action could not be completed. Try it again later.\"" and isn't any descriptive.</p>  <p>Can you help me determine what I'm doing wrong with the ActiveCard declaration or how can I trace the Teams error when hitting the button?</p>""",azure-functions
48348725,"Deleting VSTS User From Active Directory <p>Microsoft Docs has substantive info on <em>adding</em> users to VSTS via Active Directory  but I'm not finding specific info on what happens when you delete a VSTS user from AD  or what ripple effects take place when you delete them from VSTS itself. MSFT says removing them from AD <em>may</em> make them still appear in VSTS  but they won't be able to log in  yet also says it may take up to 24 hours for <em>a change</em> in AD to show up in VSTS.</p>  <ol> <li><p>When VSTS is linked to AD  does removing a VSTS user from AD ever remove them from VSTS  or does the user always need to be removed from VSTS manually?</p></li> <li><p>Does removing a user directly from within VSTS remove them from any other place in VSTS like \Assigned To\"" fields  project teams  security groups... anything?</p></li> </ol>""",azure-devops
45057862,"Neo4j on Microsoft Azure Deployment template validation failed? <p><strong>EDITED</strong> <em>My azure subscription is Visual Studio Enterprise:</em> <strong><em>BizSpark</em></strong></p>  <p>When trying to configure neo4j on Microsoft Azure by following the guide explained on <a href=\https://neo4j.com/blog/deploy-neo4j-microsoft-azure-part-2/\"" rel=\""nofollow noreferrer\"">How to Deploy Neo4j on Microsoft Azure Step-by-Step</a></p>  <p>On Step 2: Neo4j Settings... there is no SSL certificate options  VM options as explained on the guide</p>  <p><a href=\""https://i.stack.imgur.com/7xMNK.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/7xMNK.png\"" alt=\""enter image description here\""></a></p>  <p>after clicking <strong>OK</strong>..... the following error showed up  stating </p>  <pre><code>    InvalidTemplate Deployment template validation failed: 'The value for the template parameter 'SubnetName' at line '56' and column '20' is not provided. Please see https://aka.ms/arm-deploy/#parameter-file for usage details.'. </code></pre>  <p><a href=\""https://i.stack.imgur.com/6WE6V.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/6WE6V.png\"" alt=\""enter image description here\""></a></p>  <p>What am I missing? Thanks in advance</p>""",azure-virtual-machine
48312783,How to change the redis target when i swap my app service in Microsoft Azure <p>I'm using the Microsoft app service to deploy my web application </p>  <p>and it have staging.domain.com and www.domain.com </p>  <p>but now they are both link to the same redis </p>  <p>How to I let them link to different redis  when I swap them?</p>  <p>I think it can solved by the app setting.</p>  <p>Is there any best solution or suggestion?</p>,azure-web-app-service
47225926,"Adding external assembly references to Azure Function on Visual Studio 2017 <p>I'm trying to add a dependency on an external assembly to an Azure Function developed and published from Visual Studio 2017. On Azure Functions developed on the Portal  I can add dependencies as as normal using #r and referencing a .dll in the Function directory. In Visual Studio  I get \the reference is invalid or unsupported\"" if I try to reference the same .dll on my local machine (which makes sense)  and it doesn't let me reference assemblies not present on my local machine but present in the Function directory (which also makes sense). So the question is  how can I add assembly references to an Azure Function developed on Visual Studio? Am I missing something obvious?</p>  <p>(N.B. there are other reasons prohibiting just copying the function over and developing it entirely on the Portal  so that isn't an option)</p>""",azure-functions
45441724,"Web App Diagnostic Logs: Web server logging as a slot setting <p>Is it possible to configure the Web App's Diagnostic Logs \web server logging\"" storage account to be bound to a slot (i.e. as a slot setting)  in order to prevent this during the swap:</p>  <p><a href=\""https://i.stack.imgur.com/0pAsX.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/0pAsX.png\"" alt=\""These settings will be modified in the destination slot\""></a></p>  <p>The actual value for this is set as a <code>WEBSITE_HTTPLOGGING_CONTAINER_URL</code> app setting variable on the actual Web App  but it is invisible on the portal (meaning one cannot enable 'slot setting'). </p>  <p>This is unlike the \""application logging\"" storage account  which is made visible (meaning I can enable slot settings):</p>  <p><a href=\""https://i.stack.imgur.com/5PSZ8.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/5PSZ8.png\"" alt=\""App Settings\""></a></p>  <p>I would prefer not to have to do this via cmdlets.</p>""",azure-web-app-service
55918713,Azure pipelines run specific task if and ONLY IF branch is equal to master in yaml <p>I am trying to change my yaml file to add some more tasks. This is my current yaml file:</p>  <pre><code>trigger:   - master  pool:   vmImage: 'Ubuntu-16.04'  steps:   - task: Maven@3     inputs:       mavenPomFile: 'pom.xml'       # according to: https://github.com/MicrosoftDocs/vsts-docs/issues/3845         # maven options should go to goals instead  as mavenOptions is for jvm options       mavenOptions: '-Xmx3072m'       javaHomeOption: 'JDKVersion'       jdkVersionOption: '1.11'       jdkArchitectureOption: 'x64'       publishJUnitResults: true       testResultsFiles: '**/surefire-reports/TEST-*.xml'       goals: 'verify -Dorg.slf4j.simpleLogger.log.org.apache.maven.cli.transfer.Slf4jMavenTransferListener=WARN -Dorg.slf4j.simpleLogger.showDateTime=true -Djava.awt.headless=true --batch-mode --show-version' </code></pre>  <p>I want to run one goal only if the branch that runs is master. Basically with my tests  I create a dockerfile and I want to push it to dockerhub  but I don't want that to happen every time someone opens a pull request; I want that to happen only if master is running the tests. Something like this</p>  <pre><code>if branch == master  steps: * </code></pre>  <p>but I don't seem to find anything in the Azure Pipelines documentation on how to do this</p>,azure-devops
52223707,"Using App Service Static IP to Access Web Site <p>I went through the process of configuring a hostname and configured my SSL binding to be IP based.  I received a static ip address.  I then used this static IP in my DNS as documented.  Everything works great using the proper hostname from my DNS.  However I am not able to use the IP address directly.</p>  <p>I continually get a \The resource you are looking for has been removed  had its name changed  or is temporarily unavailable.\""  </p>  <p>I have a small legacy handheld device that can only use ip address to access my site.  I'd like to continue supporting these devices.  </p>  <p>Is it possible to use the App Service static ip address through a browser?  </p>""",azure-web-app-service
53367180,"how to use both the log writer and app insights within azure function? <p>I'd like to send trace and other events to both the <code>ILogger</code> as well as application insights. </p>  <p>I know that I can simply do this:</p>  <pre><code>    [FunctionName (\OnSomethingHttpTriggered\"")]     public static async System.Threading.Tasks.Task RunAsync ([QueueTrigger (\""myq\""  Connection = \""StorageAccountConnection\"")] string payload  ILogger log) {         var telemetry = new TelemetryClient {         InstrumentationKey = Environment.GetEnvironmentVariable (\""APPINSIGHTS_INSTRUMENTATIONKEY\"")         };         log.LogInformation ($\""C# Queue trigger function processed: {payload}\"");         telemetry.TrackEvent ($\""C# Queue trigger function processed: {payload}\"");          var isPayloadValidSchema = SchemaValidator.IsValid (payload);         if (!isPayloadValidSchema) {             log.LogError ($\""This visit is not valid {payload}\"");             telemetry.TrackEvent ($\""This visit is not valid {payload}\"");             return;         }     } </code></pre>  <p>But as you can see I would need to double my code each time for <code>ILogger</code> and <code>TelemetryClient</code>.</p>  <p><strong>How do I avoid this repetition?</strong></p>""",azure-functions
41623098,How do you get the list of vmInstanceIDs associated with Azure scale sets? <p>I have looked at the azure cli and tried everything under 'azure vmss' that I could find. I used the armclient and tried different REST request to determine the list. I see several requests in the cli asks for the vmInstanceID for example 'azure vmss restart'  'azure vmss update' and others. My hope is that this will lead to the hostnames of the VMs behind the scale set  or is there another way to get the hostnames.</p>,azure-virtual-machine
54470209,"How to get a token for specific user assigned managed service identity for Azure App Service? <p>I am trying to get a msi token for a specific User defined identity. Our app service has 2 user defined identities and I want a token on behalf of one of the user assigned identity.</p>  <p>Here is the code:</p>  <pre><code>        HttpWebRequest req = (HttpWebRequest)WebRequest.Create(             \http://169.254.169.254/metadata/identity/oauth2/token?api-version=2018-02-01&amp;resource=https://management.azure.com/&amp;object_id=&lt;ObjectId&gt;&amp;client_id=&lt;clientId&gt;\"");          req.Headers[\""Metadata\""] = \""true\"";         req.Method = \""GET\"";          try         {             // Call /token endpoint             HttpWebResponse response = (HttpWebResponse)req.GetResponse();              // Pipe response Stream to a StreamReader  and extract access token             StreamReader streamResponse = new StreamReader(response.GetResponseStream());             string stringResponse = streamResponse.ReadToEnd();             Dictionary&lt;string  string&gt; list =                  JsonConvert.DeserializeObject&lt;Dictionary&lt;string  string&gt;&gt;(stringResponse);             string accessToken = list[\""access_token\""];              System.IO.File.WriteAllText(@\"".\\Log.txt\""  accessToken);         }         catch (Exception e)         {             string errorText = String.Format(\""{0} \\n\\n{1}\""  e.Message  e.InnerException != null ? e.InnerException.Message : \""Acquire token failed\"");             System.IO.File.WriteAllText(@\"".\\Log.txt\""  errorText);             throw;         } </code></pre>  <p>It is deployed in an azure app service. When I hit this section I see this error: An attempt was made to access a socket in a way forbidden by its access permissions </p>  <p>I tried connecting to <a href=\""http://169.254.169.254\"" rel=\""nofollow noreferrer\"">http://169.254.169.254</a> to get the token using kudu console. But this endpoint does not seem to accessible there.</p>  <p><a href=\""https://i.stack.imgur.com/jW7pT.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/jW7pT.png\"" alt=\""enter image description here\""></a></p>  <p>I did try to use AzureServiceTokenProvider from Microsoft.Azure.Services.AppAuthentication for generating msi token but could not find any documentation about how to use it for multiple user assigned identities.</p>  <p>Edit:</p>  <p>Update 1:</p>  <p>I tried to use endpoint from MSI_ENDPOINT environment variable instead of 169.254.169.254. But it looks like MSI_ENDPOINT value is not set when I run the app service. Here is the code I have tried:</p>  <pre><code>   var endpoint = Environment.GetEnvironmentVariable(\""MSI_ENDPOINT\"");     string apiVersion = \""2018-02-01\"";     string resource = \""https://management.azure.com/\"";     string objectId = \""&lt;objectid&gt;\"";     string clientId = \""&lt;clientId&gt;\"";          // Build request to acquire managed identities for Azure resources token         //HttpWebRequest req = (HttpWebRequest)WebRequest.Create(         //    \""http://169.254.169.254/metadata/identity/oauth2/token?api-version=2018-02-01&amp;resource=https://management.azure.com/&amp;object_id=4aef1720-b3b1-4935-8d68-e330508907fa&amp;client_id=558ecc75-8697-4419-bab9-aa2c87043cfd\"");          HttpWebRequest req = (HttpWebRequest)WebRequest.Create(        String.Format(             \""{0}?resource={1}&amp;api-version={2}&amp;object_id={3}&amp;client_id={4}\""              endpoint              resource              apiVersion              objectId              clientId));          req.Headers[\""Metadata\""] = \""true\"";         req.Method = \""GET\"";          try         {             // Call /token endpoint             HttpWebResponse response = (HttpWebResponse)req.GetResponse();              // Pipe response Stream to a StreamReader  and extract access token             StreamReader streamResponse = new StreamReader(response.GetResponseStream());             string stringResponse = streamResponse.ReadToEnd();             Dictionary&lt;string  string&gt; list =                  JsonConvert.DeserializeObject&lt;Dictionary&lt;string  string&gt;&gt;(stringResponse);             string accessToken = list[\""access_token\""];              System.IO.File.WriteAllText(@\"".\\Log.txt\""  accessToken);         }         catch (Exception e)         {             string errorText = String.Format(\""{0} \\n\\n{1}\""  e.Message  e.InnerException != null ? e.InnerException.Message : \""Acquire token failed\"");              string log = \""MSI_ENDPOINT : \"" + endpoint + \""\\n\"";             log += (\""ErrorText : \"" + errorText + \""\\n\"");             System.IO.File.WriteAllText(@\"".\\Log.txt\""  errorText);             throw;         } </code></pre>""",azure-web-app-service
37927726,Visual Studio Team Services build error due to nuget <p>I am quite new to Visual Studio Team Services build and in the learning process. I created a solution and created a build definition on Visual Studio Team Services. When I build it  I got these log details and then an error:</p>  <pre><code>016-06-20T16:34:57.2842078Z Restoring NuGet package log4net.2.0.3. 2016-06-20T16:34:57.2892077Z Restoring NuGet package Microsoft.Azure.WebJobs.1.1.1. 2016-06-20T16:34:57.3452071Z WARNING: Unable to find version '1.1.1' of  package 'Microsoft.Azure.WebJobs'. 2016-06-20T16:34:57.3462075Z   C:\Users\buildguest\AppData\Local\NuGet\Cache: Package 'Microsoft.Azure.WebJobs.1.1.1' is not found on source 'C:\Users\buildguest\AppData\Local\NuGet\Cache'. 2016-06-20T16:34:57.3462075Z WARNING: Unable to find version '2.0.3' of package 'log4net'. 2016-06-20T16:34:57.3472076Z   C:\Users\buildguest\AppData\Local\NuGet\Cache: Package 'log4net.2.0.3' is not found on source 'C:\Users\buildguest\AppData\Local\NuGet\Cache'. 2016-06-20T16:34:57.4162071Z Restoring NuGet package Microsoft.Data.Edm.5.6.2. 2016-06-20T16:34:57.4432070Z WARNING: Unable to find version '5.6.2' of package 'Microsoft.Data.Edm'. 2016-06-20T16:34:57.5062068Z   C:\Users\buildguest\AppData\Local\NuGet\Cache: Package 'Microsoft.Data.Edm.5.6.2' is not found on source 'C:\Users\buildguest\AppData\Local\NuGet\Cache'. </code></pre>  <p>The final Error:</p>  <pre><code>2016-06-20T16:34:57.9012078Z ##[error]System.Exception: Unexpected exit code 1 returned from tool NuGet.exe 2016-06-20T16:34:57.9022088Z ##[error]   at Microsoft.TeamFoundation.DistributedTask.Task.Internal.PowerShell.InvokeToolCmdlet.ProcessRecord() 2016-06-20T16:34:57.9022088Z ##[error]   at System.Management.Automation.CommandProcessor.ProcessRecord() </code></pre>  <p>When I am running build locally  nuget never report any error. I don't really understand why the online version complains. Can someone help?</p>,azure-devops
50166134,"Change azure storage setting for Microsoft Bot service <p>Previously I have create a new web app bot. However  I have chosen the wrong settle for azure storage. Could someone advise me on changing Azure storage to another storage account?</p>  <p><a href=\https://i.stack.imgur.com/3cwZV.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/3cwZV.png\"" alt=\""enter image description here\""></a></p>""",azure-storage
40549580,How to write sqlcmd results directly to Azure Storage using Azure PowerShell? <p>Current story:</p>  <p>Moving overall BI solution fully to Azure cloud services. Building a new Azure DW and loading data from an Azure DB. Currently  Azure DW doesn't support linked servers and/or the elastic query (this is only supported in Azure DB). Due to price  we can <strong>not</strong> use data factory or an instance of SSIS. We <strong>can't</strong> use bcp as we don't have a local directory to hold the file in between loads.</p>  <p>Is it possible to use Azure PowerShell with sqlcmd to write results of a query directly to Azure Storage  without having to write to a file on a local directory in between?</p>  <p>Are there other options that aren't mentioned above?</p>  <p>Thank you for any input.</p>,azure-storage
52062665,How to pass extra parameters along with New-AzureRmResourceGroupDeployment cmdlet <p>I'm writing a powershell  script to create VM using New-AzureRmResourceGroupDeployment cmdlet  which is as below.</p>  <pre><code>New-AzureRmResourceGroupDeployment -Name VmDeployment  `   -TemplateFile C:\template\template.json `   -TemplateParameterFile C:\template\parameters.json </code></pre>  <p>This is used create a VM. In <code>parameters.json</code>   there are some parameters like <code>virtualMachineName</code>  <code>networkInterfaceName</code> etc which are hardcoded.<br> Now I'm trying to automate these scripts   i.e they run on there own from a tool   when ever some condition is met.   </p>  <p>My requirement here is   whenever this script runs  it has to increase the number in the VMName . Suppose the VM Name is now <code>VMName1</code>  it has to be <code>VMName2</code> when the script runs next time. Similarly <code>VMName3</code> when the script runs next time. Since the <code>virtualMachineName</code> parameter is hardcoded  this is not happening now. Is there anyway I can pass <code>virtualMachineName</code> as a parameter in the script itself rather than taking it from the json file.  </p>  <p>Any guidance is highly appreciated.Thanks!</p>,azure-virtual-machine
57450422,"Azure web app cannot find the connection string <p>I am just trying to publish my application in Azure as a Web App. I have been facing issue about the connection string. The server just can't identify what the connection string is  as you may see from the error below:</p>  <pre><code>Unhandled Exception: Microsoft.Azure.Services.AppAuthentication.AzureServiceTokenProviderException: Parameters: Connection String: [No connection string specified]  Resource: https://vault.azure.net  Authority: https://login.windows.net/b99992c6-d6c5-4028-99b5-a1f106bb90bc. Exception Message: Tried the following 3 methods to get an access token  but none of them worked. Parameters: Connection String: [No connection string specified]  Resource: https://vault.azure.net  Authority: https://login.windows.net/b99992c6-d6c5-4028-99b5-a1f106bb90bc. Exception Message: Tried to get token using Managed Service Identity. Access token could not be acquired. An attempt was made to access a socket in a way forbidden by its access permissions Parameters: Connection String: [No connection string specified]  Resource: https://vault.azure.net  Authority: https://login.windows.net/b99992c6-d6c5-4028-99b5-a1f106bb90bc. Exception Message: Tried to get token using Visual Studio. Access token could not be acquired. Visual Studio Token provider file not found at \D:\\local\\LocalAppData\\.IdentityService\\AzureServiceAuth\\tokenprovider.json\"" Parameters: Connection String: [No connection string specified]  Resource: https://vault.azure.net  Authority: https://login.windows.net/b99992c6-d6c5-4028-99b5-a1f106bb90bc. Exception Message: Tried to get token using Azure CLI. Access token could not be acquired. 'az' is not recognized as an internal or external command  operable program or batch file.     at Microsoft.Azure.Services.AppAuthentication.AzureServiceTokenProvider.GetAuthResultAsyncImpl(String authority  String resource  String scope  CancellationToken cancellationToken)    at Microsoft.Azure.Services.AppAuthentication.AzureServiceTokenProvider.&lt;get_KeyVaultTokenCallback&gt;b__8_0(String authority  String resource  String scope)    at Microsoft.Azure.KeyVault.KeyVaultCredential.PostAuthenticate(HttpResponseMessage response)    at Microsoft.Azure.KeyVault.KeyVaultCredential.ProcessHttpRequestAsync(HttpRequestMessage request  CancellationToken cancellationToken)    at Microsoft.Azure.KeyVault.KeyVaultClient.GetSecretsWithHttpMessagesAsync(String vaultBaseUrl  Nullable`1 maxresults  Dictionary`2 customHeaders  CancellationToken cancellationToken)    at Microsoft.Azure.KeyVault.KeyVaultClientExtensions.GetSecretsAsync(IKeyVaultClient operations  String vaultBaseUrl  Nullable`1 maxresults  CancellationToken cancellationToken)    at Microsoft.Extensions.Configuration.AzureKeyVault.AzureKeyVaultConfigurationProvider.LoadAsync()    at Microsoft.Extensions.Configuration.AzureKeyVault.AzureKeyVaultConfigurationProvider.Load()    at Microsoft.Extensions.Configuration.ConfigurationRoot..ctor(IList`1 providers)    at Microsoft.Extensions.Configuration.ConfigurationBuilder.Build()    at Microsoft.AspNetCore.Hosting.WebHostBuilder.BuildCommonServices(AggregateException&amp; hostingStartupErrors)    at Microsoft.AspNetCore.Hosting.WebHostBuilder.Build()    at Synergy.Program.Main(String[] args) in C:\\Users\\Erkan Er\\source\\repos\\Synergy\\Program.cs:line 21 </code></pre>  <p>Below is the appsettings.json:</p>  <pre><code>{   \""ConnectionStrings\"": {     \""DefaultConnection\"": \""Data Source=server.database.windows.net;Initial Catalog=synergylearn_db;User ID=userid;Password=password;Connect Timeout=60;Encrypt=True;TrustServerCertificate=False;ApplicationIntent=ReadWrite;MultiSubnetFailover=False;RunAs=App;\""      \""AzureStorageConnectionString-1\"": \""DefaultEndpointsProtocol=https;AccountName=encamina;AccountKey=V0/+NhCGcq1vBCc1wJ5L9V620fi5E0cX0cX4/pbOFzjqBxRapLBmaDt75LQcoX3HBskY/34E0MwGH/OWToryUg==;EndpointSuffix=core.windows.net\""   }    \""AppSettings\"": {     \""Secret\"": \""abc\""   }    \""Logging\"": {     \""LogLevel\"": {       \""Default\"": \""Warning\""     }   }    \""AllowedHosts\"": \""*\""    \""Authentication\"": {     \""Google\"": {       \""ClientId\"": \""xxx\""        \""ClientSecret\"": \""xx\""     }   } } </code></pre>  <p>And  here is the <code>Startup.cs</code>:</p>  <pre><code>    public Startup(IHostingEnvironment env)     {         var builder = new ConfigurationBuilder()             .SetBasePath(env.ContentRootPath)             .AddJsonFile(\""appsettings.json\""  optional: false  reloadOnChange: true)             .AddJsonFile($\""appsettings.{env.EnvironmentName}.json\""  optional: true)             .AddEnvironmentVariables();         Configuration = builder.Build();     }      public IConfiguration Configuration { get; }      public void ConfigureServices(IServiceCollection services)     {         services.AddCors();         services.AddMvc().SetCompatibilityVersion(CompatibilityVersion.Version_2_2)             .AddJsonOptions(options =&gt; {                 options.SerializerSettings.ReferenceLoopHandling = ReferenceLoopHandling.Ignore;             }); ;           // configure strongly typed settings objects         var appSettingsSection = Configuration.GetSection(\""AppSettings\"");         services.Configure&lt;AppSettings&gt;(appSettingsSection);          // configure jwt authentication         var appSettings = appSettingsSection.Get&lt;AppSettings&gt;();         var key = Encoding.ASCII.GetBytes(appSettings.Secret);         services.AddAuthentication(x =&gt;         {             x.DefaultAuthenticateScheme = JwtBearerDefaults.AuthenticationScheme;             x.DefaultChallengeScheme = JwtBearerDefaults.AuthenticationScheme;         });          services.AddDbContext&lt;SynergyDbContext&gt;(             options =&gt; options.UseSqlServer(                Configuration.GetConnectionString(\""DefaultConnection\"")                //Configuration[\""ConnectionStrings:DefaultConnection\""]                )            );         services.AddTransient&lt;SynergyDbContext&gt;(); </code></pre>  <p>If I run it from the local computer  using the same settings  it works fine. But  it does not work on the server. Any ideas?</p>  <p><strong>UPDATE</strong></p>  <p>When  I check from the url <code>https://myapp.scm.azurewebsites.net/env</code>  I see this section:</p>  <pre><code>Connection Strings LocalSqlServer ConnectionString = data source=.\\SQLEXPRESS;Integrated  Security=SSPI;AttachDBFilename=|DataDirectory|aspnetdb.mdf;User Instance=true ProviderName = System.Data.SqlClient </code></pre>  <p>And  also this section  where the correct connection string is displayed:</p>  <pre><code>SQLCONNSTR_DefaultConnection = Data Source=server.database.windows.net;Initial Catalog=synergylearn_db;User ID=userid;Password=password;Connect Timeout=60;Encrypt=True;TrustServerCertificate=False;ApplicationIntent=ReadWrite;MultiSubnetFailover=False;RunAs=App; </code></pre>""",azure-web-app-service
46491599,"What CosmosDb operations cause an Azure function to fire? <p>I'm following this msdn guide on creating a Azure Function that's triggered by CosmosDB - <a href=\https://docs.microsoft.com/en-us/azure/azure-functions/functions-create-cosmos-db-triggered-function\"" rel=\""nofollow noreferrer\"">https://docs.microsoft.com/en-us/azure/azure-functions/functions-create-cosmos-db-triggered-function</a></p>  <p>It's still not clear to me what db operations actually trigger the Azure Function though - the example  a new document is created via the CosmosDB Management Portal.  So we know that document creation triggers the Az Fx  but what about updates to a document?</p>  <p>Is each update/create operation mapped to a single triggering of the azure function or is it batched?</p>""",azure-functions
54351868,"Is it possible to query table storage from .net core? <p>I'm attempting to query table cache using LINQ:</p>  <pre><code>public static IEnumerable&lt;DocumentMetaDataEntity&gt; Get(string connectionString  string cacheName  DeconstructedFileName deconstructedFileName  FileMetaDataFilters filters) {     var acc = CloudStorageAccount.Parse(connectionString);     var tableClient = acc.CreateCloudTableClient();     var table = tableClient.GetTableReference(cacheName);     var translations = from entity in table.CreateQuery&lt;DocumentMetaDataEntity&gt;()                        where (entity.sourceParty == sourceParty.ToLowerTrim()                                    &amp;&amp; entity.destinationParty == destinationParty.ToLowerTrim())                              || (entity.sourceParty == \YES\""                                    &amp;&amp; entity.destinationParty == destinationParty.ToLowerTrim())                        select entity;      return translations.Where(x =&gt; x.expireAt &gt; DateTime.Now)                        .Where(x =&gt; x.effectiveAt &lt; DateTime.Now); } </code></pre>  <p>However  getting this exception:</p>  <blockquote>   <p>'CloudTable' does not contain a definition for 'CreateQuery' and no accessible extension method 'CreateQuery' accepting a first argument of type 'CloudTable' could be found (are you missing a using directive or an assembly reference?)</p> </blockquote>  <p><strong>What am I doing wrong? Is it not possible to query table cache from .net core?</strong></p>  <p><a href=\""https://i.stack.imgur.com/6E5vW.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/6E5vW.png\"" alt=\""enter image description here\""></a></p>  <p>For some additinal info  here are the <em>create</em> methods available on this class:</p>  <p><a href=\""https://i.stack.imgur.com/5wWFj.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/5wWFj.png\"" alt=\""enter image description here\""></a></p>  <p>Here are all the dependencies:</p>  <p><a href=\""https://i.stack.imgur.com/u7hLL.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/u7hLL.png\"" alt=\""enter image description here\""></a></p>  <p>I've removed LINQ from the equation  yet still getting the following issue:</p>  <p><a href=\""https://i.stack.imgur.com/gn0Jj.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/gn0Jj.png\"" alt=\""enter image description here\""></a></p>  <p>And the full source is below:</p>  <pre><code>public static IEnumerable&lt;DocumentMetaDataEntity&gt; Get(string connectionString  string cacheName  DeconstructedFileName deconstructedFileName  FileMetaDataFilters filters) {     var acc = CloudStorageAccount.Parse(connectionString);     var tableClient = acc.CreateCloudTableClient();     var table = tableClient.GetTableReference(cacheName);     var query = new TableQuery&lt;DocumentMetaDataEntity&gt;().Where         (TableQuery.CombineFilters             (TableQuery.GenerateFilterCondition(\""FacilityCode\""  QueryComparisons.Equal  deconstructedFileName.FacilityCode)                  TableOperators.And                  TableQuery.GenerateFilterCondition(\""LastName\""  QueryComparisons.LessThan  deconstructedFileName.LastName)             )         );                  var entities = table.ExecuteQuery(query).ToList(); } </code></pre>""",azure-functions
45867982,"Azure Functions: We are not able to retrieve the runtime master key <p>Azure Functions bug. I get the error in the portal</p>  <pre><code>Error:  We are not able to retrieve the runtime master key. Please try again later. Session Id: d13fceebd4ea4cb1b7fb3d3829dd1406  Timestamp: 2017-08-24T20:04:23.555Z </code></pre>  <p>I've tried all of the suggestions here: <a href=\https://blogs.msdn.microsoft.com/jpsanders/2017/05/09/function-app-error-we-are-not-able-to-retrieve-the-runtime-master-key/\"" rel=\""noreferrer\"">https://blogs.msdn.microsoft.com/jpsanders/2017/05/09/function-app-error-we-are-not-able-to-retrieve-the-runtime-master-key/</a></p>  <p>I'm using the runtime version <code>1.0.10917</code> but I've tried <code>~1</code> and get the same result.</p>  <p>This seems to occur when I delete the function from the portal and then recreate it. It consistently happens after that for every function we have. The first time the function is created  it seems to work.</p>""",azure-functions
49313046,"Azure Functions assembly conflicts when I'm using Google.Protobuf <p>I'm new in Azure Functions and I'm creating a FirestoreDb connection. But when I call the <code>FirestoreDb.Create</code> method  I take this exception:</p>  <blockquote>   <p>Exception while executing function: OutputFirebase. Output.Firebase.Services.Functions: Could not load file or assembly 'Google.Protobuf  Version=3.5.1.0  Culture=neutral  PublicKeyToken=a7d26565bac4d604'. Could not find or load a specific file. (Exception from HRESULT: 0x80131621). System.Private.CoreLib: Could not load file or assembly 'Google.Protobuf  Version=3.5.1.0  Culture=neutral  PublicKeyToken=a7d26565bac4d604'.</p> </blockquote>  <p>In the <code>AppDomain.CurrentDomain.GetAssemblies()</code> I see the <code>version 3.0.0</code></p>  <p>Google.Protobuf version 3.0.0 image:</p>  <p><a href=\https://i.stack.imgur.com/giCgT.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/giCgT.png\"" alt=\""Google.Protobuf version 3.0.0 image\""></a></p>  <p>But I installed the <code>version 3.5.1</code> into <code>*.csproj</code> </p>  <pre><code>&lt;Project Sdk=\""Microsoft.NET.Sdk\""&gt;   &lt;PropertyGroup&gt;     &lt;TargetFramework&gt;netstandard2.0&lt;/TargetFramework&gt;     &lt;AzureFunctionsVersion&gt;v2&lt;/AzureFunctionsVersion&gt;     &lt;AssemblyName&gt;Output.Firebase.Services.Functions&lt;/AssemblyName&gt;     &lt;RootNamespace&gt;Output.Firebase.Services.Functions&lt;/RootNamespace&gt;     &lt;RestoreProjectStyle&gt;PackageReference&lt;/RestoreProjectStyle&gt;   &lt;/PropertyGroup&gt;   &lt;ItemGroup&gt;     &lt;PackageReference Include=\""Google.Cloud.Firestore\"" Version=\""1.0.0-beta02\"" /&gt;     &lt;PackageReference Include=\""Google.Protobuf\"" Version=\""3.5.1\"" /&gt;     &lt;PackageReference Include=\""Microsoft.NET.Sdk.Functions\"" Version=\""1.0.9\"" /&gt;   &lt;/ItemGroup&gt;   &lt;ItemGroup&gt;     &lt;None Update=\""firestore-key.json\""&gt;       &lt;CopyToOutputDirectory&gt;Always&lt;/CopyToOutputDirectory&gt;     &lt;/None&gt;     &lt;None Update=\""host.json\""&gt;       &lt;CopyToOutputDirectory&gt;PreserveNewest&lt;/CopyToOutputDirectory&gt;     &lt;/None&gt;     &lt;None Update=\""local.settings.json\""&gt;       &lt;CopyToOutputDirectory&gt;PreserveNewest&lt;/CopyToOutputDirectory&gt;       &lt;CopyToPublishDirectory&gt;Never&lt;/CopyToPublishDirectory&gt;     &lt;/None&gt;   &lt;/ItemGroup&gt; &lt;/Project&gt; </code></pre>  <p>C# Code Sample</p>  <pre><code>using System; using System.IO; using System.Net; using System.Net.Http; using System.Threading.Tasks; using Google.Cloud.Firestore; using Microsoft.Azure.WebJobs; using Microsoft.Azure.WebJobs.Extensions.Http; using Microsoft.Azure.WebJobs.Host;  namespace Output.Firebase.Services.Functions {     public static class OutputFirebaseFunction     {         private static FirestoreDb FirestoreDb;          [FunctionName(\""OutputFirebase\"")]         public static async Task&lt;HttpResponseMessage&gt; Run([HttpTrigger(AuthorizationLevel.Anonymous  \""get\""  \""post\""  Route = \""output/firebase\"")]HttpRequestMessage req  TraceWriter log  ExecutionContext executionContext)         {             log.Info(\""C# HTTP trigger function processed a request.\"");              await InitializeDatabaseAsync(Directory.GetParent(executionContext.FunctionDirectory).FullName);             return req.CreateResponse(HttpStatusCode.OK);         }          private static async Task InitializeDatabaseAsync(string path1)         {             try             {                 var test = Google.Protobuf.FieldCodec.ForBool(13);             }             catch (Exception ex)             {                 throw;             }         }     } } </code></pre>  <p>Any help on why this is happening or how to get around it?</p>  <p>Visual Studio 2017 - Version 15.6.2</p>""",azure-functions
48242010,"psql: could not connect to server... Is the server running on host ... and accepting TCP/IP connections on port 5432? <p>I know this is a popular question.  I have tried everything suggested in similar <a href=\https://stackoverflow.com/questions/38466190/cant-connect-to-postgresql-on-port-5432\"">threads</a>.   I am trying to connect remotely to a postgresql database on an azure windows server 2012 machine.   I have tried the following...</p>  <p><strong>postgresql.conf</strong> </p>  <pre><code>listen_addresses = '*' </code></pre>  <p><strong>pg_hba.conf</strong></p>  <pre><code># IPv4 local connections: host    all             all             0.0.0.0/0            md5 </code></pre>  <p><strong>Firewall</strong></p>  <blockquote>   <p>New inbound rule (firewall) protocols and ports > protocol type > TCP</p>      <p>Local port > 5432 Remote port > All</p> </blockquote>  <p><strong>Grab IP of remote machine</strong></p>  <p>I copied from azure dashboard and also as indicated on top of remote desktop connection</p>  <p><a href=\""https://i.stack.imgur.com/S9QVS.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/S9QVS.png\"" alt=\""enter image description here\""></a></p>  <p><strong>CMD from local machine</strong></p>  <p>Then from local machine tried the following.</p>  <pre><code>psql -U postgres -h 13.xx.xx.xx  </code></pre>  <p><strong>Error message.</strong></p>  <blockquote>   <p>psql: could not connect to server: Connection timed out   (0x0000274C/10060)           Is the server running on host \""13.xx.xx.xx\"" and accepting           TCP/IP connections on port 5432?</p> </blockquote>  <p>I am not sure what else should be done.</p>""",azure-virtual-machine
49121915,"Azure Function timer is running twice and when I log onto the Azure portal <p>I have a Timed Function App in Azure that is scheduled to run at 22:00 daily. However  it appears to run at 21:59 and also at 22:00  consistently every day. It also appears to run at random when I am logged into the Azure portal checking the logs.</p>  <p>Here's an example of the timestamps of the duplicate entries I am getting:</p>  <p><a href=\https://i.stack.imgur.com/5cjvp.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/5cjvp.png\"" alt=\""enter image description here\""></a></p>  <p>I have searched the web but have found no working solution.</p>  <p>Here's the signature of the app  which takes about 20s to complete:</p>  <pre><code>[FunctionName(\""Function1\"")] public static void Run([TimerTrigger(\""0 0 22 * * *\""  RunOnStartup = false)]TimerInfo myTimer  TraceWriter log) {    // My code } </code></pre>  <p>And here's my local.settings.json:</p>  <pre><code>{   \""IsEncrypted\"": false    \""Values\"": {     \""AzureWebJobsStorage\"": \""DefaultEndpointsProtocol=https;AccountName=XXX;AccountKey=XXX\""      \""AzureWebJobsDashboard\"": \""DefaultEndpointsProtocol=https;AccountName=XXX;AccountKey=XXX\""      \""type\"": \""timerTrigger\""      \""schedule\"": \""0 0 22 * * *\""      \""useMonitor\"": false      \""SQLConn\"": \""Server=tcp:XXX.database.windows.net 1433;Initial Catalog=XXX;Persist Security Info=False;User ID=XXX;Password=XXX;MultipleActiveResultSets=False;Encrypt=True;TrustServerCertificate=False;Connection Timeout=30;\""   }    \""disabled\"": false } </code></pre>  <p>Can anyone help me out?</p>  <p>Also  the \""Monitor\"" section in Azure's functions show nothing unusual.</p>""",azure-functions
30272396,Auto generation of thumbnails or preview of images when posting to Azure blob storage <p>I am posting pictures to Azure blob storage. As I am storing full resolution images  I want to maintain a separate collection(s) of thumbnails(or previews) of the images. Is it possible to write a script(or a hook) where when an image is uploaded to the blob storage  the thumbnail of the image is also automatically saved.</p>  <p>Please inform if there's a way to script this.</p>  <p>I don't want to do the resizing on the client side or on the server side. I am using SAS to enable the client to upload the images to blob storage directly. I can send the image to the Mobile Service(server) I am running where the image can be resized and uploaded to the blob storage. But I don't want to overload the server with these calls. </p>,azure-storage
47540952,"Azure app cannot connect to Media Services using C# <p>I am trying to use Azure Media Services to encode videos uploaded to my web app. Now that ACS is removed from AMS .net extensions and api  it seems the only way to connect is using Azure AD credentials. So I have registered service principal with AAD and Granted <em>contributor</em> right on AMS. </p>  <p>All the permissions seems correct and I try to run <a href=\https://github.com/Azure-Samples/media-services-dotnet-copy-blob-into-asset/blob/master/CopyBlobIntoAsset/Program.cs\"" rel=\""nofollow noreferrer\"">this sample code</a> and Azure refuses to issue token.</p>  <p>Fails on line 80: </p>  <pre><code>IAsset sourceAsset = _sourceContext.Assets.Where(a =&gt; a.Id == _sourceAssetID).First(); </code></pre>  <p>Same case with any other operation against AMS.</p>  <pre><code>\""ExceptionMessage\"": \""Error HRESULT E_FAIL has been returned from a call to a COM component.\""          \""ExceptionType\"": \""System.Runtime.InteropServices.COMException\""          \""StackTrace\"": \""   at Microsoft.IdentityModel.Clients.ActiveDirectory.Internal.WebUI.&lt;AcquireAuthorizationAsync&gt;d__12.MoveNext()\\r\\n--- End of stack trace from previous location where exception was thrown ---\\r\\n   at System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess(Task task)\\r\\n   at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task)\\r\\n   at Microsoft.IdentityModel.Clients.ActiveDirectory.AcquireTokenInteractiveHandler.&lt;AcquireAuthorizationAsync&gt;d__10.MoveNext()\\r\\n--- End of stack trace from previous location where exception was thrown ---\\r\\n   at System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess(Task task)\\r\\n   at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task)\\r\\n   at Microsoft.IdentityModel.Clients.ActiveDirectory.AcquireTokenInteractiveHandler.&lt;PreTokenRequest&gt;d__9.MoveNext()\\r\\n--- End of stack trace from previous location where exception was thrown ---\\r\\n   at System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess(Task task)\\r\\n   at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task)\\r\\n   at System.Runtime.CompilerServices.TaskAwaiter.ValidateEnd(Task task)\\r\\n   at Microsoft.IdentityModel.Clients.ActiveDirectory.AcquireTokenHandlerBase.&lt;RunAsync&gt;d__57.MoveNext()\\r\\n--- End of stack trace from previous location where exception was thrown ---\\r\\n   at System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess(Task task)\\r\\n   at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task)\\r\\n   at Microsoft.IdentityModel.Clients.ActiveDirectory.AuthenticationContext.&lt;AcquireTokenCommonAsync&gt;d__39.MoveNext()\\r\\n--- End of stack trace from previous location where exception was thrown ---\\r\\n   at System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess(Task task)\\r\\n   at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task)\\r\\n   at Microsoft.IdentityModel.Clients.ActiveDirectory.AuthenticationContext.&lt;AcquireTokenAsync&gt;d__28.MoveNext()\"" </code></pre>  <p>This error message is from AD.</p>  <p>Wondering if there is anything I need to do on Azure Api app to make this work?</p>""",azure-web-app-service
51885661,"Can't register CosmosDB binding extension in Azure Functions V2 <p>I'm trying to add a new function(Http Trigger) with CosmosDB input binding.</p>  <p>Reading a manual about input bindings in Azure Functions Version 2 I see that I need to register my binging extension(<a href=\https://docs.microsoft.com/en-us/azure/azure-functions/functions-triggers-bindings#register-binding-extensions\"" rel=\""nofollow noreferrer\"">https://docs.microsoft.com/en-us/azure/azure-functions/functions-triggers-bindings#register-binding-extensions</a>)  and azure portal should show me some prompt for registration(<a href=\""https://docs.microsoft.com/en-us/azure/azure-functions/functions-triggers-bindings#azure-portal-development\"" rel=\""nofollow noreferrer\"">https://docs.microsoft.com/en-us/azure/azure-functions/functions-triggers-bindings#azure-portal-development</a>)</p>  <p>I'm confused  because I do not see in templates choice for CosmosDB input binding and therefore any of prompts. So I tried to add code manually in function.json like this:</p>  <pre><code>{   \""type\"": \""cosmosDB\""    \""name\"": \""inputDocument\""    \""databaseName\"": \""DBName\""    \""collectionName\"": \""CollectionName\""    \""connectionStringSetting\"": \""CosmosDBConnect\""    \""direction\"": \""in\""    \""Id\"": \""myid\""    \""partitionKey\"": \""mypartitionkey\"" } </code></pre>  <p>And when I trying to switch on my function C# code I see error <strong>\""Function error(MyFuncName): The binding type(s) 'cosmosDB' are not registered. Please ensure the type is correct and the binding extension is installed.\""</strong></p>  <p>On this page I see that CosmosDB input bindings is supported for Azure Functions Version 2(<a href=\""https://docs.microsoft.com/en-us/azure/azure-functions/functions-triggers-bindings#supported-bindings\"" rel=\""nofollow noreferrer\"">https://docs.microsoft.com/en-us/azure/azure-functions/functions-triggers-bindings#supported-bindings</a>)</p>""",azure-functions
48768415,Using JWT auth when running azure functons locally <p>I wrote some Azure functions. Deployed them to Azure. Added Azure authentication so I would have to pass a bearer token to call them from azure.</p>  <p>Is there any way I could also require bearer authentication when running them locally from Visual studio with the Azure Function runtime?</p>,azure-functions
51788368,"Cannot connect to AzureVM gives error as \An internal error occured\"" <p>I tried redeploy option on azure vm. </p>  <p>tried to reset configuration. It gave error as failed to reset rdp configuration. Stopped and restarted 3-4 times but same issue. I see that azure vm agent is also unresponsive.</p>  <p>In boot diagnostics I see an exclamation mark in image.Please help.<a href=\""https://i.stack.imgur.com/3iviR.jpg\"" rel=\""nofollow noreferrer\"">click to see boot diagnostics image</a></p>""",azure-virtual-machine
56277474,Syncing profile pictures from Azure Active Directory to Azure DevOps <p>I have created an Azure DevOps organization and it has been successfully linked with my Azure AD tenant  group search in the organization correctly shows Azure Active Directory (security) groups.</p>  <p>My user however does not have the correct profile picture in Azure DevOps. In Office 365 and in Azure AD my profile picture shows up correctly  but in Azure DevOps only my initials show up in a colored circle.</p>  <p>Is there a missing setting to make user profile pictures show up in Azure DevOps?</p>,azure-devops
12436844,Windows Azure Storage Emulator Connection String for ASP.NET MVC? <p>I am searching for the connection string that is need to be defined to use windows azure storage emulator. </p>  <p>So far  all the sources I have found says these connection strings should go to <code>ServiceDefinition</code> and <code>ServiceConfiguration</code> files located in Windows Azure project. However  I am not using Azure project but the ASP.NET MVC 3.</p>  <p>For  ASP.NET MVC project  it should probably go to <code>web.config</code> file. However  I have no idea what it should look like ?</p>  <p>I have Azure account if that is needed for emulator.</p>  <p>Thanks.</p>,azure-storage
55048371,"How do I create a POST Azure Function that can perform model binding on the body? <p>With GET  I can just put a parameter in the function definition:</p>  <pre><code>[FunctionName(\GetKittenById\"")] public static async Task&lt;IActionResult&gt; Run(     [HttpTrigger(AuthorizationLevel.Function  \""get\""  Route = \""GetKittenById/{kittenId}\"")] HttpRequest req      string kittenId      ILogger log) { ... } </code></pre>  <p>I want to do the same thing with POST. However if I add a parameter and do this:</p>  <pre><code>[FunctionName(\""CreateKitten\"")] public static async Task&lt;IActionResult&gt; Run(     [HttpTrigger(AuthorizationLevel.Function  \""POST\""  Route = \""CreateKitten\"")] HttpRequest req      Kitten kitten      ILogger log) { ... } </code></pre>  <p>Then my function throws an error when it's POST'd to.</p>  <blockquote>   <p>[07/03/2019 16:17:00] An unhandled host error has occurred.<br>   [07/03/2019 16:17:00] Microsoft.Azure.WebJobs.Host:<br>   'CreateKitten' can't be invoked from Azure WebJobs SDK. Is it   missing Azure WebJobs SDK attributes?.</p> </blockquote>  <p>I can't find on google how to do this. I assume there is built-in binding because when you do a GET you can specify if you want JSON or XML. I want to do the same thing in reverse and let the framework handle it in case they post JSON or XML.</p>  <p>Is there a way to automatically do this or do I have to start poking around in the HttpRequest and deserializing content?</p>  <hr>  <p>I've found that you can replace the <code>HttpRequest req</code> with <code>Kitten kitten</code> and it will do model binding  but I need to keep access to the <code>HttpRequest</code> to be able to read some custom authentication headers.</p>  <p>Is there a way to get both of these without rolling my own? Checking to see if they've sent JSON or XML and writing my own code to do the model binding is a pain just so that I can retrieve the http context.</p>""",azure-functions
49784017,Azure Search Indexer is too slow for large amount of documents <p>I have S1 tier with about 600 000 files in the single container in the blob storage. I've restricted the index to include only (.doc .docx .xls .xlsx .ppt .pptx .pdf .txt .rtf .htm .html) and excluding (.png .jpeg .jpg .gif .psd .mp3 .mp4 .wav .exe .zip .dmg .msi .mkv .flv .ogg .ogv .avi .mov .wmv). I also tried to increase the partitions to the max allowed 12 with no considerable changes in the performance.</p>  <p>With the current indexing speed  I can estimate 30 days to finish the process.</p>  <p>I need this to be indexed quicker. How can I increase the speed of this?</p>  <p>Thanks. </p>,azure-storage
34014259,How can I use a version of Java that isn’t supported in Azure App Service <p>I want to create a Java application on Microsoft Azure in a web app. The web app service has provides some Tomcat and Jetty versions with default configuration. i want to host an application that doesn't use these default versions and configuration. is this doable or should I opt for VM instead?</p>,azure-web-app-service
48907751,"Missing value for AzureWebJobsStorage in local.settings.json local development in Visual Studio 2017 <p>I'm developing a azure function locally  with the Storage Emulator and de Storage Explorer opened.</p>  <p><strong>File tree</strong></p>  <p><a href=\https://i.stack.imgur.com/6F56R.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/6F56R.png\"" alt=\""File tree\""></a></p>  <p><strong>local.settings.json</strong></p>  <pre><code>{   \""IsEncrypted\"": false    \""Values\"": {     \""AzureWebJobsStorage\"": \""UseDevelopmentStorage=true\""      \""AzureWebJobsDashboard\"": \""UseDevelopmentStorage=true\""   }    \""ConnectionStrings\"": {     \""PlantaoEntities\"": {       \""ConnectionString\"": \""CENSORED\""        \""ProviderName\"": \""System.Data.EntityClient\""     }   } } </code></pre>  <p>But a receives the following message when trying to run the code:</p>  <blockquote>   <p>Missing value for AzureWebJobsStorage in local.settings.json. This is required for all triggers other than HTTP. You can run 'func azure functionapp fetch-app-settings ' or specify a connection string in local.settings.json</p> </blockquote>  <p>It's was working before a rebuild solution  and if I try <code>func azure functionapp fetch-app-settings &lt;functionAppName&gt;</code> it try to retrieve the information from the azure portal itself.</p>""",azure-functions
17433892,"How does the delimiter work in Azure Blob Storage? <p>I am storing image files as blobs in Azure Storage with the following naming convention:</p>  <pre><code>directory/image-name </code></pre>  <p>When trying to retrieve the blobs using <code>BlobService.listBlobs(container  options  callback)</code> in Javascript on the server  I use:</p>  <pre><code>var options = { \prefix\"":directory } </code></pre>  <p>and it gets back only blobs that start with the directory name  as I expect  but I thought I would also be able to use:</p>  <pre><code>var options = { \""delimiter\"":\""/\""  \""prefix\"":directory } </code></pre>  <p>and get back the same blobs  perhaps without the prefix in their names.  Instead I get back nothing at all.  What is the correct way to use the delimiter?  What's the point in having it if you get the items that you want with only using the prefix?</p>""",azure-storage
30425482,Azure VM: Custom domain without www <p>I have found a lot of similar questions  but all of them are in regards to a web-app in Azure  while what I am after is virtual machine. I have only VM setup in Azure and on that VM I have Apache HTTPD. I updated A records for my domain to VM's IP and added CNAME for <em>.cloudapp.net  and even CNAMEs for asverify.</em>.azurewebsites.net and awverify.*.azurewebsites.net (using my service name instead of *  of course). And it works fine if I go to www subdomain  but not to the root domain. From manuals found online I see  that you need to setup domains in Azure itself  too  but I fail to find such options for Virtual Machine. I see similar option for Blob  but I'm not sure if it has any relevance here.</p>  <p>Can someone advise  what else I may be needing to connect to my VM using a root domain?</p>,azure-virtual-machine
53376900,"SonarQube build step fails with \Self-Signed Certificate in Certificate Chain\"" in Azure DevOps <p>I am currently setting up a build pipeline in Azure DevOps with a self-hosted agent. Everything is working great so far except the SonarQube build steps.</p>  <p>When executing the Prepare SonarQube on my self-hosted agent it fails with the following error:</p>  <pre><code>2018-11-19T14:14:19.1070144Z ##[debug]organization=null 2018-11-19T14:14:19.1087901Z ##[debug]scannerMode=MSBuild 2018-11-19T14:14:19.1093031Z ##[debug]projectKey=online:kiamservices:main 2018-11-19T14:14:19.1095851Z ##[debug]projectName=Online – KIAM Services 2018-11-19T14:14:19.1098962Z ##[debug]projectVersion=1.0 2018-11-19T14:14:19.1104908Z ##[debug][SQ] API GET: '/api/server/version' with query \""undefined\"" 2018-11-19T14:14:19.2819233Z ##[debug][SQ] API GET '/api/server/version' failed  error was: {\""code\"":\""SELF_SIGNED_CERT_IN_CHAIN\""} 2018-11-19T14:14:19.2832616Z ##[debug]task result: Failed 2018-11-19T14:14:19.2928009Z ##[error][SQ] API GET '/api/server/version' failed  error was: {\""code\"":\""SELF_SIGNED_CERT_IN_CHAIN\""} 2018-11-19T14:14:19.2943259Z ##[debug]Processed: ##vso[task.issue type=error;][SQ] API GET '/api/server/version' failed  error was: {\""code\"":\""SELF_SIGNED_CERT_IN_CHAIN\""} 2018-11-19T14:14:19.2946004Z ##[debug]Processed: ##vso[task.complete result=Failed;][SQ] API GET '/api/server/version' failed  error was: {\""code\"":\""SELF_SIGNED_CERT_IN_CHAIN\""} 2018-11-19T14:14:19.3015449Z ##[section]Finishing: Prepare SonarQube </code></pre>  <p>If I run the same setup on a microsoft hosted agent it runs just fine.</p>  <p>It is correct that my organization uses it's own Certificate Authority but the certificates are present on the self hosted agent as far as I know.</p>  <p>Is there a way to tell SonarQube to just ignore certificate errors?</p>  <p>I have looked high and low and have sadly not found any information on this error that was even remotely helpful.</p>  <p>Thank you in advance!</p>""",azure-devops
35601635,Azure I deleted VMAccessForLinux Extension on Portal <p>As the title  I deleted VMAccessForLinux Extension. However  there's no way to get back the extension.</p>  <p>How to re-install the extension on my VM?</p>  <p>In the case of using Azure CLI  it get me error like the follow:</p>  <hr>  <p>Wed Feb 24 2016 20:56:17 GMT+0900 (KST): { [Error: Invalid update to extension reference for role: Look360VM and reference: VMAccessForLinux.]   code: 'BadRequest'    statusCode: 400    requestId: '36d5f8a1bcd37ce480e26e31a2742249' } Error: Invalid update to extension reference for role: Look360VM and reference: VMAccessForLinux.     at Function.ServiceClient._normalizeError (/usr/local/azure/node_modules/azure-common/lib/services/serviceclient.js:815:23)     at /usr/local/azure/node_modules/azure-common/lib/services/filters/errorhandlingfilter.js:44:29     at Request._callback (/usr/local/azure/node_modules/azure-common/lib/http/request-pipeline.js:109:14)     at Request.self.callback (/usr/local/azure/node_modules/azure-common/node_modules/request/request.js:199:22)     at Request.emit (events.js:110:17)     at Request. (/usr/local/azure/node_modules/azure-common/node_modules/request/request.js:1160:14)     at Request.emit (events.js:129:20)     at IncomingMessage. (/usr/local/azure/node_modules/azure-common/node_modules/request/request.js:1111:12)     at IncomingMessage.emit (events.js:129:20)     at _stream_readable.js:908:16</p>  <hr>  <p>It says 'BadRequest'. I don't know why exactly  but it might be I deleted the extension.</p>  <p>Please comment on the solution if you experienced. Thanks.</p>,azure-virtual-machine
22305935,Windows Azure Virtual Machine with Startup Task <p>Is there a way to add a (parametrized) Startup task to a Windows Azure Virtual Machine through the API? I need to execute a cmdlet after the machine has been started and the code depends on two parameters that will be different for each machine. I know this could be easily achieved for a Web/Worker role  but could it be done for Virtual Machines  as well?</p>,azure-virtual-machine
52736361,Microsoft Azure Storage SDK for java V10 Max Connections <p>I'm using the Microsoft Azure Storage SDK for java and the specific artifact coordinates are: <code>com.microsoft.azure:azure-storage-blob:10.1.0</code>.</p>  <p>My use case is to stream incoming uploads from my server to Azure via the Azure Client provided by the library:</p>  <p><code>[Client] ---upload---&gt; [My Server] ---put object---&gt; [Azure]</code></p>  <p>What I would like to know is how many concurrent connections the Azure Client can handle and if the value is configurable?</p>  <p>I did try to configure the <code>channelPoolSize</code> in the following way:</p>  <pre><code>    final NettyClient.Factory factory = new NettyClient.Factory(              new Bootstrap()               0               10000); //&lt;--- channelPoolSize     final HttpClient client = factory.create(null);      final PipelineOptions pipelineOptions = new PipelineOptions()             .withLogger(new Slf4jLogger(LOG))             .withRequestRetryOptions(NO_RETRY)             .withClient(client);      final HttpPipeline pipeline = StorageURL.createPipeline(credential  pipelineOptions);     final URL endpoint = endpointForAccountOrThrow(accountName);     final ServiceURL serviceURL = new ServiceURL(endpoint  pipeline);     containerURL = serviceURL.createContainerURL(containerName); </code></pre>  <p>But what I can see is that around 250 concurrent uploads the client starts failing with:</p>  <p><code> java.util.concurrent.TimeoutException: null     at io.reactivex.internal.operators.single.SingleTimeout$TimeoutMainObserver.run(SingleTimeout.java:115)     at io.reactivex.internal.schedulers.ScheduledDirectTask.call(ScheduledDirectTask.java:38)     at io.reactivex.internal.schedulers.ScheduledDirectTask.call(ScheduledDirectTask.java:26)     at java.util.concurrent.FutureTask.run(FutureTask.java:266)     at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)     at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)     at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)     at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)     at java.lang.Thread.run(Thread.java:748) </code></p>  <p>Any idea?</p>  <hr>  <p>Hello  I found the problem and I share it here in case it is useful for somebody else. The issue was that as the users number was growing  the streaming time was becoming higher and higher. Around 250 concurrent uploads  there were requests taking more than 1 minute  but I had a generic retry policy defined as follows:</p>  <p><code> private static RequestRetryOptions NO_RETRY = new RequestRetryOptions(             RetryPolicyType.EXPONENTIAL              1              null              null              null              null); </code></p>  <p>This kind of policy is forcing the request to be completed within a minute (which is the default tryTimeout).</p>  <p>After reading the java doc of <code>RequestRetryOptions</code>:</p>  <p><code>      * @param tryTimeout      *      Indicates the maximum time allowed for any single try of an HTTP request. A value of {@code null} means that      *      you accept our default. NOTE: When transferring large amounts of data  the default TryTimeout will probably      *      not be sufficient. You should override this value based on the bandwidth available to the host machine and      *      proximity to the Storage service. A good starting point may be something like (60 seconds per MB of      *      anticipated-payload-size). </code></p>  <p>I switched to a per-request re-try policy setting the tryTimeout value based on the content size. This solved my problem</p>,azure-storage
40879251,WSO2 Identity Server and WSO2 API Management in Azure <p>Is it possible to setup WSO2 Identity Server and WSO2 API Management in Microsoft Azure??</p>  <p>If it is  can someone help me how?? Need some advice and direction.</p>  <p>Thanks.</p>,azure-storage
45499878,Azure: deploy static html app when pushed with GIT <p>I configured Azure to deploy an app from External Git source  using an App Service. The problem is that I have to press the Sync button every time I need a new deploy after a push.</p>  <p>Is there a possibility to trigger a deploy after push for static html files(not ASP.NET app) on Azure App Service? The repository is on a private BitBucket server(not the same as a private repository from the official website).</p>,azure-web-app-service
37940985,"Azure website to SQL server bad network latency <p>One of my clients is seeing inconsistent network latency between their test and live servers.</p>  <p>Using a page that does a simple <code>SELECT 1</code> 100 times:</p>  <pre><code>Test website: 100 calls took: 109.405ms Live website: 100 calls took: 396.9736ms (actually varies between 300-500ms) </code></pre>  <p>Some pages using the EF can end up making 100-200 very simple db calls  which are fast in a normal datacenter setup  but on azure suddenly a second or two are being added on because of this seemingly high network latency.</p>  <p>The DB/websites weren't originally in the same resource groups  but now are. The info from MS on locating them close to each other is inconsistent  there used to be a concept called affinity groups which has been removed  now there are resource groups but it's unclear from the article on <a href=\https://azure.microsoft.com/en-gb/documentation/articles/resource-group-move-resources/\"" rel=\""nofollow\"">moving them</a> whether it does locate them near to each other. Specifically it claims:</p>  <blockquote>   <p>The new resource group may have a different location  but that does not change the location of the resource.</p> </blockquote>  <p>But I believe that is talking about the different worldwide datacenters rather than locale within the datacenter.</p>  <p>For live it's an s3 Standard Serverfarm with a p1 database  with test it's an s1 db  have updated post. DTU is down at 5%. All via the services  no VMs.</p>  <p>Is there anything we can do to reduce this?</p>""",azure-web-app-service
52962199,"TFS build is getting fail with Zero error with message - Process 'msbuild.exe' exited with code '1' <p>I am building a solution file which is having multiple .csproj projects with the TFS(on premises with Build agent on the same network) <strong>MSBuild Task</strong> with version 14.0. As  This is not giving me any Error but getting fail with one message \<strong>Process 'msbuild.exe' exited with code '1'.</strong>\""</p>  <p><a href=\""https://i.stack.imgur.com/bBOOL.jpg\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/bBOOL.jpg\"" alt=\""enter image description here\""></a></p>  <p>My MS Build Task:</p>  <p><a href=\""https://i.stack.imgur.com/n854B.jpg\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/n854B.jpg\"" alt=\""enter image description here\""></a></p>  <p>Build Agent Configuration:</p>  <ul> <li><p>VS community 2017</p></li> <li><p>VS Express 2015 Desktop/Web (update3)</p></li> </ul>  <p>I found a link <a href=\""https://stackoverflow.com/questions/45150339/vsts-build-failing-with-error-process-msbuild-exe-exited-with-code-1\"">VSTS build failing with error &quot;Process &#39;msbuild.exe&#39; exited with code &#39;1&#39;.&quot;</a> but unable to understand the exact issue as even error is not coming.</p>  <p><strong>Full Error log</strong></p>  <blockquote>   <p>302 Warning(s)       0 Error(s) Time Elapsed 00:02:12.37 Exit code: 1</p>      <p>Error record:</p>      <p>Invoke-VstsTool : Process 'msbuild.exe' exited with code '1'.</p>      <p>At   E:\\DevOps\\agent\\vsts-agent-win-x64-2.136.1_work_tasks\\MSBuild_c6c4c611-aa2e-4c76-b606-5eaba2196824\\1.120.0\\ps_modules\\MSBuildHelpers\\InvokeFunctions.ps1:111   char:13   + Invoke-VstsTool -FileName $MSBuildPath -Arguments $arguments -Requir ...</p>      <ul>   <li><p>~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~</p></li>   <li><p>CategoryInfo : NotSpecified: (:) [Write-Error]  WriteErrorException</p></li>   <li><p>FullyQualifiedErrorId :  Microsoft.PowerShell.Commands.WriteErrorException Invoke-VstsTool</p></li>   </ul>      <p>Script stack trace: at Invoke-Tool    E:\\DevOps\\agent\\vsts-agent-win-x64-2.136.1_work_tasks\\MSBuild_c6c4c611-aa2e-4a33-b606-5eaba26824\\1.120.0\\ps_modules\\VstsTaskSdk\\ToolFunctions.ps1:   line 86</p>      <p>at Invoke-MSBuild    E:\\DevOps\\agent\\vsts-agent-win-x64-2.136.1_work_tasks\\MSBuild_c6c4c611-aa2e-4a33-b606-5eaba26824\\1.120.0\\ps_modules\\MSBuildHelpers\\InvokeFunctions.ps1:   line 111</p>      <p>at Invoke-BuildTools    E:\\DevOps\\agent\\vsts-agent-win-x64-2.136.1_work_tasks\\MSBuild_c6c4c611-aa2e-4a33-b606-5eaba26824\\1.120.0\\ps_modules\\MSBuildHelpers\\InvokeFunctions.ps1:   line 36</p>      <p>at     E:\\DevOps\\agent\\vsts-agent-win-x64-2.136.1_work_tasks\\MSBuild_c6c4c611-aa2e-4a33-b606-5eaba96824\\1.120.0\\MSBuild.ps1: line 43</p>      <p>at   : line 1</p>      <p>at   : line 22</p>      <p>at   : line 18</p>      <p>at   : line 1</p>      <p>Exception:</p>      <p>Microsoft.PowerShell.Commands.WriteErrorException: Process   'msbuild.exe'  exited with code '1'.</p>      <p>Process 'msbuild.exe' exited with code '1'.</p>      <p>Processed: ##vso[task.logissue type=error]Process 'msbuild.exe' exited   with code '1'.</p>      <p>Leaving Invoke-VstsTool.</p>      <p>Processed: ##vso[task.complete result=Failed] Leaving Invoke-MSBuild.</p>      <p>Leaving Invoke-BuildTools.</p>      <p>Leaving   E:\\DevOps\\agent\\vsts-agent-win-x64-2.136.1_work_tasks\\MSBuild_c6c4c611-aa2e-4a33-b606-5eaba2196824\\1.120.0\\MSBuild.ps1.</p> </blockquote>  <p>Thanks..!!</p>""",azure-devops
25905251,Uploading 10 000 000 files to Azure blob storage from Linux <p>I have some experience with S3  and in the past have used <code>s3-parallel-put</code> to put many (millions) small files there. Compared to Azure  S3 has an expensive PUT price so I'm thinking to switch to Azure.</p>  <p>I don't however seem to be able to figure out how to sync a local directory to a remote container using <code>azure cli</code>. In particular  I have the following questions:</p>  <p>1- <code>aws</code> client provides a <code>sync</code> option. Is there such an option for <code>azure</code>?</p>  <p>2- Can I concurrently upload multiple files to Azure storage using <code>cli</code>? I noticed that there is a <code>-concurrenttaskcount</code> flag for <code>azure storage blob upload</code>  so I assume it must be possible in principle.</p>,azure-storage
20117718,sequentiual numbering in the cloud <p>Ok so a simple task such as generating a sequential number has caused us an issue in the cloud.  Where you have more than one server it gets harder and harder to guarantee that the allocated number between servers are not clashing.</p>  <p>We are using Azure servers if it helps.</p>  <p>We thought about using the app cache but you cannot guarantee it will be updated between servers. </p>  <p>We are limited to using:  a SQL table with an identity column or  some peer to peer method between servers or use a blob store and utalise the locks to store the nost upto date number. (this could have scaling issues)</p>  <p>I just wondered of anyone has an idea of a solution to resolve this? Surely its a simple problem and must have been solved by now.</p>,azure-storage
50556427,"Retrieve the NICs and the associated VMs in Azure <p>I need to retrieve the NICs and the associated VMs in Azure I've run the following Cmdlet:</p>  <pre><code>Get-AzureRmNetworkInterface | Select Name  VirtualMachine </code></pre>  <p>But  it only generate the names of the NICs but when it come to the Virtual Machine it displays Microsoft.Azure.Commands.Network.Models.PSResourceId  as shown in the following figure.<a href=\https://i.stack.imgur.com/Rd0MD.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/Rd0MD.png\"" alt=\""Virtual Machine Output\""></a></p>  <p>Please advise how to retrieve the actual name of the VM.</p>""",azure-virtual-machine
47752599,"Wildcards in VSTS Release Definition <p>I am trying to deploy Webjobs(4 of them) to App service  but while deploying them I am getting error -</p>  <pre><code>2017-12-11T11:44:09 ============================================================================== 2017-12-11T11:44:10 Got connection details for Azure App  Service:'**********' 2017-12-11T11:44:10 ##[error]Error: More than one package  matched with specified pattern. Please restrain the search  pattern. 2017-12-11T11:44:13 Successfully updated deployment History  at *********** 2017-12-11T11:44:13 ##[section]Finishing: Deploy Azure Webjob </code></pre>  <p>Below is the configuration screen :- <a href=\https://i.stack.imgur.com/K2ZCd.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/K2ZCd.png\"" alt=\""Configuration\""></a></p>  <p>Any idea how can I deploy all webjobs from single task instead of making multiple tasks?</p>""",azure-devops
51508807,"Can't connect Azure Table Storage to PowerBI (415) Unsupported Media Type) <p>I'm getting the error below while connecting to Azure Table Storage </p>  <p>Details: </p>  <blockquote>   <p>Blockquote \AzureTables: Request failed: The remote server returned an error: </p>      <p>(415) Unsupported Media Type. (None of the provided media types are   supported)</p> </blockquote>  <p>The one thing I noticed is that if I fill up only the account name it will automatically add the rest of the url which is <code>\"".table.core.windows.net\""</code> where in the portal its <code>table.cosmosdb.azure.com</code>.</p>  <p>With <code>core.windows.net</code> Im getting err <code>\""AzureTables: Request failed: The remote name could not be resolved\""</code>. But it might messing up some headers while using <code>table.cosmosdb.azure.com</code></p>  <p>Please advise.</p>  <p>Thank you. m</p>""",azure-storage
24117990,"Regex in AzureDevOps web test <p>I am testing a scenario in AzureDevOps web performance test. i need to extract all IDs from a response of one page. As there are multiple IDs and extraction pattern is the same. How can I get all IDs in one variable?</p>  <p>following if the page response</p>  <pre><code>[ {\Id\"":20006 \""Period\"":\""13-Jul\"" \""Territory\"":\""Chicagoelected\"":true     \""Link\"":\""/PSR03/0026-03-a/Web/api/Document/Index/20006\""    \""Username\"":user1 \""Viewer\"":\""user1\""}    {\""Id\"":6 \""Period\"":\""July2013\"" \""Territory\"":\""ChicagoI:false    \""Link\"":\""/PSR03/0026-03-a/Web/api/Document/Index/6\""    \""Username\"":\""user1\"" \""Viewer\"":\""user1\""}    {Id:25008 \""Period\"":\""13-Jun\"" \""Territory\"":\""California\""     \""Selected\"":false     \""Link\"":\""/PSR03/0026-03-a/Web/api/Document/Index/25008\""     \""Username\"":\""user1\"" \""Viewer\"":\""user1}    {Id\"":25007 \""Period\"":\""13-Jun\"" \""Territory\"":\""EV Selected\"":false     \""Link\"":\""/PSR03/0026-03-a/Web/api/Document/Index/25007\""     \""Username\"":\""user1\"" \""Viewer\"":\""user1\""}    {Id:25010 \""Period\"":\""13-May\"" \""Territory\"":\""California\"" \""Selected\"":false    \""Link\"":\""/PSR03/0026-03-a/Web/api/Document/Index/25010\""    \""Username\"":\""user1\"" \""Viewer\"":\""user1}    {Id\"":25009 \""Period\"":\""13-May\"" \""Territory\"":\""Chicago\"" \""Selected:false     Link\"":\""/PSR03/0026-03-a/Web/api/Document/Index/25009\""    \""Username\"":\""user1 Viewer\"":\""user1\""}    {\""Id\"":25005 Period:\""13-Mar Territory\"":\""Chicago\"" \""Selected\"":false    \""Link\"":/PSR03/0026-03-a/Web/api/Document/Index/25005\""     Username:\""user1\"" \""Viewer\"":\""user1\""}    {\""Id\"":25006 \""Period\"":\""13-Mar\"" \""Territory\"":\""EV\"" \""Selected\"":false     \""Link\"":\""/PSR03/0026-03-a/Web/api/Document/Index/25006\""     \""Username\"":\""user1\"" \""Viewer\"":\""user1\""}    {\""Id\"":25011 \""Period\"":\""13-Feb\"" \""Territory\"":\""Chicagoelected\"":false     \""Link\"":\""/PSR03/0026-03-a/Web/api/Document/Index/25011\""     \""Username\"":\""user1\"" \""Viewer:user1\""}]     \""LocalizationDictionary\"": </code></pre>  <hr>  <p>I am writing regex as - \""<em>Id\""</em>:([0-9]*) \""<em>Period\""</em> it is working and giving me all IDs in Rubular. But how can i implement it in VSTS web performance test?</p>""",azure-devops
45740760,"The type initializer for 'Microsoft.WindowsAzure.Storage.CloudStorageAccount' threw an exception error in Xamarin.forms <p>I'm working on AzureStorage cloud solution provided by Xamarin. <a href=\https://developer.xamarin.com/guides/xamarin-forms/cloud-services/storage/azure-storage/\"" rel=\""nofollow noreferrer\"">https://developer.xamarin.com/guides/xamarin-forms/cloud-services/storage/azure-storage/</a></p>  <p>And this is what I got in GetContainer() method.</p>  <blockquote>   <p>The type initializer for   'Microsoft.WindowsAzure.Storage.CloudStorageAccount' threw an   exception</p> </blockquote>  <p>I applied my connection string in the sample project and it worked  but not in my own project.</p>  <p>Has anyone ever faced this issue? Please help me. </p>  <p>Thanks in advance.</p>  <p>Error message : </p>  <pre><code>System.TypeInitializationException: The type initializer for 'Microsoft.WindowsAzure.Storage.CloudStorageAccount' threw an exception. ---&gt; System.NotImplementedException: The method or operation is not implemented.  at Microsoft.WindowsAzure.Storage.CloudStorageAccount.Setting (System.String name  System.String[] validValues) [0x00000] in &lt;667a5fa37f124e50ab7a68ecb3437b13&gt;:0  at Microsoft.WindowsAzure.Storage.CloudStorageAccount..cctor () [0x00000] in &lt;667a5fa37f124e50ab7a68ecb3437b13&gt;:0  --- End of inner exception stack trace ---  at MyTenantWorld.AzureStorage.GetContainer (MyTenantWorld.ContainerType containerType) [0x00020] in &lt;9816076ee17d42efaf1050c5169a4310&gt;:0  at MyTenantWorld.AzureStorage+&lt;UploadFileAsync&gt;d__3.MoveNext () [0x0001a] in &lt;9816076ee17d42efaf1050c5169a4310&gt;:0  at System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw () [0x0000c] in &lt;3fd174ff54b146228c505f23cf75ce71&gt;:0  at System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess (System.Threading.Tasks.Task task) [0x0003e] in &lt;3fd174ff54b146228c505f23cf75ce71&gt;:0  at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification (System.Threading.Tasks.Task task) [0x00028] in &lt;3fd174ff54b146228c505f23cf75ce71&gt;:0  at System.Runtime.CompilerServices.TaskAwaiter.ValidateEnd (System.Threading.Tasks.Task task) [0x00008] in &lt;3fd174ff54b146228c505f23cf75ce71&gt;:0  at System.Runtime.CompilerServices.TaskAwaiter`1[TResult].GetResult () [0x00000] in &lt;3fd174ff54b146228c505f23cf75ce71&gt;:0  at MyTenantWorld.SettingsPage+&lt;SaveData&gt;d__20.MoveNext () [0x00309] in &lt;9816076ee17d42efaf1050c5169a4310&gt;:0  at System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw () [0x0000c] in &lt;3fd174ff54b146228c505f23cf75ce71&gt;:0  at System.Runtime.CompilerServices.AsyncMethodBuilderCore+&lt;&gt;c.&lt;ThrowAsync&gt;b__6_0 (System.Object state) [0x00000] in &lt;3fd174ff54b146228c505f23cf75ce71&gt;:0  at Android.App.SyncContext+&lt;&gt;c__DisplayClass2_0.&lt;Post&gt;b__0 () [0x00000] in &lt;d855bac285f44dda8a0d8510b679b1e2&gt;:0  at Java.Lang.Thread+RunnableImplementor.Run () [0x00008] in &lt;d855bac285f44dda8a0d8510b679b1e2&gt;:0  at Java.Lang.IRunnableInvoker.n_Run (System.IntPtr jnienv  System.IntPtr native__this) [0x00008] in &lt;d855bac285f44dda8a0d8510b679b1e2&gt;:0  at at (wrapper dynamic-method) System.Object:a4fed05a-cd7a-4756-85bb-5dd975374042 (intptr intptr) </code></pre>""",azure-storage
29906812,forecast package versions different result <p>I am using R forecast package auto.arima() function  testing it against a predictable sine wave time series. When I run the R code on local machine in R studio  I get a significantly different output to running exactly the same code with the same source data as in azure ML. The only difference I can see is that azure has an older version of forecast package 5.4 whereas i have downloaded the latest version on local machine 5.9. (Interestingly the older version in azure ML correctly forecasts future values  the newer version predicts an attenuating amplitude  which is incorrect). </p>  <p>My question then is for anyone who may know why a function's behaviour would change so significantly between package versions  which strikes me as very strange. Or am I missing something here? I am new to both R and azure ML.. </p>,azure-virtual-machine
45091471,How to get the name of the user that created a function app <p>Is there a direct way to get the owner/creator of a function app under my tenant? I've been trying to find anything inside the resource explorer and so far the only way to know which user deployed this function app is to go to the activity logs.</p>  <p>My objective is get the creators of every function app under my tenant  preferably using ARM Rest API. </p>,azure-functions
38851403,"Create multiple virtual machine instances in azure using java SDK without Scale Set <p>I am using <a href=\https://github.com/Azure/azure-sdk-for-java\"" rel=\""nofollow\"">java sdk</a> for creating virtual machines in windows azure.But i can create only one instance of virtual machine at a time.  <br><br> I can use Scale Set for creating multiple virtual machine instances but i am not suppose to do that  because Scale Set is a special image. If we created virtual machines using scale set it won't be displayed under virtual machines tab.  <br><br> So is there any way to create multiple virtual machine instances in azure using java SDK without using thread loops and Scale Set?</p>""",azure-virtual-machine
40371914,"Does Azure function pricing include webhooks too? <p>I understood how functions <a href=\https://azure.microsoft.com/en-in/pricing/calculator/#functions-1\"" rel=\""nofollow noreferrer\"">pricing</a> works. It is basically the sum of request charges and computation charges. Assuming I use a <strong>webhook + API</strong> triiger for my function. Now how my pricing works ? </p>""",azure-functions
9454208,Get 100 Items from Azure Table Storage by known Keys result HTTP Error 414 <p>I want to show 100 items from Azure table  I already know PartitionKey and Rowkey  so for the $filter  something looks like this: </p>  <p><code>((PartitionKey eq 'js32') and (RowKey eq '18371378441826619420')) or ((PartitionKey eq 'js53') and (RowKey eq '18371389407961060290')) or ((PartitionKey eq 'js37') and (RowKey eq '18371565010300884950')) or ((PartitionKey eq 'js64') and (RowKey eq '18371570522532718663')) or ((PartitionKey eq 'js78') and (RowKey eq '18371571234060779934')) or ((PartitionKey eq 'js18') and (RowKey eq '18371620015195251645')) or ((PartitionKey eq 'js59') and (RowKey eq '18371642621740783008')) or ((PartitionKey eq 'js27') and (RowKey eq '18371653219702884172')) or ((PartitionKey eq 'js79') and (RowKey eq '18371686842261536342')) or ((PartitionKey eq 'js25') and (RowKey eq '18371703202567992223')) or ((PartitionKey eq 'js25') and (RowKey eq '18371721921192859595')) or ((PartitionKey eq 'js40') and (RowKey eq '18371723165056625088')) or ((PartitionKey eq 'js58') and (RowKey eq '18371742515754080322')) or ((PartitionKey eq 'js59') and (RowKey eq '18371742690277511383')) or ((PartitionKey eq 'js27') and (RowKey eq '18371754349415311569')) or ((PartitionKey eq 'js41') and (RowKey eq '18371755036440371353')) or ((PartitionKey eq 'js70') and (RowKey eq '18371790002968340255'))......</code> </p>  <p><code>Total 100 items (so 100 PartitionKey and 100 RowKey)</code></p>  <p>But then I got the error: <code>HTTP Error 414. The request URL is too long.</code></p>  <p>Did you experience this error  how did you solve it?</p>,azure-storage
54201775,"Structuring Azure API Headers for use in PowerShell query <p>I am trying to write some PowerShell code to interact with the storage API in Azure Commercial and am having some challenges getting the headers structure correct.</p>  <p>Below is the code I am using to get a token for my Service Principal:</p>  <pre><code># Get token for Azure Resource Manager API $Body = @{     'resource'      = $storageResourceID     'client_id'     = $tf_sp_appid     'grant_type'    = 'client_credentials'     'client_secret' = $terraform_sp_secret }  $params = @{     ContentType = 'application/x-www-form-urlencoded'     Headers     = @{'accept' = 'application/json'}     Body        = $Body     Method      = 'Post'     URI         = $TokenEndpoint }  # Get token $token = Invoke-RestMethod @params </code></pre>  <p>When I run the code below to get a list of all of the containers in a storage account  it throws the an error about an Invalid Header Value:</p>  <pre><code>$getDate = ((get-date).ToUniversalTime()).ToString('R') $RestAPIParams = @{     Uri    = \https://$storageAcctName.blob.core.windows.net/?comp=list\""     Method = \""Get\""     Verbose = $true     Headers = @{         'authorization' = \""Bearer $($token.access_token)\""         'x-ms-date' = \""$getDate\""         'x-ms-version' = \""2017-10-01\""         }     } $result = (Invoke-RestMethod @RestAPIParams).value </code></pre>  <p><a href=\""https://i.stack.imgur.com/rCZAO.jpg\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/rCZAO.jpg\"" alt=\""enter image description here\""></a></p>""",azure-storage
52256080,"Download file in azure storage using ASP.Net core2 <p>I have web application and user should be able to download files which are stored in the azure storage.</p>  <pre><code>public class FileDownloader {     private string constring = \myconnectionstring\"";      public async Task download(string fileName  string directoryName)     {         try         {             CloudStorageAccount storageAccount = CloudStorageAccount.Parse(constring);             CloudFileClient fileClient = storageAccount.CreateCloudFileClient();             CloudFileShare share = fileClient.GetShareReference(\""myreference\"");             string userName = Environment.UserName;               if (await share.ExistsAsync())             {                 // Get a reference to the root directory for the share.                 CloudFileDirectory rootDir = share.GetRootDirectoryReference();                  // Get a reference to the directory we created previously.                 CloudFileDirectory sampleDir = rootDir.GetDirectoryReference(directoryName);                  // Ensure that the directory exists.                 if (await sampleDir.ExistsAsync())                 {                     // Get a reference to the file we created previously.                     CloudFile file = sampleDir.GetFileReference(fileName);                      // Ensure that the file exists.                     if (await file.ExistsAsync())                     {                          await file.DownloadToFileAsync(string.Format(\""C:/Users/\"" + userName + \""/Downloads/{0}\""  fileName)  FileMode.Create);                     }                 }             }          }         catch (Exception ex)         {          }     } } </code></pre>  <p>This is my code.</p>  <p>It works perfectly when I run application in my local environment(localhost) but when I deploy it and host it in the azure  it isn't downloading the files.</p>""",azure-storage
52624681,Azure Application Web Service Logout <p>So what happened is i deployed two azure web app in Azure Web App service (Frontend and Backend). Then I set-up both authenticated by Azure Active Directory.</p>  <p>Now  In the browser when I login via frontend  I can access both frontend and Backend. However  when I logout in frontend using '.auth/logout' I can still access the Backend?</p>  <p>Any idea about this ?</p>,azure-web-app-service
46428009,How to set the Java / Tomcat options for an Azure Web App using Azure Powershell SDK <p>I can successfully set the Java and Tomcat version for Azure web sites using the portal. But I am not able to do this using the Powershell SDK. </p>  <p>How I can set the needed configuration´s with Powershell?</p>,azure-web-app-service
52253100,App Service backup fails after changing DB pricing from DTU to vCore <p>I have multiple App Services running under the same App Service plan and accessing one SQL databases each in the same SQL elastic pool.<br> All apps are configured to perform a daily backup including the database.<br> This worked fine until I changed the pricing plan of the SQL elastic pool from DTU (Standard) to vCore (Gen4). Since then I only get the following message and the backup fails:</p>  <blockquote>   <p>Create Database copy of MyDB (MyDB_7dd79ad1_00af_42d9_85f6_5e011b67d765) threw an exception. Could not create Database copy. Make sure to use the admin user in the database connection string.</p> </blockquote>  <p>The connection string is using the admin user (I also tried a new dbmanger user with the same result). Using SSMS or other backup tools I can create backups of the DB with the same user.</p>  <p>Does anyone know how I can fix that so my backups are running again?<br> (if I exclude the DB they are still running fine)</p>,azure-web-app-service
55640257,Azure App Services Web App not registering update <p>I have a Azure App Service app that I'm trying to get deployed.</p>  <p>Today I ran into an issue where .NET informed me (via the yellow screen of death when I browse to the URL of my app) that I had a missing DLL (for the purposes of this question I don't think it really matters). I used <code>FileZilla</code> to publish my changes in an attempt to do a manual deployment first and then work my way to automate it.</p>  <p>After so many attempts to fix it I later realized that the error message never changed. I did something more severe and renamed my <code>bin</code> folder into something completely different and the exact same error message would appear. I've stopped the service  restarted it  and as mentioned  renamed folders  etc. and still the exact same error message persisted.</p>  <p>I also decided to open up the Azure Portal Console for my App Service app to browse a bit and to my amazement  nothing seemed to have reflected at all. The FTP shows one thing and the Console shows another.</p>  <p>Would anyone have any idea as to why this is happening?</p>,azure-web-app-service
38132519,"Bundles request returning Cache-Control response header as no-cahe when deployed on Azure Web APP <p>We are using CDN for bundling in Azure Web APP. We have implemented  approach given in below article.But it seems that for every bundle request to CDN  CDN is only forwarding this request to Azure Web-App instead of delivering it from its own cache making it more time consuming</p>  <p><a href=\https://azure.microsoft.com/en-us/documentation/articles/cdn-websites-with-cdn/#integrate-aspnet-bundling-and-minification-with-azure-cdn\"" rel=\""nofollow\"">https://azure.microsoft.com/en-us/documentation/articles/cdn-websites-with-cdn/#integrate-aspnet-bundling-and-minification-with-azure-cdn</a></p>  <p>On debugging  found that Cache-Control value is set to no-Cache from azure-web-app. In Bundle Request URL we are using build number for Querystring value. </p>  <p>URL looks like - ~/bundles/lib?v=26948 </p>  <p>Caveat is  this works well when deployed on local.Somehow azure web app is sending wrong value for Cache-Control</p>  <p>Below is fiddler trace for bundle request on webapp.</p>  <pre><code>GET /bundles/lib?v=26948 HTTP/1.1 Accept: text/html  application/xhtml+xml  image/jxr  */* Host: mseventsdevtertiary.azurewebsites.net Connection: Keep-Alive Accept-Language: en-IN en;q=0.5 Accept-Encoding: gzip  deflate  peerdist X-P2P-PeerDist: Version=1.1 X-P2P-PeerDistEx: MinContentInformation=1.0  MaxContentInformation=2.0   HTTP/1.1 200 OK               Cache-Control: no-cache    Pragma: no-cache Transfer-Encoding: chunked Content-Type: text/javascript; charset=utf-8 Content-Encoding: gzip Expires: -1 Vary: Accept-Encoding Server: Microsoft-IIS/8.0 X-AspNet-Version: 4.0.30319 Access-Control-Allow-Origin: * Date: Mon  27 Jun 2016 09:02:28 GMT  </code></pre>""",azure-web-app-service
46725179,Unable to use Visual Studio Code Coverage with Azure Functions <p>I am using Visual Studio 15.3.5 and Microsoft.NET.Sdk.Functions 1.0.6.</p>  <p>I can run tests fine  but when I analyze the tests with Code Coverage the assembly which contains the Azure Functions is not analyzed. It is not listed in the Code Coverage assembly list. Other assemblies are listed  only the Azure Functions assembly is omitted.</p>  <p>Have anyone got it working?</p>,azure-functions
28985945,"Azure \Availability Set\"" doesn´t show in other VMs configuration <p>We´ve created a number of VMs on Azure and want to group those together into a \""Frontend\"" availability set.</p>  <p>So  we created a availability set in the config of the 1st VM: <img src=\""https://i.stack.imgur.com/2wzNF.png\"" alt=\""enter image description here\""></p>  <p>Unfortunately  on the other VMs it doesn´t show up in the dropdown. <img src=\""https://i.stack.imgur.com/TO5Ou.png\"" alt=\""enter image description here\""> Are we missing something? How can we add the other Servers to the set?</p>""",azure-virtual-machine
51521056,"Get Available Virtual Machine (Classic) Sizes <p>We work with ARM and Classic Azure VM's.</p>  <p>For ARM VM we use <a href=\https://docs.microsoft.com/en-us/dotnet/api/microsoft.azure.management.compute?view=azure-dotnet\"" rel=\""nofollow noreferrer\"">Microsoft.Azure.Management.Compute</a> namespace (<a href=\""https://www.nuget.org/packages/Microsoft.Azure.Management.Compute/\"" rel=\""nofollow noreferrer\"">nuget</a>). For Classic VM we use <a href=\""https://msdn.microsoft.com/en-us/library/microsoft.windowsazure.management.compute.aspx\"" rel=\""nofollow noreferrer\"">Microsoft.WindowsAzure.Management.Compute</a> namespace (<a href=\""https://www.nuget.org/packages/Microsoft.WindowsAzure.Management.Compute/\"" rel=\""nofollow noreferrer\"">nuget</a>).</p>  <p>I need to find available sizes for specified VM.</p>  <p>I can do it using <a href=\""https://docs.microsoft.com/en-us/dotnet/api/microsoft.azure.management.compute.virtualmachinesoperationsextensions.listavailablesizes?view=azure-dotnet#Microsoft_Azure_Management_Compute_VirtualMachinesOperationsExtensions_ListAvailableSizes_Microsoft_Azure_Management_Compute_IVirtualMachinesOperations_System_String_System_String_\"" rel=\""nofollow noreferrer\"">ListAvailableSizes</a> method for <strong>ARM VM</strong>. But I can not find relevant method for <strong>Classic VM</strong>...</p>  <p>How I can retrieve available sizes for <strong>Classic VM</strong>?</p>""",azure-virtual-machine
47074971,"What is \BizTalk Server URL\"" in logic app On premises gateway connection <p>What will be used for BizTalk Server URL in creating a logic app on-premises data gateway? I used DNS of my Azure Biztalk Server VM and VM IP but it does not work for me.<a href=\""https://i.stack.imgur.com/urjb7.jpg\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/urjb7.jpg\"" alt=\""enter image description here\""></a></p>""",azure-virtual-machine
35996606,Azure Web App web API impersonate user using ClaimsIdentity <p>In my Azure Web App I want to impersonate the user by using their ClaimsIdentity to call a 3rd party API. The 3rd party web API allows Basic or Kerberos  optionally I can switch to the 3rd party SDK which uses windows integrated security if neccessary.</p>  <p>The problem I'm running into is the impersonation bit  below is my code as it is.</p>  <pre><code>var webUser = HttpContext.Current.User.Identity as ClaimsIdentity;  var windowsIdentity = S4UClient.UpnLogon(webUser.Claims.FirstOrDefault(x =&gt; x.Type.Equals(ClaimTypes.Upn)).Value);  using (var impersonationContext = windowsIdentity.Impersonate()) {     //make call to 3rd party Web API or SDK } </code></pre>  <p>When running the above I get the following error:</p>  <pre><code>The pipe endpoint 'net.pipe://localhost/s4u/022694f3-9fbd-422b-b4b2-312e25dae2a2' could not be found on your local machine. </code></pre>  <p>Everything I've read points to starting the C2WTS windows service  is there a way to start this service for an Azure web app? If not how can I go about impersonating the user or passing credentials to my 3rd party api/sdk?</p>,azure-web-app-service
56843924,Setting custom variable in Scheduled Release trigger <p>I am AzureDevOps for creating a new Release from Scheduled trigger from artifact. Same pipeline can create the release manually.</p>  <p>How can i set the value of a Custom Variable for Release that is triggered from Schedule? One of the Task in my pipeline uses that Variable.</p>,azure-devops
53749995,"Using ConfigurationBuilder in C# .NET Framework where did my App Service settings go? <p>I'm trying to combine a <em>environment-specific variables in source code</em> to an existing configuration of an <em>App.config-file</em> and <em>AppSettings and ConnectionStrings in Azure App Services</em> for an Azure WebJob (.NET Framework). Having all environment variables in App Services can be quite time-consuming when making changes.</p>  <p>After going through a bunch of blogs and posts on the subject of App.config-tranformations and Azure WebJobs it seems like adding a ConfigurationBuilder is fairly recent way to override environment specific (non-secret) settings. If I'm not mistaken it was added in .NET 4.7.1. It seemed more promising than SlowCheetah and scripting. </p>  <p>But after adding a custom ConfigurationBuilder (similarly to mentioned on link 1) <strong>the app settings specified in app service were no longer included in the result</strong>. I ended up with only entries from app.config-file and custom ConfigurationBuilder. Do I need to retrieve these app setting while making custom entries in the configuration entries? Or should I expand the EnvironmentVariables and modify those XmlNode-entries?</p>  <ol> <li><a href=\https://jeffreyfritz.com/2017/11/modern-configuration-for-asp-net-4-7-1-with-configurationbuilders/\"" rel=\""nofollow noreferrer\"">https://jeffreyfritz.com/2017/11/modern-configuration-for-asp-net-4-7-1-with-configurationbuilders/</a></li> <li><a href=\""https://docs.microsoft.com/en-us/dotnet/api/system.configuration.configurationbuilder?view=netframework-4.7.2\"" rel=\""nofollow noreferrer\"">https://docs.microsoft.com/en-us/dotnet/api/system.configuration.configurationbuilder?view=netframework-4.7.2</a></li> </ol>""",azure-web-app-service
52734333,Azure storage table connector issue in LogicApp <p>I am using logic app to process entities that are stored in Azure Storage table. Total number of entities are around 5000. If It use GetEntities action  it returns only 658 entities. Any clue why all entities are returned?</p>,azure-storage
40555780,Automatically deleting branches when completing pull requests <p>My company uses VSTS with git.  When I complete a pull request into the develop branch in VSTS the check box to delete the feature branch is automatically checked  but it won't delete unless I change the permissions on the feature branch to allow an administrators user group that I'm a member of to Rewrite and destroy history (force push).</p>  <p>It's kind of tedious to do this every time I complete a pull request  but I'm not crazy about the idea of giving all members of this administrators user group the ability to delete feature branches all the time. It seems like there could be accidental deletions.  I do feel pretty comfortable with deleting the develop branch when I'm in the process of completing a pull request that's been reviewed and approved.  Is there a third option as far as permissions?  How does your company have the policies set as far as being able to delete feature branches?</p>,azure-devops
52481049,"Why do I see a FunctionIndexingException when creating a QueueTrigger WebJob Function? <p>I created a function like this</p>  <pre><code>public static Task HandleStorageQueueMessageAsync(     [QueueTrigger(\%QueueName%\""  Connection = \""%ConnectionStringName%\"")] string body      TextWriter logger)     {         if (logger == null)         {             throw new ArgumentNullException(nameof(logger));         }          logger.WriteLine(body);         return Task.CompletedTask;     } </code></pre>  <p>The queue name and the connection string name come from my configuration that has an <code>INameResolver</code> to get the values. The connection string itself I put from my secret store into the app config at app start. If the connection string is a normal storage connection string granting all permissions for the whole account  the method works like expected.</p>  <p>However  in my scenario I am getting an SAS from a partner team that only offers read access to a single queue. I created a storage connection string from that which looks similar like </p>  <pre><code>QueueEndpoint=https://accountname.queue.core.windows.net;SharedAccessSignature=st=2017-09-24T07%3A29%3A00Z&amp;se=2019-09-25T07%3A29%3A00Z&amp;sp=r&amp;sv=2018-03-28&amp;sig=token </code></pre>  <p>(I tried successfully to connect using this connection string in Microsoft Azure Storage Explorer)</p>  <p>The queue name used in the <code>QueueTrigger</code> attribute is also gathered from the SAS</p>  <p>However  now I am getting the following exceptions</p>  <pre><code>$exception  {\""Error indexing method 'Functions.HandleStorageQueueMessageAsync'\""}    Microsoft.Azure.WebJobs.Host.Indexers.FunctionIndexingException InnerException  {\""No blob endpoint configured.\""}    System.Exception {System.InvalidOperationException} </code></pre>  <p>If you look at the connection string  you can see the exception is right. I did not configure the blob endpoint. However I also don't have access to it and neither do I want to use it. I'm using the storage account only for this <code>QueueTrigger</code>.</p>  <p>I am using Microsoft.Azure.WebJobs v2.2.0. Other dependencies prevent me from upgrading to a v3.x</p>  <p>What is the recommended way for consuming messages from a storage queue when only a SAS URI with read access to a single queue is available? If I am already on the right path  what do I need to do in order to get rid of the exception?</p>""",azure-storage
38631503,Windows Services on Azure Virtual Machines with Availability Sets <p>I have few (around 10) Windows Services on my existing environment. We are planning to migrate to Azure with the following.</p>  <ol> <li>Host our database on Azure SQL Database.</li> <li>Install all the 10 Windows Services in a Azure Virtual Machine. Please note that these Windows Services does bulk inserts into the Azure SQL databases.</li> <li>Take 2 instances of VM (specified in #2 above) and configure them in an Availability Set to avail the SLA.</li> </ol>  <p>I have two questions.</p>  <ol> <li>Do I need to install all my 10 Services to both the VMs?</li> <li>Will that NOT be reduntant running the Windows Services in both the VMs? So  the Bulk Inserts will be duplicated to the Azure SQL Databases.</li> </ol>  <p>Please let me know if I am thinking in the right direction or are there any alternate methods (like Worker Roles) of utilizing the existing Windows Services on Azure with minimum or no changes?</p>,azure-virtual-machine
35342817,Is machine key shared between Azure App Service instances? <p>If I scale out my azure app service  <strong>are all the instances sharing the same machine key</strong>? I want to use app service for my website with Web API 2.0 + Katana middleware and tokens are issued and validated using the machine key. Azure documentation does not provide any answer. </p>  <p>I made some tests and it seems that the key is shared.</p>,azure-web-app-service
54333049,"Performance Azure function with multiple output bindings <p>Hello all who read this </p>  <p>We have written a router function on azure in an app plan that receives messages from iothub and depending the message type we route our message to another eventhub.</p>  <p>Previously we had 6 out bindings to eventhubs in this function Recently we added 3 more message type so 3 more out binding to 3 more eventhubs</p>  <p>No processing of the messages happen in this function but what we see now is that we spend 16 times more time in the routing function.</p>  <p>Is there a performance issue about having multiple output bindings. We don't see an increase in load of the incoming messages.</p>  <p>We are running on azure functions 1.0 (Runtime version: 1.0.12205.0 (~1))</p>  <p>Regards Ben</p>  <p>Simplified Sample code of the routing function </p>  <pre><code>public static class IotHubRouterFunction {     [FunctionName(\IotHubRouterFunction\"")]     public static void Run([EventHubTrigger(\""%iothub%\""  Connection = \""IothubRouterListen\"")]EventData myEventHubData          [EventHub(\""%msg1-eventhub%\""  Connection = \""msg1event\"")] ICollector&lt;EventData&gt; eventHub4Dmsg1Event          [EventHub(\""%msg2-eventhub%\""  Connection = \""msg2event\"")] ICollector&lt;EventData&gt; eventHub4Dmsg2Event          [EventHub(\""%msg3-eventhub%\""  Connection = \""msg3event\"")] ICollector&lt;EventData&gt; eventHub4Dmsg3Event          //...  like 6 more bindings like this         ILogger logger     )     {         try         {             var messageType = GetValue(myEventHubData.Properties  \""type\"");              // routing             switch (messageType)             {                 case \""msg1event\"":                 {                     eventHub4DevicesStatusChanged.Add(eventHub4Dmsg1Event);                     break;                 }                 case \""msg2event\"":                 {                     eventHub4MeasurementLog.Add(eventHub4Dmsg2Event);                     break;                 }                 case \""msg3event\"":                 {                     eventHub4DeviceDiscovered.Add(eventHub4Dmsg3Event);                     break;                 }                 //6 more cases like this                 default:                 {                     logger.LogError(\""Unrouteable message of type: {messageType}\""  messageType);                     break;                 }             }         }         catch (Exception ex)         {             //removed         }     }         } </code></pre>  <p>With 6 bindings the message fly through the router function at 50ms With 9 bindings the message crawl through the router function at 800ms</p>  <p>CPU raised with 30% as well on the applan (we scaled extra so we have it under control but why so much what is causing this)</p>""",azure-functions
45696371,"\The remote certificate is invalid according to the validation procedure\"" when sending emails from a azure app <p>We have two Azure apps that run an MVC website in one and a continuous webjob in the other. Both suddenly yesterday around midday started giving the error below when sending emails using smtpclient.</p>  <blockquote>   <p>The remote certificate is invalid according to the validation procedure</p> </blockquote>  <p>No changes have been made in the code or in the mail server. We had this issue in February 2017 with no solution then (<a href=\""https://social.msdn.microsoft.com/Forums/en-US/f2f35ab9-3d0a-490f-b639-8ea5abda92d5/intermittent-the-remote-certificate-is-invalid-according-to-the-validation-procedure?forum=windowsazurewebsitespreview\"" rel=\""nofollow noreferrer\"">https://social.msdn.microsoft.com/Forums/en-US/f2f35ab9-3d0a-490f-b639-8ea5abda92d5/intermittent-the-remote-certificate-is-invalid-according-to-the-validation-procedure?forum=windowsazurewebsitespreview</a>) and again the same issue around September 2016.</p>  <p>Same code sends the email fine locally and it also works from one of our VMs. </p>  <pre><code>using (var smtp = new SmtpClient(\""mail.server.com\""  25)) {     smtp.EnableSsl = true;     smtp.Credentials = new NetworkCredential(username  password);     smtp.Send(message); } </code></pre>  <p>Tried <a href=\""https://twitter.com/AzureSupport\"" rel=\""nofollow noreferrer\"">https://twitter.com/AzureSupport</a> but they are not replying. We don't have Azure support plan but why would we have to pay for something we didn't break or wait 8 hours or even an 1 hour for such critical part of any business like sending an email?</p>  <p>We've started rolling most of our web apps to Azure but we've been moving them back to a server since it's one problem after another... Those two Azure apps were the last ones and now only one left and only because it uses webjobs and the code relies on being a webjob.</p>  <p>UPDATE: Both certificates thumbprints in Azure app and mail server match.</p>""",azure-web-app-service
51135301,"Create a private static field at module level in F# <p>I'm trying to create a configured object that can be reused along requests in Azure Functions. The example below is in C#. The idea is to avoid the expensive creation of a customized <code>DocumentClient</code> instance for each request. The <code>client</code> field is static and is reused in this example taken from the documentation:</p>  <pre><code>using System; using System.Configuration; using System.Linq; using System.Net; using System.Net.Http; using System.Threading.Tasks; using Microsoft.Azure.Documents; using Microsoft.Azure.Documents.Client; using Microsoft.Azure.WebJobs; using Microsoft.Azure.WebJobs.Extensions.Http; using Microsoft.Azure.WebJobs.Host;  private static DocumentClient client = GetCustomClient(); private static DocumentClient GetCustomClient() {     DocumentClient customClient = new DocumentClient(         new Uri(ConfigurationManager.AppSettings[\CosmosDBAccountEndpoint\""])           ConfigurationManager.AppSettings[\""CosmosDBAccountKey\""]          new ConnectionPolicy         {             ConnectionMode = ConnectionMode.Direct              ConnectionProtocol = Protocol.Tcp              // Customize retry options for Throttled requests             RetryOptions = new RetryOptions()             {                 MaxRetryAttemptsOnThrottledRequests = 10                  MaxRetryWaitTimeInSeconds = 30             }         });      // Customize PreferredLocations     customClient.ConnectionPolicy.PreferredLocations.Add(LocationNames.CentralUS);     customClient.ConnectionPolicy.PreferredLocations.Add(LocationNames.NorthEurope);      return customClient; }  [FunctionName(\""CosmosDbSample\"")] public static async Task&lt;HttpResponseMessage&gt; Run(     [HttpTrigger(AuthorizationLevel.Anonymous  \""get\""  Route = \""foo/{id}\"")] HttpRequestMessage req      string id      TraceWriter log) {     Uri documentUri = UriFactory.CreateDocumentUri(\""ToDoList\""  \""Items\""  id);     Document doc = await client.ReadDocumentAsync(documentUri);      if (doc == null)     {         return req.CreateResponse(HttpStatusCode.NotFound);     }      return req.CreateResponse(HttpStatusCode.OK  doc); } </code></pre>  <p>In order to try to simulate with a simpler example  I tried the code below. It works normally: </p>  <pre><code>namespace TransactionsAggregate  open Microsoft.AspNetCore.Http open Microsoft.Azure.WebJobs open Microsoft.Azure.WebJobs.Host open Microsoft.Azure.WebJobs.Extensions.Http open System.Net open System.Net.Http open System.Web.Http open Newtonsoft.Json open System.Text   module Ping =           type Name = {         First: string         Last: string     }      type Greeting = {         Greeting: string     }       let jsonFormatter = System.Net.Http.Formatting.JsonMediaTypeFormatter()     jsonFormatter.SerializerSettings.ContractResolver &lt;- new Newtonsoft.Json.Serialization.CamelCasePropertyNamesContractResolver()        [&lt;FunctionName(\""Ping1\"")&gt;]     let run([&lt;HttpTrigger&gt;] req: HttpRequest  log: TraceWriter) =         async {          log.Info(\""Chamando Ping 1\"")         let! jsonContent = req.ReadAsStringAsync() |&gt; Async.AwaitTask          try             let name = JsonConvert.DeserializeObject&lt;Name&gt;(jsonContent  jsonFormatter.SerializerSettings)              let response = new HttpResponseMessage(HttpStatusCode.OK)             let body = JsonConvert.SerializeObject( { Greeting = sprintf \""Hello %s %s!\"" name.First name.Last })             let content = new StringContent(body  Encoding.UTF8  \""application/json\"")             response.Content &lt;- content             return response          with _ -&gt;             return new HttpResponseMessage(HttpStatusCode.BadRequest)         } |&gt; Async.StartAsTask </code></pre>  <p>In this F# example  we have an Azure Function that runs on V2 version and is written on .NET Core. This is a precompiled function (not an script). It's a class library project. This example just echoes the parameters passed. The <code>jsonFormatter</code> is defined and configured at module level and is not marked as static of so. Is there a way to create a static field of something similar so I could cache this jsonFormatter or in the future  a much more expensive object? Also  is there any guarantee that there will be only one instance of this value on the application? </p>  <p>Documentation: <a href=\""https://docs.microsoft.com/en-us/sandbox/functions-recipes/cosmos-db\"" rel=\""noreferrer\"" title=\""CosmosDB Recipes\"">https://docs.microsoft.com/en-us/sandbox/functions-recipes/cosmos-db</a></p>  <p>Thanks in advance</p>""",azure-functions
53201870,Can we change V-Next release agent pools dynamically? <p>I have a Team project and the build and releases configured in multiple geographical locations. Since all the geographical locations are having its own drop locations and agents as well. </p>  <p>So here my question is  the release agent pool has to be selected while creating the release job. So is it possible to change this release agent pool dynamically while I trigger the build associated with that release? </p>  <p>Scenario : People from India and US can run the build job (since it is common)  The build is manual trigger so we have the freedom to choose build agent pool of India or US but the subsequent release is an automated trigger  so is it possible to trigger the release in the agents in respective country?</p>  <p>(eg  if a developer run the job from India  then the release job should run in release agents in India similarly it should trigger in US release agent if somebody triggers it from US).</p>  <p>Any help would be appreciated.</p>,azure-devops
55526090,"Configuring Twilio SMS from Azure Functions v2 <p>I have some code where I'm reading messages off of an Azure Event Hub that I want to either send an email or send an SMS.</p>  <p>The email is working through send grid  but I'm not sure how to configure the SMS part though.</p>  <p>I think I'd want to use Twilio and here's a sample of what my code's like. The \messageCollector\"" works for sending Email since there's some configuration for SendGrid in the local json. How do I configure Twilio?</p>  <pre><code>    [FunctionName(\""SendAlert\"")]     public static async Task Run(         [EventHubTrigger(\""v1-email-hub\""  Connection = \""EventHubConnection\"")] EventData[] events          [SendGrid] IAsyncCollector&lt;SendGridMessage&gt; messageCollector          [TwilioSms] IAsyncCollector&lt;CreateMessageOptions&gt; smsCollector          [Inject] NotificationEventLogic eventLogic          ILogger log)     {          foreach (EventData eventData in events)         {              string messageBody = Encoding.UTF8.GetString(eventData.Body.Array  eventData.Body.Offset  eventData.Body.Count);              var notificationEvents = JsonConvert.DeserializeObject&lt;List&lt;NotificationEvent&gt;&gt;(messageBody);              foreach (var ev in notificationEvents)             {                    if (ev.NotificationEventType == NotificationEventType.Email)                 {                     var message = new SendGridMessage();                      // ... ... make message and add it                     await messageCollector.AddAsync(message);                 }                 else if (ev.NotificationEventType == NotificationEventType.SMS)                 {                     // Not sure how to get this to work                     var mobileMessage = new CreateMessageOptions(new PhoneNumber(ev.Data))                     {                         Body = $\""Notification {ev.NotificationId}\""                     };                      await smsCollector.AddAsync(mobileMessage);                 }                   // await smsCollector.AddAsync()                 await eventLogic.CreateEventAsync(ev);             }          }     } </code></pre>""",azure-functions
39721926,"Azure File Storage - File is corrupted once uploaded <p>I have this code which I'm using for uploading files in azure file storage container.</p>  <pre><code>        var originalFileName = GetDeserializedFileName(result.FileData.First());          var uploadedFileInfo = new FileInfo(result.FileData.First().LocalFileName);          var uploadFolder = \/AzureDocuments\"" + '/' + correctLoanId ;         var patString = HttpContext.Current.Server.MapPath(uploadFolder) + \""/\"" + originalFileName;          if(!Directory.Exists(HttpContext.Current.Server.MapPath(uploadFolder)))         {             Directory.CreateDirectory(HttpContext.Current.Server.MapPath(uploadFolder + '/' + correctLoanId));         }          if (!File.Exists(patString))         {             File.Copy(uploadedFileInfo.FullName  patString);         }          CloudStorageAccount storageAccount = CloudStorageAccount.Parse(             CloudConfigurationManager.GetSetting(\""StorageConnectionString\""));          CloudFileClient fileClient = storageAccount.CreateCloudFileClient();          CloudFileShare share = fileClient.GetShareReference(\""documents\"");         CloudFileDirectory rootDir = share.GetRootDirectoryReference();          CloudFileDirectory sampleDir = rootDir.GetDirectoryReference(correctLoanId);          sampleDir.CreateIfNotExists();          CloudFile cloudFile = sampleDir.GetFileReference(originalFileName);          try         {             //Open a stream from a local file.             Stream fileStream = File.OpenRead(patString);             cloudFile.UploadFromStreamAsync(fileStream);             fileStream.Dispose();          }         catch (Exception ex)         {         } </code></pre>  <p>The file is correctly uploaded and the correct size is shown in azure but when I'm downloading the file I'm getting error message that the file is corrupted.</p>  <p>Any idea if I'm doing something wrong? </p>""",azure-storage
48722961,"Azure Function Binding Types for Stream Analytics Job? <p>The out-of-box Visual Studio 2017 (15.5.5) template for an Azure Function creates an HttpTrigger Run method with HttpRequest and TraceLog as arguments.</p>  <p>I'd like to use other binding types  like POCO  'string' or 'ILogger'.</p>  <p>I've search quite a bit but cannot seem to find a concise list of binding types for an HttpTrigger (http web hook). Some of the articles I've found include:</p>  <ul> <li><a href=\https://docs.microsoft.com/en-us/azure/stream-analytics/stream-analytics-with-azure-functions\"" rel=\""nofollow noreferrer\"">Run Azure Functions with Azure Stream Analytics jobs</a>   </li> <li><a href=\""https://docs.microsoft.com/en-us/azure/azure-functions/functions-bindings-http-webhook\"" rel=\""nofollow noreferrer\"">Azure Functions HTTP and webhook bindings</a></li> <li><a href=\""http://Run%20Azure%20Functions%20with%20Azure%20Stream%20Analytics%20jobs\"" rel=\""nofollow noreferrer\"">Trigger - usage</a></li> </ul>  <p><strong>What are all the possible binding types that are available for Azure Stream Job Functions?</strong> </p>  <p>I can start trial-and-error  but I thought i'd check first.</p>  <p>Thanks</p>  <p>-John</p>""",azure-functions
13222153,"Is the Azure Table storage 2nd generation always better than 1st generation? <p>Microsoft changed the architecture of the Azure Storage to use eg. SSD's for journaling and 10 Gbps network (instead of standard Harddrives and 1G ps network). Se <a href=\http://blogs.msdn.com/b/windowsazure/archive/2012/11/02/windows-azure-s-flat-network-storage-and-2012-scalability-targets.aspx\"" rel=\""nofollow\"">http://blogs.msdn.com/b/windowsazure/archive/2012/11/02/windows-azure-s-flat-network-storage-and-2012-scalability-targets.aspx</a></p>  <p>Here you can read that the storage is designed for \""Up to 20 000 entities/messages/blobs per second\"".</p>  <p>My concern is that 20.000 entities (or rows in Table Storage) is actually not a lot.</p>  <p>We have a rather small solution with a table with 1.000.000.000 rows. With only 20.000 entities pr. second it will take more than half a day to read all rows.</p>  <p>I realy hope that the 20.000 entities actually means that you can do up to 20.000 requests pr. second.</p>  <p>I'm pretty sure the 1st generation allowed up to 5.000 requests pr. second.</p>  <p>So my question is. Are there any scenarios where the 1st generation Azure storage is actually more scalable than the second generation?</p>  <p>Any there any other reason we should not upgrade (move our data to a new storage)? Eg. we tried to get ~100 rows pr. partition  because that was what gave us the best performance characteristic. Are there different characteristic for the 2nd generation? Or has there been any changes that might introduce bugs if we change?</p>""",azure-storage
11320764,"Azure Virtual Machine error: Unable to Capture Image: \Endpoint Not found <p>I am getting the error as below in my Azure Virtual Machine when I save my vhd:-</p>  <pre><code>Failed to capture image vmvhdtrialacc of virtual machine vmvhdalpha  Endpoint Not found: There was no endpoint listening at https://management.core.windows.net:8443/*GUID*/services/hostedservices/vmvhdalpha/deployments/vmvhdalpha/roleInstances/vmvhdalpha/Operations that could accept the message. This is often caused by an incorrect address or SOAP action. See InnerException  if present  for more details. </code></pre>  <p>Any idea what could be wrong here?</p>""",azure-virtual-machine
55922835,How to set/modify connection pool from azure web app to azure sql database - Slow App Issue <p>I have performance issue with my .NET app hosted on an azure web app  connecting to Azure SQL DB with a custom connection string. The more there are users  the more the app is slow. Therefore I am wondering if there are some improvements to perform at connection pool level.</p>  <p>How to check the pool size currently set ? How to detect sql issues when handling requests from different users ? And how to set pool size ?</p>  <p>Thank you for your help.</p>,azure-web-app-service
5958256,"Improving azure blob storage querying speed <p>We currently have a blob storage with thousands of files under the same Azure container. Our file naming convention is something like this:</p>  <p>StorageName\\Team\\SubTeam\\FileName</p>  <p>I'm writing a tool that displays the files for each particular subteam. The code gets the list of blobs for the Container and then for each of those it tries to match to the correct Team\\Subteam (see below for sample code). </p>  <p>This works but is extremely slow (because I need to go through all the files to see if they match a particular subteam). Is there some way to improve the speed of the query? I can think of optimizations such as \Find the first file that matches the team you are looking for and then keep track when you find a different team to quit the for early\"" but that would assume that the BlobList is sorted and wouldn't fix the worst case scenario. </p>  <p>Unfortunately splitting the files under different containers is not an option at this time.</p>  <p>Here is sample code:</p>  <pre><code>IEnumerable&lt;IListBlobItem&gt; blobs = blobContainer.ListBlobs(     new BlobRequestOptions()      {         UseFlatBlobListing = true           BlobListingDetails = BlobListingDetails.Metadata      }).OfType&lt;CloudBlob&gt;();  foreach (var blob in blobs) { var cloudy = blob as CloudBlob;  string blobTeamId = cloudy.Uri.Segments[2].Trim('/'); if (blobTeamId != teamId)         continue;  //Do something interesting with the file </code></pre>""",azure-storage
51556745,"Selenium UI Test pass on local test but fail on VSTS CI <p>I'm using selenium 3.12.0 + VSTS CI for test automation  and there are some problems that confuse me...I have about 400 test cases in my project  and all tests are passed on local environment  but when I build to the VSTS CI  and start test automatically  it goes wrong.</p>  <p>About 60 test cases are failed when the test run on CI  and these cases are always the same. So I try to build another CI pipeline to test these specific cases which are always failed  and they are passed......</p>  <p>Is there any settings or environments missing? thanks for your reply!</p>  <p><a href=\https://i.stack.imgur.com/m9b2x.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/m9b2x.png\"" alt=\""\""></a></p>  <p>it seems like the login element can't be caught on the current page  but the same code of the login action runs successfully in other cases  and if this case test independently on another CI pipeline  it works</p>""",azure-devops
38071006,"Azure Virtual Machine CPU Cores Limit <p>When I try to deploy a new virtual machine in my Azure portal I get the following error at deployment time.</p>  <blockquote>   <p>Deployment to resource group 'Testing' failed. Additional  details   from the underlying API that might be helpful: At least  one resource   deployment operation failed. Please list  deployment operations for   details. Please see  <a href=\https://aka.ms/arm-debug\"" rel=\""nofollow\"">https://aka.ms/arm-debug</a> for usage details.   (Code:  DeploymentFaiIed) Operation results in exceeding quota limits    of Core. Maximum allowed: 20  Current in use: 24  Additional    requested: 4. (Code: OperationNotAIIowed)</p> </blockquote>  <p>Is there a way to work around this issue please? Or can the maximum allowed cores be increased?</p>""",azure-virtual-machine
42336765,"Azure server not accepting rdp  stuck on Settings screen? <p>I cannot currently rdp to my Azure server. After checking the RDP endpoints were open I looked at the Boot Diagnostics and a Settings window was displayed.</p>  <p>Is this significant  if so how do I correct it.</p>  <p>Note: I created another VM based on a previous image of the problematic server and the same thing happened.</p>  <p><a href=\https://i.stack.imgur.com/5XtPE.jpg\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/5XtPE.jpg\"" alt=\""enter image description here\""></a> Thanks Phil</p>""",azure-virtual-machine
5108378,"Exposing Azure Table with oData but working with \Domain\"" objects not Azure Entity Objects <p>Pardon my terminology if incorrect but I'd rather not expose the Azure Table Entity objects directly to the end user  although I want to expose IQueryable.</p>  <p>How can I convert an <code>IQueryable&lt;TableEntity&gt;</code>  to <code>IQueryable&lt;Object&gt;</code></p>  <p>I'm basing my oData logic as explained in this blog. Do share a better way if you have one.</p>  <p><a href=\""http://blogs.southworks.net/fboerr/2010/07/29/create-a-wcf-data-service-odata-to-share-an-azure-table/\"" rel=\""nofollow\"">http://blogs.southworks.net/fboerr/2010/07/29/create-a-wcf-data-service-odata-to-share-an-azure-table/</a> </p>""",azure-storage
56019515,"Permission issues with default deployment script in Azure Web App (linux) dotnet core 2.2 <p>Using the local git deployment method in an Azure WebApp (linux) for dotnet core 2.2 I get permission issues with what I am guessing a default nuget path.</p>  <p>This being my deployment pipeline on bitbucket</p>  <pre><code>- step:   image: microsoft/dotnet   name: Deploy DataCore   script:     - git subtree split -P data-core -b split     - git push https://$BACKEND_LOGIN:$BACKEND_PASSWORD@$BACKEND_GITURL split:master --force </code></pre>  <p>This is what is returned from remote and also part of the deployment logs:</p>  <pre><code>+ git push https://$BACKEND_LOGIN:$BACKEND_PASSWORD@$BACKEND_GITURL split:master --force remote: Deploy Async         remote: Updating branch 'master'.         remote: Updating submodules.         remote: Preparing deployment for commit id '449e740796'.         remote: Generating deployment script.         remote: Running deployment command...         remote: Handling ASP.NET Core Web Application deployment.         remote: ......................... remote:   Restoring packages for /home/site/repository/data-core.csproj...         remote: . remote:   Installing NuGet.Frameworks 4.7.0.         remote: /opt/dotnet/2.2.104/sdk/2.2.104/NuGet.targets(114 5): error : Access to the path '/var/nuget/nuget.frameworks/4.7.0' is denied. [/home/site/repository/data-core.csproj]         remote: /opt/dotnet/2.2.104/sdk/2.2.104/NuGet.targets(114 5): error :   Permission denied [/home/site/repository/data-core.csproj]         remote: An error has occurred during web site deployment.         remote: dotnet restore failed         remote: App container will begin restart within 10 seconds.         remote: Deployment Logs : 'https://_NAME_.scm.azurewebsites.net/newui/jsonviewer?view_url=/api/deployments/449e74079667b8ff046c75a45d4e2e251f99e4d0/log'         To https://_NAME_.scm.azurewebsites.net:443/_NAME_.git    9bfde94..449e740  split -&gt; master </code></pre>  <p>Note the two errors</p>  <pre><code>remote:   Installing NuGet.Frameworks 4.7.0.         remote: /opt/dotnet/2.2.104/sdk/2.2.104/NuGet.targets(114 5): error : Access to the path '/var/nuget/nuget.frameworks/4.7.0' is denied. [/home/site/repository/data-core.csproj]         remote: /opt/dotnet/2.2.104/sdk/2.2.104/NuGet.targets(114 5): error :   Permission denied [/home/site/repository/data-core.csproj] </code></pre>  <p>This WebApp hasn't been configured outside the default and I have used this setup at other times. So I am wondering if there has been an update that requires me to change something.</p>  <p>This is my .csproj file</p>  <pre><code>&lt;Project Sdk=\Microsoft.NET.Sdk.Web\""&gt;    &lt;PropertyGroup&gt;     &lt;TargetFramework&gt;netcoreapp2.2&lt;/TargetFramework&gt;     &lt;AspNetCoreHostingModel&gt;InProcess&lt;/AspNetCoreHostingModel&gt;     &lt;RootNamespace&gt;data_core&lt;/RootNamespace&gt;   &lt;/PropertyGroup&gt;    &lt;ItemGroup&gt;     &lt;PackageReference Include=\""AutoMapper\"" Version=\""8.1.0\"" /&gt;     &lt;PackageReference Include=\""AutoMapper.Extensions.Microsoft.DependencyInjection\"" Version=\""6.1.0\"" /&gt;     &lt;PackageReference Include=\""Microsoft.AspNetCore.App\"" /&gt;     &lt;PackageReference Include=\""Microsoft.AspNetCore.Razor.Design\"" Version=\""2.2.0\"" PrivateAssets=\""All\"" /&gt;     &lt;PackageReference Include=\""Microsoft.EntityFrameworkCore.SqlServer\"" Version=\""2.2.4\"" /&gt;     &lt;PackageReference Include=\""Microsoft.EntityFrameworkCore.Tools\"" Version=\""2.2.4\""&gt;       &lt;PrivateAssets&gt;all&lt;/PrivateAssets&gt;       &lt;IncludeAssets&gt;runtime; build; native; contentfiles; analyzers&lt;/IncludeAssets&gt;     &lt;/PackageReference&gt;     &lt;PackageReference Include=\""Pomelo.EntityFrameworkCore.MySql\"" Version=\""2.2.0\"" /&gt;     &lt;PackageReference Include=\""Microsoft.VisualStudio.Web.CodeGeneration.Design\"" Version=\""2.2.3\"" /&gt;   &lt;/ItemGroup&gt;  &lt;/Project&gt; </code></pre>  <p>Full deployment log here also</p>  <pre><code>[{\""log_time\"":\""2019-05-07T08:41:18.5348434Z\"" \""id\"":\""\"" \""message\"":\""Command: \\\""/home/site/deployments/tools/deploy.sh\\\""\"" \""type\"":0 \""details_url\"":null} {\""log_time\"":\""2019-05-07T08:41:18.6366309Z\"" \""id\"":\""\"" \""message\"":\""Handling ASP.NET Core Web Application deployment.\"" \""type\"":0 \""details_url\"":null} {\""log_time\"":\""2019-05-07T08:41:47.6970957Z\"" \""id\"":\""\"" \""message\"":\""  Restoring packages for /home/site/repository/data-core.csproj...\"" \""type\"":0 \""details_url\"":null} {\""log_time\"":\""2019-05-07T08:41:53.3146873Z\"" \""id\"":\""\"" \""message\"":\""  Installing NuGet.Frameworks 4.7.0.\"" \""type\"":0 \""details_url\"":null} {\""log_time\"":\""2019-05-07T08:41:53.3801758Z\"" \""id\"":\""\"" \""message\"":\""/opt/dotnet/2.2.104/sdk/2.2.104/NuGet.targets(114 5): error : Access to the path '/var/nuget/nuget.frameworks/4.7.0' is denied. [/home/site/repository/data-core.csproj]\"" \""type\"":0 \""details_url\"":null} {\""log_time\"":\""2019-05-07T08:41:53.4164253Z\"" \""id\"":\""\"" \""message\"":\""/opt/dotnet/2.2.104/sdk/2.2.104/NuGet.targets(114 5): error :   Permission denied [/home/site/repository/data-core.csproj]\"" \""type\"":0 \""details_url\"":null} {\""log_time\"":\""2019-05-07T08:41:53.5778675Z\"" \""id\"":\""\"" \""message\"":\""An error has occurred during web site deployment.\"" \""type\"":0 \""details_url\"":null} {\""log_time\"":\""2019-05-07T08:41:53.6091768Z\"" \""id\"":\""\"" \""message\"":\""dotnet restore failed\"" \""type\"":0 \""details_url\"":null} {\""log_time\"":\""2019-05-07T08:41:53.6748839Z\"" \""id\"":\""\"" \""message\"":\""\\\\n/opt/Kudu/KuduConsole/Scripts/starter.sh \\\""/home/site/deployments/tools/deploy.sh\\\""\"" \""type\"":2 \""details_url\"":null}] </code></pre>""",azure-web-app-service
52128635,"Azure HTTP function trigger 2.x with Cosmos DB Output local dev host failing <p>I am developing a http trigger using azure functions 2.x and dotnet core  after the latest update to VS 2017 15.8.2 I am getting the following error when running the function locally</p>  <pre><code>1/9/2018 13:30:50] Stopping Host [1/9/2018 13:31:06] Reading host configuration file 'C:\\Users\\MattDouhan\\source\\repos\\NWMposTransInput\\NWMposTransInput\\bin\\Debug\\netstandard2.0\\host.json' [1/9/2018 13:31:06] Host configuration file read: [1/9/2018 13:31:06] {} [1/9/2018 13:31:06] Starting Host (HostId=desktop7cks1do-260439321  InstanceId=5fd41a43-b3ca-47e4-adf6-320d40fa9613  Version=2.0.11960.0  ProcessId=13156  AppDomainId=1  Debug=False  ConsecutiveErrors=5  StartupCount=6  FunctionsExtensionVersion=) [1/9/2018 13:31:07] A ScriptHost error has occurred [1/9/2018 13:31:07] System.Private.CoreLib: Could not load type 'Microsoft.Azure.WebJobs.Hosting.IWebJobsStartup' from assembly 'Microsoft.Azure.WebJobs.Host  Version=3.0.0.0  Culture=neutral  PublicKeyToken=null'. [1/9/2018 13:31:07] Stopping Host </code></pre>  <p>I am running Function Core tools 2.0.1-Beta.35 and runtime version 2.0.11960.0</p>  <p>The function looks as follows</p>  <pre><code>using System.IO; using Microsoft.AspNetCore.Mvc; using Microsoft.Azure.WebJobs; using Microsoft.Azure.WebJobs.Extensions.Http; using Microsoft.AspNetCore.Http; using Microsoft.Azure.WebJobs.Host; using Newtonsoft.Json; using Microsoft.Extensions.Logging; using System;  namespace NWMposTransInput {     public static class Function1     {         [FunctionName(\Function1\"")]         public static IActionResult Run([HttpTrigger(AuthorizationLevel.Function  \""get\""  \""post\""  Route = null)]         HttpRequest req  ILogger log              [CosmosDB(             databaseName: \""xxxx\""              collectionName: \""yyyy\""              ConnectionStringSetting = \""CosmosDbConnection\"")]out dynamic document              ILogger log2)         {             log.LogInformation(\""C# HTTP trigger function processed a request.\"");              string name = req.Query[\""name\""];              string requestBody = new StreamReader(req.Body).ReadToEnd();             dynamic data = JsonConvert.DeserializeObject(requestBody);             name = name ?? data?.name;              document = new { SSourceSystem = \""jongelSystem\""                               id = Guid.NewGuid()                               SSourceSystemVersion = \""1.1\""                               STransactionId = \""12345\""};              log.LogInformation($\""C# Queue trigger function inserted one row\"");             log.LogInformation($\""Description={req.Body}\"");              return name != null                 ? (ActionResult)new OkObjectResult($\""Hello  {name}\"")                 : new BadRequestObjectResult(\""Please pass a name on the query string or in the request body\"");         }     }      public class NWCloudOrder     {         public string Id { get; set; }         public string SSourceSystem { get; set; }         public string SSourceSystemVersion { get; set; }         public string STransactionId { get; set; }     } } </code></pre>  <p>--- EDIT --- Making sure I use the correct runtime this now produces the following error</p>  <pre><code>[2/9/2018 05:44:15] A ScriptHost error has occurred [2/9/2018 05:44:15] System.Private.CoreLib: Could not load file or assembly 'Microsoft.AspNetCore.Mvc.Abstractions  Version=2.2.0.0  Culture=neutral  PublicKeyToken=adb9793829ddae60'. Could not find or load a specific file. (Exception from HRESULT: 0x80131621). System.Private.CoreLib: Could not load file or assembly 'Microsoft.AspNetCore.Mvc.Abstractions  Version=2.2.0.0  Culture=neutral  PublicKeyToken=adb9793829ddae60'. [2/9/2018 05:44:15] Stopping Host </code></pre>  <p>I do have 2.2.0-preview1-35029 installed</p>""",azure-functions
30031452,"How to I pass a stream from Web API to Azure Blob storage without temp files? <p>I am working on an application where file-uploads happen often  and can be pretty big in size.</p>  <p>Those files are being uploaded to Web API  which will then get the stream from the request  and pass it on to my storage service  that then uploads it to Azure Blob Storage.</p>  <p>I need to make sure that:</p>  <ul> <li>No temp. files are written on the Web API instance</li> <li>The request stream is not fully read into memory before passing it on to the storage service (to prevent Out of Memory exceptions).</li> </ul>  <p>I've looked at <a href=\http://www.strathweb.com/2012/09/dealing-with-large-files-in-asp-net-web-api/\"" rel=\""noreferrer\"">this article</a>  that describes how to disable input stream buffering  but as many file uploads from many different users happen simultaneously  it's important that it actually does what it says on the tin.</p>  <p>This is what I have in my controller at the moment:</p>  <pre><code>if (this.Request.Content.IsMimeMultipartContent()) {     var provider = new MultipartMemoryStreamProvider();     await this.Request.Content.ReadAsMultipartAsync(provider);     var fileContent = provider.Contents.SingleOrDefault();      if (fileContent == null)     {         throw new ArgumentException(\""No filename.\"");     }      var fileName = fileContent.Headers.ContentDisposition.FileName.Replace(\""\\\""\""  string.Empty);      // I need to make sure this stream is ready to be processed by      // the Azure client lib  but not buffered fully  to prevent OoM.     var stream = await fileContent.ReadAsStreamAsync(); } </code></pre>  <p>I don't know how I can reliably test this.</p>  <p><strong>EDIT</strong>: I forgot to mention that uploading directly to Blob Storage (circumventing my API) won't work  as I am doing some size checking (e.g. can this user upload 500mb? Has this user used his quota?).</p>""",azure-storage
42424957,Keep nuget configuration when Azure App Service Plan allocated <p>I added private Nuget repository on Web App  which is hosted on an App Service Plan.</p>  <p><code> nuget.exe sources add -name {name} -source {feed} -username {username} -password {PAT} </code></p>  <p>But if the App Service Plan instances were re-allocated(scale-up/out  Azure mainternance...)  nuget.config above will not be kept.</p>  <p>I don't want to add this configuration on the repository's nuget.config  because it contains a password. How to keep nuget.config on the Azure App Service Plan hosts?</p>,azure-web-app-service
51162930,"Azure Functions NodeJS Express app throws Unable to determine function entry point error <p>I am trying to create a simple hello world azure functions app using nodejs and express. But  i am getting the following error:</p>  <pre><code>Exception while executing function: Functions.httpexpressapp. mscorlib: Unable to determine function entry point. If multiple functions are exported  you must indicate the entry point  either by naming it 'run' or 'index'  or by naming it explicitly via the 'entryPoint' metadata property. </code></pre>  <p>Here is my code:</p>  <p>function.json   </p>  <pre><code> {   \bindings\"": [     {       \""authLevel\"": \""anonymous\""        \""type\"": \""httpTrigger\""        \""direction\"": \""in\""        \""name\"": \""req\""     }      {       \""type\"": \""http\""        \""direction\"": \""out\""        \""name\"": \""res\""     }   ]    \""entryPoint\"": \""index\""    \""disabled\"": false } </code></pre>  <p><strong>index.js:</strong></p>  <pre><code>const express = require('express') const app = express()  app.get('/'  (req  res) =&gt; res.send('Express JS Hello World App!!!')) </code></pre>  <p><strong>package.json:</strong></p>  <pre><code>{   \""name\"": \""httpexpressapp\""    \""version\"": \""1.0.0\""    \""description\"": \""sample app\""    \""main\"": \""index.js\""    \""scripts\"": {     \""test\"": \""echo \\\""Error: no test specified\\\"" &amp;&amp; exit 1\""   }    \""author\"": \""john doe\""    \""license\"": \""ISC\""    \""dependencies\"": {     \""express\"": \""^4.16.3\""   } } </code></pre>  <p>Then  i have a <code>node_modules</code> directory under the function app</p>  <p>Any help is appreciated. Thanks in advance!</p>""",azure-functions
48345679,"Azure Functions Performance and Dependancy Injection <p>I have been looking at Azure functions with vs 2017 from Performance improvement point of view. Dependency injection is something that's not currently supported by azure function. But if we use workaround (something like this <a href=\https://blog.wille-zone.de/post/azure-functions-proper-dependency-injection/\"" rel=\""nofollow noreferrer\"">https://blog.wille-zone.de/post/azure-functions-proper-dependency-injection/</a> ) and perform dependancy injection from Static Construction of a function  what impact does it have on performance? Especially with two hosting plans.</p>  <p>1)Consumption Plan: If I understand correctly  it is possible that every request is seperate and will create a new host in this plan. Does this mean  that every time static constructor will be called? and make all objects instantiate again? in that case  should dependency injection be avoided for Consumption Plan?</p>  <p>2)App Service Plan: This will have a dedicated vm on which Function will run  and provided \""Always On\"" will be enabled  function will only be initiated once . In this case   does dependency injection make more sense? or still the function will exit context once trigger is complete  and every time new instances will be created?</p>  <p>I couldn't find a proper explanation about this possibility(if at all it's a possibility) . anyone has an idea?</p>""",azure-functions
21786742,Code Review Information - TFS <p>I was wondering if it was possible to query TFS for information regarding code reviews. Specifically I want to get information related to how long it takes reviewers to complete reviews from the time the review is submitted  what reviewers give what answers (Looks Good  Needs Work  etc.) most frequently  what projects get the most reviews etc.</p>  <p>Is there a way to do this in Visual Studio Online?</p>,azure-devops
50118199,"VSTS Load Test : Add server side performance counters(CPU utilization  Private Bytes etc) <p>Please let me know how to capture server-side(DB Server  Web Server) performance counters(like CPU utilization  Private Bytes  deadlocks etc.) from VSTS Load test script.</p>  <p>I have added them from 'Manage counter sets' window    However they are not captured.  Please help me. <a href=\https://i.stack.imgur.com/Wt2f6.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/Wt2f6.png\"" alt=\""enter image description here\""></a> <a href=\""https://i.stack.imgur.com/L4KdC.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/L4KdC.png\"" alt=\""enter image description here\""></a></p>""",azure-devops
24155978,"proxy authentication required in azure table using java <p>I need to access azure cloud table using java. My internet works behind proxy and needs authentication. I searched on internet and found this - </p>  <pre><code>System.setProperty(\http.proxyHost\""  \""172.16.2.1\""); System.setProperty(\""http.proxyPort\""  \""3128\""); System.setProperty(\""http.proxyUser\""  \""username\""); System.setProperty(\""http.proxyPassword\""  \""password\""); </code></pre>  <p>but it gives the following error  </p>  <p>The Azure storage client library sample TableBasics starting... Got an exception from running samples. Exception details: com.microsoft.windowsazure.services.core.storage.StorageException: The server encountered an unknown failure: <strong>Proxy Authentication Required</strong>     at com.microsoft.windowsazure.services.core.storage.StorageException.translateException(StorageException.java:129)     at com.microsoft.windowsazure.services.core.storage.utils.implementation.StorageOperation.materializeException(StorageOperation.java:158)     at com.microsoft.windowsazure.services.core.storage.utils.implementation.ExecutionEngine.executeWithRetry(ExecutionEngine.java:142)     at com.microsoft.windowsazure.services.table.client.QueryTableOperation.performRetrieve(QueryTableOperation.java:218)     at com.microsoft.windowsazure.services.table.client.TableOperation.execute(TableOperation.java:562)     at com.microsoft.windowsazure.services.table.client.CloudTableClient.execute(CloudTableClient.java:262)     at com.microsoft.windowsazure.services.table.client.CloudTable.exists(CloudTable.java:416)     at com.microsoft.windowsazure.services.table.client.CloudTable.createIfNotExist(CloudTable.java:223)     at com.microsoft.windowsazure.services.table.client.CloudTable.createIfNotExist(CloudTable.java:186)     at test1.TableBasics.main(TableBasics.java:63)</p>  <p>The Azure storage client library sample TableBasics completed.</p>""",azure-storage
52202299,how to add threshhold value in the QnA maker if it being called using the QnAMakerRecognizer.recognize method <p>I replaced my code where I was making a QnA dialog using new cognitiveservices.QnAMakerDialog constructor and I was able to pass extra key-value pair for example threshold  feedbackLib etc. with the code where I can use QnA in single dialog using </p>  <pre><code>cognitiveservices.QnAMakerRecognizer.recognize(query  'QnAhost'  'endpointKey key' 'Authorization'  3  'intentname'  function (error  results)          {             session.send(results.answers[0].answer);             // console.log(results);     });  }).triggerAction({     matches: 'intentname' });      </code></pre>  <p>But I am not sure how can I add the threshold value and feedbackLib to the QnA. This way it is returning an answer even if the confidence score is very low.</p>  <p>Please help.</p>  <p>Thanks.</p>,azure-storage
54707996,"How to set the path of a CSV file that is in account storage in azure data factory pipeline <p>I have created a SSIS package that reads from a CSV file (using the <code>Flat file connection manager</code>) and loads records into a database. I have deployed it on Azure data factory pipeline and I need to give the path of the CSV file as a parameter. I have created a azure storage account and uploaded the source file there as shown below. </p>  <p>Can I just give the URL of the source file for the Import file in the SSIS package settings as shown below? I tried it but it is currently throwing 2906 error. I am new to Azure - appreciate any help here. </p>  <p><a href=\https://i.stack.imgur.com/afxqP.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/afxqP.png\"" alt=\""Azure account storage - Source file:\""></a></p>  <p><a href=\""https://i.stack.imgur.com/SQCFk.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/SQCFk.png\"" alt=\""Azure DF - Execute SSIS Package\""></a></p>""",azure-storage
48828653,Azure Functions - TCP Persistent <p>I'm looking for a way to scale a Azure Function properly but I have a problem.</p>  <p>I have a set of IoT devices that send data to Azure by HTTP (For this there is a set of Azure Functions that scale automatically)</p>  <p>But now there is a new IoT device that sends the data via TCP/IP Persistent connections and as far as I know this ins't supported by Azure Functions.</p>  <p>Anyone has some ideia on how to implement this?</p>  <p>One option I thought was to have a VM treating the TCP connections and sending the data to a queue so that a function can pull from the queue in a scalable manner.</p>  <p>Thanks in advance  cheers.</p>,azure-functions
54681507,"How to I map a storage account in Linux PHP7.2 in PAAS Azure <p>Being quite new to Azure  does anyone know how to map a Blob File storage on Linux PHP7.2 box as PAAS ? </p>  <p>I looked at the documentation followed the instruction  but they do not work on my App Service.  <a href=\https://docs.microsoft.com/en-us/azure/storage/blobs/storage-how-to-mount-container-linux\"" rel=\""nofollow noreferrer\"">https://docs.microsoft.com/en-us/azure/storage/blobs/storage-how-to-mount-container-linux</a></p>  <p>According to this documentation  Blobfuse needs to be installed in order for this to work. I cannot install Blobfuse  lsb_release -a does not work (part of the instructions)  according to terminal the installed package is linux 4.4.0-128.154. </p>  <p>I can find a Wordpress plugin that uses the Wordpress CLI  but that is not really what I am looking for. (I dont use Wordpress on my site  but I thought the code could give me a hint)</p>  <p>I am just looking for a file share to add store uploaded images.</p>  <p>Has anyone done this before?  Thanks in advance !</p>""",azure-storage
6491585,Android video streaming to windows azure <p>I want to store <strong>stream video to the <em>windows azure server from the android camera</strong> captured video</em>*.How it possible?</p>  <p>In android i know the use of <strong>parcelfiledescriptor</strong> class.And i also created a application to stream video to the server.In that application server side controled by java socket programming.that fully successful..</p>  <p>But now i want the server side programming to do with the help of Windows Azure ???please help me.....thanks in advance.. </p>,azure-storage
56354654,"Publishing a Self-Hosting Owin app in Azure App Service <p>I have an existing ASP.Net WebApi OWIN Self-hosting web application. The application is a simple console application and outputs a .exe file and some dlls.</p>  <p>Currently  the application can be hosted in two ways</p>  <ol> <li>By simply running the exe file. (Which will run as a console application)</li> <li>As windows service using <a href=\http://topshelf-project.com/\"" rel=\""nofollow noreferrer\"">Topshelf</a> library.</li> </ol>  <p>The services can be consumed by accessing a configured URL and a port number. Ex: <a href=\""http://www.demoapp.com:8080\"" rel=\""nofollow noreferrer\"">http://www.demoapp.com:8080</a></p>  <p>Below code is the entry point of the application.</p>  <pre><code>public class WebServer {     private IDisposable app;      public void Start()     {         app = WebApp.Start&lt;Startup&gt;(url: \""http://demoapp.com:8080\"");     }      public void Stop()     {         app?.Dispose();     } } </code></pre>  <p><strong>Requirement</strong></p>  <p>Now there is a requirement to host the application in Azure AppServices. How can I achieve this without modifying existing code as much as possible? Appreciated if you can provide a step by step instruction.</p>""",azure-web-app-service
30936622,Enforce only pull request on visual studio team services <p>There is any way I could enforce that some people could contribute by one branch only by pull request I want them to be able to accept pull request but not to direct push changes.</p>  <p>This would be useful because we have some branch polices in place that for someone to accept a pull request for example the build must pass. The problem is if we allow someone to accept pull request we would be allowing them to push direct to the branch. There it is any way to give permissions to a branches to only receive changes trough pull request  or at least give permissions to someone to only accept pull requests but not to push directly to the branch.</p>  <p>I need to do that on visual studio online.</p>  <p>What I need it is to remove the permission of someone to direct push commits to a branch without a pull request.</p>,azure-devops
14595977,Azure Storage from Silverlight (REST?) <p>I'm trying to query an azure Blob Storage container from Silverlight.  </p>  <p>I saw that the Windows.Azure.Storage.dll is not working with Silverlight so I presume the best way to communicate with my storage container is with REST Services.  I saw the Azure Storage REST API  but I can't find an easy way to :</p>  <ul> <li>List all blobs in a container</li> <li>Retrieve a blob from a container</li> <li>Add a new blob in a container</li> </ul>  <p>Anyone have a clear example on how to do that (for a complete REST dummy)?</p>  <p>By the way  It has to be a private container.</p>  <p>Thanks</p>,azure-storage
47032896,"Get Azure AppSettings in a Controller <p>I have an ASP.NET Core 2 application hosted on Azure  and I added a new Application Settings <code>MyNewSetting</code> for my App in the Azure Portal. </p>  <p>How do I access that setting from a controller?</p>  <p>My code bellow: </p>  <pre><code>public void ConfigureServices(IServiceCollection services) {     services.AddOptions();      services.Configure&lt;AppSecrets&gt;(Configuration);     services.AddSingleton&lt;ITableRepositories  TableClientOperationsService&gt;();     //... </code></pre>  <p>My Controller: </p>  <pre><code>public class RecordController : Controller {     const int MyNewSetting = 7; // this one to replace with Azure Setting one     private readonly ITableRepositories repository;      public RecordController(ITableRepositories rep) {         repository = rep;     } </code></pre>  <p>Here  I need probably to add <code>FromServices</code> injection  but I am not sure if it will work...</p>  <p><strong>EDIT:</strong></p>  <p>Folowing the @dee_zg answer  the following code could probably do the job: </p>  <pre><code>public class RecordController : Controller {     int MyNewSetting = 7;     private readonly ITableRepositories repository;      public RecordController(ITableRepositories rep) {         repository = rep;         int myInt;         if (int.TryParse(System.Environment.GetEnvironmentVariable(\MY_NEW_SETTING\"")                            out myInt)) {             MyNewSetting = myInt;         };     } </code></pre>""",azure-web-app-service
45251202,I can not check in project <blockquote>   <p>TF400963: The supplied paths are considered identical by the database.   Please change one or both of them. The paths are:   $/SAA/ArNikAPI/02-Api/ArNikAPI/ArNikAPI.csproj and   $/SAA/ArNikAPI/02-Api/ArNikAPI/ArNikAPI.csproj.</p> </blockquote>,azure-devops
39215513,"How to add custom http header in response from Azure function <p>I am trying azure function (nodejs) with google authentication from a client side javascript app. I have set up CORS for the correct URL(i.e. <a href=\http://localhost:8080\"" rel=\""noreferrer\"">http://localhost:8080</a>). But I am still getting the following error:</p>  <blockquote>   <p>Credentials flag is 'true'  but the 'Access-Control-Allow-Credentials'   header is ''. It must be 'true' to allow credentials. Origin   '<a href=\""http://localhost:8080\"" rel=\""noreferrer\"">http://localhost:8080</a>' is therefore not allowed access.</p> </blockquote>  <p>I have tried everywhere on the internet and spent few days to get the answers myself. It seems Azure http response needs to add this Access-Control-Allow-Credentials:true in the header. Is there a way to add custom headers?</p>  <p>Any help will be greatly appreciated.</p>""",azure-functions
53283242,"Calling Microsoft Graph API from Azure Functions <p>I am not sure if I am on the right path  but I am attempting to retrieve my contacts within an Azure Function. I don't need to present a login as this is only for my account. I just want to be able to retrieve my Contacts from the Graph without having to explicitly authenticate. Is this possible? My attempts have failed and I ultimately get stuck trying to add permission...</p>  <p><a href=\https://i.stack.imgur.com/V4mQJ.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/V4mQJ.png\"" alt=\""Add Permission\""></a></p>  <p>When I click to add Permission  I get this error:</p>  <p><a href=\""https://i.stack.imgur.com/W8Rgs.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/W8Rgs.png\"" alt=\""Error\""></a></p>  <p>I am trying to use AAD to authenticate. I tried creating the function within the Portal and also from VS. Any suggestions? Thanks!!</p>""",azure-functions
48868650,Where is the option for PowerShell script in Azure Functions <p>I want to create Azure Function with PowerShell. When I get to the point Azure wants me to choose which type of function I want to create the only available languages are C#  F# and JavaScript. Have I missed something? How can I create an Azure function with PowerShell or do I have to convert the script to any other supported language? </p>  <p>Help much appreciated!</p>,azure-functions
56456221,"how to deploy existing azure function using terraform <p>I have an azure function created using visual studio locally. I am trying to deploy the azure function using terraform but it is throwing an error</p>  <p>The code that i am trying is shown below : </p>  <pre><code>resource \azurerm_function_app\"" \""testDeployTF\"" {   name                      = \""testDeployADddecendant\""   location                  = \""${azurerm_resource_group.rg-testDeployTF.location}\""   resource_group_name       = \""${azurerm_resource_group.rg-testDeployTF.name}\""   app_service_plan_id       = \""${azurerm_app_service_plan.sp-testDeployTF.id}\""   storage_connection_string = \""DefaultEndpointsProtocol=https;AccountName=xxxx;AccountKey=xxxxxxxxxxx;EndpointSuffix=core.windows.net\""    app_settings {     HASH            = \""${base64sha256(file(\""FunctionApp1.zip\""))}\""     WEBSITE_USE_ZIP = \""https://${decendant.sa-testDeployTF.name}.blob.core.windows.net/${azurerm_storage_container.sc-testDeployTF.name}/${azurerm_storage_blob.sb-testDeployTF.name}${data.azurerm_storage_account_sas.sas-testDeployTF.sas}\""    } } </code></pre>  <p>If i remove the app_setting the code creates a new empty function but what i want is i need a new function with the code that i have it in my local. </p>  <p>The above code throws the below error when i use app_seettings : </p>  <p>Error: Unsupported block type</p>  <p>on terraformscript.tf line 78  in resource \""azurerm_function_app\"" \""testDeployTF\"":   78:   app_settings {</p>  <p>Blocks of type \""app_settings\"" are not expected here.</p>""",azure-functions
50163645,MongoDB on Azure VM connection Error Network is unreachable <p>I have a MongoDB installed on a Azure VM but I can't connect remotely. Everything is double checked including : port Inbound and outboung to Azure VM  Firewall   MongoDB config file. I also tried every solution I found online without success. I also checked the remote access to a different service of mine running on port 8091 to check the Azure side and it works fine.</p>,azure-virtual-machine
56373956,"Azure Service Bus scheduled message \in\"" binding undefined <p>I'm using @azure/service-bus JavaScript library to publish and subscribe to messages on Azure Service Bus topic from Azure Functions. To receive messages  I'm using Azure Service Bus Topic trigger function created from the template without any changes. When I publish message using sender.send(message) I receive it fine.</p>  <pre><code>import { AzureFunction  Context  HttpRequest } from \""@azure/functions\"" import * as sb from \""@azure/service-bus\""  const PublishToServiceBus: AzureFunction = async function (context: Context  req: HttpRequest): Promise&lt;void&gt; {     const eventDoc = req.body;     const serviceBusConnectionString = process.env[\""ServiceBusConnection\""];     const topicName = process.env[\""TopicName\""]';     const sbClient = sb.ServiceBusClient.createFromConnectionString(serviceBusConnectionString);     const topicClient = sbClient.createTopicClient(topicName);     const sender = topicClient.createSender();      const message: sb.SendableMessageInfo = { body: eventDoc };      // this works     sender.send(message);      // this creates message without body?     const scheduledEnqueueTimeUtc = new Date(Date.now() + 10000);     sender.scheduleMessages(scheduledEnqueueTimeUtc  [message]);  }; export default PublishToServiceBus; </code></pre>  <p>But when I schedule message with sender.scheduleMessages()  my incoming binding variable is undefined in Azure Service Bus Topic trigger function.</p>  <pre><code>import { AzureFunction  Context } from \""@azure/functions\""  const serviceBusTopicTrigger: AzureFunction = async function (context: Context  mySbMsg: any): Promise&lt;void&gt; {     context.log('ServiceBus topic trigger function processed message'  mySbMsg); }; export default serviceBusTopicTrigger; </code></pre>  <p>Output: <code>ServiceBus topic trigger function processed message undefined</code></p>  <p>Is this a problem with the library or I'm doing something wrong?</p>""",azure-functions
49495766,Configure Windows Defender for VMs in Scaleset <p>I have an Azure Scaleset with 5 VMs in it. When I deploy my app (service fabric app) to the scaleset  Windows Defender Real Time Protection is causing the CPU/Memory to max out. I think this is because there are no appropriate exclusions set up in the Windows Defender software.</p>  <p>Can anyone tell me if I can configure the exclusions on each VM without having to RDP on to all of the VMs?</p>,azure-virtual-machine
54534924,"ARM Template for to configure App Services with new VNet Integration feature? <p>I am working on ARM Templates  I have created the template file with two or more azure app services along with app service plan and then configured with VNET Integration of each app service. </p>  <p>This is sample JSON code:</p>  <pre><code>    {   \comments\"": \""Web-App-01\""    \""name\"": \""[variables('app_name_01')]\""    \""type\"": \""Microsoft.Web/sites\""    \""location\"": \""[variables('location')]\""    \""apiVersion\"": \""2016-08-01\""    \""dependsOn\"": [     \""[resourceId('Microsoft.Web/serverfarms'  variables('asp_name_01'))]\""   ]    \""tags\"": {     \""displayName\"": \""[variables('app_name_01')]\""   }    \""properties\"": {     \""name\"": \""[variables('app_name_01')]\""      \""serverFarmId\"": \""[resourceId('Microsoft.Web/serverfarms'  variables('asp_name_01'))]\""      \""siteConfig\"": {       \""alwaysOn\"": true     }   }      \""resources\"": [       {         \""type\"": \""Microsoft.Web/sites/virtualNetworkConnections\""          \""name\"": \""[concat(variables('app_name_01')  '/'  variables('vnet_connection_name') uniqueString('asdsdaxsdsd'))]\""          \""apiVersion\"": \""2016-08-01\""          \""location\"": \""[variables('location')]\""          \""properties\"": {           \""vnetResourceId\"": \""[resourceId('Microsoft.Network/virtualNetworks/subnets'  variables('vm_vnet_name')  variables('web_subnet_name'))]\""         }          \""dependsOn\"": [           \""[resourceId('Microsoft.Web/sites'  variables('app_name_01'))]\""            \""[resourceId('Microsoft.Network/virtualNetworks/subnets'  variables('vm_vnet_name')  variables('web_subnet_name'))]\""         ]       }     ] }  {   \""comments\"": \""Web-App-02\""    \""name\"": \""[variables('app_name_02')]\""    \""type\"": \""Microsoft.Web/sites\""    \""location\"": \""[variables('location')]\""    \""apiVersion\"": \""2016-08-01\""    \""dependsOn\"": [     \""[resourceId('Microsoft.Web/serverfarms'  variables('asp_name_02'))]\""   ]    \""tags\"": {     \""displayName\"": \""[variables('app_name_02')]\""   }    \""properties\"": {     \""name\"": \""[variables('app_name_02')]\""      \""serverFarmId\"": \""[resourceId('Microsoft.Web/serverfarms'  variables('asp_name_01'))]\""      \""siteConfig\"": {       \""alwaysOn\"": true     }   }      \""resources\"": [       {         \""type\"": \""Microsoft.Web/sites/virtualNetworkConnections\""          \""name\"": \""[concat(variables('app_name_02')  '/'  variables('vnet_connection_name') uniqueString('asdsdaxsdsd'))]\""          \""apiVersion\"": \""2016-08-01\""          \""location\"": \""[variables('location')]\""          \""properties\"": {           \""vnetResourceId\"": \""[resourceId('Microsoft.Network/virtualNetworks/subnets'  variables('vm_vnet_name')  variables('web_subnet_name'))]\""         }          \""dependsOn\"": [           \""[resourceId('Microsoft.Web/sites'  variables('app_name_02'))]\""            \""[resourceId('Microsoft.Network/virtualNetworks/subnets'  variables('vm_vnet_name')  variables('web_subnet_name'))]\""         ]       }     ] } </code></pre>  <p>The above code works fine for few azure app services  but for the rest of the app services I am getting internal server error or Conflict or Bad Request during VNET Integration of Azure App Service.</p>  <blockquote>   <p>Note: When I deployed the above the JSON Code  the old VNET   integration is configured instead of New VNET (Preview) feature. So  I need to configure New VNET (Preview) feature for each app service.</p> </blockquote>  <p>So  can anyone suggest me how to resolve the above issue.</p>""",azure-web-app-service
51942253,Azure Function deployment slow <p>We're finding that a deployment of our Azure Function (AFRv1 / Node.JS) is taking a really long time (15-25 minutes). The cause of this is clearly the number of files in node_modules  but I feel like there must be a better way around this that I haven't looked at.</p>  <p>We deploy the application and node_modules (pre-yarn-installed) as a zip package using the <code>Azure App Service Deploy</code> VSTS task.</p>  <p>Is there an optimised way of deployment using an archive that doesn't take such a long time? Perhaps something that is better at differential deployments?</p>,azure-functions
49088410,Geo-distributed Azure App's vs One-region <p>I'm using Azure App Service to setup my website. I have 2 Azure App Service instances and 2 Azure SQL.</p>  <p>1 App Service instance is in the Central US and 1 App Service instance Central India. 1 SQL instance is in the Central US and the other is in Central India.</p>  <p>I use Traffic Manager to route traffic to either region.</p>  <p>What confuses me is that  when I access the Indian server directly the page seems to load at pretty much the same speed as the server in the US.</p>  <p>And both seem to load relatively quickly. Around 250-350ms each to load a page with no styling that performs one database query.</p>  <p>Does this mean that deploying in multiple regions is overkill? Would I be better deploying a larger instance in a single region?</p>,azure-web-app-service
44392244,"CPU  RAM and I/O intensive code runs slowly on Azure Functions <p>We have some code that is fairly CPU  RAM and I/O intensive (it creates lots of temporary files  decompresses  resizes and compresses images). We're trying to integrate this into a \serverless\"" web application  and seeing as our code only runs on Windows at the moment we're testing it on Azure Functions.</p>  <p>We've observed that our code runs considerably slower on Azure Functions than it does on my local workstation (Core i7-4790  16GB RAM  SSD). For example  one typical workload gives us these timings:</p>  <pre><code>Dev workstation:                                2.47 sec Azure Functions  \""App Service\"" plan (S3 size): 10.59 sec Azure Functions  \""Consumption\"" plan:           15.96 sec </code></pre>  <p>We've also found that on the \""Consumption\"" plan  timings vary quite widely - one particular job gave us times varying between 112 and 153 seconds. The same job on the S3 \""App Service\"" plan took between 117 and 119 seconds  and around 31 seconds on my workstation.</p>  <p>Timings on P3 were similar to S3  which is about what I expected as the CPU and RAM specs are the same.</p>  <p>So I have a few questions really:</p>  <ol> <li>Is there anything we can do to profile our application running on Azure  to identify where the bottlenecks might be?</li> <li>Are we crazy to be trying to run such a heavy workload on Azure Functions?</li> <li>Does anyone have any suggestions as to how we could get our code running on more powerful hardware without swallowing all the complexity of managing a farm of virtual machines?</li> </ol>""",azure-functions
42518880,Azure Function App: compile code in EXE <p>the run.csx displays the code in Azure Function App. could we hide the code or compile in EXE so that the code is not seen on screen?</p>,azure-functions
33425385,"Visual Studio Git: Nothing happens when trying to view branches <p>In the alleged duplicate question  the person is able to open the Branches page and I am not.</p>  <p>Ok I am a total noob with git. This is the first time I have ever had to use it.</p>  <p>I am trying to join a project hosted in visual studio online using the built in git functionality in visual studio 2015.</p>  <p>I click join team project  enter the adress of the server  select the project and then press clone repository. The repository gets cloned successfully and I can access the code. </p>  <p>What I am accessing is the master branch  though. I need to be able to access another branch. So what I do is go to Team Explorer -> Press Branches....aand nothing happens. Ever. I could not find anything remotely related to my situation online  which I find really weird. I am able to access the branch fine through the web portal.</p>  <p>Also in source control explorer  I get a message saying that I am supposed to select the Team Foundation Server Source Control plugin even though visual studio automatically has selected Microsoft Git. I am not sure what I am supposed to do.</p>  <p>I have tried installing the git for windows tools  restarting visual studio etc. and nothing helped.</p>  <p>Really would appreciate some assistance.</p>  <p><a href=\https://i.stack.imgur.com/GVOYC.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/GVOYC.png\"" alt=\""enter image description here\""></a></p>  <p>As you can see  I have cloned the repository.</p>  <p><a href=\""https://i.stack.imgur.com/PBd4F.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/PBd4F.png\"" alt=\""enter image description here\""></a></p>  <p>But when I attempt to click on Branches in the second screenshot  nothing happens.</p>""",azure-devops
13477033,"Azure CloudQueue PeekMessage get invisible Messages <p>According to this documentation : <a href=\http://msdn.microsoft.com/en-us/library/microsoft.windowsazure.storageclient.cloudqueue.peekmessage.aspx\"" rel=\""nofollow\"">http://msdn.microsoft.com/en-us/library/microsoft.windowsazure.storageclient.cloudqueue.peekmessage.aspx</a></p>  <blockquote>   <p>Only messages that are visible may be retrieved with PeekMessage.</p> </blockquote>  <p>My question is there a way to Peek a Message that has its visibility set to hidden?</p>""",azure-storage
49760213,"Azure App Service Autoscale Fails to Scale In <p>My app service has failed to scale-in after scaling-out. This seems to be a pattern I've been trying to troubleshoot for several months. </p>  <p>I've tried the following but none have worked:</p>  <p>My scale condition is based on CPU and memory. However  I've never seen CPU go past 12%  so I'm assuming it's actually scaling based on memory.</p>  <ol> <li><p>Set the scale out condition to memory over 90% over a 5 minute average with 10 min. cooldown and scale in condition for memory under 70% over a 5 minute average. This doesn't seem to make sense since if my memory utilization is already at 90%  I'm really having underlying memory leaks and should have already scaled out.</p></li> <li><p>Set the scale out condition to memory over 80% over a 60 minute average with 10 min. cooldown and scale in condition for memory under 60% over a 5 minute average. This makes more sense  as I've seen memory usage burst over a few hours only to drop. </p></li> </ol>  <p><a href=\https://i.stack.imgur.com/2qolT.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/2qolT.png\"" alt=\""enter image description here\""></a></p>  <p>Expected behavior: App service autoscaling will reduce instance count after 5 minutes where memory usage drops below 60%. </p>  <p>Question:</p>  <p>What is the ideal threshold on a metric to scale smoothly by if my baseline CPU remains roughly at an average of 6% and memory at 53%? Meaning  what is the best minimum values to scale in by and best max values to scale out without worrying about anti-patterns such as flapping? A larger threshold of 20% difference makes more sense to me.</p>  <p>Alternative solution: </p>  <p>Given the amount of troubleshooting involved with what's marketed as as simple as \""push button scaling\""  makes it almost not even worth the headache of the configuration vagueness (you can't even use IIS metrics like connection count without a custom powershell script!). I'm considering disabling autoscaling because of its unpredictability and just keep 2 instances running for automatic load balancing and scale manually.</p>  <p>Autoscale Configuration:</p>  <pre><code>{     \""location\"": \""East US 2\""      \""tags\"": {         \""$type\"": \""Microsoft.WindowsAzure.Management.Common.Storage.CasePreservedDictionary  Microsoft.WindowsAzure.Management.Common.Storage\""     }      \""properties\"": {         \""name\"": \""CPU and Memory Autoscale\""          \""enabled\"": true          \""targetResourceUri\"": \""/redacted\""          \""profiles\"": [             {                 \""name\"": \""Auto created scale condition\""                  \""capacity\"": {                     \""minimum\"": \""1\""                      \""maximum\"": \""10\""                      \""default\"": \""1\""                 }                  \""rules\"": [                     {                         \""scaleAction\"": {                             \""direction\"": \""Increase\""                              \""type\"": \""ChangeCount\""                              \""value\"": \""1\""                              \""cooldown\"": \""PT10M\""                         }                          \""metricTrigger\"": {                             \""metricName\"": \""MemoryPercentage\""                              \""metricNamespace\"": \""\""                              \""metricResourceUri\"": \""/redacted\""                              \""operator\"": \""GreaterThanOrEqual\""                              \""statistic\"": \""Average\""                              \""threshold\"": 80                              \""timeAggregation\"": \""Average\""                              \""timeGrain\"": \""PT1M\""                              \""timeWindow\"": \""PT1H\""                         }                     }                      {                         \""scaleAction\"": {                             \""direction\"": \""Decrease\""                              \""type\"": \""ChangeCount\""                              \""value\"": \""1\""                              \""cooldown\"": \""PT5M\""                         }                          \""metricTrigger\"": {                             \""metricName\"": \""MemoryPercentage\""                              \""metricNamespace\"": \""\""                              \""metricResourceUri\"": \""/redacted\""                              \""operator\"": \""LessThanOrEqual\""                              \""statistic\"": \""Average\""                              \""threshold\"": 60                              \""timeAggregation\"": \""Average\""                              \""timeGrain\"": \""PT1M\""                              \""timeWindow\"": \""PT10M\""                         }                     }                      {                         \""scaleAction\"": {                             \""direction\"": \""Increase\""                              \""type\"": \""ChangeCount\""                              \""value\"": \""1\""                              \""cooldown\"": \""PT5M\""                         }                          \""metricTrigger\"": {                             \""metricName\"": \""CpuPercentage\""                              \""metricNamespace\"": \""\""                              \""metricResourceUri\"": \""/redacted\""                              \""operator\"": \""GreaterThanOrEqual\""                              \""statistic\"": \""Average\""                              \""threshold\"": 60                              \""timeAggregation\"": \""Average\""                              \""timeGrain\"": \""PT1M\""                              \""timeWindow\"": \""PT1H\""                         }                     }                      {                         \""scaleAction\"": {                             \""direction\"": \""Decrease\""                              \""type\"": \""ChangeCount\""                              \""value\"": \""1\""                              \""cooldown\"": \""PT5M\""                         }                          \""metricTrigger\"": {                             \""metricName\"": \""CpuPercentage\""                              \""metricNamespace\"": \""\""                              \""metricResourceUri\"": \""/redacted\""                              \""operator\"": \""LessThanOrEqual\""                              \""statistic\"": \""Average\""                              \""threshold\"": 40                              \""timeAggregation\"": \""Average\""                              \""timeGrain\"": \""PT1M\""                              \""timeWindow\"": \""PT10M\""                         }                     }                 ]             }         ]          \""notifications\"": [             {                 \""operation\"": \""Scale\""                  \""email\"": {                     \""sendToSubscriptionAdministrator\"": false                      \""sendToSubscriptionCoAdministrators\"": false                      \""customEmails\"": [                         \""redacted\""                     ]                 }                  \""webhooks\"": []             }         ]          \""targetResourceLocation\"": \""East US 2\""     }      \""id\"": \""/redacted\""      \""name\"": \""CPU and Memory Autoscale\""      \""type\"": \""Microsoft.Insights/autoscaleSettings\"" } </code></pre>""",azure-web-app-service
56975387,Define approvals in yaml release pipelines <p>I am working on release pipelines and looking into any mechanism to define release approval flows in Yaml. I checked the Rest API too and could not find any pointers. </p>  <p>I am looking into a approval process where a deployment to an environment would need approval with a timeout setting. </p>,azure-devops
54996945,Is there any equivalent to aws eip in azure? Apart from load balancer <p>we have an active-passive server setup.So we want to allocate a public ip to active  server. We are able to do this in AWS using eip .Is there any feature which we can use in azure just like eip in aws? </p>,azure-virtual-machine
50449994,"Accessing an azure vm through Powershell remote from Azure Automation <p>I am trying to access an azure vm via powershell remoting from azure automation. All our vms inside the subscription do not have public ips (only private ip). I have tried to access by New-Pssession (as below)   but no luck.</p>  <p>Could you please let me know what are the other ways to achive this?</p>  <pre><code>$connectionName = \AzureRunAsConnection\"" $SPC = Get-AutomationConnection -Name $connectionName Write-Output $SPC Add-AzureRmAccount -ServicePrincipal -TenantId $SPC.TenantId -ApplicationId $SPC.ApplicationId -CertificateThumbprint $SPC.CertificateThumbprint Get-AzureRmSubScription Select-AzureRMSubscription -SubscriptionId 'XXXXXXXXXXXXXXX' Get-AzureRMAutomationAccount | fl * $username = 'XXXXXXX' $password = 'XXXXXXXX' $secpasswd = ConvertTo-SecureString $password -AsPlainText -Force $mycreds = New-Object System.Management.Automation.PSCredential ($username  $secpasswd) $S = New-PsSession -ComputerName XXXXXXXX -Credential $mycreds Enter-PSSession -Session $S </code></pre>""",azure-virtual-machine
28885113,"Receiving 404 Response When Attempting to Use the Windows Azure Storage Emulator <p><strong>The Problem</strong></p>  <p>When I try to work with the storage emulator (v3.4.0.0)  I receive the following exception:</p>  <pre><code>System.Net.WebException: The remote server returned an error: (404) Not Found. </code></pre>  <p>Specifically  this happens when I attempt to interact with my <code>CloudBlobContainer</code> instance  which was created via <code>blobClient.GetContainerReference( myContainerName )</code>. In this case  it's happening when I try the following:</p>  <pre><code>var permissions = await container.GetPermissionsAsync(); </code></pre>  <p>When I debug the code and watch the container instance before this line is executed  I can see that the object's internals are indeed set to be using the emulator and that all of the appropriate fields/properties are as they should be (using the correct \devstoreaccount1\"" account name and so on).</p>  <p>Any idea why this is happening? Even better: how can I get my code to see the emulator?</p>  <p><strong>Additional Info</strong></p>  <ul> <li>The storage emulator is running  I've set it to use my local Sql Server 2012 instance and can confirm that it has created all of the appropriate tables in the database.</li> <li>I tried pinging <code>127.0.0.1:10000</code> but get the message \""Ping request could not find host 127.0.0.1:10000. Please check the name and try again.\""</li> <li>I have a local instance of IIS 8.5 running as well  though I guess that's not the problem. Regardless  I'm running my app through IIS  so turning it off isn't an option for me.</li> <li>Running on Windows 8.1</li> </ul>""",azure-storage
46685122,"How to measure exactly what \data out\"" in Azure web app? <p>I have a web app in Azure  which has roughly 100k visitors a month  with less than 2 page views pr session (purely SEO visitors).</p>  <p>I just studied our Azure bills  and was shocked to find out that during last month we <code>3.41 TB</code> of data out.</p>  <p>Terabyte.</p>  <p>This makes absolutely no sense. Our average page size is less than 3mb (a lot  but not 30mb which the math would say). The total data out should in practice be:</p>  <p>3431000 (mb) / 150000 (sessions) = 23mb pr session  which is absolutely bogus. A result from a service such as Pingdom says:</p>  <p><a href=\""https://i.stack.imgur.com/1ItGm.png\"" rel=\""noreferrer\""><img src=\""https://i.stack.imgur.com/1ItGm.png\"" alt=\""result from Pingdom\""></a></p>  <p>(Seems Stack.Imgur is down - temp link: <a href=\""http://prntscr.com/gvzoaz\"" rel=\""noreferrer\"">http://prntscr.com/gvzoaz</a> )</p>  <p>My graph looks like this  and it's not something that just came up. I have not analyzed our bills for a while  so this could easily have been going on for a while:</p>  <p><a href=\""https://i.stack.imgur.com/PemEL.png\"" rel=\""noreferrer\""><img src=\""https://i.stack.imgur.com/PemEL.png\"" alt=\""Azure data out\""></a></p>  <p>(Seems Stack.Imgur is down - temp link: <a href=\""http://prntscr.com/gvzohm\"" rel=\""noreferrer\"">http://prntscr.com/gvzohm</a> )</p>  <p>The pages we have most visits on are an autogenerated SEO page which reads from a database with +3mio records  but it's quite optimized and our databases are not that expensive. The main challenge is the data out  which costs a lot.</p>  <p>However  how do I go about any test this? Where do I start? </p>  <p><strong>My architecture:</strong></p>  <p>I honestly believe that all my resources are in the same area. Here is a screenshot of my main killers of usage - my app and database :</p>  <p><strong>App:</strong></p>  <p><a href=\""https://i.stack.imgur.com/tdzKD.png\"" rel=\""noreferrer\""><img src=\""https://i.stack.imgur.com/tdzKD.png\"" alt=\""enter image description here\""></a></p>  <p><a href=\""https://i.stack.imgur.com/5uNYr.png\"" rel=\""noreferrer\""><img src=\""https://i.stack.imgur.com/5uNYr.png\"" alt=\""enter image description here\""></a></p>  <p><strong>Database:</strong></p>  <p><a href=\""https://i.stack.imgur.com/3Pknw.png\"" rel=\""noreferrer\""><img src=\""https://i.stack.imgur.com/3Pknw.png\"" alt=\""enter image description here\""></a></p>  <p><strong>All my resources:</strong></p>  <p><a href=\""https://i.stack.imgur.com/Fl2cZ.png\"" rel=\""noreferrer\""><img src=\""https://i.stack.imgur.com/Fl2cZ.png\"" alt=\""enter image description here\""></a></p>""",azure-web-app-service
17408927,"Do HTTP RANGE headers work with Azure Blob Storage Shared Access Signatures? <p>I'm using Azure Blob Storage to store media files and providing access to these files using Shared Access Signatures; everything is working well in this regard.</p>  <p>However  I have a client application that needs to \resume\"" access to these files and does so using an HTTP RANGE header.  When it makes a request like this  it is unhappy with the result it gets back from Azure.</p>  <p>I'm not sure how to view the details on the Azure side to see if the request failed  or if it just returned something the client didn't expect  and I have no debugging visibility into the client.</p>  <p>Here's what the incoming range header looks like:</p>  <pre><code>RANGE: bytes=4258672- </code></pre>  <p>From the Azure documentation I've read it appears to support RANGE headers  however I'm wondering if there is a conflict using RANGE and Shared Access Signatures together?</p>  <p><strong>Update:</strong> It appears that Azure may be returning an incorrect status code for RANGE requests  which is causing my client apps to reject the response.  The documentation states that Azure will respond with an HTTP status code of 206 when responding to a RANGE request  however when I issue a RANGE request like this:</p>  <pre><code>curl -I -H \""User-Agent: Bonos\"" -r 500- \""https://murfie.blob.core.windows.net/168464/1.mp3?st=2013-07-03T16%3A34%3A32.4832235Z&amp;se=2013-07-03T17%3A34%3A32.4613735Z&amp;sr=b&amp;sp=r&amp;sig=mJgQGW%2Fr3v8HN2%2BVV3Uady7J68nFqeHyzQb37HAhfuE%3D\"" </code></pre>  <p>Azure returns the following:</p>  <pre><code>HTTP/1.1 200 OK Content-Length: 19988911 Content-Type: application/octet-stream Charset=UTF-8 Last-Modified: Fri  07 Jun 2013 16:44:50 GMT ETag: 0x8D031B57670B986 Server: Blob Service Version 1.0 Microsoft-HTTPAPI/2.0 x-ms-request-id: 77312761-65a9-42ef-90cd-ff718a80b231 Date: Wed  03 Jul 2013 16:41:01 GMT </code></pre>""",azure-storage
24851901,running a wcf service on an Azure VM <p>I can browse to it from the local desktop on the server  I setup my endpoints in Azure for port 8053  I can't hit the url remotely though.  I assume it's  myservice.cloudapp.net:8053/service.svc.</p>  <p>Did I miss a step?</p>,azure-virtual-machine
56394772,"Error while trying to pull azure key vault from azure function - Value cannot be null. Parameter name: authKeyOrResourceToken <p>I want to integrate my azure functions app with the key vault. I followed the steps shown here <a href=\http://blogs.adatis.co.uk/benjarvis/post/Azure-Functions-Key-Vault-Integration\"" rel=\""nofollow noreferrer\"">http://blogs.adatis.co.uk/benjarvis/post/Azure-Functions-Key-Vault-Integration</a></p>  <p>But facing this error- Value cannot be null. Parameter name: authKeyOrResourceToken</p>  <p>Not sure where I'm going wrong. Any help would be greatly appreciated.</p>  <p>I tried to add an environmental variable named 'authKeyOrResourceToken' under the application settings  proving the value with default func key. But no luck.</p>  <p>This is how my function.json looks like</p>  <p>{       \""type\"": \""CosmosDB\""        \""name\"": \""&lt;>\""        \""databaseName\"": \""&lt;>\""        \""collectionName\"": \""&lt;>\""        \""connectionStringSetting\"": \""&lt;>\""        \""sqlQuery\"": \""SELECT * FROM c where c.recordType = {recordType}\""        \""direction\"": \""in\""     }</p>  <p>While I expect the result of the query  I'm facing the exception.</p>""",azure-functions
54758182,Azure Function API Versioning - How to structure my code? <p>I have created a demo microservices application implemented with the help of Azure Function Apps. For separation of concerns  I have created an API Layer  Business Layer  and a Data Layer.</p>  <p>The API layer  being the function app  calls the business layer which implements the business logic while the data layer implements logic for storing and retrieving data.</p>  <p>After considerable thought  I have decided to use query-based API versioning for my demo.</p>  <p>The question I have is  </p>  <p>What is the best way to organize my code to facilitate this? Is there any other way to organize my code to accommodate the different versions apart from using different namespaces / repos?</p>  <p>As of now  I've created separate namespaces for each version but this has created a lot of code duplication. Also after getting it reviewed by some of my friends  they raised the concern that If separate namespaces are being used I would be forcing legacy systems to change references to the new namespace if they need to update which is not recommended. </p>  <p>Any help would be appreciated.</p>,azure-functions
52915651,Anaconda Installation on Azure Web App Services <p>I install my python modules via pip for my Azure Web Apps. But some of python libraries that I need are only available in conda. I have been trying to install anaconda on Azure Web Apps (windows/linux)  no success so far. Any suggestions/examples on how to use conda env on azure web apps?</p>,azure-web-app-service
46541247,Indication when an Azure function is destroyed <p>Do i have a way to programmatically identify when a running Azure function is killed/destroyed? </p>  <p>I have a metric value for counting when functions are created - i'm doing it by a global variable <code>FirstRun</code> that sets to false in the first run... Now i need the opposite metric - when is this instance is killed.</p>,azure-functions
57081812,"How to pass secrets downloaded from Azure KeyVault as parameters to an Azure Function? <p>In an Azure release pipeline  I'm trying to download a password stored as a secret in an Azure KeyVault  and then pass that password as a parameter when invoking an Azure app function.</p>  <p>I've created a release pipeline in Azure that contains 3 tasks; the first two are run on an agent:</p>  <pre><code>1. Deploy an Azure Function App 2. Download secrets from an Azure Key Vault. </code></pre>  <p><a href=\https://i.stack.imgur.com/9EKgX.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/9EKgX.png\"" alt=\""enter image description here\""></a></p>  <p>The final task is run as an agentless job:</p>  <pre><code>3. Invoke Azure Function </code></pre>  <p>The name of the secret that I'm downloading is <code>e-password</code>.</p>  <p>In the Query parameters when invoking the Azure function  I've added the following:</p>  <pre><code>`password=$(e-password)` </code></pre>  <p>I would expect the value of the secret downloaded from the Key Vault to be substituted  but instead the URL called turns out as:</p>  <pre><code>`https://&lt;my app's name&gt;.azurewebsites.net/api/HttpTrigger?password=$(e-password)` </code></pre>  <p>where the value of <code>e-password</code> is not substituted.</p>""",azure-functions
48039880,"Azure Functions 2.0 Not Loading Referenced Libraries <p>I've created a new Azure Function in VS 2017.</p>  <p>Ran it  debugged it.</p>  <p>Then referenced a library of shared code and modified the code to call into the library.</p>  <p>Re-ran the function  upon calling the function it dies loading one of the dependent DLLs. </p>  <p>This seems to be publishing as a precompiled function and the inner bin that is referenced in the function.json as the home for the \scriptFile\"" has the DLLs including the one that is failing to load.</p>  <p><code>[1/5/2018 4:04:18 AM] ScriptHost initialization failed [1/5/2018 4:04:18 AM] System.Private.CoreLib: Could not load file or assembly 'Microsoft.AspNetCore.Mvc.Abstractions  Version=2.0.1.0  Culture=neutral  PublicKeyToken=adb9793829ddae60'. Could not find or load a specific file. (Exception from HRESULT: 0x80131621). System.Private.CoreLib: Could not load file or assembly 'Microsoft.AspNetCore.Mvc.Abstractions  Version=2.0.1.0  Culture=neutral  PublicKeyToken=adb9793829ddae60'.</code></p>  <p>Is there a trick to getting the function to load these DLLs?</p>""",azure-functions
55351173,"How to connect to mosquitto broker installed on virtual machine hosted on azure? <p>I have installed mosquitto broker on virtual machine at port 1883.This virtual machine is hosted on azure cloud.To gain access to this broker i have opened the ports by adding inbound rules.Still i am not able to publish to this mosquitto broker from outside network.</p>  <p>I have added the inbound rules by allowing port 1883 to allow access from the outside network</p>  <pre><code>string ClientId = new Guid().ToString(); client = new MqttClient(\104.211.219.200\""  1883  false  null); client.Connect(ClientId); client.Publish(\""local\""  Encoding.UTF8.GetBytes(\""Message from local PC\"")  MqttMsgBase.QOS_LEVEL_EXACTLY_ONCE  false); </code></pre>""",azure-virtual-machine
17116540,deploy solution to azure virtual machine <p>i have a .net solution  with a Mvc 4.5 web  a c# server dll  another webservice layer dll  etc. I want to deploy it on a azure virtual machine xx.cloudapp.net:8080</p>  <p>There are many guids on how to deploy a new website on azure  but since this solutions contains a lot of dlls  i need a virtual machine. I didnt found any guide on how to do it  can you please give me a link or something?</p>,azure-virtual-machine
56568417,"How to retrieve all data from azure database with tyescript? <p>I created a CRUD application with typescript querying azure storage table. I can get a single record from the database   but haven't figured out how to retrieve all data. any help ? here's my code for getting a single record and an attempt to get all records : </p>  <pre><code>async getSystem(partitionKey: string  rowKey: string):  Promise&lt;Array&lt;System&gt;&gt; {     return new Promise&lt;Array&lt;System&gt;&gt;((resolve  reject) =&gt; {       try {         this.tableService.retrieveEntity&lt;Array&lt;System&gt;&gt;(           this.tableName            partitionKey            rowKey            (err  entity) =&gt; {             if (err){ reject(err) };             resolve(this.tableRecordToJavacript(entity));           }         );       } catch (err) {         reject(err);       }     });   }        async getAllSystem(): Promise&lt;Array&lt;System&gt;&gt; {     return new Promise&lt;Array&lt;System&gt;&gt;((resolve  reject) =&gt; {       try {         const query = new azure.TableQuery().top(100);         this.tableService.queryEntities&lt;Array&lt;System&gt;&gt;(           this.tableName            query            null            (err  entitites) =&gt; {             if (err){ reject(err) };             resolve(this.tableRecordToJavacript(entitites));           }         );       } catch (err) {         reject(err);       }     });   }     private tableRecordToJavacript(entity: Array&lt;System&gt;): Array&lt;System&gt; {     let result: any = {};     Object.keys(entity).forEach(k =&gt; {       // we do not want to decode metadata       if (k !== \.metadata\"") {         let prop = Object.getOwnPropertyDescriptor(entity  k);         if (prop) {           result[k] = prop.value[\""_\""];         }       }     });     return result;   } </code></pre>""",azure-storage
56915002,"Need help investigating Azure App Service .NET Core 2.1 ArgumentOutOfRangeException and System.OverflowException <p>Today I've adjusted the <strong>App Service Log</strong> settings for my Azure App Serivce: a .NET Core 2.1 Web API. Soon after I changed the <strong>Application Logging (file system)</strong> setting from Information to Warning  my application stopped responding. I immediately kicked of a .NET Trace using the <strong>Diagnose and solve problems</strong> feature.</p>  <p>This Trace report showed the following:</p>  <pre><code>system.private.corelib! microsoft.aspnetcore.hosting! System.Private.CoreLib!System.Runtime.CompilerServices.AsyncMethodBuilderCore.Start microsoft.aspnetcore.hosting.il!Microsoft.AspNetCore.Hosting.Views.ErrorPage.ExecuteAsync microsoft.aspnetcore.hosting! System.Private.CoreLib!System.Runtime.CompilerServices.AsyncMethodBuilderCore.Start microsoft.aspnetcore.hosting.il!Microsoft.Extensions.RazorViews.BaseView.ExecuteAsync microsoft.aspnetcore.hosting! microsoft.aspnetcore.hosting! System.Private.CoreLib!System.Runtime.CompilerServices.AsyncTaskMethodBuilder`1+AsyncStateMachineBox`1+&lt;&gt;c[System.Threading.Tasks.VoidTaskResult Microsoft.AspNetCore.Server.Kestrel.Core.Internal.Http.HttpProtocol+&lt;ProcessRequests&gt;d__188`1[Microsoft.AspNetCore.Hosting.Internal.HostingApplication+Context]].&lt;.cctor&gt;b__9_0 system.private.corelib! System.Private.CoreLib!System.Runtime.CompilerServices.AsyncTaskMethodBuilder`1+AsyncStateMachineBox`1[System.Threading.Tasks.VoidTaskResult Microsoft.AspNetCore.Server.Kestrel.Core.Internal.Http.HttpProtocol+&lt;ProcessRequests&gt;d__188`1[Microsoft.AspNetCore.Hosting.Internal.HostingApplication+Context]].MoveNext system.private.corelib! system.private.corelib! system.private.corelib! system.private.corelib! system.private.corelib!  </code></pre>  <p>Same time  the Azure Blob log showed these lines:</p>  <pre><code>2019-07-06 14:04:06.476 +00:00 [Error] Microsoft.AspNetCore.Server.Kestrel: Connection id \0HLO233NHLK6Q\""  Request id \""0HLO233NHLK6Q:000003BF\"": An unhandled exception was thrown by the application. System.OverflowException: Arithmetic operation resulted in an overflow.    at System.IO.StreamWriter.Write(String value)    at Microsoft.Extensions.RazorViews.BaseView.Write(String value)    at Microsoft.AspNetCore.Hosting.Views.ErrorPage.ExecuteAsync()    at Microsoft.Extensions.RazorViews.BaseView.ExecuteAsync(HttpContext context)    at Microsoft.AspNetCore.Server.Kestrel.Core.Internal.Http.HttpProtocol.ProcessRequests[TContext](IHttpApplication`1 application)  2019-07-06 14:04:19.245 +00:00 [Error] Microsoft.AspNetCore.Server.Kestrel: Connection id \""0HLO233NHLK6T\""  Request id \""0HLO233NHLK6T:000000EF\"": An unhandled exception was thrown by the application. System.ArgumentOutOfRangeException: Index and count must refer to a location within the buffer. Parameter name: chars    at System.Text.EncoderNLS.GetBytes(Char[] chars  Int32 charIndex  Int32 charCount  Byte[] bytes  Int32 byteIndex  Boolean flush)    at System.IO.StreamWriter.Flush(Boolean flushStream  Boolean flushEncoder)    at System.IO.StreamWriter.Write(String value)    at Microsoft.AspNetCore.Hosting.Views.ErrorPage.ExecuteAsync()    at Microsoft.Extensions.RazorViews.BaseView.ExecuteAsync(HttpContext context)    at Microsoft.AspNetCore.Server.Kestrel.Core.Internal.Http.HttpProtocol.ProcessRequests[TContext](IHttpApplication`1 application) </code></pre>  <p>These stacktraces don't show any of my own code  they seem framework related.</p>  <p>Is there a message or a hint in these error stack traces that I can use to prevent these situations?</p>  <p>Many thanks in advance</p>""",azure-web-app-service
54777208,"Terraform on Azure cloud - VM name and Data disk name are not aligned <p>I have created VM and added Data Disk to be  however there is one issue.The VM name and data disk name DO NOT align. Please refer to the screenshot below.</p>  <p><a href=\https://i.stack.imgur.com/gyIBc.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/gyIBc.png\"" alt=\""NXTPREPAOS-1 Machine Disks \""></a></p>  <p><a href=\""https://i.stack.imgur.com/9gaLQ.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/9gaLQ.png\"" alt=\""NXTPREPAOS-1 Machine Disks\""></a></p>  <p><a href=\""https://i.stack.imgur.com/LL35X.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/LL35X.png\"" alt=\""NXTPREPAOS-5 Machine Disk\""></a></p>  <p>The terraform code is below:</p>  <pre><code>resource \""azurerm_managed_disk\"" \""tf-mdsk-cluster\"" {   count                = 5   name                 = \""${var.ax_base_hostname}-${count.index+1}-DATADISK-1\""   location             = \""${azurerm_resource_group.tf-rg-cluster-aos.location}\""   resource_group_name  = \""${azurerm_resource_group.tf-rg-cluster-aos.name}\""   storage_account_type = \""Standard_LRS\""   create_option        = \""Empty\""   disk_size_gb         = \""1024\"" }  resource \""azurerm_managed_disk\"" \""tf-mdsk-2-cluster\"" {   count                = 5   name                 = \""${var.ax_base_hostname}-${count.index+1}-DATADISK-2\""   location             = \""${azurerm_resource_group.tf-rg-cluster-aos.location}\""   resource_group_name  = \""${azurerm_resource_group.tf-rg-cluster-aos.name}\""   storage_account_type = \""Standard_LRS\""   create_option        = \""Empty\""   disk_size_gb         = \""1024\"" }  resource \""azurerm_virtual_machine\"" \""tf-vm-cluster-aos\"" {   count                 = 5   name                  = \""${var.ax_base_hostname}-${count.index+1}\""   location              = \""${azurerm_resource_group.tf-rg-cluster-aos.location}\""   resource_group_name   = \""${azurerm_resource_group.tf-rg-cluster-aos.name}\""   availability_set_id   = \""${azurerm_availability_set.tf-as-cluster-aos.id}\""   network_interface_ids = [\""${element(azurerm_network_interface.tf-ni-cluster-aos.*.id  count.index+1)}\""]   vm_size               = \""${var.ax_vm_size}\""    storage_data_disk {     name            = \""${element(azurerm_managed_disk.tf-mdsk-cluster.*.name  count.index+1)}\""     managed_disk_id = \""${element(azurerm_managed_disk.tf-mdsk-cluster.*.id  count.index+1)}\""     create_option   = \""Attach\""     lun             = 0     disk_size_gb    = \""${element(azurerm_managed_disk.tf-mdsk-cluster.*.disk_size_gb  count.index+1)}\""   }    storage_data_disk {     name            = \""${element(azurerm_managed_disk.tf-mdsk-2-cluster.*.name  count.index+1)}\""     managed_disk_id = \""${element(azurerm_managed_disk.tf-mdsk-2-cluster.*.id  count.index+1)}\""     create_option   = \""Attach\""     lun             = 1     disk_size_gb    = \""${element(azurerm_managed_disk.tf-mdsk-2-cluster.*.disk_size_gb  count.index+1)}\""   } } </code></pre>  <p>I have <strong>changed</strong> the <strong>managed disk block</strong> </p>  <p><strong><em>FROM</em></strong></p>  <pre><code>managed_disk_id = \""${element(azurerm_managed_disk.tf-mdsk-cluster.*.id  count.index+1)}\"" </code></pre>  <p><strong><em>TO</em></strong></p>  <pre><code>managed_disk_id = \""${element(azurerm_managed_disk.tf-mdsk-cluster.*.id  count.index)}\"" </code></pre>  <p>But that has not solved the mystery  any idea as to how to resolve it?</p>""",azure-virtual-machine
52642452,TLS 1.0 for certain URLs in an Azure Web App <p>Can I allow TLS 1.0 for certain URLs in an Azure Web App? A minimum version of TLS 1.2 works for >99% of my site but a few URL's are used by legacy clients that don't support it.</p>,azure-web-app-service
26083461,Azure Storage / File System abstraction library <p>As part of the web application that I'd developing at the moment I have a requirement to write files out to storage. The will initially be hosted on Azure Websites  but in the future I would like to have the ability to host it on non-azure servers.</p>  <p>So - I'm looking for a library (and I hope that one exists) that would make it easy to switch between outputting files out to Azure Blob Storage or a local file system. Ideally something that would have a common API and would allow you to switch between the storage location by changing config files only.</p>  <p>I'm having some issues finding libraries that would have this sort of functionality and I hope someone can point me in the right direction.</p>,azure-storage
6951588,"Access denied or permission denied triggered if document loaded to iframe is stored on Azure Blob Storage <p>I have a website hosted on Windows Azure Cloud. In one of the aspx pages  I have an iframe. Into this iframe I will be loading a html page that is stored in Windows Azure Blob storage. When I do this  I get an instant error on the webpage when i try to access the contents/properties of the iframe. The error is</p>  <p>\Access Denied\"" or \""Permission Denied\"". Can anyone please strike me with a solution to the same. I guess it is one problem that is not addressed by the people in Windows Azure.</p>  <p>Thanks in advance</p>  <p>Regards</p>  <p>Sandeep</p>""",azure-storage
34633715,Multiple public IPs to Azure VM <p>I'm using the new Resource Manager setup of azure with a couple of VMs and I'm trying to find the best way to associate multiple IPs to a single VM.</p>  <p>I've read a few different articles  ILPIP (Instance level public IP)  Load Balanced pools and multiple NICs.</p>  <p>I'm not sure of the best options. My VMs are already setup and configured so I don't want to go through that process again of loading a new VM to enable certain features (some mention multiple NICs are only available on new VMs).</p>  <p>I looked into the Load Balanced solution but it appears to be missing from the new management portal. You can view your load balancers but you can't add new ones (if they are still available).</p>  <p>I need multiple IPs per VM as we have sites that have SSLs which can't be served over SNI due to older browser restrictions.</p>  <p>I'm at a loss as most article refer to older setups and not the resource manager method.</p>  <p>If anyone has a solid way of performing this  I would appreciate any help.</p>,azure-virtual-machine
52529971,Are multiple entry points for Azure Logic Apps possible or should I be looking at Azure Functions? <p>I've got an issue currently that I'm trying to sync some of our Salesforce data to an external CRM. Now originally I found that through Azure functions it would be so easy to listen to any record being modified or created and push that data somewhere (In this case straight to a Topic in Azure). I love the functionality and it works wonderfully but I can't seem to figure out if there is a way to have multiple entry points in a Logic App. I'm assuming the answer is no since they aren't really designed for that.</p>  <p>If that is the case is there some already built out easy way with Azure functions to listen to records being modified/created in Salesforce?</p>,azure-functions
54776812,Does PrimaryThenSecondary LocationMode check if RA-GRS for primary exists? <p>I am using LocationMode in order to Retry to download stream from the blob storage. In certain cases  RA-GRS for the account might not exist. Do I need to take care that LocationMode is used only when RA-GRS exists for a storage account?</p>,azure-storage
50869849,Azure File Storage ReadWriteMany access mode <p>I'm pretty new on the Azure platform. Please help me to choose the most appropriate Azure components to implement the following scenario. </p>  <p>I have to have an HA service which will be deployed on two or more Docker containers. The access to the containers group will be done through the internal facade  like Azure Load Balancer. The most important requirement is a safe access to the File Storage  all containers have to share the same volume with an ability to read an write there simultaneously.</p>  <p>I read that Azure File Storage does support <strong>ReadWriteMany</strong> access mode. Any thoughts what should be the best design to handle this. What I need is a direction to focus on. </p>  <p>Thanks in advance.</p>,azure-storage
46379443,"Unable to connect to Azure VM after changing RDP Port to 443 <p>I have set up an Azure virtual machine running Windows 10 Client. As per the below post I changed the RDP Port to 443 but didn't add the VM Firewall Rule and restarted the VM.  <a href=\https://stackoverflow.com/questions/36031980/new-azure-portal-no-end-points-how-to-connect-to-vm-with-rdp-from-behind-a-fir\"">New Azure portal (no End Points) how to connect to VM with RDP from behind a firewall</a> Now I am unable to connect to my Azure VM. I tried the following things 1) Unable to connect to remote Powershell since WinRM is disabled. I tried enabling it but somehow not working 2) Read about attaching this VM hard disk to second VM and loading the registry in second VM. But not sure how to do it.</p>  <p>Any suggestions.</p>""",azure-virtual-machine
43344993,"Azure / Xamarin - SyncContext.InitializeAsync Deadlock <p>I have a Xamarin.Forms App which use Azure App Service with SQLLite Offline Sync. When calling SyncContext.InitializeAsync a deadlock appears and the function InitializeAsync never finished.</p>  <p>In this Thread in found the solution: <a href=\https://stackoverflow.com/questions/36944296/azure-xamarin-mobile-app-hangs-at-synccontext-initializeasync\"">Azure/Xamarin Mobile App Hangs at SyncContext.InitializeAsync</a></p>  <p>This works:</p>  <pre><code> System.Threading.Tasks.Task.Run(() =&gt; this.IDataProvider.IMobileServiceClient.SyncContext.InitializeAsync(localStore  _syncHandler)).Wait(); </code></pre>  <p>This not:</p>  <pre><code>await this.IDataProvider.IMobileServiceClient.SyncContext.InitializeAsync(localStore  _syncHandler); </code></pre>  <p>Whole function:</p>  <pre><code>   public override async System.Threading.Tasks.Task Init()         {             string storePath = System.IO.Path.Combine(Microsoft.WindowsAzure.MobileServices.MobileServiceClient.DefaultDatabasePath  localStoreName);             Microsoft.WindowsAzure.MobileServices.SQLiteStore.MobileServiceSQLiteStore localStore = new Microsoft.WindowsAzure.MobileServices.SQLiteStore.MobileServiceSQLiteStore(storePath);              localStore.DefineTable&lt;CPM.Recruitment.Mobile.Freelancer.DataObjects.Entities.Promoter&gt;();              System.Threading.Tasks.Task.Run(() =&gt; this.IDataProvider.IMobileServiceClient.SyncContext.InitializeAsync(localStore  _syncHandler)).Wait();             //await this.IDataProvider.IMobileServiceClient.SyncContext.InitializeAsync(localStore  _syncHandler);              _promoters = new Azure.AppService.DataObjects.Client.Sync.List&lt;CPM.Recruitment.Mobile.Freelancer.DataObjects.Entities.Promoter&gt;(this  this.IDataProvider.IMobileServiceClient.GetSyncTable&lt;CPM.Recruitment.Mobile.Freelancer.DataObjects.Entities.Promoter&gt;());         } </code></pre>  <p>But why? I dont want to use Wait(); </p>""",azure-web-app-service
38162178,"Visual Studio Git branches <p>I am new to GIT and GIT in VS  and struggling to create branch that will be visible to others. </p>  <p>What have I tried:</p>  <ol> <li>Created local branch from remote/master as specified <a href=\https://www.visualstudio.com/en-us/docs/git/tutorial/branches\"" rel=\""nofollow\"">here</a></li> <li>Right click on branch shows <strong>disabled option \""Publish branch\""</strong></li> <li>Everything I commit and sync is <strong>visible on master branch</strong> to other developers (but they don't see my new branch). This is especially annoying.</li> </ol>  <p>Please help me on how to create branch that will be visible to others and more important how to commit and sync changes to that branch only and master. Basically I expect to reproduce branches with the same behavior as in TFS source control (not GIT)</p>  <p>I am using: Visual Studio 2015 Community Edition with Visual Studio Team Services (was VS Online) git repository</p>""",azure-devops
50419871,Run Cypress.io on VSTS Hosted Linux <p>I'm trying to run Cypress tests on the Hosted Linux Pool for Visual Studio Team Services. Unfortunately  the Hosted Agent doesn't have all the dependencies for Cypress installed.</p>  <p>Running the documented <code>apt-get</code> doesn't work:</p>  <pre><code>2018-05-18T21:03:14.7423331Z ##[section]Starting: Install cypress dependencies 2018-05-18T21:03:14.7474742Z ============================================================================== 2018-05-18T21:03:14.7488281Z Task         : Bash 2018-05-18T21:03:14.7501148Z Description  : This is an early preview. Run a Bash script on macOS  Linux  or Windows 2018-05-18T21:03:14.7513088Z Version      : 3.127.0 2018-05-18T21:03:14.7524823Z Author       : Microsoft Corporation 2018-05-18T21:03:14.7537179Z Help         : [More Information](https://go.microsoft.com/fwlink/?LinkID=613738) 2018-05-18T21:03:14.7549730Z ============================================================================== 2018-05-18T21:03:15.0174503Z Generating script. 2018-05-18T21:03:15.0535056Z Script contents: 2018-05-18T21:03:15.0547355Z apt-get install xvfb libgtk2.0-0 libnotify-dev libgconf-2-4 libnss3 libxss1 libasound2 2018-05-18T21:03:15.0656822Z [command]/bin/bash --noprofile --norc /opt/vsts/work/_temp/cac4d3f9-42e7-49f3-94f6-7d0444827d83.sh 2018-05-18T21:03:15.6040707Z Reading package lists... 2018-05-18T21:03:15.6085335Z Building dependency tree... 2018-05-18T21:03:15.6153815Z Reading state information... 2018-05-18T21:03:15.6186788Z Package libgconf-2-4 is not available  but is referred to by another package. 2018-05-18T21:03:15.6198707Z This may mean that the package is missing  has been obsoleted  or 2018-05-18T21:03:15.6211380Z is only available from another source 2018-05-18T21:03:15.6216969Z  2018-05-18T21:03:15.6229592Z E: Unable to locate package xvfb 2018-05-18T21:03:15.6242128Z E: Unable to locate package libnotify-dev 2018-05-18T21:03:15.6254440Z E: Package 'libgconf-2-4' has no installation candidate 2018-05-18T21:03:15.6268141Z E: Unable to locate package libxss1 2018-05-18T21:03:15.6370826Z ##[error]Bash exited with code '100'. 2018-05-18T21:03:15.7283047Z ##[section]Finishing: Install cypress dependencies </code></pre>  <p>Running <code>apt-get update</code> takes forever (25 minutes and still not done). </p>  <p>Any clues on how to get Cypress working quickly on the Hosted Agent is welcome.</p>  <p><strong>Note:</strong> I tried running on Windows  that works  fortunately  so I'm not completely blocked. But to use the Windows Agent I now have 2 agent phases which adds overhead due to artefact downloads and npm install overhead.</p>,azure-devops
47738845,VSTS build number for build definition <p>I have a few branches in my git repo e.g. master for production  dev for development  qa for testing  etc.</p>  <p>Each branch has it's own build definition  like app-dev  app-qa  app-prod  etc. </p>  <p>I'd like to include build number as a part of artifact name  e.g.  0.3.0-SNAPSHOT.<strong>53</strong> for development or 0.2.0-RC.<strong>12</strong> for testing.</p>  <p>Obviously each build definition's number should be unique. </p>  <p>Is it possible?</p>,azure-devops
41390956,Costing of Aure Webjob vs Azure function under free tier app service plan? <p>As you all knows that if I create azure app service under free tier plan then I don't need to pay any amount for that but now I am creating a azure Webjob under this free tier plan so my question is do I need to pay any extra amount/charge for that ?</p>  <p>I also know that Azure webjob always on feature is not under this pricing tier but that is completely fine for me as per my requirement.</p>  <p>Please give me suggestion on that.</p>  <p>The same thing is applicable to azure function if I create azure function under free app service plan then do I need to pay any extra cost ?</p>,azure-functions
40650681,".net core azure deployment failing: Project file does not exist <p>I have an app-service app set up in Azure which is set to deploy upon commit into a team-services git repository. This has been working fine until now  and the deployment is failing with:</p>  <pre><code>MSBUILD : error MSB1009: Project file does not exist. </code></pre>  <p>However  If I open the azure console and CD to my project directory I can see that the project file (an asp.net core .xproj) does indeed exist. I know its in the correct directory from the output in the deployment log  showing that the packages are being restored:</p>  <pre><code>Command: \D:\\home\\site\\deployments\\tools\\deploy.cmd\"" Handling ASP.NET Core Web Application deployment. Restoring packages for D:\\home\\site\\repository\\IDPTest\\src\\IDPTest\\project.json... Restoring packages for tool 'Microsoft.AspNetCore.Server.IISIntegration.Tools' in D:\\home\\site\\repository\\IDPTest\\src\\IDPTest\\project.json... Committing restore... Lock file has not changed. Skipping lock file write. Path: D:\\home\\site\\repository\\IDPTest\\src\\IDPTest\\project.lock.json D:\\home\\site\\repository\\IDPTest\\src\\IDPTest\\project.json Restore completed in 10549ms. Restoring packages for D:\\home\\site\\repository\\IDPTest\\src\\IDPTest.MVCClient\\project.json... Restoring packages for tool 'BundlerMinifier.Core' in D:\\home\\site\\repository\\IDPTest\\src\\IDPTest.MVCClient\\project.json... Restoring packages for tool 'Microsoft.AspNetCore.Razor.Tools' in D:\\home\\site\\repository\\IDPTest\\src\\IDPTest.MVCClient\\project.json... Restoring packages for tool 'Microsoft.AspNetCore.Server.IISIntegration.Tools' in D:\\home\\site\\repository\\IDPTest\\src\\IDPTest.MVCClient\\project.json... Committing restore... Lock file has not changed. Skipping lock file write. Path: D:\\home\\site\\repository\\IDPTest\\src\\IDPTest.MVCClient\\project.lock.json D:\\home\\site\\repository\\IDPTest\\src\\IDPTest.MVCClient\\project.json Restore completed in 7119ms.  NuGet Config files used:     C:\\DWASFiles\\Sites\\#1IDPTest\\AppData\\NuGet\\NuGet.Config  Feeds used:     https://api.nuget.org/v3/index.json Microsoft (R) Build Engine version 15.1.0.0 Copyright (C) Microsoft Corporation. All rights reserved.  MSBUILD : error MSB1009: Project file does not exist. Switch: D:\\home\\site\\repository\\IDPTest\\src\\IDPTest.MVCClient Failed exitCode=1  command=dotnet publish \""D:\\home\\site\\repository\\IDPTest\\src\\IDPTest.MVCClient\"" --output \""D:\\local\\Temp\\8d40eb8007743fd\"" --configuration Release An error has occurred during web site deployment. \\r\\nD:\\Program Files (x86)\\SiteExtensions\\Kudu\\59.51109.2534\\bin\\Scripts\\starter.cmd \""D:\\home\\site\\deployments\\tools\\deploy.cmd </code></pre>  <p>\""</p>  <p>Interestingly I have two app-service apps pointing at different projects in the same solution. Suddently they're both failing with the same error message even though they're deploying different projects...</p>  <p>Any help much appreciated.</p>  <p>Thanks</p>  <p><strong>EDIT</strong></p>  <p>I already had a global.json in my solution root (at the same level as my .sln file) but that was pointing at an older version of the SDK  so I updated this and it made no difference. I then tried getting rid of the 'test' project in the json file and that made no difference either. Still failing with the same error<a href=\""https://i.stack.imgur.com/78bv2.png\"" rel=\""noreferrer\""><img src=\""https://i.stack.imgur.com/78bv2.png\"" alt=\""enter image description here\""></a></p>""",azure-web-app-service
47360608,"Getting \TypeError: file argument must be a non-empty string\"" when Cordova Build task <p>I am running a Cordova Build task in VSTS that builds for iOS the signing files attached:</p>  <p><a href=\""https://i.stack.imgur.com/PPnKy.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/PPnKy.png\"" alt=\""enter image description here\""></a></p>  <p>However  when I execute the task  I get the following error:</p>  <pre><code>TypeError: \""file\"" argument must be a non-empty string     at normalizeSpawnArguments (child_process.js:383:11)     at spawnSync (child_process.js:519:38)     at /Users/dummyuser/Desktop/dev/agent/_work/_tasks/CordovaBuild_70e94267-15dc-434d-8973-023d766825d7/1.3.11/lib/xcode-task-utils.js:55:31     at _fulfilled (/Users/dummyuser/Desktop/dev/agent/_work/_tasks/CordovaBuild_70e94267-15dc-434d-8973-023d766825d7/1.3.11/node_modules/q/q.js:854:54)     at self.promiseDispatch.done (/Users/dummyuser/Desktop/dev/agent/_work/_tasks/CordovaBuild_70e94267-15dc-434d-8973-023d766825d7/1.3.11/node_modules/q/q.js:883:30)     at Promise.promise.promiseDispatch (/Users/dummyuser/Desktop/dev/agent/_work/_tasks/CordovaBuild_70e94267-15dc-434d-8973-023d766825d7/1.3.11/node_modules/q/q.js:816:13)     at /Users/dummyuser/Desktop/dev/agent/_work/_tasks/CordovaBuild_70e94267-15dc-434d-8973-023d766825d7/1.3.11/node_modules/q/q.js:877:14     at runSingle (/Users/dummyuser/Desktop/dev/agent/_work/_tasks/CordovaBuild_70e94267-15dc-434d-8973-023d766825d7/1.3.11/node_modules/q/q.js:137:13)     at flush (/Users/dummyuser/Desktop/dev/agent/_work/_tasks/CordovaBuild_70e94267-15dc-434d-8973-023d766825d7/1.3.11/node_modules/q/q.js:125:13)     at _combinedTickCallback (internal/process/next_tick.js:131:7) </code></pre>  <p>Tracing back through the code of <a href=\""https://github.com/nodejs/node/blob/edb03cb65d51e336713d6af1134a7394c0776635/lib/child_process.js#L381\"" rel=\""nofollow noreferrer\"">child_process</a>  I am pretty confident this error is occurring because the file argument is not a string. Below is a snippet of the call chain:</p>  <p><strong>xcode-util-task.js</strong></p>  <pre><code>var spawnResult = spawn(createKeychain  createKeychainArgs  { stdio: \""inherit\"" }); </code></pre>  <p><strong>child_process.js</strong></p>  <pre><code>function spawnSync() {   var opts = normalizeSpawnArguments.apply(null  arguments);  ...  function normalizeSpawnArguments(file  args  options) {   if (typeof file !== 'string' || file.length === 0)     throw new TypeError('\""file\"" argument must be a non-empty string'); </code></pre>  <p>Indeed that does appear to be the case. The first argument of spawn()  createKeychain  is an object and not a string. I get the following when I print the object out:</p>  <pre><code>{ [String: '/bin/bash']   stdout: '/bin/bash'    stderr: null    code: 0    cat: [Function: bound ]    exec: [Function: bound ]    grep: [Function: bound ]    head: [Function: bound ]    sed: [Function: bound ]    sort: [Function: bound ]    tail: [Function: bound ]    to: [Function: bound ]    toEnd: [Function: bound ]    uniq: [Function: bound ] } </code></pre>  <p>I'm sure I am missing something  but this one feels like it's a bug within the Cordova Build extension.</p>  <p>FYI Node: 8.9.1  NPM: 5.5.1  Cordova Build: 1.3.11</p>""",azure-devops
55839028,"Tomcat Web-App on Azure App Service 404-0 error <p>I have created a Microsoft azure web app and configured java version 8 and tomcat 9 (Auto update). As per their documentation   I have uploaded my WAR file using KUDU in the web-app folder (ROOT.war my file name).</p>  <p>When I created the web-app without the deployment it did render the home page as Java TomCat Ready and as soon as I have deployed the ROOT.War file in my new Resource group it is now giving me 404 error.</p>  <p>The sub-status is 404 -\0\"" and I am not sure what has gone wrong the same deployment was working yesterday in the same resource group and now if I try to browse the URL of my web-app I get 404 error. I have done all sorts of research and trials but no help. Can someone help me where I can find n fix this one?</p>  <p>Update (04/24) RESOLVED:- Finally something came to my help and that was the CATLENA LOGS under the Logs (using KUDU portal)-->> Application Logs. Issue was with the DATABASE Connection to my Azure Postgres SQL which had SSL REQUIRED enabled. The Application settings for the WAR File web-app needed the SSL setting in the connection string. Fixing that fixed my issue. NEEDED the SSL=TRUE ${POSTGRES_URL} =. jdbc:postgresql://abcd-corp-chatbotpgsql.postgres.database.azure.com:5432/chatbotsqldb?ssl=true&amp;sslfactory=org.postgresql.ssl.NonValidatingFactory</p>""",azure-web-app-service
43072047,How to associate public Ip Address with an existing domain name <p>i don t understand how DNS works!</p>  <p>I have an public IP address bouaght from AZURE and Now my website already has a domain name (myWebsite.com) that is tied to my old server.</p>  <p>Now I have bought a new VM in AZURE ( it is a Ubuntu). </p>  <p>Now  how can i change that my domain name (myWebsite.com) to point now to the new Public IP ADDRESS of my VM at azure. </p>  <p>Do i have to do it in the command line or not? ??</p>,azure-virtual-machine
51418410,"Getting 500 error from my mvc application on azure <p>I SOLVED PROBLEM AND I ADDED MY SOLUTION TO PROBLEM AS A REPLY TO THIS POST.</p>  <p>I started to learn asp.net mvc and entity framework. I finished a site and tried to upload azure for sharing with other people. When I uploaded it I get 500 error and I looked out for solving this problem. But I couldn't found correct answer to my problem in stack overflow and msdn and I don't know what is the real error  I couldn't spot it in azure logs or in kudu. I tried republish my project  publishing to different web app service and the result did not change. I am trying to solve this problem for 2 days and I couldn't find correct answer yet. I can reach static pages like my error pages in html/aspx forms or dummy page I recently created but when I try to reach a mvc view I am getting error. Also when I got 404 error display of the error site is wrong and I am getting 404 errors for images and scripts in 404 page as well. Could you help me? I am adding what I show in log stream as well.</p>  <pre><code>2018-07-19T08:45:22  Welcome  you are now connected to log-streaming service. 2018-07-19T08:45:27  PID[9284] Information Unpacking resources... 2018-07-19T08:45:27  PID[9284] Information 07-19 08:45:27 Information: Executing Application Insights Profiler agent version 2.4.60711.2 with arguments:  2018-07-19T08:45:27  PID[9284] Information 07-19 08:45:27 Information: Detected an Azure App Service sandbox. 2018-07-19T08:45:27  PID[9284] Information 07-19 08:45:27 Information: Detected an Azure App Service sandbox. 2018-07-19T08:45:27  PID[9284] Information 07-19 08:45:27 Information: Minimum version enabled on machine:  2018-07-19T08:45:27  PID[9284] Information 07-19 08:45:27 Information: Instrumentation key:  2018-07-19T08:45:27  PID[9284] Information 07-19 08:45:27 Information: Application Insights Profiler endpoint: https://agent.azureserviceprofiler.net 2018-07-19T08:45:27  PID[9284] Information 07-19 08:45:27 Information: Application Insights endpoint: default 2018-07-19T08:45:27  PID[9284] Information 07-19 08:45:27 Information: Runtime Environment: Antares 2018-07-19T08:45:27  PID[9284] Information 07-19 08:45:27 Information: Support files: D:\\local\\Temp\\jobs\\continuous\\ApplicationInsightsProfiler2\\e1izfqr5.4is\\spsupport 2018-07-19T08:45:27  PID[9284] Information 07-19 08:45:27 Information: Providing usage data (to opt out set the AppSettings ApplicationInsightsProvideUsageTelemetryData with the value \false\""): True 2018-07-19T08:45:27  PID[9284] Information 07-19 08:45:27 Information: Engine mode: Immediate 2018-07-19T08:45:28  PID[9284] Information 07-19 08:45:28 Error: Unexpected exception in agent main process. Details: Microsoft.ServiceProfiler.Utilities.AppIdNotFoundException: Unable to find AppId for iKey:  2018-07-19T08:45:28  PID[9284] Information    at Microsoft.ServiceProfiler.Utilities.AppInsightsProfileFetcher.&lt;FetchProfileAsync&gt;d__3.MoveNext() 2018-07-19T08:45:28  PID[9284] Information --- End of stack trace from previous location where exception was thrown --- 2018-07-19T08:45:28  PID[9284] Information    at System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw() 2018-07-19T08:45:28  PID[9284] Information    at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task) 2018-07-19T08:45:28  PID[9284] Information    at Microsoft.ServiceProfiler.DiagnosticsAgent.Program.GetApplicationInsightsAppId(String instrumentationKey  String appInsightsEndpoint) 2018-07-19T08:45:28  PID[9284] Information    at Microsoft.ServiceProfiler.DiagnosticsAgent.Program.Main(String[] cmdArgs) 2018-07-19T08:45:30 sandboxproc.exe C:\\DWASFiles\\Sites\\ECommerceFurkan\\Temp\\applicationhost.config True True 2018-07-19T08:45:30 env XPROC_TYPENAME=Microsoft.Web.Hosting.Transformers.ApplicationHost.SiteExtensionHelper  Microsoft.Web.Hosting  Version=7.1.0.0  Culture=neutral  PublicKeyToken=31bf3856ad364e35 2018-07-19T08:45:30 env XPROC_METHODNAME=Transform 2018-07-19T08:45:30 Start 'Microsoft.ApplicationInsights.AzureWebSites' site extension transform 2018-07-19T08:45:30 StartSection Executing InsertIfMissing (transform line 6  21) 2018-07-19T08:45:30 on /configuration/system.webServer 2018-07-19T08:45:30 Applying to 'configuration' element (no source line info) 2018-07-19T08:45:30 EndSection Done executing InsertIfMissing 2018-07-19T08:45:30 StartSection Executing InsertIfMissing (transform line 7  14) 2018-07-19T08:45:30 on /configuration/system.webServer/runtime 2018-07-19T08:45:30 Applying to 'system.webServer' element (no source line info) 2018-07-19T08:45:30 Inserted 'runtime' element 2018-07-19T08:45:30 EndSection Done executing InsertIfMissing 2018-07-19T08:45:30 StartSection Executing InsertIfMissing (transform line 8  29) 2018-07-19T08:45:30 on /configuration/system.webServer/runtime/environmentVariables 2018-07-19T08:45:30 Applying to 'runtime' element (no source line info) 2018-07-19T08:45:30 EndSection Done executing InsertIfMissing 2018-07-19T08:45:30 StartSection Executing InsertIfMissing (transform line 9  227) 2018-07-19T08:45:30 on /configuration/system.webServer/runtime/environmentVariables/add[@name='MicrosoftAppInsights_ManagedHttpModulePath'] 2018-07-19T08:45:30 Applying to 'environmentVariables' element (no source line info) 2018-07-19T08:45:30 EndSection Done executing InsertIfMissing 2018-07-19T08:45:30 StartSection Executing InsertIfMissing (transform line 10  164) 2018-07-19T08:45:30 on /configuration/system.webServer/runtime/environmentVariables/add[@name='MicrosoftAppInsights_ManagedHttpModuleType'] 2018-07-19T08:45:30 Applying to 'environmentVariables' element (no source line info) 2018-07-19T08:45:30 EndSection Done executing InsertIfMissing 2018-07-19T08:45:30 StartSection Executing InsertOrAppendAttribute (transform line 11  270) 2018-07-19T08:45:30 on /configuration/system.webServer/runtime/environmentVariables/add[@name='DOTNET_ADDITIONAL_DEPS'] 2018-07-19T08:45:30 Applying to 'environmentVariables' element (no source line info) 2018-07-19T08:45:30 EndSection Done executing InsertOrAppendAttribute 2018-07-19T08:45:30 StartSection Executing InsertOrAppendAttribute (transform line 12  160) 2018-07-19T08:45:30 on /configuration/system.webServer/runtime/environmentVariables/add[@name='DOTNET_SHARED_STORE'] 2018-07-19T08:45:30 Applying to 'environmentVariables' element (no source line info) 2018-07-19T08:45:30 EndSection Done executing InsertOrAppendAttribute 2018-07-19T08:45:30 StartSection Executing InsertOrAppendAttribute (transform line 13  111) 2018-07-19T08:45:30 on /configuration/system.webServer/runtime/environmentVariables/add[@name='ASPNETCORE_HOSTINGSTARTUPASSEMBLIES'] 2018-07-19T08:45:30 Applying to 'environmentVariables' element (no source line info) 2018-07-19T08:45:30 EndSection Done executing InsertOrAppendAttribute 2018-07-19T08:45:30 StartSection Executing InsertIfMissing (transform line 15  78) 2018-07-19T08:45:30 on /configuration/system.webServer/runtime/environmentVariables/add[@name='COR_ENABLE_PROFILING'] 2018-07-19T08:45:30 Applying to 'environmentVariables' element (no source line info) 2018-07-19T08:45:30 EndSection Done executing InsertIfMissing 2018-07-19T08:45:30 StartSection Executing InsertIfMissing (transform line 16  107) 2018-07-19T08:45:30 on /configuration/system.webServer/runtime/environmentVariables/add[@name='COR_PROFILER'] 2018-07-19T08:45:30 Applying to 'environmentVariables' element (no source line info) 2018-07-19T08:45:30 EndSection Done executing InsertIfMissing 2018-07-19T08:45:30 StartSection Executing InsertIfMissing (transform line 17  206) 2018-07-19T08:45:30 on /configuration/system.webServer/runtime/environmentVariables/add[@name='COR_PROFILER_PATH_32'] 2018-07-19T08:45:30 Applying to 'environmentVariables' element (no source line info) 2018-07-19T08:45:30 EndSection Done executing InsertIfMissing 2018-07-19T08:45:30 StartSection Executing InsertIfMissing (transform line 18  206) 2018-07-19T08:45:30 on /configuration/system.webServer/runtime/environmentVariables/add[@name='COR_PROFILER_PATH_64'] 2018-07-19T08:45:30 Applying to 'environmentVariables' element (no source line info) 2018-07-19T08:45:30 EndSection Done executing InsertIfMissing 2018-07-19T08:45:30 StartSection Executing InsertIfMissing (transform line 19  130) 2018-07-19T08:45:30 on /configuration/system.webServer/runtime/environmentVariables/add[@name='MicrosoftInstrumentationEngine_Host'] 2018-07-19T08:45:30 Applying to 'environmentVariables' element (no source line info) 2018-07-19T08:45:30 EndSection Done executing InsertIfMissing 2018-07-19T08:45:30 StartSection Executing InsertIfMissing (transform line 20  244) 2018-07-19T08:45:30 on /configuration/system.webServer/runtime/environmentVariables/add[@name='MicrosoftInstrumentationEngine_HostPath_32'] 2018-07-19T08:45:30 Applying to 'environmentVariables' element (no source line info) 2018-07-19T08:45:30 EndSection Done executing InsertIfMissing 2018-07-19T08:45:30 StartSection Executing InsertIfMissing (transform line 21  244) 2018-07-19T08:45:30 on /configuration/system.webServer/runtime/environmentVariables/add[@name='MicrosoftInstrumentationEngine_HostPath_64'] 2018-07-19T08:45:30 Applying to 'environmentVariables' element (no source line info) 2018-07-19T08:45:30 EndSection Done executing InsertIfMissing 2018-07-19T08:45:30 StartSection Executing InsertIfMissing (transform line 22  82) 2018-07-19T08:45:30 on /configuration/system.webServer/runtime/environmentVariables/add[@name='CORECLR_ENABLE_PROFILING'] 2018-07-19T08:45:30 Applying to 'environmentVariables' element (no source line info) 2018-07-19T08:45:30 EndSection Done executing InsertIfMissing 2018-07-19T08:45:30 StartSection Executing InsertIfMissing (transform line 23  111) 2018-07-19T08:45:30 on /configuration/system.webServer/runtime/environmentVariables/add[@name='CORECLR_PROFILER'] 2018-07-19T08:45:30 Applying to 'environmentVariables' element (no source line info) 2018-07-19T08:45:30 EndSection Done executing InsertIfMissing 2018-07-19T08:45:30 StartSection Executing InsertIfMissing (transform line 24  210) 2018-07-19T08:45:30 on /configuration/system.webServer/runtime/environmentVariables/add[@name='CORECLR_PROFILER_PATH_32'] 2018-07-19T08:45:30 Applying to 'environmentVariables' element (no source line info) 2018-07-19T08:45:30 EndSection Done executing InsertIfMissing 2018-07-19T08:45:30 StartSection Executing InsertIfMissing (transform line 25  210) 2018-07-19T08:45:30 on /configuration/system.webServer/runtime/environmentVariables/add[@name='CORECLR_PROFILER_PATH_64'] 2018-07-19T08:45:30 Applying to 'environmentVariables' element (no source line info) 2018-07-19T08:45:30 EndSection Done executing InsertIfMissing 2018-07-19T08:45:30 StartSection Executing InsertIfMissing (transform line 29  181) 2018-07-19T08:45:30 on /configuration/system.webServer/runtime/environmentVariables/add[@name='MicrosoftProductionDiagnostics_RuntimeFolder'] 2018-07-19T08:45:30 Applying to 'environmentVariables' element (no source line info) 2018-07-19T08:45:30 EndSection Done executing InsertIfMissing 2018-07-19T08:45:30 StartSection Executing InsertIfMissing (transform line 31  111) 2018-07-19T08:45:30 on /configuration/system.webServer/runtime/environmentVariables/add[@name='MicrosoftProductionDiagnostics_DisableInstrumentation'] 2018-07-19T08:45:30 Applying to 'environmentVariables' element (no source line info) 2018-07-19T08:45:30 EndSection Done executing InsertIfMissing 2018-07-19T08:45:30 StartSection Executing InsertIfMissing (transform line 33  112) 2018-07-19T08:45:30 on /configuration/system.webServer/runtime/environmentVariables/add[@name='MicrosoftProductionDiagnostics_GrantException_Websites'] 2018-07-19T08:45:30 Applying to 'environmentVariables' element (no source line info) 2018-07-19T08:45:30 EndSection Done executing InsertIfMissing 2018-07-19T08:45:30 StartSection Executing InsertIfMissing (transform line 36  102) 2018-07-19T08:45:30 on /configuration/system.webServer/runtime/environmentVariables/add[@name='MicrosoftInstrumentationEngine_LogLevel'] 2018-07-19T08:45:30 Applying to 'environmentVariables' element (no source line info) 2018-07-19T08:45:30 EndSection Done executing InsertIfMissing 2018-07-19T08:45:30 StartSection Executing InsertIfMissing (transform line 46  372) 2018-07-19T08:45:30 on /configuration/system.webServer/runtime/environmentVariables/add[@name='MicrosoftInstrumentationEngine_ConfigPath32_Private'] 2018-07-19T08:45:30 Applying to 'environmentVariables' element (no source line info) 2018-07-19T08:45:30 EndSection Done executing InsertIfMissing 2018-07-19T08:45:30 StartSection Executing InsertIfMissing (transform line 47  372) 2018-07-19T08:45:30 on /configuration/system.webServer/runtime/environmentVariables/add[@name='MicrosoftInstrumentationEngine_ConfigPath64_Private'] 2018-07-19T08:45:30 Applying to 'environmentVariables' element (no source line info) 2018-07-19T08:45:30 EndSection Done executing InsertIfMissing 2018-07-19T08:45:30 StartSection Executing InsertIfMissing (transform line 54  23) 2018-07-19T08:45:30 on /configuration/location[@path='ECommerceFurkan']/system.webServer 2018-07-19T08:45:30 Applying to 'location' element (no source line info) 2018-07-19T08:45:30 EndSection Done executing InsertIfMissing 2018-07-19T08:45:30 StartSection Executing InsertIfMissing (transform line 55  16) 2018-07-19T08:45:30 on /configuration/location[@path='ECommerceFurkan']/system.webServer/modules 2018-07-19T08:45:30 Applying to 'system.webServer' element (no source line info) 2018-07-19T08:45:30 Inserted 'modules' element 2018-07-19T08:45:30 EndSection Done executing InsertIfMissing 2018-07-19T08:45:30 StartSection Executing InsertIfMissing (transform line 60  16) 2018-07-19T08:45:30 on /configuration/location[@path='ECommerceFurkan']/system.webServer/rewrite 2018-07-19T08:45:30 Applying to 'system.webServer' element (no source line info) 2018-07-19T08:45:30 Inserted 'rewrite' element 2018-07-19T08:45:30 EndSection Done executing InsertIfMissing 2018-07-19T08:45:30 StartSection Executing InsertIfMissing (transform line 61  33) 2018-07-19T08:45:30 on /configuration/location[@path='ECommerceFurkan']/system.webServer/rewrite/allowedServerVariables 2018-07-19T08:45:30 Applying to 'rewrite' element (no source line info) 2018-07-19T08:45:30 EndSection Done executing InsertIfMissing 2018-07-19T08:45:30 StartSection Executing InsertIfMissing (transform line 62  81) 2018-07-19T08:45:30 on /configuration/location[@path='ECommerceFurkan']/system.webServer/rewrite/allowedServerVariables/add[@name='HTTP_X_ORIGINAL_ACCEPT_ENCODING'] 2018-07-19T08:45:30 Applying to 'allowedServerVariables' element (no source line info) 2018-07-19T08:45:30 EndSection Done executing InsertIfMissing 2018-07-19T08:45:30 StartSection Executing InsertIfMissing (transform line 63  70) 2018-07-19T08:45:30 on /configuration/location[@path='ECommerceFurkan']/system.webServer/rewrite/allowedServerVariables/add[@name='HTTP_ACCEPT_ENCODING'] 2018-07-19T08:45:30 Applying to 'allowedServerVariables' element (no source line info) 2018-07-19T08:45:30 EndSection Done executing InsertIfMissing 2018-07-19T08:45:30 StartSection Executing InsertIfMissing (transform line 66  16) 2018-07-19T08:45:30 on /configuration/location[@path='ECommerceFurkan']/system.webServer/rewrite/rules 2018-07-19T08:45:30 Applying to 'rewrite' element (no source line info) 2018-07-19T08:45:30 EndSection Done executing InsertIfMissing 2018-07-19T08:45:30 StartSection Executing InsertIfMissing (transform line 67  75) 2018-07-19T08:45:30 on /configuration/location[@path='ECommerceFurkan']/system.webServer/rewrite/rules/rule 2018-07-19T08:45:30 Applying to 'rules' element (no source line info) 2018-07-19T08:45:30 EndSection Done executing InsertIfMissing 2018-07-19T08:45:30 StartSection Executing InsertOrAppendAttribute (transform line 81  50) 2018-07-19T08:45:30 on /configuration/location[@path='ECommerceFurkan']/system.webServer/rewrite/outboundRules 2018-07-19T08:45:30 Applying to 'rewrite' element (no source line info) 2018-07-19T08:45:30 EndSection Done executing InsertOrAppendAttribute 2018-07-19T08:45:30 StartSection Executing InsertIfMissing (transform line 82  97) 2018-07-19T08:45:30 on /configuration/location[@path='ECommerceFurkan']/system.webServer/rewrite/outboundRules/rule 2018-07-19T08:45:30 Applying to 'outboundRules' element (no source line info) 2018-07-19T08:45:30 EndSection Done executing InsertIfMissing 2018-07-19T08:45:30 StartSection Executing InsertIfMissing (transform line 87  96) 2018-07-19T08:45:30 on /configuration/location[@path='ECommerceFurkan']/system.webServer/rewrite/outboundRules/rule 2018-07-19T08:45:30 Applying to 'outboundRules' element (no source line info) 2018-07-19T08:45:30 EndSection Done executing InsertIfMissing 2018-07-19T08:45:30 StartSection Executing InsertIfMissing (transform line 92  26) 2018-07-19T08:45:30 on /configuration/location[@path='ECommerceFurkan']/system.webServer/rewrite/outboundRules/preConditions 2018-07-19T08:45:30 Applying to 'outboundRules' element (no source line info) 2018-07-19T08:45:30 EndSection Done executing InsertIfMissing 2018-07-19T08:45:30 StartSection Executing InsertIfMissing (transform line 93  89) 2018-07-19T08:45:30 on /configuration/location[@path='ECommerceFurkan']/system.webServer/rewrite/outboundRules/preConditions/preCondition[@name='IsApplicationInsightsEnabled'] 2018-07-19T08:45:30 Applying to 'preConditions' element (no source line info) 2018-07-19T08:45:30 EndSection Done executing InsertIfMissing 2018-07-19T08:45:30 StartSection Executing InsertIfMissing (transform line 100  89) 2018-07-19T08:45:30 on /configuration/location[@path='ECommerceFurkan']/system.webServer/rewrite/outboundRules/preConditions/preCondition[@name='NeedsRestoringAcceptEncoding'] 2018-07-19T08:45:30 Applying to 'preConditions' element (no source line info) 2018-07-19T08:45:30 EndSection Done executing InsertIfMissing 2018-07-19T08:45:30 StartSection Executing InsertIfMissing (transform line 106  20) 2018-07-19T08:45:30 on /configuration/location[@path='ECommerceFurkan']/system.webServer/rewrite/providers 2018-07-19T08:45:30 Applying to 'rewrite' element (no source line info) 2018-07-19T08:45:30 EndSection Done executing InsertIfMissing 2018-07-19T08:45:30 StartSection Executing RemoveAll (transform line 107  69) 2018-07-19T08:45:30 on /configuration/location[@path='ECommerceFurkan']/system.webServer/rewrite/providers/provider[@name='EnvVarProvider'] 2018-07-19T08:45:30 Applying to 'provider' element (no source line info) 2018-07-19T08:45:30 Removed 'provider' element 2018-07-19T08:45:30 Applying to 'provider' element (no source line info) 2018-07-19T08:45:30 Removed 'provider' element 2018-07-19T08:45:30 EndSection Done executing RemoveAll 2018-07-19T08:45:30 StartSection Executing InsertIfMissing (transform line 108  21) 2018-07-19T08:45:30 on /configuration/location[@path='ECommerceFurkan']/system.webServer/rewrite/providers/provider 2018-07-19T08:45:30 Applying to 'providers' element (no source line info) 2018-07-19T08:45:30 Inserted 'provider' element 2018-07-19T08:45:30 EndSection Done executing InsertIfMissing 2018-07-19T08:45:30 StartSection Executing InsertOrAppendAttribute (transform line 112  61) 2018-07-19T08:45:30 on /configuration/location[@path='ECommerceFurkan']/system.webServer/urlCompression 2018-07-19T08:45:30 Applying to 'system.webServer' element (no source line info) 2018-07-19T08:45:30 EndSection Done executing InsertOrAppendAttribute 2018-07-19T08:45:31 Successful 'D:\\home\\SiteExtensions\\Microsoft.ApplicationInsights.AzureWebSites\\applicationHost.xdt' site extension transform 2018-07-19T08:45:31 sandboxproc.exe complete successfully. Elapsed = 1010.00 ms &lt;!DOCTYPE html PUBLIC \""-//W3C//DTD XHTML 1.0 Strict//EN\"" \""http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd\""&gt;  &lt;html xmlns=\""http://www.w3.org/1999/xhtml\""&gt;  &lt;head&gt;  &lt;title&gt;IIS Detailed Error - 500.0 - Internal Server Error&lt;/title&gt;  &lt;style type=\""text/css\""&gt;  &lt;!--  body{margin:0;font-size:.7em;font-family:Verdana Arial Helvetica sans-serif;}  code{margin:0;color:#006600;font-size:1.1em;font-weight:bold;}  .config_source code{font-size:.8em;color:#000000;}  pre{margin:0;font-size:1.4em;word-wrap:break-word;}  ul ol{margin:10px 0 10px 5px;}  ul.first ol.first{margin-top:5px;}  fieldset{padding:0 15px 10px 15px;word-break:break-all;}  .summary-container fieldset{padding-bottom:5px;margin-top:4px;}  legend.no-expand-all{padding:2px 15px 4px 10px;margin:0 0 0 -12px;}  legend{color:#333333;;margin:4px 0 8px -12px;_margin-top:0px;  font-weight:bold;font-size:1em;}  a:link a:visited{color:#007EFF;font-weight:bold;}  a:hover{text-decoration:none;}  h1{font-size:2.4em;margin:0;color:#FFF;}  h2{font-size:1.7em;margin:0;color:#CC0000;}  h3{font-size:1.4em;margin:10px 0 0 0;color:#CC0000;}  h4{font-size:1.2em;margin:10px 0 5px 0;  }#header{width:96%;margin:0 0 0 0;padding:6px 2% 6px 2%;font-family:\""trebuchet MS\"" Verdana sans-serif;  color:#FFF;background-color:#5C87B2;  }#content{margin:0 0 0 2%;position:relative;}  .summary-container .content-container{background:#FFF;width:96%;margin-top:8px;padding:10px;position:relative;}  .content-container p{margin:0 0 10px 0;  }#details-left{width:35%;float:left;margin-right:2%;  }#details-right{width:63%;float:left;overflow:hidden;  }#server_version{width:96%;_height:1px;min-height:1px;margin:0 0 5px 0;padding:11px 2% 8px 2%;color:#FFFFFF;  background-color:#5A7FA5;border-bottom:1px solid #C1CFDD;border-top:1px solid #4A6C8E;font-weight:normal;  font-size:1em;color:#FFF;text-align:right;  }#server_version p{margin:5px 0;}  table{margin:4px 0 4px 0;width:100%;border:none;}  td th{vertical-align:top;padding:3px 0;text-align:left;font-weight:normal;border:none;}  th{width:30%;text-align:right;padding-right:2%;font-weight:bold;}  thead th{background-color:#ebebeb;width:25%;  }#details-right th{width:20%;}  table tr.alt td table tr.alt th{}  .highlight-code{color:#CC0000;font-weight:bold;font-style:italic;}  .clear{clear:both;}  .preferred{padding:0 5px 2px 5px;font-weight:normal;background:#006633;color:#FFF;font-size:.8em;}  --&gt;  &lt;/style&gt;   &lt;/head&gt;  &lt;body&gt;  &lt;div id=\""content\""&gt;  &lt;div class=\""content-container\""&gt;  &lt;h3&gt;HTTP Error 500.0 - Internal Server Error&lt;/h3&gt;  &lt;h4&gt;The page cannot be displayed because an internal server error has occurred.&lt;/h4&gt;  &lt;/div&gt;  &lt;div class=\""content-container\""&gt;  &lt;fieldset&gt;&lt;h4&gt;Most likely causes:&lt;/h4&gt;  &lt;ul&gt;    &lt;li&gt;IIS received the request; however  an internal error occurred during the processing of the request. The root cause of this error depends on which module handles the request and what was happening in the worker process when this error occurred.&lt;/li&gt;    &lt;li&gt;IIS was not able to access the web.config file for the Web site or application. This can occur if the NTFS permissions are set incorrectly.&lt;/li&gt;    &lt;li&gt;IIS was not able to process configuration for the Web site or application.&lt;/li&gt;     &lt;li&gt;The authenticated user does not have permission to use this DLL.&lt;/li&gt;   &lt;li&gt;The request is mapped to a managed handler but the .NET Extensibility Feature is not installed.&lt;/li&gt; &lt;/ul&gt;  &lt;/fieldset&gt;  &lt;/div&gt;  &lt;div class=\""content-container\""&gt;  &lt;fieldset&gt;&lt;h4&gt;Things you can try:&lt;/h4&gt;  &lt;ul&gt;    &lt;li&gt;Ensure that the NTFS permissions for the web.config file are correct and allow access to the Web server's machine account.&lt;/li&gt;     &lt;li&gt;Check the event logs to see if any additional information was logged.&lt;/li&gt;  &lt;li&gt;Verify the permissions for the DLL.&lt;/li&gt;    &lt;li&gt;Install the .NET Extensibility feature if the request is mapped to a managed handler.&lt;/li&gt;  &lt;li&gt;Create a tracing rule to track failed requests for this HTTP status code. For more information about creating a tracing rule for failed requests  click &lt;a href=\""http://go.microsoft.com/fwlink/?LinkID=66439\""&gt;here&lt;/a&gt;. &lt;/li&gt; &lt;/ul&gt;  &lt;/fieldset&gt;  &lt;/div&gt;   &lt;div class=\""content-container\""&gt;  &lt;fieldset&gt;&lt;h4&gt;Detailed Error Information:&lt;/h4&gt;  &lt;div id=\""details-left\""&gt;  &lt;table border=\""0\"" cellpadding=\""0\"" cellspacing=\""0\""&gt;  &lt;tr class=\""alt\""&gt;&lt;th&gt;Module&lt;/th&gt;&lt;td&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;ManagedPipelineHandler&lt;/td&gt;&lt;/tr&gt;  &lt;tr&gt;&lt;th&gt;Notification&lt;/th&gt;&lt;td&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;ExecuteRequestHandler&lt;/td&gt;&lt;/tr&gt;  &lt;tr class=\""alt\""&gt;&lt;th&gt;Handler&lt;/th&gt;&lt;td&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;System.Web.Mvc.MvcHandler&lt;/td&gt;&lt;/tr&gt;  &lt;tr&gt;&lt;th&gt;Error Code&lt;/th&gt;&lt;td&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;0x00000000&lt;/td&gt;&lt;/tr&gt;   &lt;/table&gt;  &lt;/div&gt;  &lt;div id=\""details-right\""&gt;  &lt;table border=\""0\"" cellpadding=\""0\"" cellspacing=\""0\""&gt;  &lt;tr class=\""alt\""&gt;&lt;th&gt;Requested URL&lt;/th&gt;&lt;td&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;http://ECommerceFurkan:80/&lt;/td&gt;&lt;/tr&gt;  &lt;tr&gt;&lt;th&gt;Physical Path&lt;/th&gt;&lt;td&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;D:\\home\\site\\wwwroot&lt;/td&gt;&lt;/tr&gt;  &lt;tr class=\""alt\""&gt;&lt;th&gt;Logon Method&lt;/th&gt;&lt;td&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;Anonymous&lt;/td&gt;&lt;/tr&gt;  &lt;tr&gt;&lt;th&gt;Logon User&lt;/th&gt;&lt;td&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;Anonymous&lt;/td&gt;&lt;/tr&gt;   &lt;/table&gt;  &lt;div class=\""clear\""&gt;&lt;/div&gt;  &lt;/div&gt;  &lt;/fieldset&gt;  &lt;/div&gt;   &lt;div class=\""content-container\""&gt;  &lt;fieldset&gt;&lt;h4&gt;More Information:&lt;/h4&gt;  This error means that there was a problem while processing the request. The request was received by the Web server  but during processing a fatal error occurred  causing the 500 error.  &lt;p&gt;&lt;a href=\""http://go.microsoft.com/fwlink/?LinkID=62293&amp;amp;IIS70Error=500 0 0x00000000 14393\""&gt;View more information &amp;raquo;&lt;/a&gt;&lt;/p&gt;  &lt;p&gt;Microsoft Knowledge Base Articles:&lt;/p&gt;    &lt;/fieldset&gt;  &lt;/div&gt;  &lt;/div&gt;  &lt;/body&gt;  &lt;/html&gt;  </code></pre>""",azure-web-app-service
38856829,"How do I add framework assemblies in Azure Function <p>I need to add System.Web.Script.Serialization and System.Web.Extensions to my function app so that I can deserialize json string using the following code :</p>  <pre><code>JavaScriptSerializer serializer = new JavaScriptSerializer();  dynamic item = serializer.Deserialize&lt;object&gt;(\{ \\\""test\\\"":\\\""some data\\\"" }\""); string test= item[\""test\""]; </code></pre>  <p>This does not work :</p>  <pre><code>#r \""System.Web.Script.Serialization\"" #r \""System.Web.Extensions\"" </code></pre>  <p>How do I add resolve this issue?</p>""",azure-functions
28728389,"How do I disable automatic updates for Azure VM extensions? <p>We have a few VMs in Azure and we rely on the <a href=\http://blogs.msdn.com/b/powershell/archive/2014/08/07/introducing-the-azure-powershell-dsc-desired-state-configuration-extension.aspx\"" rel=\""nofollow noreferrer\"">PowerShell DSC extension</a> to deploy our code to the machines. I want to make sure that this extension is not updated automatically so that our code that uses functionality from this extension don't break without we knowing about it first.</p>  <p>The problem is that we have some deployment scripts that read the extension's status codes/messages and do custom logic based on them. When the extension was updated from 1.4.0.0 (which is the version that the plugin was on when we first started using it) to the version 1.5.0.0  <a href=\""https://stackoverflow.com/a/26759691/1946412\"">some of the status messages changed and our script stopped working</a>. This completely broke our deployment process and we had to do an emergency update on our scripts to be compatible with v1.5. Now that version 1.7.0.0 was released the same exact problem happened again. Some new status codes were added and I had to update our scripts or we would not have a working deployment pipeline.</p>  <p>Is it possible to specify a manual update process for these extensions? Their installation and update seem to be completely automated. Ideally  I'd like to be able to update them on a case by case basis after testing our scripts against the newer versions first  so that our deployment process is not halted because of that. Bonus points for anyone who manages to find up to date documentation or some kind of release notes document for this extension in particular  as I could find none... I was just surprised to see that version 1.7 was installed today when I got an error from our script  and was lucky to know exactly where to look for the status changes.</p>""",azure-virtual-machine
55035740,How to determine the Git Tag value in Azure DevOps? <p>I'm trying to figure out how to get the <code>tag</code> value when some code is tagged  in GitHub. (eg -> GitHub repo -> releases -> create a new release).</p>  <p>For example  I'm trying to set the <code>Build Version</code> based on the Git tag value.</p>  <pre><code>steps:  - script: ##vso[area.action Build.BuildNumber=value;]Build.BuildNumber   displayName: 'Setting the build number based on a Tag or not.'   condition: and(succeeded()  startsWith(variables['Build.SourceBranch']  'refs/tags/')) </code></pre>  <p>So in the above <code>step</code> I'm trying to say:</p>  <ul> <li>given a tag has been pushed</li> <li>get the tab value (eg. v1.2.3)</li> <li>set the environment variable <code>Build.BuildNumber</code> to this tag value.</li> </ul>  <p>So now all the other steps can access <code>Build.BuildNumber</code> which will be <code>v1.2.3</code>.</p>,azure-devops
56707157,Does Azure Artifacts store the deltas of Universal Packages? <p>I'm already familiar with Azure Artifacts  and lately I've been trying to optimize billing expenses. Since Azure Artifacts charges per/GB  I've been wanting to know  does the Universal Packages feature attempt to optimize storage usage by only storing the differences between one version of the package and the next version of the package?</p>,azure-devops
15660250,"What is the azure table storage query equivalent of T-sql's LIKE command? <p>I'm querying Azure table storage using the Azure Storage Explorer. I want to find all messages that contain the given text  like this in T-SQL:</p>  <pre><code>message like '%SysFn%' </code></pre>  <p>Executing the T-SQL gives \An error occurred while processing this request\""</p>  <p>What is the equivalent of this query in Azure?</p>""",azure-storage
56389038,"Javascript Durable Functions fail when called during Azure Function App warmup period <p>Also reported on GitHub: <a href=\https://github.com/Azure/azure-functions-durable-js/issues/86\"" rel=\""nofollow noreferrer\"">https://github.com/Azure/azure-functions-durable-js/issues/86</a></p>  <p>When using the Consumption Tier of Azure Function Apps  the service is put into an idle state. The next request to the service \""wakes up\"" the service  and may take a while to respond (which is expected).</p>  <p>When the service is \""hot\""  then everything works fine  however  if the wakeup request calls an Orchestrator function from the Durable Functions library  then the Orchestrator throws a Service Unavailable error:</p>  <pre><code>Exception while executing function: Functions.HttpTrigger Result: Failure Exception: Error: The service is unavailable. Stack: Error: The service is unavailable.     at DurableOrchestrationClient.&lt;anonymous&gt; (D:\\home\\site\\wwwroot\\node_modules\\durable-functions\\lib\\src\\durableorchestrationclient.js:247:43)     at Generator.next (&lt;anonymous&gt;)     at fulfilled (D:\\home\\site\\wwwroot\\node_modules\\durable-functions\\lib\\src\\durableorchestrationclient.js:4:58)     at process._tickCallback (internal/process/next_tick.js:68:7)  </code></pre>  <p>Stack Trace:</p>  <pre><code>Microsoft.Azure.WebJobs.Host.FunctionInvocationException:    at System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw (System.Private.CoreLib  Version=4.0.0.0  Culture=neutral  PublicKeyToken=7cec85d7bea7798e)    at Microsoft.Azure.WebJobs.Host.Executors.FunctionExecutor+&lt;ExecuteWithLoggingAsync&gt;d__19.MoveNext (Microsoft.Azure.WebJobs.Host  Version=3.0.8.0  Culture=neutral  PublicKeyToken=31bf3856ad364e35Microsoft.Azure.WebJobs.Host  Version=3.0.8.0  Culture=neutral  PublicKeyToken=31bf3856ad364e35: C:\\projects\\azure-webjobs-sdk-rqm4t\\src\\Microsoft.Azure.WebJobs.Host\\Executors\\FunctionExecutor.csMicrosoft.Azure.WebJobs.Host  Version=3.0.8.0  Culture=neutral  PublicKeyToken=31bf3856ad364e35: 321)    at System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw (System.Private.CoreLib  Version=4.0.0.0  Culture=neutral  PublicKeyToken=7cec85d7bea7798e)    at System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess (System.Private.CoreLib  Version=4.0.0.0  Culture=neutral  PublicKeyToken=7cec85d7bea7798e)    at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification (System.Private.CoreLib  Version=4.0.0.0  Culture=neutral  PublicKeyToken=7cec85d7bea7798e)    at System.Runtime.CompilerServices.TaskAwaiter`1.GetResult (System.Private.CoreLib  Version=4.0.0.0  Culture=neutral  PublicKeyToken=7cec85d7bea7798e)    at Microsoft.Azure.WebJobs.Host.Executors.FunctionExecutor+&lt;TryExecuteAsyncCore&gt;d__16.MoveNext (Microsoft.Azure.WebJobs.Host  Version=3.0.8.0  Culture=neutral  PublicKeyToken=31bf3856ad364e35Microsoft.Azure.WebJobs.Host  Version=3.0.8.0  Culture=neutral  PublicKeyToken=31bf3856ad364e35: C:\\projects\\azure-webjobs-sdk-rqm4t\\src\\Microsoft.Azure.WebJobs.Host\\Executors\\FunctionExecutor.csMicrosoft.Azure.WebJobs.Host  Version=3.0.8.0  Culture=neutral  PublicKeyToken=31bf3856ad364e35: 117) Inner exception Microsoft.Azure.WebJobs.Script.Rpc.RpcException handled at System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw:    at System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw (System.Private.CoreLib  Version=4.0.0.0  Culture=neutral  PublicKeyToken=7cec85d7bea7798e)    at System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess (System.Private.CoreLib  Version=4.0.0.0  Culture=neutral  PublicKeyToken=7cec85d7bea7798e)    at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification (System.Private.CoreLib  Version=4.0.0.0  Culture=neutral  PublicKeyToken=7cec85d7bea7798e)    at System.Runtime.CompilerServices.TaskAwaiter`1.GetResult (System.Private.CoreLib  Version=4.0.0.0  Culture=neutral  PublicKeyToken=7cec85d7bea7798e)    at Microsoft.Azure.WebJobs.Script.Description.WorkerLanguageInvoker+&lt;InvokeCore&gt;d__6.MoveNext (Microsoft.Azure.WebJobs.Script  Version=2.0.0.0  Culture=neutral  PublicKeyToken=nullMicrosoft.Azure.WebJobs.Script  Version=2.0.0.0  Culture=neutral  PublicKeyToken=null: C:\\azure-webjobs-sdk-script\\src\\WebJobs.Script\\Description\\Rpc\\WorkerLanguageInvoker.csMicrosoft.Azure.WebJobs.Script  Version=2.0.0.0  Culture=neutral  PublicKeyToken=null: 74)    at System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw (System.Private.CoreLib  Version=4.0.0.0  Culture=neutral  PublicKeyToken=7cec85d7bea7798e)    at System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess (System.Private.CoreLib  Version=4.0.0.0  Culture=neutral  PublicKeyToken=7cec85d7bea7798e)    at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification (System.Private.CoreLib  Version=4.0.0.0  Culture=neutral  PublicKeyToken=7cec85d7bea7798e)    at System.Runtime.CompilerServices.TaskAwaiter`1.GetResult (System.Private.CoreLib  Version=4.0.0.0  Culture=neutral  PublicKeyToken=7cec85d7bea7798e)    at Microsoft.Azure.WebJobs.Script.Description.FunctionInvokerBase+&lt;Invoke&gt;d__24.MoveNext (Microsoft.Azure.WebJobs.Script  Version=2.0.0.0  Culture=neutral  PublicKeyToken=nullMicrosoft.Azure.WebJobs.Script  Version=2.0.0.0  Culture=neutral  PublicKeyToken=null: C:\\azure-webjobs-sdk-script\\src\\WebJobs.Script\\Description\\FunctionInvokerBase.csMicrosoft.Azure.WebJobs.Script  Version=2.0.0.0  Culture=neutral  PublicKeyToken=null: 85)    at System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw (System.Private.CoreLib  Version=4.0.0.0  Culture=neutral  PublicKeyToken=7cec85d7bea7798e)    at System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess (System.Private.CoreLib  Version=4.0.0.0  Culture=neutral  PublicKeyToken=7cec85d7bea7798e)    at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification (System.Private.CoreLib  Version=4.0.0.0  Culture=neutral  PublicKeyToken=7cec85d7bea7798e)    at System.Runtime.CompilerServices.TaskAwaiter`1.GetResult (System.Private.CoreLib  Version=4.0.0.0  Culture=neutral  PublicKeyToken=7cec85d7bea7798e)    at Microsoft.Azure.WebJobs.Script.Description.FunctionGenerator+&lt;Coerce&gt;d__3`1.MoveNext (Microsoft.Azure.WebJobs.Script  Version=2.0.0.0  Culture=neutral  PublicKeyToken=nullMicrosoft.Azure.WebJobs.Script  Version=2.0.0.0  Culture=neutral  PublicKeyToken=null: C:\\azure-webjobs-sdk-script\\src\\WebJobs.Script\\Description\\FunctionGenerator.csMicrosoft.Azure.WebJobs.Script  Version=2.0.0.0  Culture=neutral  PublicKeyToken=null: 225)    at System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw (System.Private.CoreLib  Version=4.0.0.0  Culture=neutral  PublicKeyToken=7cec85d7bea7798e)    at System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess (System.Private.CoreLib  Version=4.0.0.0  Culture=neutral  PublicKeyToken=7cec85d7bea7798e)    at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification (System.Private.CoreLib  Version=4.0.0.0  Culture=neutral  PublicKeyToken=7cec85d7bea7798e)    at System.Runtime.CompilerServices.TaskAwaiter`1.GetResult (System.Private.CoreLib  Version=4.0.0.0  Culture=neutral  PublicKeyToken=7cec85d7bea7798e)    at Microsoft.Azure.WebJobs.Host.Executors.FunctionInvoker`2+&lt;InvokeAsync&gt;d__10.MoveNext (Microsoft.Azure.WebJobs.Host  Version=3.0.8.0  Culture=neutral  PublicKeyToken=31bf3856ad364e35Microsoft.Azure.WebJobs.Host  Version=3.0.8.0  Culture=neutral  PublicKeyToken=31bf3856ad364e35: C:\\projects\\azure-webjobs-sdk-rqm4t\\src\\Microsoft.Azure.WebJobs.Host\\Executors\\FunctionInvoker.csMicrosoft.Azure.WebJobs.Host  Version=3.0.8.0  Culture=neutral  PublicKeyToken=31bf3856ad364e35: 52)    at System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw (System.Private.CoreLib  Version=4.0.0.0  Culture=neutral  PublicKeyToken=7cec85d7bea7798e)    at System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess (System.Private.CoreLib  Version=4.0.0.0  Culture=neutral  PublicKeyToken=7cec85d7bea7798e)    at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification (System.Private.CoreLib  Version=4.0.0.0  Culture=neutral  PublicKeyToken=7cec85d7bea7798e)    at System.Runtime.CompilerServices.TaskAwaiter`1.GetResult (System.Private.CoreLib  Version=4.0.0.0  Culture=neutral  PublicKeyToken=7cec85d7bea7798e)    at Microsoft.Azure.WebJobs.Host.Executors.FunctionExecutor+&lt;InvokeAsync&gt;d__27.MoveNext (Microsoft.Azure.WebJobs.Host  Version=3.0.8.0  Culture=neutral  PublicKeyToken=31bf3856ad364e35Microsoft.Azure.WebJobs.Host  Version=3.0.8.0  Culture=neutral  PublicKeyToken=31bf3856ad364e35: C:\\projects\\azure-webjobs-sdk-rqm4t\\src\\Microsoft.Azure.WebJobs.Host\\Executors\\FunctionExecutor.csMicrosoft.Azure.WebJobs.Host  Version=3.0.8.0  Culture=neutral  PublicKeyToken=31bf3856ad364e35: 584)    at System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw (System.Private.CoreLib  Version=4.0.0.0  Culture=neutral  PublicKeyToken=7cec85d7bea7798e)    at System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess (System.Private.CoreLib  Version=4.0.0.0  Culture=neutral  PublicKeyToken=7cec85d7bea7798e)    at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification (System.Private.CoreLib  Version=4.0.0.0  Culture=neutral  PublicKeyToken=7cec85d7bea7798e)    at System.Runtime.CompilerServices.TaskAwaiter.GetResult (System.Private.CoreLib  Version=4.0.0.0  Culture=neutral  PublicKeyToken=7cec85d7bea7798e)    at Microsoft.Azure.WebJobs.Host.Executors.FunctionExecutor+&lt;ExecuteWithWatchersAsync&gt;d__26.MoveNext (Microsoft.Azure.WebJobs.Host  Version=3.0.8.0  Culture=neutral  PublicKeyToken=31bf3856ad364e35Microsoft.Azure.WebJobs.Host  Version=3.0.8.0  Culture=neutral  PublicKeyToken=31bf3856ad364e35: C:\\projects\\azure-webjobs-sdk-rqm4t\\src\\Microsoft.Azure.WebJobs.Host\\Executors\\FunctionExecutor.csMicrosoft.Azure.WebJobs.Host  Version=3.0.8.0  Culture=neutral  PublicKeyToken=31bf3856ad364e35: 531)    at System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw (System.Private.CoreLib  Version=4.0.0.0  Culture=neutral  PublicKeyToken=7cec85d7bea7798e)    at System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess (System.Private.CoreLib  Version=4.0.0.0  Culture=neutral  PublicKeyToken=7cec85d7bea7798e)    at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification (System.Private.CoreLib  Version=4.0.0.0  Culture=neutral  PublicKeyToken=7cec85d7bea7798e)    at System.Runtime.CompilerServices.TaskAwaiter.GetResult (System.Private.CoreLib  Version=4.0.0.0  Culture=neutral  PublicKeyToken=7cec85d7bea7798e)    at Microsoft.Azure.WebJobs.Host.Executors.FunctionExecutor+&lt;ExecuteWithLoggingAsync&gt;d__25.MoveNext (Microsoft.Azure.WebJobs.Host  Version=3.0.8.0  Culture=neutral  PublicKeyToken=31bf3856ad364e35Microsoft.Azure.WebJobs.Host  Version=3.0.8.0  Culture=neutral  PublicKeyToken=31bf3856ad364e35: C:\\projects\\azure-webjobs-sdk-rqm4t\\src\\Microsoft.Azure.WebJobs.Host\\Executors\\FunctionExecutor.csMicrosoft.Azure.WebJobs.Host  Version=3.0.8.0  Culture=neutral  PublicKeyToken=31bf3856ad364e35: 467)    at System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw (System.Private.CoreLib  Version=4.0.0.0  Culture=neutral  PublicKeyToken=7cec85d7bea7798e)    at System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess (System.Private.CoreLib  Version=4.0.0.0  Culture=neutral  PublicKeyToken=7cec85d7bea7798e)    at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification (System.Private.CoreLib  Version=4.0.0.0  Culture=neutral  PublicKeyToken=7cec85d7bea7798e)    at System.Runtime.CompilerServices.TaskAwaiter.GetResult (System.Private.CoreLib  Version=4.0.0.0  Culture=neutral  PublicKeyToken=7cec85d7bea7798e)    at Microsoft.Azure.WebJobs.Host.Executors.FunctionExecutor+&lt;ExecuteWithLoggingAsync&gt;d__19.MoveNext (Microsoft.Azure.WebJobs.Host  Version=3.0.8.0  Culture=neutral  PublicKeyToken=31bf3856ad364e35Microsoft.Azure.WebJobs.Host  Version=3.0.8.0  Culture=neutral  PublicKeyToken=31bf3856ad364e35: C:\\projects\\azure-webjobs-sdk-rqm4t\\src\\Microsoft.Azure.WebJobs.Host\\Executors\\FunctionExecutor.csMicrosoft.Azure.WebJobs.Host  Version=3.0.8.0  Culture=neutral  PublicKeyToken=31bf3856ad364e35: 277)  </code></pre>  <p>We are following this pattern  using an HTTP trigger to call an orchestrator function: <a href=\""https://docs.microsoft.com/en-us/azure/azure-functions/durable/durable-functions-sequence\"" rel=\""nofollow noreferrer\"">https://docs.microsoft.com/en-us/azure/azure-functions/durable/durable-functions-sequence</a></p>  <p>The requests work perfectly and the functions executed as expected when the service is \""hot\"". We only see this error if the HTTP request that calls the orchestrator is the request that triggers the warmup process to bring the service out of the idle state.</p>""",azure-functions
24160209,"Azure Files: System error 64 has occurred <p>I have Azure Files Preview enabled to my Azure account. I have created a new storage account  created a share following the <a href=\http://blogs.msdn.com/b/windowsazurestorage/archive/2014/05/11/introducing-microsoft-azure-file-service.aspx\"" rel=\""nofollow\"">instructions</a>.</p>  <p>Now when I try to map the share to a network drive (just as the aforementioned article says)  I get the following error:</p>  <pre><code>net use z: \\\\mystorageaccount.file.core.windows.net\\share /u:mystorageaccount mystorageaccountkey </code></pre>  <blockquote>   <p>System error 64 has occurred.</p>      <p>The specified network name is no longer available.</p> </blockquote>  <p>What causes this?</p>""",azure-storage
56001645,Read version of project in yaml file from pom.xml in azure-pipelines <p>I have a <code>pom.xml</code> file that includes my project version like this</p>  <pre><code> &lt;version&gt; 1.14.0 &lt;/version&gt; </code></pre>  <p>and I also have a YAML file that autogenerates a GitHub tag when the tests have passed and it's like this </p>  <pre><code>- job: createTag     dependsOn: ifBranchIsMaster     condition: and(succeeded()  eq(variables['Build.SourceBranch']  'refs/heads/master')     steps:       - task: GitHubRelease@0         displayName: ‘Create GitHub Release’         inputs:           gitHubConnection: $(GITHUB_CONNECTION)           repositoryName: $(GITHUB_REPO)           action: create           tag: 1.14.0 </code></pre>  <p>and I want to remove from my YAML file the hard-coded version tag and read it from <code>pom.xml</code> immediately is there any way that can happen I try to minimize the hard-coded version to 1. I want to change it in 1 place and change everywhere.</p>,azure-devops
38562652,"Azure VM (ARM) external port not working <p>I am trying to open port 8080 in a Windows Azure virtual machine. I have a test website listening in that port  and I am able to access it via localhost  so the website is running.</p>  <p>I have also opened the port in the firewall and created an inbound security rule in azure portal for the virtual machine  but the port doesn't seem to be open to the outside world. I have tried accessing it both via the IP address and the DNS with the same results.</p>  <p><a href=\https://i.stack.imgur.com/Lc0VC.jpg\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/Lc0VC.jpg\"" alt=\""enter image description here\""></a> <a href=\""https://i.stack.imgur.com/n9cbM.jpg\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/n9cbM.jpg\"" alt=\""enter image description here\""></a></p>  <p>Is there anything else I should be doing?</p>""",azure-virtual-machine
47324836,"No option for Azure NC/NV VMs? <p>I'm trying to create a Windows 10 Pro VM on Azure using an NC/NV server in the correct regions here: <a href=\https://azure.microsoft.com/en-au/regions/services/\"" rel=\""nofollow noreferrer\"">https://azure.microsoft.com/en-au/regions/services/</a> but don't find the option to select NC or NV even when looking at the correct regions.</p>  <p>Is this a limitation of the free trial?</p>""",azure-virtual-machine
46486378,Sharing VSTS backlog board publicly <p>I am using VSTS work item tracking for personal projects and I want to share my progress with people who do not have access to my VSTS account.</p>  <p>Is it possible to achieve this ? Ideally  I would like to show a read-only backlog board for the project across iterations.</p>,azure-devops
42485120,Fetching RSS Feeds with Azure Functions <p>Is there any documentation for fetching RSS feeds and writing it in database with Azure functions? I want to do it in Javascript but I could not find a good documentation.</p>,azure-functions
49532803,How long does VSTS keep a branch once it is deleted? <p>There is an option to delete the branch and once it is deleted  we can recover it using the search using the exact match.</p>  <p>How long does the branch remain and can be recovered once it is deleted?</p>,azure-devops
25399574,"Accessing Azure Storage Blobs from Silverlight in Firefox / Chrome <p>I'm trying to access Azure Storage blobs (via SAS string) from a Silverlight application. A <code>clientaccesspolicy.xml</code> is present in the <code>$root</code> blob container  allowing Silverlight access.</p>  <p>I've created a sample Silverlight application with just one button. The button executes the following code:</p>  <pre><code>        var request = (HttpWebRequest)WebRequestCreator.ClientHttp.Create(new Uri(\http://[mystoragename].blob.core.windows.net/[mycontainername]/[myfilename]?[sasString]\""));         request.Method = \""GET\"";         request.BeginGetResponse(r =&gt;         {             try             {                 var response = request.EndGetResponse(r);                 using (var s = response.GetResponseStream())                 {                     this.Dispatcher.BeginInvoke(() =&gt; MessageBox.Show(s.Length.ToString()));                 }             }             catch(Exception ex)             {                 this.Dispatcher.BeginInvoke(() =&gt; MessageBox.Show(ex.Message));             }         }  null); </code></pre>  <p>Running this code on Internet Explorer produces the expected result - the size of a blob uploaded to Azure Storage. Unfortunately  the same application  when ran in Firefox or Chrome  produces a \""Security Error\"" with no further indication of what might be wrong.</p>  <p>The SAME issue occurs when I try to download a file from a PUBLIC blob container (same code as above  only different URL). The public blob container also has it's own <code>clientaccesspolicy.xml</code> and <code>crossdomain.xml</code> files (albeit I don't think these are needed). Again - the code works in IE  but fails to function in Firefox / Chrome.</p>  <p>What could be the issue? Where should I even begin looking for one?</p>""",azure-storage
50762528,"Run custom commands on startup on Azure App Service on Linux <p>In the Application settings for an App Service on Linux we can specify Startup File <a href=\https://i.stack.imgur.com/YPKIO.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/YPKIO.png\"" alt=\""enter image description here\""></a></p>  <p>We are deploying a PHP (Drupal) application. Could I along with this app have a bash script that I would run that would mount a file share to the machine? This share would then be used to store all images  documents and other content.</p>""",azure-web-app-service
16604372,Azure - Running an http server on an VM <p>I have created a VM on Windows Azure with Ubuntu 12.04 running on it.</p>  <p>I have two end-points<br> <strong>End-point1</strong><br> public port: 50348<br> private port: 22</p>  <p><strong>End-point2</strong><br> public port: 81<br> private port: 81</p>  <p>Now  I have a simple python HTTP server running on the Virtual Machine  which is listening on port 81.  </p>  <p>When I try to connect to localhost:81 from within the Virtual machine  I am able to connect  so I know that the server is up and running.</p>  <p>Say  the DNS name assigned to my VM be <code>blah-blah.cloudapp.net</code></p>  <p>But  when I try to connect to <code>http://blah-blah.cloudapp.net:81</code> from somewhere outside  I always get a Server Not Found error.</p>  <p>So  how can I connect to my server?</p>,azure-virtual-machine
55121783,"Create and Request Array of Azure parameter function <p>I am trying to create an Array of Azure parameter function  but it's not working for me. For these  I tried below code. </p>  <p><strong>ABCBarCodes Class</strong></p>  <pre><code>using System; using System.Collections.Generic; using System.Linq; using System.Text; using System.Threading.Tasks;  namespace FunctionApp4 {      public class ALCBarCodes     {          public string BarCodeText { get; set; }         public string BarCodeWidth { get; set; }         public string BarCodeHeight { get; set; }         public string BarCodeType { get; set; }         public string BarCodeFont { get; set; }      }  } </code></pre>  <p><strong>Azure Function</strong></p>  <pre><code>using System.Collections.Generic; using System.Net; using System.Net.Http; using Microsoft.Azure.WebJobs; using Microsoft.Azure.WebJobs.Extensions.Http; using Microsoft.Azure.WebJobs.Host;  namespace FunctionApp4 {     public static class Function4     {         [FunctionName(\Function4\"")]         public static HttpResponseMessage Run([HttpTrigger(AuthorizationLevel.Anonymous  \""get\""  \""post\""  Route = \""Function4/{ALCBarCodes}\"")]HttpRequestMessage req  List&lt;ALCBarCodes&gt; list  TraceWriter log)         {             log.Info(\""C# HTTP trigger function processed a request.\"");              // Fetching the name from the path parameter in the request URL             return req.CreateResponse(HttpStatusCode.OK  list);         }     } } </code></pre>  <p>On this case how can I request the URL?</p>  <p>I tried below URL but it's not working.</p>  <p><a href=\""http://localhost:7071/api/Function4/1\"" rel=\""nofollow noreferrer\"">http://localhost:7071/api/Function4/1</a></p>  <p>Any help on this?</p>""",azure-functions
38257112,SAS for CloudBlobDirectory or path within a container <p>Is there a way to generate a SAS token or policy for a virtual path within blob container ?</p>  <p>E.g. I have a blob container called <code>mycontainer</code>. Inside it have the following blobs</p>  <p><code>FolderA/PathA/file.pdf</code></p>  <p><code>FolderA/PathA/file2.mpg</code></p>  <p><code>FolderA/PathC/file.doc</code></p>  <p><code>FolderB/PathA/file.pdf</code></p>  <p>I want to generate SAS token such that the client/application can perform operations inside of <code>FolderA</code> <strong>only</strong> within container <code>mycontainer</code></p>  <p>Is that possible ?</p>  <p><strong>Alternate approach is either to</strong></p>  <p>a) Create a list of SAS tokens for each file (i.e. blockblob) within <code>FolderA</code></p>  <p>b) Re-design such that <code>FolderA</code> is a blob container instead</p>,azure-storage
46208636,"Azure recovery services not allowing me to select VM <p>I am trying to migrate a VM in Southeast Asia to Western Europe</p>  <p>After defining the source in the Enable Replication Section  I am not able to select the virtual machine. </p>  <p>Source Details</p>  <p><a href=\https://i.stack.imgur.com/KCIpP.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/KCIpP.png\"" alt=\""enter image description here\""></a></p>  <p>Select Virtual Machine section shows the VM grayed out.  <a href=\""https://i.stack.imgur.com/JcjJM.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/JcjJM.png\"" alt=\""enter image description here\""></a></p>  <p>My account has Owner  Site Recovery Contributor  Site Recovery Operator  Site Recovery Reader and Virtual Machine Contributor roles. </p>""",azure-virtual-machine
55023824,"Azure Function failing to initialise Serilog Sink when using appsettings.json <p>I've created a simple Azure Function with the intension of using Serililog for logging to Azure Blob Storage.</p>  <p>When using inline configuration for the Serilog sink  that works perfectly fine  the sink is created and Serilog happily wirtes to Blob storage.</p>  <p><strong>This works:</strong></p>  <pre><code>Log.Logger = new LoggerConfiguration()    .WriteTo.AzureBlobStorage(            \STORAGEACCOUNT CONNECTION STRING\""  // &lt;-- inline config            LogEventLevel.Information             null             \""{yyyy}/{MM}/{dd}/MyLogFile.txt\"")    .CreateLogger(); </code></pre>  <p><a href=\""https://i.stack.imgur.com/kIeDI.png\"" rel=\""noreferrer\""><img src=\""https://i.stack.imgur.com/kIeDI.png\"" alt=\""enter image description here\""></a></p>  <p>The problem is that I would like to configure this all via <code>appsettings.json</code>  but when I try this (both locally running in the emulator &amp; in the cloud)  it fails to bind the sink settings  and as a result its failing to log to to the Blog storage.</p>  <p>If I debug  I can see that the config values <em>are being loaded as expected into the <code>configuration</code> object</em>  but they are <em>not</em> being applied to the logging configuration.</p>  <p><strong>This doesnt work:</strong></p>  <pre><code>Log.Logger = new LoggerConfiguration()    .ReadFrom.Configuration(configuration)    .CreateLogger(); </code></pre>  <p><code>appsettings.json</code> in this snippet: <div class=\""snippet\"" data-lang=\""js\"" data-hide=\""true\"" data-console=\""false\"" data-babel=\""false\"">  <div class=\""snippet-code snippet-currently-hidden\"">  <pre class=\""snippet-code-js lang-js prettyprint-override\""><code>{      \""Serilog\"": {      \""MinimumLevel\"": {        \""Default\"": \""Information\""         \""Override\"": {          \""Microsoft\"": \""Information\""        }      }       \""WriteTo\"": [{          \""Name\"": \""AzureBlobStorage\""           \""Args\"": {            \""connectionString\"": \"" --- REPLACE WITH STORAGEACCOUNT BLOB CONNECTION STRING --- \""             \""formatter\"": \""Serilog.Formatting.Compact.RenderedCompactJsonFormatter  Serilog.Formatting.Compact\""             \""storageFileName\"": \""{yyyy}/{MM}/{dd}/MyLogFile.txt\""             \""retainedFileCountLimit\"": 31          }        }        ]       \""Properties\"": {        \""Application\"": \""int-test-logging\""         \""Environment\"": \""int\""      }    }    }</code></pre>  </div>  </div>  </p>  <p><a href=\""https://i.stack.imgur.com/sGslC.png\"" rel=\""noreferrer\""><img src=\""https://i.stack.imgur.com/sGslC.png\"" alt=\""enter image description here\""></a></p>  <p>I'm not sure what I'm doing incorrectly but any help would be appreciated. The following github repo contains code to implement the above (both approaches)  and reproduces this behaviour. <a href=\""https://github.com/oneiltomlinson/AzureFunctionsLogging\"" rel=\""noreferrer\"">https://github.com/oneiltomlinson/AzureFunctionsLogging</a></p>""",azure-functions
49321529,Use Azure DNS if local DNS not available <p>I have an Azure VM which is a DNS Server. If this server goes down  is it possible for the other VM's in the same Vnet to then switch over to Azure DNS?</p>,azure-virtual-machine
55435222,How to deploy aspnet core web api and aspnet webapi on single app service <p>I have an aspnet core web api project which I can deploy through publish wizard to Azure App service. But later on I developed on normal aspnet web api (MVC 5 on .Net framework 4.6) because of the certain classes not available in dotnet core.</p>  <p>Now I want to deploy both them on same App service instance. Can I do that? will aspnet publish overwrite earlier aspnetcore publish when done to the same App service?</p>,azure-web-app-service
57264556,"Prevent quotes from disappearing in JSON in between Azure DevOps tasks <p>I'm looking to enable static site hosting on a storage account  created by an Azure Resource Manager (ARM) template in in an Azure DevOps pipeline  but fail to get <code>jq</code> to parse the ARM output variable.</p>  <p><strong>Step 1: YML of Azure DevOps task that creates the resource group</strong></p>  <pre><code>- task: AzureResourceGroupDeployment@2   inputs:     azureSubscription: 'AzureSubscription'     action: 'Create Or Update Resource Group'     resourceGroupName: 'vue-demo-app'     location: 'West Europe'     templateLocation: 'Linked artifact'     csmFile: '$(Build.ArtifactStagingDirectory)/infra/infra.json'     csmParametersFile: '$(Build.ArtifactStagingDirectory)/infra/env-arm-params-default.json'     deploymentMode: 'Incremental'     deploymentOutputs: 'appstoragename'   displayName: 'Create or update resource group' </code></pre>  <p>Logs show as follows: </p>  <pre><code>##[debug]set appstoragename={\appstoragename\"":{\""type\"":\""String\"" \""value\"":\""demoappstaticstore\""}} </code></pre>  <p>So at this point  there is a <em>valid</em> JSON value returned to Azure DevOps. So far  so good.</p>  <p><strong>Step 2: Azure DevOps task that tries to enable static website hosting on the storage account</strong></p>  <pre><code>- task: AzureCLI@1   inputs:     azureSubscription: 'AzureSubscription'     scriptLocation: 'inlineScript'     inlineScript: |       echo \""Enabling static website hosting on the storage account\""       SA_NAME=$(appstoragename) | jq -r '.appstoragename'       echo \""Script input argument is: $(appstoragename)\""       echo \""Parsed storage account name is: $SA_NAME\""       az storage blob service-properties update --account-name $SA_NAME --static-website --index-document index.html </code></pre>  <p>Logs show as follows:</p>  <pre><code>Enabling static website hosting on the storage account Script input argument is: {appstoragename:{type:String value:jvwdemoappstaticstore}} Parsed storage account name is:  </code></pre>  <p>IMHO the problem is that I'm 'losing' the quotes in <code>$(appstoragename)</code> and I need them because I think <code>jq</code> does not like the fact that they're not there.</p>  <p>How can I prevent those quotes from disappearing?</p>""",azure-devops
41723595,"Azure Functions: How does the life-cycle work? <p>I'm running into some problems with Azure Functions where a Function App which deployed properly and worked great  now claims to be missing dependencies (NodeJS) and errors out the next day when testing. If I understood the life-cycle of how Azure Functions work  I think I could troubleshoot and fix this easier.</p>  <p>Can anyone explain the life-cycle or point me to the documentation I can't seem to find?</p>  <p>For example  I'm using continuous deployment. With this method it appears that there is a default deploy.cmd that is used to:</p>  <ol> <li>Git clone/pull the repository to D:\\Site\\repository</li> <li>Run npm install on the repository.</li> <li>Kudosync (whatever this means) these files to D:\\Site\\wwwroot</li> </ol>  <p>This all works beautifully. What I'm wondering is what happens next.</p>  <p>e.g. The function sits unused for a period of time and therefore I assume its spun down and taken \out-of-order\""?</p>  <p>When its access again  it needs to spin something up again.</p>  <ul> <li>Does it go through the deployment process again (Doesn't seem like it).</li> <li>What/where/how does it restore files back to the instance?</li> <li>Is this the same process which is used when scaling the app?</li> </ul>""",azure-functions
55345713,Azure WebJob In its own AppService or in an AppService with Api <p>I have an AppService which hosts an Api. I also have two WebJobs. My question is should I host the WebJobs in the same AppService as the Api or would it be better to host each WebJob in their own AppService.</p>,azure-web-app-service
41396479,Unable to import work item type definition: Microsoft.TeamFoundation.WorkItemTracking.Server.ProvisioningImportEventsCallback <p>I have been searching the web for a solution to this issue with no luck.  I have a team project in Visual Studio Team Services (VSTS) using an inherited copy of the scrum process template so that I can make modifications to the individual work item templates.</p>  <p>Any time I attempted to import a modified WIT I received a very vague error which appears to simply quote the Microsoft.TeamFoundation.WorkItemTracking.Server.ProvisioningImportEventsCallback namespace or class.</p>  <p>In an attempt to keep this simple I am simply exporting the product backlog item WIT and then immediately re-importing it to ensure that the error is not related to a change I have made. I have also renamed what I am importing in case there was an issue overwriting the existing WIT and that made no difference.  I have been able to do this with TFS 2010 with Visual Studio 2013 but in both VS 2013 and 2015 with VSTS I am not able to import any WIT modifications. </p>,azure-devops
39814618,"Azure resource manager windows VM accessing endpoints from internet not working <p>I have installed mirthconnect on windows virtual machine in azure resource manager. I am able to access admin console with <a href=\http://localhost:8080\"" rel=\""nofollow noreferrer\"">http://localhost:8080</a> .But same is not accessible from internet. I have added endpoints in network security.<a href=\""https://i.stack.imgur.com/GDBq8.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/GDBq8.png\"" alt=\""Below is NSG rules for the winodws VM\""></a></p>  <p>Is there any other configuration I am missing here ? I am able to RDP to the machine . I have tried with source as * and destination as * also . But still no luck.</p>  <p>I am not able to telnet also with the VM public IP and  the given ports.</p>""",azure-virtual-machine
45055307,"How to get a connection string environment variable in an Azure function running locally? <p>I am trying to setup an Azure Function to run locally on my development environment. I wish to connect to a MongoDb database instance.</p>  <p>In my <code>local.settings.json</code> file I have added:</p>  <pre><code>\ConnectionStrings\"": {     \""DB_CONNECT_STRING\"": \""mongodb://localhost:27017/MyDatabase\"" } </code></pre>  <p>In my function I then have:</p>  <pre><code>module.exports = function (context  myTimer) {     console.log(process.env.DB_CONNECT_STRING);     context.done(); }; </code></pre>  <p><code>process.env.DB_CONNECT_STRING</code> is undefined.</p>  <p>I assume I need to add some kind of prefix to the environment variable  but I can't find this documented anywhere. How do I specify a connection string and reference it in the function code?</p>""",azure-functions
57417220,"Weird behavior of Azure Functions DI for ILogger <p>I've two identical Azure Functions V2 projects on my local. Both project have same configurations  nuget library versions  SDK  code  startup.cs  CLI and Function Runtime versions. Basically they are identical. However  logs written to ILogger instance in the function appears on CLI as expected but  the other one is missing the message on CLI!</p>  <p><strong>Functions.csproj for both projects;</strong></p>  <pre class=\lang-cs prettyprint-override\""><code>&lt;Project Sdk=\""Microsoft.NET.Sdk\""&gt;   &lt;PropertyGroup&gt;     &lt;TargetFramework&gt;netcoreapp2.2&lt;/TargetFramework&gt;     &lt;AzureFunctionsVersion&gt;v2&lt;/AzureFunctionsVersion&gt;   &lt;/PropertyGroup&gt;   &lt;ItemGroup&gt;     &lt;PackageReference Include=\""Microsoft.Azure.Functions.Extensions\"" Version=\""1.0.0\"" /&gt;     &lt;PackageReference Include=\""Microsoft.Azure.ServiceBus\"" Version=\""3.4.0\"" /&gt;     &lt;PackageReference Include=\""Microsoft.Azure.WebJobs.Extensions.ServiceBus\"" Version=\""3.0.6\"" /&gt;     &lt;PackageReference Include=\""Microsoft.NET.Sdk.Functions\"" Version=\""1.0.29\"" /&gt;   &lt;/ItemGroup&gt;    &lt;ItemGroup&gt;     &lt;None Update=\""host.json\""&gt;       &lt;CopyToOutputDirectory&gt;PreserveNewest&lt;/CopyToOutputDirectory&gt;     &lt;/None&gt;     &lt;None Update=\""local.settings.json\""&gt;       &lt;CopyToOutputDirectory&gt;PreserveNewest&lt;/CopyToOutputDirectory&gt;       &lt;CopyToPublishDirectory&gt;Never&lt;/CopyToPublishDirectory&gt;     &lt;/None&gt;   &lt;/ItemGroup&gt; &lt;/Project&gt;  </code></pre>  <p><strong>Startup.cs ;</strong></p>  <pre class=\""lang-cs prettyprint-override\""><code>[assembly: FunctionsStartup(typeof(FunctionAppLogTest.Startup))] namespace FunctionAppLogTest {     public class Startup : IWebJobsStartup     {         public void Configure(IWebJobsBuilder builder)         {             ConfigureServices(builder.Services).BuildServiceProvider(true);         }          private IServiceCollection ConfigureServices(IServiceCollection services)         {             return services;         }     } } </code></pre>  <p><strong>Function.cs ;</strong></p>  <pre class=\""lang-cs prettyprint-override\""><code>    public class Function1     {         private readonly ILogger&lt;Function1&gt; _logger;          public Function1(ILogger&lt;Function1&gt; logger)         {             _logger = logger;         }          [FunctionName(\""Function1\"")]         public async Task Run([ServiceBusTrigger(\""topic-name\""  \""sb-name\""  Connection = \""AzureServiceBus\"")]string message)         {             _logger.LogInformation($\"" HELLO! : {message}\"");         }     }  </code></pre>  <p><strong>CLI and project configurations;</strong></p>  <p><strong>\""HELLO!\"" is being written to the CLI as you see in the logs at the bottom !!</strong> <a href=\""https://i.stack.imgur.com/ZNojL.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/ZNojL.png\"" alt=\""enter image description here\""></a></p>  <p><strong>But the other project is missing the HELLO log as you see below;</strong></p>  <p><a href=\""https://i.stack.imgur.com/lzeqA.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/lzeqA.png\"" alt=\""enter image description here\""></a></p>  <p><strong>I'm just curries about a bug that creates race condition for DI that breaks the dependencies..</strong></p>""",azure-functions
51926562,Azure functions fail when creating a blank/empty project in an existing solution <p>I upgrade to Visual Studio 2017 15.8.1 and am having issues creating an Azure function project. The project I am trying to create is through the template wizard  just a new V1 empty function project. </p>  <p>I receive the following error  which seems to be .net core related.</p>  <blockquote>   <p>NETSDK1004    Assets file '\obj\project.assets.json' not   found. Run a NuGet package restore to generate this   file. FunctionApp1    C:\Program Files\dotnet\sdk\2.1.400\Sdks\Microsoft.NET.Sdk\targets\Microsoft.PackageDependencyResolution.targets    198   Run a NuGet package restore to generate this file.</p> </blockquote>  <p>But my project file states: </p>  <pre><code>  &lt;PropertyGroup&gt;     &lt;TargetFramework&gt;net461&lt;/TargetFramework&gt;     &lt;AzureFunctionsVersion&gt;v1&lt;/AzureFunctionsVersion&gt;   &lt;/PropertyGroup&gt; </code></pre>  <p>Just to be clear  I do want a 4.6.1 project  not a core one.</p>  <p>I have looked at other answers to this issue but none resolve it. Package reinstall  dotnet restore etc. I get more errors if I select a different template (e.g. HTTP Trigger)</p>  <p>Any ideas?</p>  <p>I thought I had a solution to reboot  then open %temp% and delete all the temporary files in that folder. Then reboot again for good measure and it worked from a blank / empty project  but as soon as I try include this in another solution or move the project it fails. </p>,azure-functions
48611702,"How to include tags in NuGet package using CLI only <p>I want to add <code>Tags</code> for a nuget package. I do NOT want to use a separate <code>.nuspec</code> file (maintenance)   I'm only using the csproj for packing.</p>  <p>I've tried setting it using <code>nuget pack -Properties Tags=demo</code> but that doesn't seem to work..?</p>  <p>I'm trying to solve a bigger problem to create some traceability using the commit id from the build in the tags? (on VSTS using <em>Build.SourceVersion</em>)</p>  <p>References:</p>  <ul> <li><a href=\https://docs.microsoft.com/nl-nl/nuget/tools/cli-ref-pack\"" rel=\""nofollow noreferrer\"">NuGet CLI ref.</a></li> <li><a href=\""https://github.com/NuGet/Home/wiki/Adding-nuget-pack-as-a-msbuild-target\"" rel=\""nofollow noreferrer\"">Adding nuget pack as a msbuild target</a></li> <li><a href=\""https://docs.microsoft.com/en-us/vsts/build-release/concepts/definitions/build/variables?tabs=batch\"" rel=\""nofollow noreferrer\"">VSTS Variables</a></li> </ul>""",azure-devops
48518621,"Azure Web App - 504 Gateway error while connecting Azure SQL DB over https <p>I am using the following environment for my web app:</p>  <p>Web App Hosted on Azure  using Azure Verizon Standard CDN with HTTPS enabled. DNS on Azure pointing to endpoint. SQL Database on Azure (basically  the entire app  DB and environment are on Azure).</p>  <p>I am getting <code>504 Gateway Timeout</code> error for this link:</p>  <p><code>https://www.kunshtech.com/myMagicStringBlogAccount/Login</code></p>  <p>My guess is that it's an issue with the HTTPS request.</p>  <p>I connected the same link on localhost using visual studio and using the Azure database and that is working fine. I also used HTTPS on localhost which is also working fine.</p>  <p>I am using this connection string:</p>  <p><code>connectionString=\Server=tcp:mydbname.database.windows.net 1433;Initial Catalog={mycatalogname};Persist Security Info=False;User ID={username};Password={mypassword};MultipleActiveResultSets=False;Encrypt=True;TrustServerCertificate=False;Connection Timeout=300;\"" providerName=\""System.Data.SqlClient\"" /&gt;</code></p>  <p>I also have set the firewall rules for Azure SQL DB to accept the IP from the app server.</p>""",azure-web-app-service
56786096,"Retry failed deployment takes 5-10 to start actual deployment(hangs !!) <p>I have TFS 2015   with Release Management Server 2015(In Release) on a different server  when I connect to RM Server from RM client to retry failed deployment  it takes around 5-10 minutes(It basically hangs and) to trigger the actual deployment. </p>  <p>How can I find whats happening in 5-10 mins ? Can you suggest me where to find logs ?</p>  <p><a href=\https://i.stack.imgur.com/MrPbi.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/MrPbi.png\"" alt=\""Retry failed deployment hsngs\""></a></p>""",azure-devops
50324924,Object of type 'Submission#0+Payload[]' cannot be converted to type 'Submission#0+Payload[]' - C# Azure AppService <p>I have a C# AppService running on Azure with the following code snippet:</p>  <pre><code>public static async Task&lt;string&gt; Run(Payload[] req  TraceWriter log) {     ... }  public class Payload {     public object registration { get; set; }     public object _event { get; set; } } </code></pre>  <p>When I try and 'Save and Run'  I get the following error log:</p>  <blockquote>   <p>Submission#0+Payload[]' cannot be converted to type 'Submission#0+Payload[]'</p> </blockquote>  <p>If I remove the '[]' from the parameter  click 'Save and Run'  then put the array back in &amp; save  it works but a huge nuisance. I'm just wondering if someone can spot something that I've done wrong  or should be doing better to fix this?</p>,azure-web-app-service
46293600,"I would like to make deployment to Azure web app from a private git repository <p>I pull the source code from a private git repository into my computer and then I push it with local git repository into the web app on Azure cloud. I want to pull the source code directly into the Azure cloud without any middle copy process. I added Azure web app outbound IP addresses into the white list of my private repository and then I saved its url as an external deployment option of Azure web app.</p>  <p>But I can't run the following comments with Kudu console it gives permission error:</p>  <pre><code>git config --global user.name \&lt;Name Surname&gt;\"" git config --global user.email &lt;email&gt; export GIT_SSL_NO_VERIFY=1; git clone https://&lt;url_of_private_git_repository&gt; </code></pre>""",azure-web-app-service
44936793,"Azure Linux VM Template - Parameter osProfile not allowed but without I can't connect <p>I created a VM manually in Azure then used the automation script to generate a template to use from Visual Studio for a deployment however when I try to deploy it everything else works bar the VM which complains about the osProfile parameter  If I remove the osProfile section the deployment works but creates a VM I have no way to login to  all the examples I find say the osProfile I have should be fine so I'm a bit stuck</p>  <p>The template attached only works when the osProfile is commented out and then you can't login to the VM</p>  <p>Appreciate any suggestions as I've tried all sorts and am stumped now!</p>  <p>This is the error when the osProfile is included:</p>  <pre><code>08:58:16 - Template deployment returned the following errors: 08:58:16 - 08:58:15 - Resource Microsoft.Compute/virtualMachines 'TheFaireyDevSolr' failed with message '{ 08:58:16 -   \error\"": { 08:58:16 -     \""code\"": \""InvalidParameter\""  08:58:16 -     \""target\"": \""osProfile\""  08:58:16 -     \""message\"": \""Parameter 'osProfile' is not allowed.\"" 08:58:16 -   } 08:58:16 - }' </code></pre>  <p>I updated the Password parameter to something more complex that I know meets the min reqs.</p>  <p>Below is the template json</p>  <pre><code>{   \""$schema\"": \""https://schema.management.azure.com/schemas/2015-01-01/deploymentTemplate.json#\""    \""contentVersion\"": \""1.0.0.0\""    \""parameters\"": {     \""adminUsername\"": {       \""type\"": \""string\""        \""minLength\"": 1        \""metadata\"": {         \""description\"": \""User name for the Virtual Machine.\""       }     }      \""adminPassword\"": {       \""type\"": \""securestring\""        \""metadata\"": {         \""description\"": \""Password for the Virtual Machine.\""       }     }      \""disks_TheFaireyDevSolrDataDisk_name\"": {       \""type\"": \""string\""     }      \""disks_TheFaireyDevSolrOsDisk_name\"": {       \""type\"": \""string\""     }      \""virtualMachines_TheFaireyDevSolr_name\"": {       \""type\"": \""string\""     }      \""networkInterfaces_thefaireydevsolr_ni_name\"": {       \""type\"": \""string\""     }      \""networkSecurityGroups_TheFaireyDevSolr_nsg_name\"": {       \""type\"": \""string\""     }      \""publicIPAddresses_TheFaireyDevSolr_ip_name\"": {       \""type\"": \""string\""     }      \""virtualNetworks_TheFaireyDev_vnet_name\"": {       \""type\"": \""string\""     }      \""storageAccounts_thefaireydevmainstorage_name\"": {       \""type\"": \""string\""     }      \""extensions_Microsoft.Insights.VMDiagnosticsSettings_name\"": {       \""type\"": \""string\""     }   }    \""resources\"": [     {       \""type\"": \""Microsoft.Compute/disks\""        \""name\"": \""[parameters('disks_TheFaireyDevSolrDataDisk_name')]\""        \""apiVersion\"": \""2016-04-30-preview\""        \""location\"": \""[resourceGroup().location]\""        \""scale\"": null        \""properties\"": {         \""accountType\"": \""Standard_LRS\""          \""creationData\"": {           \""createOption\"": \""Empty\""         }          \""diskSizeGB\"": 32       }        \""dependsOn\"": []     }      {       \""type\"": \""Microsoft.Compute/disks\""        \""name\"": \""[parameters('disks_TheFaireyDevSolrOsDisk_name')]\""        \""apiVersion\"": \""2016-04-30-preview\""        \""location\"": \""[resourceGroup().location]\""        \""scale\"": null        \""properties\"": {         \""accountType\"": \""Standard_LRS\""          \""osType\"": \""Linux\""          \""creationData\"": {           \""createOption\"": \""FromImage\""            \""imageReference\"": {             \""id\"": \""/Subscriptions/&lt;YOUR SUBSCRIPTION ID&gt;/Providers/Microsoft.Compute/Locations/uksouth/Publishers/Canonical/ArtifactTypes/VMImage/Offers/UbuntuServer/Skus/17.04/Versions/latest\""           }         }          \""diskSizeGB\"": 30       }        \""dependsOn\"": []     }      {       \""type\"": \""Microsoft.Compute/virtualMachines\""        \""name\"": \""[parameters('virtualMachines_TheFaireyDevSolr_name')]\""        \""apiVersion\"": \""2016-04-30-preview\""        \""location\"": \""[resourceGroup().location]\""        \""scale\"": null        \""properties\"": {         \""hardwareProfile\"": {           \""vmSize\"": \""Standard_A1_v2\""         }          \""storageProfile\"": {           \""osDisk\"": {             \""osType\"": \""Linux\""              \""name\"": \""[parameters('disks_TheFaireyDevSolrOSDisk_name')]\""              \""createOption\"": \""Attach\""              \""caching\"": \""ReadWrite\""              \""managedDisk\"": {               \""storageAccountType\"": \""Standard_LRS\""                \""id\"": \""[resourceId('Microsoft.Compute/disks'  parameters('disks_TheFaireyDevSolrOsDisk_name'))]\""             }              \""diskSizeGB\"": 30           }            \""dataDisks\"": [             {               \""lun\"": 0                \""name\"": \""[concat(parameters('virtualMachines_TheFaireyDevSolr_name') 'DataDisk')]\""                \""createOption\"": \""Attach\""                \""caching\"": \""None\""                \""managedDisk\"": {                 \""storageAccountType\"": \""Standard_LRS\""                  \""id\"": \""[resourceId('Microsoft.Compute/disks'  parameters('disks_TheFaireyDevSolrDataDisk_name'))]\""               }                \""diskSizeGB\"": 32             }           ]         }          \""osProfile\"": {           \""computerName\"": \""[parameters('virtualMachines_TheFaireyDevSolr_name')]\""            \""adminUsername\"": \""[parameters('adminUsername')]\""            \""adminPassword\"": \""[parameters('adminPassword')]\""         }          \""networkProfile\"": {           \""networkInterfaces\"": [             {               \""id\"": \""[resourceId('Microsoft.Network/networkInterfaces'  parameters('networkInterfaces_thefaireydevsolr_ni_name'))]\""             }           ]         }          \""diagnosticsProfile\"": {           \""bootDiagnostics\"": {             \""enabled\"": true              \""storageUri\"": \""[concat('https'  '://'  parameters('storageAccounts_thefaireydevmainstorage_name')  '.blob.core.windows.net'  '/')]\""           }         }       }        \""dependsOn\"": [         \""[resourceId('Microsoft.Compute/disks'  parameters('disks_TheFaireyDevSolrOsDisk_name'))]\""          \""[resourceId('Microsoft.Compute/disks'  parameters('disks_TheFaireyDevSolrDataDisk_name'))]\""          \""[resourceId('Microsoft.Network/networkInterfaces'  parameters('networkInterfaces_thefaireydevsolr_ni_name'))]\""          \""[resourceId('Microsoft.Storage/storageAccounts'  parameters('storageAccounts_thefaireydevmainstorage_name'))]\""       ]     }      {       \""type\"": \""Microsoft.Network/networkInterfaces\""        \""name\"": \""[parameters('networkInterfaces_thefaireydevsolr_ni_name')]\""        \""apiVersion\"": \""2017-03-01\""        \""location\"": \""[resourceGroup().location]\""        \""scale\"": null        \""properties\"": {         \""ipConfigurations\"": [           {             \""name\"": \""ipconfig1\""              \""properties\"": {               \""privateIPAddress\"": \""10.0.0.4\""                \""privateIPAllocationMethod\"": \""Dynamic\""                \""publicIPAddress\"": {                 \""id\"": \""[resourceId('Microsoft.Network/publicIPAddresses'  parameters('publicIPAddresses_TheFaireyDevSolr_ip_name'))]\""               }                \""subnet\"": {                 \""id\"": \""[concat(resourceId('Microsoft.Network/virtualNetworks'  parameters('virtualNetworks_TheFaireyDev_vnet_name'))  '/subnets/default')]\""               }             }           }         ]          \""dnsSettings\"": {           \""dnsServers\"": []         }          \""enableIPForwarding\"": false          \""networkSecurityGroup\"": {           \""id\"": \""[resourceId('Microsoft.Network/networkSecurityGroups'  parameters('networkSecurityGroups_TheFaireyDevSolr_nsg_name'))]\""         }       }        \""dependsOn\"": [         \""[resourceId('Microsoft.Network/publicIPAddresses'  parameters('publicIPAddresses_TheFaireyDevSolr_ip_name'))]\""          \""[resourceId('Microsoft.Network/virtualNetworks'  parameters('virtualNetworks_TheFaireyDev_vnet_name'))]\""          \""[resourceId('Microsoft.Network/networkSecurityGroups'  parameters('networkSecurityGroups_TheFaireyDevSolr_nsg_name'))]\""       ]     }      {       \""type\"": \""Microsoft.Network/networkSecurityGroups\""        \""name\"": \""[parameters('networkSecurityGroups_TheFaireyDevSolr_nsg_name')]\""        \""apiVersion\"": \""2017-03-01\""        \""location\"": \""[resourceGroup().location]\""        \""scale\"": null        \""properties\"": {         \""securityRules\"": [           {             \""name\"": \""default-allow-ssh\""              \""properties\"": {               \""protocol\"": \""Tcp\""                \""sourcePortRange\"": \""*\""                \""destinationPortRange\"": \""22\""                \""sourceAddressPrefix\"": \""*\""                \""destinationAddressPrefix\"": \""*\""                \""access\"": \""Allow\""                \""priority\"": 1000                \""direction\"": \""Inbound\""             }           }         ]       }        \""dependsOn\"": []     }      {       \""type\"": \""Microsoft.Network/publicIPAddresses\""        \""name\"": \""[parameters('publicIPAddresses_TheFaireyDevSolr_ip_name')]\""        \""apiVersion\"": \""2017-03-01\""        \""location\"": \""[resourceGroup().location]\""        \""scale\"": null        \""properties\"": {         \""publicIPAllocationMethod\"": \""Dynamic\""          \""idleTimeoutInMinutes\"": 4       }        \""dependsOn\"": []     }      {       \""type\"": \""Microsoft.Network/virtualNetworks\""        \""name\"": \""[parameters('virtualNetworks_TheFaireyDev_vnet_name')]\""        \""apiVersion\"": \""2017-03-01\""        \""location\"": \""[resourceGroup().location]\""        \""scale\"": null        \""properties\"": {         \""addressSpace\"": {           \""addressPrefixes\"": [             \""10.0.0.0/24\""           ]         }          \""subnets\"": [           {             \""name\"": \""default\""              \""properties\"": {               \""addressPrefix\"": \""10.0.0.0/24\""             }           }         ]          \""virtualNetworkPeerings\"": []       }        \""dependsOn\"": []     }      {       \""type\"": \""Microsoft.Storage/storageAccounts\""        \""sku\"": {         \""name\"": \""Standard_LRS\""          \""tier\"": \""Standard\""       }        \""kind\"": \""Storage\""        \""name\"": \""[parameters('storageAccounts_thefaireydevmainstorage_name')]\""        \""apiVersion\"": \""2016-01-01\""        \""location\"": \""[resourceGroup().location]\""        \""tags\"": {}        \""scale\"": null        \""properties\"": {}        \""dependsOn\"": []     }      //{     //  \""type\"": \""Microsoft.Compute/virtualMachines/extensions\""      //  \""name\"": \""[parameters('extensions_Microsoft.Insights.VMDiagnosticsSettings_name')]\""      //  \""apiVersion\"": \""2016-04-30-preview\""      //  \""location\"": \""[resourceGroup().location]\""      //  \""scale\"": null      //  \""properties\"": {     //    \""publisher\"": \""Microsoft.OSTCExtensions\""      //    \""type\"": \""LinuxDiagnostic\""      //    \""typeHandlerVersion\"": \""2.3\""      //    \""autoUpgradeMinorVersion\"": true      //    \""settings\"": {     //      \""xmlCfg\"": \""<WadCfg><DiagnosticMonitorConfiguration overallQuotaInMB="4096"><DiagnosticInfrastructureLogs scheduledTransferPeriod="PT1M" scheduledTransferLogLevelFilter="Warning"/><PerformanceCounters scheduledTransferPeriod="PT1M"><PerformanceCounterConfiguration counterSpecifier="\Memory\AvailableMemory" sampleRate="PT15S" unit="Bytes"><annotation displayName="Memory available" locale="en-us"/></PerformanceCounterConfiguration><PerformanceCounterConfiguration counterSpecifier="\Memory\PercentAvailableMemory" sampleRate="PT15S" unit="Percent"><annotation displayName="Mem. percent available" locale="en-us"/></PerformanceCounterConfiguration><PerformanceCounterConfiguration counterSpecifier="\Memory\UsedMemory" sampleRate="PT15S" unit="Bytes"><annotation displayName="Memory used" locale="en-us"/></PerformanceCounterConfiguration><PerformanceCounterConfiguration counterSpecifier="\Memory\PercentUsedMemory" sampleRate="PT15S" unit="Percent"><annotation displayName="Memory percentage" locale="en-us"/></PerformanceCounterConfiguration><PerformanceCounterConfiguration counterSpecifier="\Memory\PercentUsedByCache" sampleRate="PT15S" unit="Percent"><annotation displayName="Mem. used by cache" locale="en-us"/></PerformanceCounterConfiguration><PerformanceCounterConfiguration counterSpecifier="\Memory\PagesPerSec" sampleRate="PT15S" unit="CountPerSecond"><annotation displayName="Pages" locale="en-us"/></PerformanceCounterConfiguration><PerformanceCounterConfiguration counterSpecifier="\Memory\PagesReadPerSec" sampleRate="PT15S" unit="CountPerSecond"><annotation displayName="Page reads" locale="en-us"/></PerformanceCounterConfiguration><PerformanceCounterConfiguration counterSpecifier="\Memory\PagesWrittenPerSec" sampleRate="PT15S" unit="CountPerSecond"><annotation displayName="Page writes" locale="en-us"/></PerformanceCounterConfiguration><PerformanceCounterConfiguration counterSpecifier="\Memory\AvailableSwap" sampleRate="PT15S" unit="Bytes"><annotation displayName="Swap available" locale="en-us"/></PerformanceCounterConfiguration><PerformanceCounterConfiguration counterSpecifier="\Memory\PercentAvailableSwap" sampleRate="PT15S" unit="Percent"><annotation displayName="Swap percent available" locale="en-us"/></PerformanceCounterConfiguration><PerformanceCounterConfiguration counterSpecifier="\Memory\UsedSwap" sampleRate="PT15S" unit="Bytes"><annotation displayName="Swap used" locale="en-us"/></PerformanceCounterConfiguration><PerformanceCounterConfiguration counterSpecifier="\Memory\PercentUsedSwap" sampleRate="PT15S" unit="Percent"><annotation displayName="Swap percent used" locale="en-us"/></PerformanceCounterConfiguration><PerformanceCounterConfiguration counterSpecifier="\Processor\PercentIdleTime" sampleRate="PT15S" unit="Percent"><annotation displayName="CPU idle time" locale="en-us"/></PerformanceCounterConfiguration><PerformanceCounterConfiguration counterSpecifier="\Processor\PercentUserTime" sampleRate="PT15S" unit="Percent"><annotation displayName="CPU user time" locale="en-us"/></PerformanceCounterConfiguration><PerformanceCounterConfiguration counterSpecifier="\Processor\PercentNiceTime" sampleRate="PT15S" unit="Percent"><annotation displayName="CPU nice time" locale="en-us"/></PerformanceCounterConfiguration><PerformanceCounterConfiguration counterSpecifier="\Processor\PercentPrivilegedTime" sampleRate="PT15S" unit="Percent"><annotation displayName="CPU privileged time" locale="en-us"/></PerformanceCounterConfiguration><PerformanceCounterConfiguration counterSpecifier="\Processor\PercentInterruptTime" sampleRate="PT15S" unit="Percent"><annotation displayName="CPU interrupt time" locale="en-us"/></PerformanceCounterConfiguration><PerformanceCounterConfiguration counterSpecifier="\Processor\PercentDPCTime" sampleRate="PT15S" unit="Percent"><annotation displayName="CPU DPC time" locale="en-us"/></PerformanceCounterConfiguration><PerformanceCounterConfiguration counterSpecifier="\Processor\PercentProcessorTime" sampleRate="PT15S" unit="Percent"><annotation displayName="CPU percentage guest OS" locale="en-us"/></PerformanceCounterConfiguration><PerformanceCounterConfiguration counterSpecifier="\Processor\PercentIOWaitTime" sampleRate="PT15S" unit="Percent"><annotation displayName="CPU IO wait time" locale="en-us"/></PerformanceCounterConfiguration><PerformanceCounterConfiguration counterSpecifier="\PhysicalDisk\BytesPerSecond" sampleRate="PT15S" unit="BytesPerSecond"><annotation displayName="Disk total bytes" locale="en-us"/></PerformanceCounterConfiguration><PerformanceCounterConfiguration counterSpecifier="\PhysicalDisk\ReadBytesPerSecond" sampleRate="PT15S" unit="BytesPerSecond"><annotation displayName="Disk read guest OS" locale="en-us"/></PerformanceCounterConfiguration><PerformanceCounterConfiguration counterSpecifier="\PhysicalDisk\WriteBytesPerSecond" sampleRate="PT15S" unit="BytesPerSecond"><annotation displayName="Disk write guest OS" locale="en-us"/></PerformanceCounterConfiguration><PerformanceCounterConfiguration counterSpecifier="\PhysicalDisk\TransfersPerSecond" sampleRate="PT15S" unit="CountPerSecond"><annotation displayName="Disk transfers" locale="en-us"/></PerformanceCounterConfiguration><PerformanceCounterConfiguration counterSpecifier="\PhysicalDisk\ReadsPerSecond" sampleRate="PT15S" unit="CountPerSecond"><annotation displayName="Disk reads" locale="en-us"/></PerformanceCounterConfiguration><PerformanceCounterConfiguration counterSpecifier="\PhysicalDisk\WritesPerSecond" sampleRate="PT15S" unit="CountPerSecond"><annotation displayName="Disk writes" locale="en-us"/></PerformanceCounterConfiguration><PerformanceCounterConfiguration counterSpecifier="\PhysicalDisk\AverageReadTime" sampleRate="PT15S" unit="Seconds"><annotation displayName="Disk read time" locale="en-us"/></PerformanceCounterConfiguration><PerformanceCounterConfiguration counterSpecifier="\PhysicalDisk\AverageWriteTime" sampleRate="PT15S" unit="Seconds"><annotation displayName="Disk write time" locale="en-us"/></PerformanceCounterConfiguration><PerformanceCounterConfiguration counterSpecifier="\PhysicalDisk\AverageTransferTime" sampleRate="PT15S" unit="Seconds"><annotation displayName="Disk transfer time" locale="en-us"/></PerformanceCounterConfiguration><PerformanceCounterConfiguration counterSpecifier="\PhysicalDisk\AverageDiskQueueLength" sampleRate="PT15S" unit="Count"><annotation displayName="Disk queue length" locale="en-us"/></PerformanceCounterConfiguration><PerformanceCounterConfiguration counterSpecifier="\NetworkInterface\BytesTransmitted" sampleRate="PT15S" unit="Bytes"><annotation displayName="Network out guest OS" locale="en-us"/></PerformanceCounterConfiguration><PerformanceCounterConfiguration counterSpecifier="\NetworkInterface\BytesReceived" sampleRate="PT15S" unit="Bytes"><annotation displayName="Network in guest OS" locale="en-us"/></PerformanceCounterConfiguration><PerformanceCounterConfiguration counterSpecifier="\NetworkInterface\PacketsTransmitted" sampleRate="PT15S" unit="Count"><annotation displayName="Packets sent" locale="en-us"/></PerformanceCounterConfiguration><PerformanceCounterConfiguration counterSpecifier="\NetworkInterface\PacketsReceived" sampleRate="PT15S" unit="Count"><annotation displayName="Packets received" locale="en-us"/></PerformanceCounterConfiguration><PerformanceCounterConfiguration counterSpecifier="\NetworkInterface\BytesTotal" sampleRate="PT15S" unit="Bytes"><annotation displayName="Network total bytes" locale="en-us"/></PerformanceCounterConfiguration><PerformanceCounterConfiguration counterSpecifier="\NetworkInterface\TotalRxErrors" sampleRate="PT15S" unit="Count"><annotation displayName="Packets received errors" locale="en-us"/></PerformanceCounterConfiguration><PerformanceCounterConfiguration counterSpecifier="\NetworkInterface\TotalTxErrors" sampleRate="PT15S" unit="Count"><annotation displayName="Packets sent errors" locale="en-us"/></PerformanceCounterConfiguration><PerformanceCounterConfiguration counterSpecifier="\NetworkInterface\TotalCollisions" sampleRate="PT15S" unit="Count"><annotation displayName="Network collisions" locale="en-us"/></PerformanceCounterConfiguration></PerformanceCounters><Metrics resourceId="/subscriptions/492368ea-a062-40d4-b6b5-e54db9a91d06/resourceGroups/AxiomDev/providers/Microsoft.Compute/virtualMachines/AxiomDevSolr"><MetricAggregation scheduledTransferPeriod="PT1H"/><MetricAggregation scheduledTransferPeriod="PT1M"/></Metrics></DiagnosticMonitorConfiguration></WadCfg>\""     //    }      //    \""protectedSettings\"": {}     //  }      //  \""dependsOn\"": [     //    \""[resourceId('Microsoft.Compute/virtualMachines'  parameters('virtualMachines_TheFaireyDevSolr_name'))]\""     //  ]     //}   ]    \""variables\"": {} } </code></pre>  <p>and the parameters json</p>  <pre><code>{   \""$schema\"": \""https://schema.management.azure.com/schemas/2015-01-01/deploymentParameters.json#\""    \""contentVersion\"": \""1.0.0.0\""    \""parameters\"": {     \""adminUsername\"": {       \""value\"": \""thefairey\""     }      \""disks_TheFaireyDevSolrDataDisk_name\"": {       \""value\"": \""TheFaireyDevSolrDataDisk\""     }      \""disks_TheFaireyDevSolrOsDisk_name\"": {       \""value\"": \""TheFaireyDevSolrOsDisk\""     }      \""virtualMachines_TheFaireyDevSolr_name\"": {       \""value\"": \""TheFaireyDevSolr\""     }      \""networkInterfaces_thefaireydevsolr_ni_name\"": {       \""value\"": \""TheFaireyDevSolr-ni\""     }      \""networkSecurityGroups_TheFaireyDevSolr_nsg_name\"": {       \""value\"": \""TheFaireyDevSolr-nsg\""     }      \""publicIPAddresses_TheFaireyDevSolr_ip_name\"": {       \""value\"": \""TheFaireyDevSolr-ip\""     }      \""virtualNetworks_TheFaireyDev_vnet_name\"": {       \""value\"": \""TheFaireyDev-vnet\""     }      \""storageAccounts_thefaireydevmainstorage_name\"": {       \""value\"": \""thefaireydevmainstorage\""     }      \""extensions_Microsoft.Insights.VMDiagnosticsSettings_name\"": {       \""value\"": \""TheFaireyDevSolr/Microsoft.Insights.VMDiagnosticsSettings\""     }   } } </code></pre>  <p><strong>UPDATE</strong></p>  <p>I started with a plain Ubuntu VM template from VS and started adding stuff and the problem regarding the osProfile starts happening as soon as I try to add a Managed Disk as the OS disk  I removed that but tried with a managed disk for the DataDisk and got the error \""Addition of a managed disk to a VM with blob based disks is not supported\""</p>  <p>Not sure if it helps but I believe the issue may be related to having a Managed Disk as the OS disk. Will continue to research and experiment!</p>""",azure-virtual-machine
41173482,"AzureRM Web App - How to control the slot setting with Powershell <p>I would like to set the connection strings and app settings  of my Azure web app using powershell. And I would like those settings to stick with the slot  and not with the app when it is swapped. </p>  <p>The code for app settings looks like this and it works:</p>  <pre><code>$PropertiesObject = @{\SMTPUser\""=\""myuser\""; \""SMTPPassword\""=\""secretpwd\"";} $webAppName = \""mywebapp\"" $slotName = \""demo\"" $resourceGroupName = \""myResourceGroup\""  New-AzureRmResource -PropertyObject $PropertiesObject -ResourceGroupName $resourceGroupName -ResourceType Microsoft.Web/sites/slots/config -ResourceName $webAppName/$slotName/appsettings -ApiVersion 2015-08-01 -Force   $stickSlotConfigObject = @{\""connectionStringNames\""=@(); \""appSettingNames\"" = @(\""SMTPUserName\"" \""SMTPPassword\"");}  $result = Set-AzureRmResource -PropertyObject $stickSlotConfigObject -ResourceGroupName $resourceGroupName -ResourceType Microsoft.Web/sites/config -ResourceName $webAppName/slotConfigNames -ApiVersion 2015-08-01 -Force </code></pre>  <p>This works. When I go to the slot blade of the web app in the Azure portal  the \""Slot Setting\"" check box is checked as I want it to be. </p>  <p>I'm struggling with how to set the <strong>connection strings</strong> to also have the \""slot setting\"" box checked. I tried the following   </p>  <pre><code>$PropertiesObject =  @{    AzureWebJobsStorage = @{       Type = \""Custom\"";      Value = \""somestring\""   };   Common = @{        Type = \""SQLAzure\"";      Value = \""somedatabasestring\""    }; };  $webAppName = \""mywebapp\"" $slotName = \""demo\"" $resourceGroupName = \""myResourceGroup\""  New-AzureRmResource -PropertyObject $PropertiesObject -ResourceGroupName $resourceGroupName -ResourceType Microsoft.Web/sites/slots/config -ResourceName $webAppName/$slotName/appsettings -ApiVersion 2015-08-01 -Force  $stickSlotConfigObject = @{\""appSettingNames\""=@();\""connectionStringNames\""=@(\""AzureWebJobsStorage\"" \""Common\""); }  $result = Set-AzureRmResource -PropertyObject $stickSlotConfigObject -ResourceGroupName $resourceGroupName -ResourceType Microsoft.Web/sites/config -ResourceName $webAppName/appsettings -ApiVersion 2015-08-01 -Force </code></pre>  <p>This did not work. I got the following error:</p>  <pre><code>New-AzureRmResource : {\""Code\"":\""BadRequest\"" \""Message\"":\""The parameter properties has an invalid value.\"" \""Target\"":null \""Details\"":[{\""Message\"":\""The parameter properties has an invalid value.\""} {\""Code\"":\""BadRequest\""} {\""ErrorEntity\"":{\""Code\"":\""BadRequest\"" \""Message\"":\""The parameter properties has an invalid value.\"" \""ExtendedCode\"":\""51008\"" \""MessageTemplate\"":\""The parameter {0} has an invalid value.\"" \""Parameters\"":[\""properties\""] \""InnerErrors\"":null}}] \""Innererror\"":null} </code></pre>  <p>I tried another tweak (which I forgot) and it said that the $PropertiesObject object was not in the right format. </p>  <p>How do I code it in Powershell so that I can check the slot setting check box of a web app connection string (or configure it as \""sticky\""? </p>""",azure-web-app-service
14972861,VM migration on Azure <p>I wish to run a web server on Azure. My concern is whether Azure migrates virtual instances (VMs) between physical servers for performance optimization purposes and if so does it provide some kind of guarantees on the performance hit that migration incurs?</p>,azure-virtual-machine
56774041,Angular build cannot find module with relative path (on azure dev ops) <p>I have a problem getting a mid-sized Angular 7 project to build on Azure Dev Ops Pipelines. So I created a minimal project to recreate the issue.</p>  <p>Using Angular CLI (7.2.4) I created a new project</p>  <pre><code>ng new minimal-app </code></pre>  <p>It builds locally and on Azure just fine. I edited app.component.ts to use my UserModel  lines 2  11 &amp; 14</p>  <pre><code>import {Component} from '@angular/core'; import {UserModel} from '../Models/User.model';  @Component({   selector: 'app-root'    templateUrl: './app.component.html'    styleUrls: ['./app.component.css'] }) export class AppComponent {   title = 'minimal-app';   user = new UserModel();    constructor() {     this.user.name = 'Jo';   }  } </code></pre>  <p>the User.model.ts file contains</p>  <pre><code>export class UserModel {   id: number;   name: string; } </code></pre>  <p>This also compiles on local and Azure just fine. The issue comes when trying to add a nested model  see Action.model.ts</p>  <pre><code>export class ActionModel {   id: number;   datetime: string; } </code></pre>  <p>and changing the UserModel</p>  <pre><code>import {ActionModel} from './Action.Model';  export class UserModel {   id: number;   name: string;   actions: ActionModel[]; } </code></pre>  <p>This works locally but on Azure Dev Ops I get</p>  <pre><code>ERROR in src/Models/User.model.ts(1 27): error TS2307: Cannot find module './Action.Model'.  ##[error]Bash exited with code '1' </code></pre>  <p>I've not changed any Angular config files  they are all default for new project. The azure pipelines yml is</p>  <pre><code># Node.js with Angular # Build a Node.js project that uses Angular. # Add steps that analyze code  save build artifacts  deploy  and more: # https://docs.microsoft.com/azure/devops/pipelines/languages/javascript  trigger: - master  pool:   vmImage: 'ubuntu-latest'  steps: - task: NodeTool@0   inputs:     versionSpec: '10.x'   displayName: 'Install Node.js'  - script: |     npm install -g @angular/cli     npm install     ng build --prod   displayName: 'npm install and build' </code></pre>,azure-devops
25978647,"\303 See other\"" in HTTP HEAD response <p>I am building  an ASP.NET Azure Web Application (Web Role) which controls access to files stored in Azure Blob Storage. On  a GET request  my HttpHandler authenticates the user and creates a Shared Access Signature for this specific  file and user with a short time frame (say 30 mins). The client is a media player which checks for updated media files using HEAD  and if the Last-modified header differs  it will make a GET request. Therefore I do not want to create a SAS url but rather return LAst-modified  Etag and Content-length headers in response to the HEAD request. Is this bad practice? In case the file is up to date  there is no need to download the file again and thus no need to create a SAS url.</p>  <p>Example request: </p>  <pre><code>GET /testblob.zip Host: myblobapp.azurewebsites.net Authorization: Zm9v:YmFy </code></pre>  <p>Response: </p>  <pre><code>HTTP/1.1 303 See other Location: https://myblobstorage.blob.core.windows.net/blobcontainer/testblob.zip?SHARED_ACCESS_SIGNATURE_DATA </code></pre>  <p>Any thoughts?</p>""",azure-storage
54914953,"RangeError: Invalid typed array length error during Deploy Azure App Service in Azure DevOps <p>I'm getting the following when performing Deploy Azure App Service in Azure DevOps.</p>  <pre><code>2019-02-27T18:51:57.5018577Z ##[section]Starting: Deploy Azure App Service 2019-02-27T18:51:57.5028370Z ============================================================================== 2019-02-27T18:51:57.5028503Z Task : Azure App Service Deploy 2019-02-27T18:51:57.5029162Z Description : Update Azure App Services on Windows  Web App on Linux with built-in images or Docker containers  ASP.NET  .NET Core  PHP  Python or Node.js based Web applications  Function Apps  Mobile Apps  API applications  Web Jobs using Web Deploy / Kudu REST APIs 2019-02-27T18:51:57.5029281Z Version : 3.4.21 2019-02-27T18:51:57.5029357Z Author : Microsoft Corporation 2019-02-27T18:51:57.5029433Z Help : [More information](https://aka.ms/azurermwebdeployreadme) 2019-02-27T18:51:57.5029534Z ============================================================================== 2019-02-27T18:51:58.2314716Z Got connection details for Azure App Service:'myproject' 2019-02-27T18:52:01.5712562Z Updating App Service Application settings. Data: {\MSDEPLOY_RENAME_LOCKED_FILES\"":\""1\""} 2019-02-27T18:52:20.6292666Z Updated App Service Application settings and Kudu Application settings. 2019-02-27T18:52:20.6292953Z Rename locked files enabled for App Service. 2019-02-27T18:52:20.6811253Z ##[error]RangeError: Invalid typed array length 2019-02-27T18:52:23.2141473Z Successfully updated deployment History at https://myproject.scm.azurewebsites.net/api/deployments/31551293542097 2019-02-27T18:52:23.2230607Z ##[section]Finishing: Deploy Azure App Service </code></pre>  <p>I don't know what script / config is controlling this and so I have no idea what array this error is referring to.</p>  <p>My build pipeline completed successfully.</p>""",azure-devops
50516516,"Getting 500 Error on Home page when publishing ASP.Net Core Web App with class library to Azure <p>I've been trying to deploy my web application to Azure but I get a 500 Error on the first page. I am assuming this is because of an issue with the model that I am referencing on the first page  which is being referenced to a class library in my solution.  Here's how the project looks</p>  <p><a href=\https://i.stack.imgur.com/vHd5g.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/vHd5g.png\"" alt=\""Here&#39;s how the project looks.\""></a></p>  <p>I've had some issues with referencing the class library before but I have been able to remedy those issues and build both projects successfully so far. And the project runs just fine in IISExpress. But when I try to deploy it to Azure  I get a 500 Error on my Home page. Here's the code for it:</p>  <pre><code>@using LNCLibrary.Models.HomeViewModel @model HomeViewModel @{     ViewData[\""Title\""] = \""Home Page\""; } @inject SignInManager&lt;ApplicationUser&gt; SignInManager @inject UserManager&lt;ApplicationUser&gt; UserManager &lt;!-- Au&lt;!-- Author: W3layouts Author URL: http://w3layouts.com License: Creative Commons Attribution 3.0 Unported License URL: http://creativecommons.org/licenses/by/3.0/ --&gt; &lt;!DOCTYPE HTML&gt; &lt;html&gt; &lt;head&gt;     &lt;title&gt;New Shop a E-Commerce Online Shopping Category Flat Bootstrap Responsive Website Template | Home :: w3layouts&lt;/title&gt;     &lt;!--css--&gt;     &lt;link href=\""css/bootstrap.css\"" rel=\""stylesheet\"" type=\""text/css\"" media=\""all\"" /&gt;     &lt;link href=\""css/style.css\"" rel=\""stylesheet\"" type=\""text/css\"" media=\""all\"" /&gt;     &lt;link href=\""css/font-awesome.css\"" rel=\""stylesheet\""&gt;     &lt;!--css--&gt;     &lt;meta name=\""viewport\"" content=\""width=device-width  initial-scale=1\""&gt;     &lt;meta http-equiv=\""Content-Type\"" content=\""text/html; charset=utf-8\"" /&gt;     &lt;meta name=\""keywords\"" content=\""New Shop Responsive web template  Bootstrap Web Templates  Flat Web Templates  Android Compatible web template  Smartphone Compatible web template  free webdesigns for Nokia  Samsung  LG  SonyEricsson  Motorola web design\"" /&gt;     &lt;script type=\""application/x-javascript\""&gt; addEventListener(\""load\""  function() { setTimeout(hideURLbar  0); }  false); function hideURLbar(){ window.scrollTo(0 1); } &lt;/script&gt;     &lt;script src=\""js/jquery.min.js\""&gt;&lt;/script&gt;     &lt;link href='//fonts.googleapis.com/css?family=Cagliostro' rel='stylesheet' type='text/css'&gt;     &lt;link href='//fonts.googleapis.com/css?family=Open+Sans:400 800italic 800 700italic 700 600italic 600 400italic 300italic 300' rel='stylesheet' type='text/css'&gt;     &lt;!--search jQuery--&gt;     &lt;script src=\""js/main.js\""&gt;&lt;/script&gt;     &lt;!--search jQuery--&gt;     &lt;script src=\""js/responsiveslides.min.js\""&gt;&lt;/script&gt;     &lt;script&gt;         $(function () {             $(\""#slider\"").responsiveSlides({                 auto: true                  nav: true                  speed: 500                  namespace: \""callbacks\""                  pager: true              });         });     &lt;/script&gt;     &lt;!--mycart--&gt;     &lt;script type=\""text/javascript\"" src=\""js/bootstrap-3.1.1.min.js\""&gt;&lt;/script&gt;     &lt;!-- cart --&gt;     &lt;script src=\""js/simpleCart.min.js\""&gt;&lt;/script&gt;     &lt;!-- cart --&gt;     &lt;!--start-rate--&gt;     &lt;script src=\""js/jstarbox.js\""&gt;&lt;/script&gt;     &lt;link rel=\""stylesheet\"" href=\""css/jstarbox.css\"" type=\""text/css\"" media=\""screen\"" charset=\""utf-8\"" /&gt;     &lt;script type=\""text/javascript\""&gt;         jQuery(function () {             jQuery('.starbox').each(function () {                 var starbox = jQuery(this);                 starbox.starbox({                     average: starbox.attr('data-start-value')                      changeable: starbox.hasClass('unchangeable') ? false : starbox.hasClass('clickonce') ? 'once' : true                      ghosting: starbox.hasClass('ghosting')                      autoUpdateAverage: starbox.hasClass('autoupdate')                      buttons: starbox.hasClass('smooth') ? false : starbox.attr('data-button-count') || 5                      stars: starbox.attr('data-star-count') || 5                 }).bind('starbox-value-changed'  function (event  value) {                     if (starbox.hasClass('random')) {                         var val = Math.random();                         starbox.next().text(' ' + val);                         return val;                     }                 })             });         });     &lt;/script&gt;     &lt;!--//End-rate--&gt; &lt;/head&gt; &lt;body&gt;     &lt;!--header--&gt;     &lt;div class=\""header\""&gt;         &lt;div class=\""header-top\""&gt;             &lt;div class=\""container\""&gt;                 &lt;div class=\""top-left\""&gt;                     &lt;a href=\""#\""&gt; Help  &lt;i class=\""glyphicon glyphicon-phone\"" aria-hidden=\""true\""&gt;&lt;/i&gt; +0123-456-789&lt;/a&gt;                     &lt;a asp-controller=\""Admin\"" asp-action=\""Index\""&gt;Administration&lt;/a&gt;                 &lt;/div&gt;                 &lt;div class=\""top-right\"" style=\""padding-right:1em;\""&gt;                     &lt;ul&gt;                         @await Html.PartialAsync(\""_LoginPartial\"")                     &lt;/ul&gt;                 &lt;/div&gt;                 &lt;div class=\""clearfix\""&gt;&lt;/div&gt;             &lt;/div&gt;         &lt;/div&gt;         &lt;div class=\""heder-bottom\""&gt;             &lt;div class=\""container\""&gt;                 &lt;div class=\""logo-nav\""&gt;                     &lt;div class=\""logo-nav-left\""&gt;                         &lt;h1&gt;&lt;a href=\""index.html\""&gt;New Shop &lt;span&gt;Shop anywhere&lt;/span&gt;&lt;/a&gt;&lt;/h1&gt;                     &lt;/div&gt;                     &lt;div class=\""logo-nav-left1\""&gt;                         &lt;nav class=\""navbar navbar-default\""&gt;                             &lt;!-- Brand and toggle get grouped for better mobile display --&gt;                             &lt;div class=\""navbar-header nav_2\""&gt;                                 &lt;button type=\""button\"" class=\""navbar-toggle collapsed navbar-toggle1\"" data-toggle=\""collapse\"" data-target=\""#bs-megadropdown-tabs\""&gt;                                     &lt;span class=\""sr-only\""&gt;Toggle navigation&lt;/span&gt;                                     &lt;span class=\""icon-bar\""&gt;&lt;/span&gt;                                     &lt;span class=\""icon-bar\""&gt;&lt;/span&gt;                                     &lt;span class=\""icon-bar\""&gt;&lt;/span&gt;                                 &lt;/button&gt;                             &lt;/div&gt;                             &lt;div class=\""collapse navbar-collapse\"" id=\""bs-megadropdown-tabs\""&gt;                                 &lt;ul class=\""nav navbar-nav\""&gt;                                     &lt;li class=\""active\""&gt;&lt;a href=\""index.html\"" class=\""act\""&gt;Home&lt;/a&gt;&lt;/li&gt;                                     &lt;!-- Mega Menu --&gt;                                     &lt;li class=\""dropdown\""&gt;                                         &lt;a href=\""#\"" class=\""dropdown-toggle\"" data-toggle=\""dropdown\""&gt;Women&lt;b class=\""caret\""&gt;&lt;/b&gt;&lt;/a&gt;                                         &lt;ul class=\""dropdown-menu multi-column columns-3\""&gt;                                             &lt;div class=\""row\""&gt;                                                 &lt;div class=\""col-sm-3  multi-gd-img\""&gt;                                                     &lt;ul class=\""multi-column-dropdown\""&gt;                                                          &lt;li&gt;&lt;a href=\""products.html\""&gt;Clothing&lt;/a&gt;&lt;/li&gt;                                                         &lt;li&gt;&lt;a href=\""products.html\""&gt;Wallets&lt;/a&gt;&lt;/li&gt;                                                         &lt;li&gt;&lt;a href=\""products.html\""&gt;Shoes&lt;/a&gt;&lt;/li&gt;                                                         &lt;li&gt;&lt;a href=\""products.html\""&gt;Watches&lt;/a&gt;&lt;/li&gt;                                                         &lt;li&gt;&lt;a href=\""products.html\""&gt; Underwear &lt;/a&gt;&lt;/li&gt;                                                         &lt;li&gt;&lt;a href=\""products.html\""&gt;Accessories&lt;/a&gt;&lt;/li&gt;                                                     &lt;/ul&gt;                                                 &lt;/div&gt;                                                 &lt;div class=\""col-sm-3  multi-gd-img\""&gt;                                                     &lt;ul class=\""multi-column-dropdown\""&gt;                                                         &lt;h6&gt;Submenu2&lt;/h6&gt;                                                         &lt;li&gt;&lt;a href=\""products.html\""&gt;Sunglasses&lt;/a&gt;&lt;/li&gt;                                                         &lt;li&gt;&lt;a href=\""products.html\""&gt;Wallets Bags&lt;/a&gt;&lt;/li&gt;                                                         &lt;li&gt;&lt;a href=\""products.html\""&gt;Footwear&lt;/a&gt;&lt;/li&gt;                                                         &lt;li&gt;&lt;a href=\""products.html\""&gt;Watches&lt;/a&gt;&lt;/li&gt;                                                         &lt;li&gt;&lt;a href=\""products.html\""&gt;Accessories&lt;/a&gt;&lt;/li&gt;                                                         &lt;li&gt;&lt;a href=\""products.html\""&gt;Jewellery&lt;/a&gt;&lt;/li&gt;                                                     &lt;/ul&gt;                                                 &lt;/div&gt;                                                 &lt;div class=\""col-sm-3  multi-gd-img\""&gt;                                                     &lt;a href=\""products.html\""&gt;&lt;img src=\""images/woo.jpg\"" alt=\"" \"" /&gt;&lt;/a&gt;                                                 &lt;/div&gt;                                                 &lt;div class=\""col-sm-3  multi-gd-img\""&gt;                                                     &lt;a href=\""products.html\""&gt;&lt;img src=\""images/woo1.jpg\"" alt=\"" \"" /&gt;&lt;/a&gt;                                                 &lt;/div&gt;                                                 &lt;div class=\""clearfix\""&gt;&lt;/div&gt;                                             &lt;/div&gt;                                         &lt;/ul&gt;                                     &lt;/li&gt;                                     &lt;li class=\""dropdown\""&gt;                                         &lt;a href=\""#\"" class=\""dropdown-toggle\"" data-toggle=\""dropdown\""&gt;Men &lt;b class=\""caret\""&gt;&lt;/b&gt;&lt;/a&gt;                                         &lt;ul class=\""dropdown-menu multi-column columns-3\""&gt;                                             &lt;div class=\""row\""&gt;                                                 &lt;div class=\""col-sm-3  multi-gd-img\""&gt;                                                     &lt;ul class=\""multi-column-dropdown\""&gt;                                                          &lt;li&gt;&lt;a href=\""products.html\""&gt;Clothing&lt;/a&gt;&lt;/li&gt;                                                         &lt;li&gt;&lt;a href=\""products.html\""&gt;Wallets&lt;/a&gt;&lt;/li&gt;                                                         &lt;li&gt;&lt;a href=\""products.html\""&gt;Shoes&lt;/a&gt;&lt;/li&gt;                                                         &lt;li&gt;&lt;a href=\""products.html\""&gt;Watches&lt;/a&gt;&lt;/li&gt;                                                         &lt;li&gt;&lt;a href=\""products.html\""&gt; Underwear &lt;/a&gt;&lt;/li&gt;                                                         &lt;li&gt;&lt;a href=\""products.html\""&gt;Accessories&lt;/a&gt;&lt;/li&gt;                                                     &lt;/ul&gt;                                                 &lt;/div&gt;                                                 &lt;div class=\""col-sm-3  multi-gd-img\""&gt;                                                     &lt;ul class=\""multi-column-dropdown\""&gt;                                                          &lt;li&gt;&lt;a href=\""products.html\""&gt;Sunglasses&lt;/a&gt;&lt;/li&gt;                                                         &lt;li&gt;&lt;a href=\""products.html\""&gt;Wallets Bags&lt;/a&gt;&lt;/li&gt;                                                         &lt;li&gt;&lt;a href=\""products.html\""&gt;Footwear&lt;/a&gt;&lt;/li&gt;                                                         &lt;li&gt;&lt;a href=\""products.html\""&gt;Watches&lt;/a&gt;&lt;/li&gt;                                                         &lt;li&gt;&lt;a href=\""products.html\""&gt;Accessories&lt;/a&gt;&lt;/li&gt;                                                         &lt;li&gt;&lt;a href=\""products.html\""&gt;Jewellery&lt;/a&gt;&lt;/li&gt;                                                     &lt;/ul&gt;                                                 &lt;/div&gt;                                                 &lt;div class=\""col-sm-3  multi-gd-img\""&gt;                                                     &lt;a href=\""products1.html\""&gt;&lt;img src=\""images/woo3.jpg\"" alt=\"" \"" /&gt;&lt;/a&gt;                                                 &lt;/div&gt;                                                 &lt;div class=\""col-sm-3  multi-gd-img\""&gt;                                                     &lt;a href=\""products1.html\""&gt;&lt;img src=\""images/woo4.jpg\"" alt=\"" \"" /&gt;&lt;/a&gt;                                                 &lt;/div&gt;                                                 &lt;div class=\""clearfix\""&gt;&lt;/div&gt;                                             &lt;/div&gt;                                         &lt;/ul&gt;                                     &lt;/li&gt;                                     &lt;li&gt;&lt;a href=\""codes.html\""&gt;Short Codes&lt;/a&gt;&lt;/li&gt;                                     &lt;li&gt;&lt;a href=\""mail.html\""&gt;Mail Us&lt;/a&gt;&lt;/li&gt;                                 &lt;/ul&gt;                             &lt;/div&gt;                         &lt;/nav&gt;                     &lt;/div&gt;                     @*&lt;div class=\""logo-nav-right\""&gt;                             &lt;ul class=\""cd-header-buttons\""&gt;                                 &lt;li&gt;&lt;a class=\""cd-search-trigger\"" href=\""#cd-search\""&gt; &lt;span&gt;&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;                             &lt;/ul&gt;  cd-header-buttons                             &lt;div id=\""cd-search\"" class=\""cd-search\""&gt;                                 &lt;form action=\""#\"" method=\""post\""&gt;                                     &lt;input name=\""Search\"" type=\""search\"" placeholder=\""Search...\""&gt;                                 &lt;/form&gt;                             &lt;/div&gt;                         &lt;/div&gt;*@                     @*&lt;div class=\""header-right2\""&gt;                             &lt;div class=\""cart box_1\""&gt;                                 &lt;a href=\""checkout.html\""&gt;                                     &lt;h3&gt;                                         &lt;div class=\""total\""&gt;                                             &lt;span class=\""simpleCart_total\""&gt;&lt;/span&gt; (&lt;span id=\""simpleCart_quantity\"" class=\""simpleCart_quantity\""&gt;&lt;/span&gt; items)                                         &lt;/div&gt;                                         &lt;img src=\""images/bag.png\"" alt=\""\"" /&gt;                                     &lt;/h3&gt;                                 &lt;/a&gt;                                 &lt;p&gt;&lt;a href=\""javascript:;\"" class=\""simpleCart_empty\""&gt;Empty Cart&lt;/a&gt;&lt;/p&gt;                                 &lt;div class=\""clearfix\""&gt; &lt;/div&gt;                             &lt;/div&gt;                         &lt;/div&gt;*@                     &lt;div class=\""clearfix\""&gt; &lt;/div&gt;                 &lt;/div&gt;             &lt;/div&gt;         &lt;/div&gt;     &lt;/div&gt;     &lt;!--header--&gt;     &lt;!--banner--&gt;     &lt;div class=\""banner-w3\""&gt;         &lt;div class=\""demo-1\""&gt;             &lt;div id=\""example1\"" class=\""core-slider core-slider__carousel example_1\""&gt;                 &lt;div class=\""core-slider_viewport\""&gt;                     &lt;div class=\""core-slider_list\""&gt;                         &lt;div class=\""core-slider_item\""&gt;                             &lt;img src=\""images/b1.jpg\"" class=\""img-responsive\"" alt=\""\""&gt;                         &lt;/div&gt;                         &lt;div class=\""core-slider_item\""&gt;                             &lt;img src=\""images/b2.jpg\"" class=\""img-responsive\"" alt=\""\""&gt;                         &lt;/div&gt;                         &lt;div class=\""core-slider_item\""&gt;                             &lt;img src=\""images/b3.jpg\"" class=\""img-responsive\"" alt=\""\""&gt;                         &lt;/div&gt;                         &lt;div class=\""core-slider_item\""&gt;                             &lt;img src=\""images/b4.jpg\"" class=\""img-responsive\"" alt=\""\""&gt;                         &lt;/div&gt;                     &lt;/div&gt;                 &lt;/div&gt;                 &lt;div class=\""core-slider_nav\""&gt;                     &lt;div class=\""core-slider_arrow core-slider_arrow__right\""&gt;&lt;/div&gt;                     &lt;div class=\""core-slider_arrow core-slider_arrow__left\""&gt;&lt;/div&gt;                 &lt;/div&gt;                 &lt;div class=\""core-slider_control-nav\""&gt;&lt;/div&gt;             &lt;/div&gt;         &lt;/div&gt;         &lt;link href=\""css/coreSlider.css\"" rel=\""stylesheet\"" type=\""text/css\""&gt;         &lt;script src=\""js/coreSlider.js\""&gt;&lt;/script&gt;         &lt;script&gt;             $('#example1').coreSlider({                 pauseOnHover: false                  interval: 3000                  controlNavEnabled: true             });          &lt;/script&gt;      &lt;/div&gt;     &lt;!--banner--&gt;     &lt;!--content--&gt;     &lt;div class=\""content\""&gt;         &lt;!--banner-bottom--&gt;         &lt;div class=\""ban-bottom-w3l\""&gt;             &lt;div class=\""container\""&gt;                 &lt;div class=\""col-md-6 ban-bottom\""&gt;                     &lt;div class=\""ban-top\""&gt;                         &lt;img src=\""images/p1.jpg\"" class=\""img-responsive\"" alt=\""\"" /&gt;                         &lt;div class=\""ban-text\""&gt;                             &lt;h4&gt;Men’s Clothing&lt;/h4&gt;                         &lt;/div&gt;                         &lt;div class=\""ban-text2 hvr-sweep-to-top\""&gt;                             &lt;h4&gt;50% &lt;span&gt;Off/-&lt;/span&gt;&lt;/h4&gt;                         &lt;/div&gt;                     &lt;/div&gt;                 &lt;/div&gt;                 &lt;div class=\""col-md-6 ban-bottom3\""&gt;                     &lt;div class=\""ban-top\""&gt;                         &lt;img src=\""images/p2.jpg\"" class=\""img-responsive\"" alt=\""\"" /&gt;                         &lt;div class=\""ban-text1\""&gt;                             &lt;h4&gt;Women's Clothing&lt;/h4&gt;                         &lt;/div&gt;                     &lt;/div&gt;                     &lt;div class=\""ban-img\""&gt;                         &lt;div class=\"" ban-bottom1\""&gt;                             &lt;div class=\""ban-top\""&gt;                                 &lt;img src=\""images/p3.jpg\"" class=\""img-responsive\"" alt=\""\"" /&gt;                                 &lt;div class=\""ban-text1\""&gt;                                     &lt;h4&gt;T - Shirt&lt;/h4&gt;                                 &lt;/div&gt;                             &lt;/div&gt;                         &lt;/div&gt;                         &lt;div class=\""ban-bottom2\""&gt;                             &lt;div class=\""ban-top\""&gt;                                 &lt;img src=\""images/p4.jpg\"" class=\""img-responsive\"" alt=\""\"" /&gt;                                 &lt;div class=\""ban-text1\""&gt;                                     &lt;h4&gt;Hand Bag&lt;/h4&gt;                                 &lt;/div&gt;                             &lt;/div&gt;                         &lt;/div&gt;                         &lt;div class=\""clearfix\""&gt;&lt;/div&gt;                     &lt;/div&gt;                 &lt;/div&gt;                 &lt;div class=\""clearfix\""&gt;&lt;/div&gt;             &lt;/div&gt;         &lt;/div&gt;         &lt;!--banner-bottom--&gt;         &lt;!--new-arrivals--&gt;         &lt;div class=\""new-arrivals-w3agile\""&gt;             &lt;div class=\""container\""&gt;                 &lt;h2 class=\""tittle\""&gt;New Arrivals&lt;/h2&gt;                 &lt;div class=\""arrivals-grids\""&gt;                     @foreach (var item in Model.ShopProducts)                     {                          &lt;div class=\""col-md-3 arrival-grid simpleCart_shelfItem\"" style=\""padding-bottom:1em;\""                               price=\""@item.Price\"" id=\""@item.ID\"" name=\""@item.ProductName\"" profilepicture=\""@item.ProfilePicture\""&gt;                             &lt;div class=\""grid-arr\""&gt;                                 &lt;div class=\""grid-arrival\""&gt;                                     &lt;figure&gt;                                         &lt;a href=\""#\"" class=\""new-gri\"" data-toggle=\""modal\"" data-target=\""#myModal1\""&gt;                                             &lt;div class=\""grid-img\""&gt;                                                 &lt;img src=\""~/ProductPictures/@item.ProfilePicture\"" class=\""img-responsive\"" alt=\""\""&gt;                                             &lt;/div&gt;                                             &lt;div class=\""grid-img\""&gt;                                                 &lt;img src=\""~/ProductPictures/@item.ProfilePicture\"" class=\""img-responsive\"" alt=\""\""&gt;                                             &lt;/div&gt;                                         &lt;/a&gt;                                     &lt;/figure&gt;                                 &lt;/div&gt;                                 @*&lt;div class=\""ribben\""&gt;                                     &lt;p&gt;NEW&lt;/p&gt;                                 &lt;/div&gt;                                 &lt;div class=\""ribben1\""&gt;                                     &lt;p&gt;SALE&lt;/p&gt;                                 &lt;/div&gt;*@                                 &lt;div class=\""block\""&gt;                                     &lt;div class=\""starbox small ghosting\""&gt; &lt;/div&gt;                                 &lt;/div&gt;                                 &lt;div class=\""women\""&gt;                                     &lt;h6&gt;&lt;a href=\""single.html\""&gt;@item.ProductName&lt;/a&gt;&lt;/h6&gt;                                     &lt;span class=\""size\""&gt;XL / XXL / S &lt;/span&gt;                                     &lt;p&gt;@*&lt;del&gt;$100.00&lt;/del&gt;*@&lt;em class=\""item_price\""&gt;$@item.Price&lt;/em&gt;&lt;/p&gt;                                     &lt;a href=\""#\"" data-text=\""Add To Cart\"" class=\""my-cart-b item_add\""&gt;Add To Cart&lt;/a&gt;                                 &lt;/div&gt;                             &lt;/div&gt;                         &lt;/div&gt;                      }                     &lt;div class=\""clearfix\""&gt;&lt;/div&gt;                 &lt;/div&gt;             &lt;/div&gt;         &lt;/div&gt; </code></pre>  <p>I'm sure that it must be an issue with the model i'm using for the page because it resides in the Web app project but references a model in the class library  and so I'm thinking it's another issue with the library or reference. But the problem is I can't figure out how to debug in Azure to see what the actual issue is due to the 500 error. Here's the ViewModel  Model and Controller:</p>  <p>ViewModel:</p>  <pre><code>using System; using System.Collections.Generic; using System.Text;  namespace LNCLibrary.Models.HomeViewModel {     public class HomeViewModel     {         public ICollection&lt;Product&gt; ShopProducts { get; set; }     } } </code></pre>  <p>Model: </p>  <pre><code>using System; using System.Collections.Generic; using System.ComponentModel.DataAnnotations; using System.Text;  namespace LNCLibrary.Models {     public enum Category     {         Shirts          Accesories       }     public enum Gender     {         Men          Women          Both      }       public class Product     {         public int ID { get; set; }         [Display(Name =\""Name\"")]         public string ProductName { get; set; }         public int Price { get; set; }         [Display(Name = \""Gender\"")]         public Gender GenderOption { get; set; }         public int Quantity { get; set; }         public Category Category { get; set; }         [Display(Name =\""Created\"")]         public DateTime DateCreated { get; set; }         [Display(Name = \""Description\"")]         public string ProductDescription { get; set; }         public ICollection&lt;Size&gt; AvailableSizes { get; set; }         [Display(Name = \""Profile Picture\"")]         public string ProfilePicture { get; set; }     } } </code></pre>  <p>Controller: </p>  <pre><code> private readonly ApplicationDbContext _context;      public HomeController(ApplicationDbContext context)     {         _context = context;     }     public async Task&lt;IActionResult&gt; Index()     {         HomeViewModel HVM = new HomeViewModel();         HVM.ShopProducts = await _context.Products.ToListAsync();         return View(HVM);     } </code></pre>  <p>Any ideas? I'm stumped.</p>""",azure-web-app-service
50235556,"Difference between Azure Function and Web Job Or Azure function Vs Web Job <p><strong>Azure Function :</strong></p>  <ul> <li>Azure function based on the web job SDK.</li> <li>Deployment through visual studio: not deploy as a package   its only create  function within resourceGroup\</li> <li>Consumption plan** and App service plan both available</li> <li>Don't support remote debugging.</li> <li><strong>return OUTPUT</strong> when call via http.</li> <li>Integrate with webhook</li> <li>we can create Web Api.</li> <li>bydefault it support autoscale.</li> </ul>  <p><strong>Web Job :</strong></p>  <ul> <li>web job sdk depends on language.(e.g. C#..)</li> <li>Always Deploy with App Service.(e.g. web App web Api etc..)</li> <li>** <strong>Only</strong> App service plan.</li> <li>Support Remote debugging.</li> <li>not return any value.</li> <li>not option to integrate with <strong>webhook</strong>.</li> <li>do not create web api.</li> <li>For Continious Trigger: its provide two options for Scale-   <ul> <li>a. <strong>multi instance</strong> : scale your web jobs across all instances of app service plan </li> <li>b. <strong>single instance</strong> - copy only single copy of your web job running regardless on app service plan instance count. \""</li> </ul></li> </ul>""",azure-functions
45457898,Factory reset Windows Server 2016 on Azure <p>I installed a few beta version of some apps and now the functionality of the Windows is broken. </p>  <p>Is there any way I can reset the windows to it's initial state from the portal or I have to remove it and create a new one? </p>,azure-virtual-machine
54258188,Can I get the PartionKey and RowKey from TableOperation Retrieve operation? <p>is there a way to get the PartitionKey and RowKey from the TableOperation parameter  </p>  <pre><code>public override Task&lt;TableResult&gt; ExecuteAsync(TableOperation operation) {     switch (operation.OperationType)     {         case TableOperationType.Retrieve:             //entityResult = Get&lt;ITableEntity&gt;(operation.PartitionKey  operation.RowKey);             break;     }  } </code></pre>,azure-storage
44302000,"How to use Azure Data Factory for importing data incrementally from MySQL to Azure Data Warehouse? <p>I'm using Azure Data Factory to periodically import data from MySQL to Azure SQL Data Warehouse.</p>  <p>The data goes through a staging blob storage on an Azure storage account  but when I run the pipeline it fails because it can't separate the blob text back to columns. Each row that the pipeline tries to insert into the destination becomes a long string which contains all the column values delimited by a \⯑\"" character.</p>  <p>I used Data Factory before  without trying the incremental mechanism  and it worked fine. I don't see a reason it would cause such a behavior  but I'm probably missing something.</p>  <p>I'm attaching the JSON that describes the pipeline with some minor naming changes  please let me know if you see anything that can explain this.</p>  <p>Thanks!</p>  <p>EDIT: Adding exception message:</p>  <blockquote>   <p>Failed execution Database operation failed. Error message from   database execution :   ErrorCode=FailedDbOperation 'Type=Microsoft.DataTransfer.Com‌​mon.Shared.HybridDel‌​iveryException Messa‌​ge=Error   happened when loading data into SQL Data   Warehouse. Source=Microsoft.DataTransfer.ClientLibrary ''Typ‌​e=System.Data.SqlCli‌​ent.SqlException Mes‌​sage=Query   aborted-- the maximum reject threshold (0 rows) was reached while   reading from an external source: 1 rows rejected out of total 1 rows   processed.   (/f4ae80d1-4560-4af9-9e74-05de941725ac/Data.8665812f-fba1-40‌​7a-9e04-2ee5f3ca5a7e‌​.txt)              Column ordinal: 27  Expected data type: VARCHAR(45) collate SQL_Latin1_General_CP1_CI_AS  Offending value:* ROW OF VALUES   * (Tokenization failed)  Error: Not enough columns in this   line. } ] '.</p> </blockquote>  <pre><code>{ \""name\"": \""CopyPipeline-move_incremental_test\""  \""properties\"": {     \""activities\"": [         {             \""type\"": \""Copy\""              \""typeProperties\"": {                 \""source\"": {                     \""type\"": \""RelationalSource\""                      \""query\"": \""$$Text.Format('select * from [table] where InsertTime &gt;= \\\\'{0:yyyy-MM-dd HH:mm}\\\\' AND InsertTime &lt; \\\\'{1:yyyy-MM-dd HH:mm}\\\\''  WindowStart  WindowEnd)\""                 }                  \""sink\"": {                     \""type\"": \""SqlDWSink\""                      \""sqlWriterCleanupScript\"": \""$$Text.Format('delete [schema].[table] where [InsertTime] &gt;= \\\\'{0:yyyy-MM-dd HH:mm}\\\\' AND [InsertTime] &lt;\\\\'{1:yyyy-MM-dd HH:mm}\\\\''  WindowStart  WindowEnd)\""                      \""allowPolyBase\"": true                      \""polyBaseSettings\"": {                         \""rejectType\"": \""Value\""                          \""rejectValue\"": 0                          \""useTypeDefault\"": true                     }                      \""writeBatchSize\"": 0                      \""writeBatchTimeout\"": \""00:00:00\""                 }                  \""translator\"": {                     \""type\"": \""TabularTranslator\""                      \""columnMappings\"": \""column1:column1 column2:column2 column3:column3\""                 }                  \""enableStaging\"": true                  \""stagingSettings\"": {                     \""linkedServiceName\"": \""StagingStorage-somename\""                      \""path\"": \""somepath\""                 }             }              \""inputs\"": [                 {                     \""name\"": \""InputDataset-input\""                 }             ]              \""outputs\"": [                 {                     \""name\"": \""OutputDataset-output\""                 }             ]              \""policy\"": {                 \""timeout\"": \""1.00:00:00\""                  \""concurrency\"": 10                  \""style\"": \""StartOfInterval\""                  \""retry\"": 3                  \""longRetry\"": 0                  \""longRetryInterval\"": \""00:00:00\""             }              \""scheduler\"": {                 \""frequency\"": \""Hour\""                  \""interval\"": 1             }              \""name\"": \""Activity-0-_Custom query_-&gt;[schema]_[table]\""         }     ]      \""start\"": \""2017-06-01T05:29:12.567Z\""      \""end\"": \""2099-12-30T22:00:00Z\""      \""isPaused\"": false      \""hubName\"": \""datafactory_hub\""      \""pipelineMode\"": \""Scheduled\"" } </code></pre>  <p>}</p>""",azure-storage
8103021,"Read file from blob url container <p>Below is my blob url where my word file is located  and I want to read the file and show its content in my web form(C#).</p>  <p><a href=\https://vikranttest.blob.core.windows.net/Vikrantproduction/applicationeulaVikrant/vikky.rtf\"" rel=\""nofollow\"">https://vikranttest.blob.core.windows.net/Vikrantproduction/applicationeulaVikrant/vikky.rtf</a></p>""",azure-storage
34038410,Azure web app security: How to allow connections only from a whitelisted domains <p>I have one Azure webApp  I need to provide some security to that web app. I have below requirement.</p>  <ol> <li>Web app should not accept connection from all the domains. (It should have a list of domains from where it will accept connections)</li> <li>If a new domain got added to whitelist domain  then my app will allow request from that new domain without restart or reconfigure.</li> </ol>  <p>Is there a way to configure at Azure level to allow requests  from specific domains.</p>  <p>Thanks  Abhi</p>,azure-web-app-service
45556953,Calling Azure Function from Code <p>I'm using the Azure Function Tools for Visual Studio 2017 15.3.</p>  <p>I am trying to move my application to ASP.Net Core 2.0 and have some code which uses system.drawing which will not port.  My intention is to move some of the code which will not port into Azure Functions (running on .Net 4.6) and then call these functions from my ASP.Net Core 2.0 application.</p>  <p>I was hoping to get some advice on the best way to call Azure functions from my ASP.Net Core 2.0 code.  The first thing that springs to mind is using something like RestSharp but I was wondering if there is any other tooling I should consider using?</p>,azure-functions
32515758,How to maintain drive mapping creating new VM from custom image <p>I am trying to create a TeamCity build agent that can be scaled as needed. I've created a VM  and configured it accordingly. Because we have a lot of projects  I have attached a DATA disk  and have installed the build agent to point to that. Based on other posts  I've mapped the DATA disk to F:. Once completed  I've created an image which I plan to use for all other VM creation of agent. The issue is  when I do perform a creation  it's not maintaining the drive mapping of the DATA disk  so it's now E:. When the agent service tries to start  it's looking for F:.  Even if I install the agent on C:\  I want the checkout directory to be on the DATA disk as we'll have a lot of files being checked out (hundreds of GB's).  Can't seem to find how this will work from an Azure Powershell perspective. </p>,azure-virtual-machine
56775355,How to create external table for data in azure blob storage <p>I'm trying to create an external table for data in Azure blob  and I have used the flow script</p>  <pre><code>create table [Sales].Currency (     [CurrencyCode] [nchar](3) NOT NULL      [Name] [nchar](200) NOT NULL      [ModifiedDate] [datetime] NOT NULL   ) with (     Location = '/samplefile/'      data_source=currenytable      file_format=uncompressedData      reject_type=value      reject_value=0 ); </code></pre>  <p>when I execute this code I get the following error Parse error at line: 10  column: 13: Incorrect syntax near ''/samplefile/''. how to resolve this one thank you  Note: I have successfully created all prior things for creating the external table</p>,azure-storage
52726195,Flexera agent installation getting timed out <p>Hi I am trying to install custom extension via a azure automation runbook in Windows Azure VM but cmdlet <code>Set-AzureRmVMCustomScriptExtension</code> is getting timed out  any suggestion what could be going wrong here?</p>  <p>Error message:</p>  <blockquote>   <p>Set-AzureRmVMCustomScriptExtension : Long running operation failed with status 'Failed'. Additional Info:'Provisioning of VM extension 'FlexeraInstall' has timed out. Extension installation may be taking too long  or extension status could not be.</p> </blockquote>,azure-virtual-machine
53133663,"Azure web apps: “You do not have permission to view this directory or page” error <p>I am trying to deploy my nodejs application on azure and I got this error :</p>  <pre><code>“You do not have permission to view this directory or page” </code></pre>  <p>I followed this <a href=\https://docs.microsoft.com/fr-fr/azure/app-service/app-service-web-get-started-nodejs\"" rel=\""nofollow noreferrer\"">tutorial</a> from Azure web site. To be sure Itried again but with the hello wold example given in the tutorial. However  when I deploy the zip  I got a successful deployment but when I try to access to my web site I get the same error.</p>  <p>I searched on internet about this error and I tried to follow the response from the following links <a href=\""https://github.com/Azure-Samples/nodejs-docs-hello-world/issues/9\"" rel=\""nofollow noreferrer\"">link1</a>  <a href=\""https://stackoverflow.com/questions/51452336/you-do-not-have-permission-to-view-this-directory-or-page-error-in-azure\"">link2</a> but I still get the error. </p>  <p>Do you have an idea please ?</p>  <p>I would be very thnakful for any help.</p>""",azure-web-app-service
46499630,"Getting Error When Starting Node in ASP.NET Core 2.0 <p>I first create a vanilla asp.net core 2.0 web site with vs2017. Then  I add node starting by updating startup.cs with these lines:</p>  <pre><code>    public void ConfigureServices(IServiceCollection services)     {         services.AddMvc();          services.AddNodeServices(options =&gt; {             options.LaunchWithDebugging = true;             options.DebuggingPort = 9229;         });     } </code></pre>  <p>I create a view that returns some data and when I run it locally  it works. Here is that code:</p>  <pre><code>    public async Task&lt;IActionResult&gt; NodeTest([FromServices] INodeServices nodeServices)     {          ViewData[\ResultFromNode\""] =              await nodeServices.InvokeAsync&lt;string&gt;(\""NodeSrc/myNodeModule.js\"");         return View(viewName: \""NodeTest\"");      } </code></pre>  <p>My myNodeModule.js is as follows:</p>  <pre><code>module.exports = function (callback) {     var message = 'Hello from Node js script at ' +         new Date().toString() + ' process.versions ' +         process.version;     callback(/* error */ null  message); }; </code></pre>  <p>When I run this locally with vs2017 it works.  When I use VSTS and deploy  even after adding a process variable of ASPNETCORE_ENVIRONMENT to Development  I still get an error when I try to browse to the page.  The error i below.</p>  <p>My 2 questions are:   1.  How can I get better errors reported   2.  How can I get node to run on the server in both debug and production modes.</p>  <p>Error:</p>  <pre><code>Error. An error occurred while processing your request. Request ID: 0HL87NKEP2GL6:00000002  Development Mode Swapping to Development environment will display more detailed information about the error that occurred.  Development environment should not be enabled in deployed applications  as it can result in sensitive information from exceptions being displayed to end users. For local debugging  development environment can be enabled by setting the ASPNETCORE_ENVIRONMENT environment variable to Development  and restarting the application.  </code></pre>""",azure-devops
54291473,"Azure Functions - RedirectResult causing a HTTP500 error <p>One of our Azure Functions (running 2.0) should return a RedirectResult (gets triggered by an external webhook  does some processing and should do a redirect to a web page).</p>  <p>This works in our test environment  but does not work when deploying the same function to our production environment. I've tried changing the redirect URL with no luck. </p>  <p>Also wrote a test function like this which still causes a HTTP500 (without logging an exception):</p>  <pre><code>public static class RedirectTest {     [FunctionName(\RedirectTest\"")]     public static async Task&lt;IActionResult&gt; Run([HttpTrigger(AuthorizationLevel.Anonymous  \""get\""  Route = \""RedirectTest\"")] HttpRequest req  ILogger log)     {         try         {             log.LogInformation(\""Trying to redirect\"");             return new RedirectResult(\""https://www.stackoverflow.com\"");         }         catch (Exception e)         {             log.LogError($\""Something bad happened here: {e.Message}\""  e);             return new OkResult();         }     } } </code></pre>  <p>So I would think this is some settings outside the actual Function - and would appreciate tips &amp; tricks how to go on about debugging this and get it to work.</p>""",azure-functions
53019679,performance issue with app service in azure portal <p>I have just started to work on azure portal. I need to deploy 8 applications on azure portal for this I am using app service  I am using P2v2 service plan and into this plan i am creating 8 app services and deployed the code  but when users browsing the sites  performance of sites are too slow I tried to stop all app services except 2 app services which i need but still performance slow. Even I change plan from P2v2 to S2 now but still performance is not well. Can anyone suggest how can I improve my app service performace.</p>  <p>Thanks  Sandy</p>,azure-web-app-service
26052131,"how to bulkcopy Excel file from Azure Blob <p>I have made an mvc application which saves excel file on azure blob blob storage. now i want to read the content of this excel file. </p>  <p>earlier i saved this file on my c:/temp folder and code to bulk copy it is as follows :-</p>  <pre><code>         string excelConnectionString = string.Format(@\Provider=Microsoft.ACE.OLEDB.12.0;Data      Source={0};Extended Properties=\""\""Excel 12.0 Xml;HDR=YES;\""\""\""  path);          OleDbConnection connection = new OleDbConnection();          connection.ConnectionString = excelConnectionString;          OleDbCommand command = new OleDbCommand(\""select * from [Sheet1$]\""  connection);          connection.Open();          DbDataReader dr = command.ExecuteReader();             using (var bulkCopy = new SqlBulkCopy(ConfigurationManager.ConnectionStrings[\""myString\""].ConnectionString  SqlBulkCopyOptions.KeepNulls &amp; SqlBulkCopyOptions.KeepIdentity))             {                //my logic              }           connection.Close(); </code></pre>  <p>since i want to implement this solution on Azure cloud. </p>  <p>now i am saving excel file to Azure blobstorage instead of c:/temp. but i am not able to bulkcopy it. </p>  <p>Please suggest something.</p>""",azure-storage
55365038,"Azure DevOps REST call - How to find out my identity <p>We recently migrated from on prem TFS to Azure Devops in the cloud. I am updating my powershell scripts that I use to automate my work item tracking  moving them from api v3 to v5 and ensuring all my authentication/endpoints are working properly. I have the authentication setup and can make some GET calls (list the repositories  run WIQL queries  etc) Now I need to create new work items using the <a href=\https://docs.microsoft.com/en-us/rest/api/azure/devops/wit/work%20items/create?view=azure-devops-rest-5.0\"" rel=\""nofollow noreferrer\"">Create endpoint</a>.</p>  <p>My body looks like (and this was working on Prem  TFS 2018  REST version 3.0):</p>  <pre><code>[     {         \""op\"": \""add\""          \""path\"": \""/fields/System.Title\""          \""value\"": \""My PBI title\""     }      {         \""op\"": \""add\""          \""path\"": \""/fields/System.AssignedTo\""          \""value\"": \""DOMAIN\\\\USERNAME\""     }      {         \""op\"": \""add\""          \""path\"": \""/fields/System.AreaPath\""          \""value\"": \""My\\\\Teams\\\\Path\""     }      {         \""op\"": \""add\""          \""path\"": \""/fields/System.IterationPath\""          \""value\"": \""backlog\\\\2019.03.25\""     } ] </code></pre>  <p>When I POST with this body  I get a 400 response code and a error message that states: <code>The identity value 'DOMAIN\\\\USERNAME' for field 'Assigned To' is an unknown identity.\""</code></p>  <p>If I exclude that property from my body statement I am able to create the work item  so I am trying different variations of my domain username/name (last name  first name/ first name last name) to try to get it to work/assign the item to me  but I keep getting the same error. </p>  <p>So my next step is to check the API documentation  and I see a <a href=\""https://docs.microsoft.com/en-us/rest/api/azure/devops/graph/users/get?view=azure-devops-rest-5.0\"" rel=\""nofollow noreferrer\"">Users - Get</a> method  but that requires me to enter the <code>userDescriptor</code> which I assume is some sort of GUID to identify each user... but I don't know what mine is! </p>  <p>At this point I am stumped. There are a few other REST endpoints to get Profile/Security data  but that seems overly complicated for creating a work item. </p>  <p>How have you used this REST endpoint to create an item/assign it to a user via Azure-Devops in the cloud? </p>""",azure-devops
52745095,Figuring out which Azure region VM is in from within the VM <p>We are looking to make decisions based on which azure region VM is in. I am hoping there is an environment variable being set or some other api to call from within the VM to retrieve the azure region.</p>,azure-virtual-machine
46795519,Debugging a React Azure Web App <p>I've got a React app running on Azure. It runs fine in my localhost  however  when I go to the Azure address  it doesn't load; all I get is a blank page with a head and body html element  which is throwing the following error:</p>  <pre><code>Uncaught SyntaxError: Unexpected token &lt; </code></pre>  <p>The immediate question  of course  is what's causing the error and how do I fix it?</p>  <p>The bigger question in the background is  with a backend app  I can enable logging and look at a log stream and see what's throwing errors in real time. With a frontend app  the errors are happening in my browser; the React Chrome extension doesn't even recognize this as a React app. How do I debug in this context?</p>,azure-web-app-service
57679839,"Consume AZURE ML with nodejs error 400 status code <p>I have a problem when I try to consuming the web service  the error is: </p>  <pre><code>The request failed with status code: 400  {\error\"": {\""code\"":\""BadArgument\"" \""message\"":\""Invalid argument provided.\""  \""details\"":[{\""code\"":\""BatchJobInputsNotSpecified\"" \""message\"":\""The following required input(s) were not specified with the request: input1. Please ensure all input data is specified and try again.\""}]}} </code></pre>  <p>I don't know how to solve that  because in the code I send <code>input1</code>.</p>  <p>Please help me  thanks.</p>  <pre><code>let req = require(\""request\"");      const uri = \""bla\"";     const apiKey = \""key\"";      let data = {         \""Inputs\"": {             \""input1\"":             [                 {                     'IdEmpleado': \""20000\""                      'NivelSatisfaccion': \""0.38\""                      'SatisfaccionLaboral_Disc': \""Insatisfecho\""                      'UltimaEvaluacion': \""0.53\""                      'UltimaEvaluacion_Disc': \""Media\""                      'ProyectosRealizados': \""2\""                      'ProyectosRealizados_Disc': \""[2-3]\""                      'HorasMensuales': \""157\""                      'HorasMensuales_Disc': \""[150-199]\""                      'Antiguedad': \""3\""                      'Antiguedad_Disc': \""[2-4]\""                      'AccidentesTrabajo': \""0\""                      'AccidentesTrabajo_Disc': \""NO\""                      'Ascendido': \""0\""                      'Ascendido_Disc': \""NO\""                      'AreaTrabajo': \""Ventas\""                      'NivelSalarial': \""Bajo\""                      'Renuncia': \""1\""                      'Renuncia_Disc': \""SI\""                 }             ]          }          \""GlobalParameters\"": {}     } </code></pre>""",azure-web-app-service
56068134,"Cannot filter by artifactSourceId in Azure DevOps API <p>Given a known buildDefinitionId I am attempting to determine the (one or more) Release Definitions that depend on the output of the build.</p>  <p>The docs : <a href=\https://docs.microsoft.com/en-us/rest/api/azure/devops/release/definitions/list?view=azure-devops-rest-5.0\"" rel=\""nofollow noreferrer\"">https://docs.microsoft.com/en-us/rest/api/azure/devops/release/definitions/list?view=azure-devops-rest-5.0</a></p>  <p>state that I can pass in an <code>artifactSourceId</code> parameter in the format <code>{projectGuid}:{BuildDefinitionId}</code> however when I try to pass in this parameter I get <em>every</em> release definition for the specified project.</p>  <p>Using the url : <code>https://vsrm.dev.azure.com/my-company/d4155bbc-d85f-4aaf-9a8e-0ba70272cca4/_apis/release/definitions?artifactSourceId=d4155bbc-d85f-4aaf-9a8e-0ba70272cca4:950&amp;api-version=5.0</code></p>  <p>In my project I get a list of 553 build definitions. Searching in the response body for the artifact key <code>d4155bbc-d85f-4aaf-9a8e-0ba70272cca4:950</code> ({projectGuid}:{buildDefinitionId}) gives me the expected 2 results as per below:</p>  <pre><code>\""artifacts\"": [             {                 \""sourceId\"": \""d4155bbc-d85f-4aaf-9a8e-0ba70272cca4:950\""                  \""type\"": \""Build\""                  \""alias\"": \""my-build-definition\""                  // more fields here              }              ] </code></pre>  <p>Curiously if I don't pass in the <code>artifactSourceId</code> parameter  I don't get any artifact data in the response at all - including when I specify the <code>$expand=artifact</code> parameter - but I can specify <code>artifactSourceId=xyz</code> and it will still return a list of <strong>all</strong> release definitions.</p>  <p>This seems like it could be a bug with the api  but if anyone has any insight or workarounds I would be grateful. </p>""",azure-devops
52492992,"Compilation error when trying to reference a CloudBlockBlob in blobstorage triggered function <p>Here's my function code. </p>  <pre><code>#r \Microsoft.WindowsAzure.Storage.Blob\""  public static async Task Run(CloudBlockBlob uploadedVideo  string name  CloudBlockBlob processedVideo  ILogger log) {     log.LogInformation($\""C# Blob trigger function Processed blob\\n Name:{name} \\n Size: {uploadedVideo.Length} Bytes\"");     var fileEntry = new      {         fileName = $\""uploaded-videos/{name}\""          fileType = \""video\""          correlationId = Guid.NewGuid()     };     await processedVideo.StartCopyAsync(uploadedVideo);       await uploadedVideo.DeleteIfExistsAsync(); } </code></pre>  <p>and here is my function.json</p>  <pre><code>{   \""bindings\"": [     {       \""name\"": \""uploadedVideo\""        \""type\"": \""blobTrigger\""        \""direction\"": \""in\""        \""path\"": \""uploaded-videos/{name}\""        \""connection\"": \""AzureWebJobsStorage\""     }      {       \""type\"": \""blob\""        \""name\"": \""processedVideo\""        \""path\"": \""processed-videos/{name}-{rand-guid}\""        \""connection\"": \""AzureWebJobsStorage\""        \""direction\"": \""out\""     }   ] } </code></pre>  <p>And here is the error that it keeps throwing when I run this function. </p>  <blockquote>   <p>2018-09-25T07:34:10.813 [Error] Function compilation error   2018-09-25T07:34:10.982 [Error] BlobTriggerCSharp.csx(2 1): error CS0006: Metadata file 'Microsoft.WindowsAzure.Storage.Blob' could not be found   2018-09-25T07:34:11.040 [Error] BlobTriggerCSharp.csx(4 30): error CS0246: The type or namespace name 'CloudBlockBlob' could not be found (are you missing a using directive or an assembly reference?)   2018-09-25T07:34:11.128 [Error] BlobTriggerCSharp.csx(4 73): error CS0246: The type or namespace name 'CloudBlockBlob' could not be found (are you missing a using directive or an assembly reference?)</p> </blockquote>""",azure-functions
52368814,"Can we connect to Azure VM remotely which is different Virtual Network <p>I have 2 Azure VMs   say <code>VM1</code> and <code>VM2</code>. I have logged into <code>VM1</code> through RDP. Now my requirement is to connect to <code>VM2</code> from <code>VM1</code> through powershell and run some commands remotely. </p>  <p>When I run the below command :</p>  <pre><code>$UserName = \&lt;IP&gt;\\username\"" $Password = ConvertTo-SecureString \""password@123\"" -AsPlainText -Force $psCred = New-Object System.Management.Automation.PSCredential($UserName  $Password) $s = New-PSSession -ComputerName &lt;IP&gt; -Credential $psCred </code></pre>  <p>It is giving the following error :</p>  <p>New-PSSession : [] Connecting to remote server failed with the following error message : WinRM cannot complete the operation. Verify that the specified computer name is valid  that the computer is accessible over the network  and that a firewall exception for the WinRM service is enabled and allows access from this computer. By default  the WinRM firewall exception for public profiles limits access to remote computers within the same local subnet. For more information  see the about_Remote_Troubleshooting Help topic.</p>  <p>I have tried all the solutions which I found on internet  but none solved my problem.  </p>  <p>The VirtualNetwork/Subnet of both the VMs is different and both of them do no have public IP and DNS name(which is a business requirement and cannot be changed) . So I'm using Private IP to login.Location of both the VMs is also different.   </p>  <p>Is there a possibility that this might be the reason?</p>""",azure-virtual-machine
53601642,"Azure Pipeline Ruby Step fails without error <p>I build a rubygem on Azure DevOps. I used that step to use RSpec:</p>  <p>script: bundle exec rspec spec --format RspecJunitFormatter --out test_results/TEST-rspec.xml  displayName: 'rake spec' </p>  <p>While execution i'm getting that issue: <a href=\https://dev.azure.com/saigkill/hoe-manns/_build?definitionId=3\"" rel=\""nofollow noreferrer\"">https://dev.azure.com/saigkill/hoe-manns/_build?definitionId=3</a></p>  <p>So it returns '1' without any error before. Maybe i have missed something?</p>""",azure-devops
56971869,Your azure function app has functions_worker_runtime set to node while your local project is set to none <p>I have a node function app that runs fine locally and when deployed. However  I receive the error : Your azure function app has functions_worker_runtime set to node while your local project is set to none and am unable to deploy it if I don't check in local.settings.json which has the FUNCTIONS_WORKER_RUNTIME set to node. My arm template app settings has the FUNCTIONS_WORKER_RUNTIME set to node. </p>  <p>I've tried setting an environment variable during deployment  but it seems like it is reading it out of local settings?</p>  <p>How can I deploy this without checking in the local.settings.json file?</p>,azure-functions
52815281,"How to open and read the content of \.RTF\"" File using c# <p><strong><em>My need :</em></strong> I need to open an RTF File and read the content inside the RTF File and store it in a string variable. </p>  <p><strong><em>What i have done :</em></strong> I have done it using \""<em>microsoft.office.interop.word.dll</em>\""  ie.. Docment.open(String Filename);</p>  <p><strong><em>But My Final necessity is :</em></strong> I need to open it using some other way to read the RTF File. This is Because in AzureFunction (microsoft.office.interop.word.dll is not supported ) ie.. word cant be installed in server.</p>  <p><strong><em>OpenXML -</em></strong> This is used to open word   excel   powerpoint files . it cannot able to open RTF File.</p>  <p>Any possible answer is welcomed.</p>""",azure-functions
48148273,Azure web app scale out - database considerations <p>The scenario is I have a web site running in an azure web app. The site has a database behind it.</p>  <p>What happens if the app service plan that is running the site is scaled out to multiple instances?</p>  <p>will all the site instances hit the same database?</p>,azure-web-app-service
56659509,Migration On-premises SQL Server 2008 to Azure vm <ul> <li>How to identify workload ? testing performance issue ?</li> <li>Before migration what i have to check in the VM ?</li> <li>after migration any db setting need to change ?</li> </ul>,azure-virtual-machine
50237511,"How to guarantee at least once delivery with Azure Function with Cosmos DB trigger <p>I have a Cosmos DB trigger for an Azure function. I want to flatten and write some data from the incoming Document(s) to an (Azure) SQL Server.</p>  <p>What is a way to guarantee at least once delivery?</p>  <p>I looked at <a href=\https://hackernoon.com/reliable-event-processing-in-azure-functions-37054dc2d0fc\"" rel=\""nofollow noreferrer\"">https://hackernoon.com/reliable-event-processing-in-azure-functions-37054dc2d0fc</a> which gives some options in the case of an Azure Function triggered by an Event Hub event  but I am not sure if the same applies for the CosmosDB changefeed that causes the trigger to fire.</p>  <p>On the Cosmos DB Change Feed site <a href=\""https://docs.microsoft.com/en-us/azure/cosmos-db/change-feed\"" rel=\""nofollow noreferrer\"">https://docs.microsoft.com/en-us/azure/cosmos-db/change-feed</a> it states:</p>  <blockquote>   <p>Each change to a document appears exactly once in the change feed  and clients manage their checkpointing logic. The change feed processor library provides automatic checkpointing and \""at least once\"" semantics.</p> </blockquote>  <p>Does that mean that it implements the same (or something similar to) the checkpoint system from Event Hub?</p>  <p>Does the circuit breaker pattern work the same way if applied to this flow of a CosmosDB trigger to an Azure Function as detailed at the end of <a href=\""https://hackernoon.com/reliable-event-processing-in-azure-functions-37054dc2d0fc\"" rel=\""nofollow noreferrer\"">https://hackernoon.com/reliable-event-processing-in-azure-functions-37054dc2d0fc</a> ?</p>""",azure-functions
52957876,"Copy Azure Managed Image from Azure Comercial to Azure China <p>We have a custom Managed Image that we built from Windows VM in Azure. We need to copy that Managed Image to China and create VMs from it. Unfortunately  we are unable to connect to VMs created from copied .vhd. The steps we did:  1. Created VM in Europe from custom Managed Image.  2. Ran Sysprep.  3. Exported Managed Disk  and uploaded .vhd to Storage Account in China.  4. Created VM from that image. The problem is we are not able to RDP to that VM. What is the proper way to do it? (connection time out) We can't recreate that Image in China  because we need that Image to be consistent with the image we have in Europe. <a href=\https://i.stack.imgur.com/LaRPC.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/LaRPC.png\"" alt=\""enter image description here\""></a></p>""",azure-virtual-machine
54238992,"How to use ConfigurationBuilder staticly in an Azure Function v2 (core)? <p>While porting an Azure Function from v1 to v2 there is a change in how the configuration manager is used to read the local.settings.json. </p>  <p>Previously  I used the following code to enable redis connection pooling between function instances:</p>  <pre><code>public static class Redis {     /// &lt;summary&gt;     /// Initializes the REDIS connection.     /// &lt;/summary&gt;     private static readonly Lazy&lt;ConnectionMultiplexer&gt; LazyConnection = new Lazy&lt;ConnectionMultiplexer&gt;(() =&gt;     {         return ConnectionMultiplexer.Connect(ConfigurationManager.AppSettings[\CacheConnection\""]);         });      public static IDatabase Database =&gt; LazyConnection.Value.GetDatabase(); } </code></pre>  <p>However in v2 the ConfigurationManager is no longer available and we have to use something like:</p>  <pre><code>new ConfigurationBuilder()         .SetBasePath(context.FunctionAppDirectory)         .AddJsonFile(\""local.settings.json\""  optional: true  reloadOnChange: true)         .AddEnvironmentVariables()         .Build(); </code></pre>  <p>However  because it requires the <code>context</code> which is only available during function runtime we cannot create a static class shared across all functions. Is it possible to read the app.settings.json statically in Azure Functions v2?</p>""",azure-functions
30743391,"New-AzureQuickVM not creating VM on exsisting Cloud Service? <p>I'm trying to run the following Azure Powershell cmdlet to provision a new Virtual Machine on a existing Cloud Service.</p>  <pre><code>PS C:\\&gt; Get-AzureService | ft ServiceName  ServiceName                                                                                                                                                                     -----------                                                                                                                                                                     $AZURETEST-EUWEST0                                                                                                                                                                  $AZURETEST-JPWEST0                                                                                                                                                                  $AZURETEST-USEAST0                                                                                                                                                                  $AZURETEST-USWEST0                                                                                                                                                                                                                                                                                                                             PS C:\\&gt; $image = \a699494373c04fc0bc8f2bb1389d6106__Windows-Server-2012-R2-201505.01-en.us-127GB.vhd\""  PS C:\\&gt; New-AzureQuickVM -Windows -ServiceName \""$AZURETEST-USEAST0\"" -name \""AZURESVM-USE1\"" -ImageName $image -Password Password1 -AdminUsername admin -WaitForBoot New-AzureQuickVM : ResourceNotFound: The deployment name '$AZURETEST-USEAST0' does not exist. At line:1 char:1 + New-AzureQuickVM -Windows -ServiceName \""$AZURETEST-USEAST0\"" -name \""AZURESVM-USE1\"" -Im ... + ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~     + CategoryInfo          : CloseError: (:) [New-AzureQuickVM]  CloudException     + FullyQualifiedErrorId : Microsoft.WindowsAzure.Commands.ServiceManagement.IaaS.PersistentVMs.NewQuickVM  New-AzureQuickVM : Sequence contains no matching element At line:1 char:1 + New-AzureQuickVM -Windows -ServiceName \""$AZURETEST-USEAST0\"" -name \""AZURESVM-USE1\"" -Im ... + ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~     + CategoryInfo          : CloseError: (:) [New-AzureQuickVM]  InvalidOperationException     + FullyQualifiedErrorId : Microsoft.WindowsAzure.Commands.ServiceManagement.IaaS.PersistentVMs.NewQuickVM   PS C:\\&gt;  </code></pre>  <p>What doesn't make sense is I'm getting an error that says my Cloud Service - or Deployment Name doesn't exist when you can clearly see it returned when I listed all the available Cloud Services!</p>""",azure-virtual-machine
43812146,"Unable to lock a file  folder or branch in VS 2015 connected to Visual Studio team Services <p>I am trying to lock a branch from Visual Studio 2015 which is connected to Visual studio Team Services. The locking succeeds  but when I am about to check-in  all the changes are undone and the check-in fails. I have all the permissions  to be double sure I have explicitly added myself as the admin and given all permissions on VSTS.</p>  <p>Here are the step by step screen shots of what is happening:</p>  <p><strong>1) I right click on the branch and select the lock option form source control.</strong>  <a href=\https://i.stack.imgur.com/nREyX.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/nREyX.png\"" alt=\""Right and selecting **lock** from source control\""></a></p>  <p><strong>2) Lock popup opens up</strong> <a href=\""https://i.stack.imgur.com/g1AA4.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/g1AA4.png\"" alt=\""lock popup opens up\""></a></p>  <p><strong>3) I am about to check-in</strong></p>  <p><a href=\""https://i.stack.imgur.com/EsRxh.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/EsRxh.png\"" alt=\""I am about to check-in\""></a></p>  <p><strong>4) The check-in fails  everything is undo-ed and a warning message is shown :</strong> <em>All of the changes were either unmodified files or locks. The changes have been undone by the server.</em> <a href=\""https://i.stack.imgur.com/G5sXD.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/G5sXD.png\"" alt=\""check-in fails with a warning message\""></a></p>  <p>I have also tried to modify a file  then lock it and then check it in. But it fails with the same message. </p>  <p><a href=\""https://www.visualstudio.com/en-us/docs/tfvc/lock-unlock-folders-files\"" rel=\""nofollow noreferrer\"">The documentation for VSTS</a> indicates that there should have been an option to check out lock or check in lock in the lock popup in #3 image above  but that is not being shown to me  not matter what. </p>  <p>I just need to lock the branch to prevent further changes to it!</p>""",azure-devops
51671347,"Get the list of azure web app settings to be swapped using PowerShell <p>When we perform the swap through the azure portal  it gives us the warning &amp; informative messages regarding the settings to be swapped. Just like in below image: <img src=\https://i.stack.imgur.com/N6pVe.png\"" alt=\""enter image description here\""></p>  <p>My question is  is there any way I can get these messages list (regarding the settings) through PowerShell code?</p>  <p>I tried googling it but couldn't find any way.</p>""",azure-web-app-service
56577178,Can I set AAD app registration to be multi-tenant if it is pointing to azure function in the another tenant? <p>I have an Azure Function deployed on <strong>tenant A</strong>. This function is accessed from the <strong>tenant B</strong> where it's secured with AAD App Registration.</p>  <p>I need to activate Multi-tenanted property. App ID URI points to the azure function in the <strong>tenant A</strong></p>  <p>When I change the Multi-tenanted property to yes I'm getting this error:</p>  <blockquote>   <p>Failed to update App ID URI application property. Error detail: The App ID URI is not available. The App ID URI must be from a verified domain within your organization's directory.</p> </blockquote>  <p>I understand that App ID URI has to be in the trusted domain  but I have no idea how can I do it. Is it even possible? The Azure Function has to be in the <strong>tenant A</strong>. Can I add somehow new record here /ActiveDirectoryMenuBlade/Domains and make it work?</p>,azure-functions
36029910,"Azure VM Capture (Process Overview) <p>I am planning to capture my VM image in Azure to create a copy for VM deployments (I am using this to deploy multiple VM or any redeployment scenarios).</p>  <p>Will any data/ configurations lost during the process? Be it application wise or server. I am expecting it to work just as simple as copy and paste functionality no Gotchas. Everything within this VM is critical to my clients (Customized apps/ web services etc.)</p>  <p>P/S: I have done my research here: <a href=\https://azure.microsoft.com/en-us/documentation/articles/virtual-machines-capture-image-windows-server/\"" rel=\""nofollow\"">https://azure.microsoft.com/en-us/documentation/articles/virtual-machines-capture-image-windows-server/</a></p>  <p>It says it will delete my VM once I have captured the image  now this is where I am very worried about.  </p>""",azure-storage
51775980,"Azure Function to Azure SQL - Performance and Scaling <p>I have an Azure Function that writes to Azure SQL.  It currently reads from a topic but could be changed to read from a queue.  Is there a preference to read from a topic or a queue?  </p>  <p>There are 200K messages per hour hitting the topic.  I need to write the 200K messages per hour to Azure SQL.  During processing I regularly get the error \The request limit for the database is 60 and has been reached.\"".  I understand that I've hit the maximum number of DB connections.  Is there a way to stop Azure from scaling up the number of Azure Function instances?  What's the best way to share SQL connections?</p>  <p>Any other Azure Function to Azure SQL performance tips?</p>  <p>Thanks </p>  <p>Richard</p>""",azure-functions
57690085,"AzureDevOps - Different behavior from custom task for Services and Server <p>I created a custom task using the documentation  however it works on Azure DevOps Services but on Server it gives the error</p>  <pre><code>An error occurred while loading the YAML build pipeline. Value cannot be null. Parameter name: key </code></pre>  <p>My first thoughts are \what is the parameter that is missing?\"" so i filled all the available and possible parameters and still continued with the error.</p>  <p>After that i went to the event viewer in the machine running Azure DevOps Server and got this error:</p>  <pre><code>Detailed Message: The subscriber Pipelines Check Run: build completed event listener raised an exception while being notified of event Microsoft.TeamFoundation.Build2.Server.BuildCompletedEvent. Exception Message: Value cannot be null. Parameter name: definition and repository (type ArgumentNullException) Exception Stack Trace:    at Microsoft.TeamFoundation.Pipelines.Server.Providers.TfsGitProvider.TfsGitConnectionCreator.IsProviderDefinition(IVssRequestContext requestContext  BuildDefinition definition)    at Microsoft.TeamFoundation.Pipelines.Server.Extensions.BuildCompletedEventListener2.HandleCompletedEvent(IVssRequestContext requestContext  IReadOnlyBuildData build  BuildDefinition definition)    at Microsoft.TeamFoundation.Pipelines.Server.Extensions.BuildCompletedEventListener.ProcessEvent(IVssRequestContext requestContext  NotificationType notificationType  Object notificationEvent  Int32&amp; statusCode  String&amp; statusMessage  ExceptionPropertyCollection&amp; properties)    at Microsoft.TeamFoundation.Framework.Server.TeamFoundationEventService.SubscriptionList.Notify(IVssRequestContext requestContext  NotificationType notificationType  Object notificationEventArgs  String&amp; statusMessage  ExceptionPropertyCollection&amp; properties  Exception&amp; exception) </code></pre>  <p>task.json:</p>  <pre><code>{     \""id\"": \""25156245-9317-48e2-bcf4-7dab4c130a3e\""      \""name\"": \""ping-pong-build-trigger\""      \""friendlyName\"": \""Ping Pong Build Trigger\""      \""description\"": \""Randomly trigger builds to find a sequenced build order\""      \""helpMarkDown\"": \""https://github.com/brunomartinspro/Ping-Pong-Build-Trigger-AzureDevOps\""      \""category\"": \""Build\""      \""author\"": \""Bruno Martins (brunomartins.pro)\""      \""version\"": {         \""Major\"": 1          \""Minor\"": 0          \""Patch\"": 0     }      \""instanceNameFormat\"": \""Ping Pong Build Trigger\""      \""properties\"": {         \""mode\"": {             \""type\"": \""string\""              \""description\"": \""Mode to be used\""              \""label\"": \""Mode\""              \""required\"": \""true\""         }          \""apiKey\"": {             \""type\"": \""string\""              \""label\"": \""PAT\""              \""defaultValue\"": \""\""              \""description\"": \""Personal Access Token.\""              \""required\"": \""true\""         }          \""source\"": {             \""type\"": \""string\""              \""label\"": \""AzureDevOps Project URI\""              \""defaultValue\"": \""http://kamina.azuredevops.local/DefaultCollection/Kamina\""              \""description\"": \""AzureDevOps Project URI.\""              \""required\"": \""true\""         }          \""projectName\"": {             \""type\"": \""string\""              \""label\"": \""AzureDevOps Project Name\""              \""defaultValue\"": \""Kamina\""              \""description\"": \""AzureDevOps Project Name.\""              \""required\"": \""true\""         }          \""sourceBranch\"": {             \""type\"": \""string\""              \""label\"": \""Git Source Branch\""              \""defaultValue\"": \""develop\""              \""description\"": \""The branch the builds will trigger\""              \""required\"": \""true\""         }          \""lastKnownFile\"": {             \""type\"": \""string\""              \""label\"": \""Sequence Location\""              \""defaultValue\"": \""\""              \""description\"": \""The location of the Build Order.\""              \""required\"": \""true\""         }          \""maxErrorCycles\"": {             \""type\"": \""int\""              \""label\"": \""Maximum Error Cycles\""              \""defaultValue\"": 10              \""description\"": \""The number of fails allowed.\""              \""required\"": \""true\""         }          \""infiniteCycles\"": {             \""type\"": \""string\""              \""label\"": \""Infinite Cycles\""              \""defaultValue\"": \""false\""              \""description\"": \""Infinite Cycles - only ends until everything succeeds.\""              \""required\"": \""true\""         }     }      \""inputs\"": [{             \""name\"": \""mode\""              \""type\"": \""string\""              \""label\"": \""Mode\""              \""defaultValue\"": \""AzureDevOps\""              \""helpMarkDown\"": \""Mode to be used.\""              \""required\"": \""true\""         }          {             \""name\"": \""apiKey\""              \""type\"": \""string\""              \""label\"": \""PAT\""              \""defaultValue\"": \""\""              \""helpMarkDown\"": \""Personal Access Token.\""              \""required\"": \""true\""         }          {             \""name\"": \""source\""              \""type\"": \""string\""              \""label\"": \""AzureDevOps Project URI\""              \""defaultValue\"": \""http://kamina.azuredevops.local/DefaultCollection/Kamina\""              \""helpMarkDown\"": \""AzureDevOps Project URI.\""              \""required\"": \""true\""         }          {             \""name\"": \""projectName\""              \""type\"": \""string\""              \""label\"": \""AzureDevOps Project Name\""              \""defaultValue\"": \""Kamina\""              \""helpMarkDown\"": \""AzureDevOps Project Name.\""              \""required\"": \""true\""         }          {             \""name\"": \""sourceBranch\""              \""type\"": \""string\""              \""label\"": \""Git Source Branch\""              \""defaultValue\"": \""develop\""              \""helpMarkDown\"": \""The branch the builds will trigger\""              \""required\"": \""true\""         }          {             \""name\"": \""lastKnownFile\""              \""type\"": \""string\""              \""label\"": \""Sequence Location\""              \""defaultValue\"": \""\""              \""helpMarkDown\"": \""The location of the Build Order.\""              \""required\"": \""true\""         }          {             \""name\"": \""maxErrorCycles\""              \""type\"": \""int\""              \""label\"": \""Maximum Error Cycles\""              \""defaultValue\"": 10              \""helpMarkDown\"": \""The number of fails allowed.\""              \""required\"": \""true\""         }          {             \""name\"": \""infiniteCycles\""              \""type\"": \""string\""              \""label\"": \""Infinite Cycles\""              \""defaultValue\"": \""false\""              \""helpMarkDown\"": \""Infinite Cycles - only ends until everything succeeds.\""              \""required\"": \""true\""         }     ]      \""execution\"": {         \""PowerShell\"": {             \""target\"": \""ping-pong-build-trigger.ps1\""              \""argumentFormat\"": \""\""         }     } } </code></pre>  <p>vss-extension.json</p>  <pre><code>{     \""manifestVersion\"": 1      \""id\"": \""ping-pong-build-trigger-task\""      \""name\"": \""Ping Pong Build Trigger\""      \""version\"": \""1.0.0\""      \""publisher\"": \""BrunoMartinsPro\""      \""targets\"": [{         \""id\"": \""Microsoft.VisualStudio.Services\""     }]      \""description\"": \""Randomly trigger builds to find a sequenced build order\""      \""categories\"": [         \""Azure Pipelines\""     ]      \""icons\"": {         \""default\"": \""extensionIcon.png\""     }      \""files\"": [{         \""path\"": \""task\""     }]      \""contributions\"": [{         \""id\"": \""ping-pong-build-trigger\""          \""type\"": \""ms.vss-distributed-task.task\""          \""targets\"": [             \""ms.vss-distributed-task.tasks\""         ]          \""properties\"": {             \""name\"": \""task\""         }     }] } </code></pre>  <p>How can i use a custom task in both Services and Server?</p>  <p>The .vsix can be downloaded in the release page of the Github Repository: <a href=\""https://github.com/brunomartinspro/Ping-Pong-Build-Trigger-AzureDevOps\"" rel=\""nofollow noreferrer\"">https://github.com/brunomartinspro/Ping-Pong-Build-Trigger-AzureDevOps</a></p>  <p>Developer Community: <a href=\""https://developercommunity.visualstudio.com/content/problem/715570/server-and-services-have-different-behavior.html\"" rel=\""nofollow noreferrer\"">https://developercommunity.visualstudio.com/content/problem/715570/server-and-services-have-different-behavior.html</a></p>""",azure-devops
47002514,"Azure function is not triggered locally <p>I developed my Azure function app locally using VScode and pushed it to azure cloud  I have eventhub-trigger functions  I used to debug my code locally through VScode normally  but now when I run <code>func host start --debuge</code>  functions in my app started but nothing is triggered  I can see them triggered on the cloud through their log  it drive me mad  why they are not triggered locally  they are enabled  I restarted my function app several times  but I got nothing. My app is <a href=\https://butterflyfnapp.azurewebsites.net\"" rel=\""nofollow noreferrer\"">https://butterflyfnapp.azurewebsites.net</a> </p>""",azure-functions
50766087,"My tsconfig.json cannot find a module in my node_modules directory  not sure what is wrong <p>I have the following hierarchy:</p>  <pre><code>dist/  |- BuildTasks/   |- CustomTask/    - CustomTask.js node_modules/ source/  |- BuildTasks/   |- CustomTask/    - CustomTask.ts    - tsconfig.json </code></pre>  <p>Additionally  I am trying to create a VSTS Task extension for internal (private) usage. Originally  I had my tsconfig.json at my root directory  and everything worked just fine on my local machine. The problem is that a VSTS Extension requires all the files to be included in the same directory as the task folder itself. See <a href=\https://github.com/Microsoft/vsts-task-lib/issues/274\"" rel=\""nofollow noreferrer\"">https://github.com/Microsoft/vsts-task-lib/issues/274</a> for more information:</p>  <blockquote>   <p>you need to publish a self contained task folder. the agent doesnt run   npm install to restore your dependencies.</p> </blockquote>  <hr>  <p>Originally  I had a this problem solved by include a step to copy the entire node_modules directory into each Task folder  in this case my <strong>CustomTask</strong> folder which contains my JS file. But  this seems a bit much considering that not every task I am writing has the same module requirements.</p>  <p>My idea was to create a tsconfig.json in each of the Task folders which would specify to create a single output file containing all of the dependent modules  but unfortunately it is not working:</p>  <pre><code>{   \""compilerOptions\"": {     \""baseUrl\"": \"".\""      \""target\"": \""ES6\""      \""module\"": \""system\""      \""strict\"": true      \""rootDir\"": \"".\""      \""outFile\"": \""../../../dist/BuildTasks/CustomTask/CustomTask.js\""      \""paths\"": {       \""*\"" : [\""../../../node_modules/*\""]     }   } } </code></pre>  <p>Prior to adding the \""paths\""  I was getting the following errors:</p>  <blockquote>   <p>error TS2307: Cannot find module 'vsts-task-lib/task'.<br />   error TS2307: Cannot find module 'moment'.</p> </blockquote>  <p>After adding the paths  I still get the error that it cannot find the module 'moment'  which is in my node_modules directory. Also  when I look at the output JS it seems that it didn't include the 'vsts-tasks-lib' code necessary  maybe because it still had an error in regards to the 'moment' module? Not sure what I missed?</p>""",azure-devops
48824228,"Azure deployment from GitLab is replacing App_Data folder <p>I have an app service in Azure and I have connected it with my source control on GitLab  everything works fine except one thing. When I deploy from Visual Studio I can tell that App_Data should not be replaced and it works. However  deploying from GitLab (I used this tutorial <a href=\https://christianliebel.com/2016/05/auto-deploying-to-azure-app-services-from-gitlab/\"" rel=\""nofollow noreferrer\"">https://christianliebel.com/2016/05/auto-deploying-to-azure-app-services-from-gitlab/</a>) just replaces all the files with what I have in source control  effectively removing customers data from App_Data.</p>  <p>I presume that this is just simple FTP replace (as I have to run my migrations on App_Start)  yet is there a way how to not replace App_Data folder on the app service when deploying from gitlab? Having synchronized App_Data with source control is not acceptable.</p>  <p>Thank you</p>""",azure-web-app-service
42991354,"make a backup for azure database <p>I need to make a backup to my azure database  I'm trying with this command:</p>  <pre><code>\C:\\Program Files\\Microsoft SQL Server\\120\\DAC\\bin\\SqlPackage.exe\"" /Action:Export /SourceServerName:\""tcp:MyDataServer.database.windows.net 1433\"" /SourceDatabaseName:MyDatabase /SourceUser:MyUser /SourcePassword:MyPass /TargetFile:C:\\backups\\backup.bacpac </code></pre>  <p>but it seems that the format that downloads it is \""bacpac\"" and I need it to be \"".bak\""  I tried to change the extension but says: \""The TargetFile argument must refer to a file with a '.bacpac' extension \""</p>  <p>Any idea how to download the database in \"".bak\"" format?</p>""",azure-storage
42251754,"Azure view public dns name in dashboard <p>In my virtual machine dashboard  I added the <code>public DNS name</code> column.</p>  <p>Is it supposed to be detected automatically or should I set it somewhere? If so  where?</p>  <p><a href=\https://i.stack.imgur.com/ci2rl.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/ci2rl.png\"" alt=\""Public DNS Name\""></a></p>""",azure-virtual-machine
22381548,"Azure - Multiple Cloud Services  Single Storage Account <p>I want to create a couple of cloud services - Int  QA  and Prod. Each of these will connect to separate Db's.</p>  <p><strong>Do these cloud services require \storage accounts\""?</strong> Conceptually the cloud services have executables and they must be physically located somewhere.</p>  <p>Note: I do not use any blobs/queues/tables.</p>  <p>If so  must I <strong>create 3 separate</strong> storage accounts or link them up to <strong>one</strong>?</p>""",azure-storage
50450581,"Azure Function (Service Bus): Unable to connect to remote server <p>Just before I get to the question  I must confess I'm very new to Azure Functions thus not truly understanding \the over-all\"".</p>  <p>A bit about the Environment we have an \""API\"" which inserts \""some\"" data then pushes a model to a Service Bus Queue.</p>  <p>We then have an Azure Function which triggers on Service Bus message received  admittedly this works perfect unless left for 30-60 seconds  then an error is thrown.</p>  <p>This is all done locally (VS17)... There is no logic  all I do is debug and view the contents of the message.</p>  <p>Ideally I'd like to know why I'm receiving this error to begin with  I assume behind the scenes the Azure Function needs to stay in state of active connection.</p>  <p><a href=\""https://i.stack.imgur.com/AYd4J.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/AYd4J.png\"" alt=\""enter image description here\""></a></p>  <p>I'd really appreciate some guidance  or advice on missing parameters.</p>  <p>Thanks.</p>""",azure-functions
50469011,"Copy manged disk between subscriptions <p>I'm looking into how to copy VMs from one subscriptions to another. After doing some research I found a lot of great articles describing the process on how to perform a move.</p>  <p>Examples</p>  <p><a href=\https://dzimchuk.net/moving-azure-vm-with-managed-disks-to-another-subscription/\"" rel=\""nofollow noreferrer\"">https://dzimchuk.net/moving-azure-vm-with-managed-disks-to-another-subscription/</a></p>  <p><a href=\""https://stackoverflow.com/questions/49115985/move-azure-vm-to-other-subscription-in-other-region\"">Move Azure VM to other subscription in other region</a></p>  <p>However  one thing I'm wondering is:  In the scenario of managed disk  why bother with the performing a snapshot saved to a blob > copying the blob > re-creating the VM. When you just save a snapshot to another subscription and then create a vm from that snapshot?</p>  <p>My reference:</p>  <p><a href=\""https://docs.microsoft.com/en-us/azure/virtual-machines/scripts/virtual-machines-windows-powershell-sample-copy-snapshot-to-same-or-different-subscription\"" rel=\""nofollow noreferrer\"">https://docs.microsoft.com/en-us/azure/virtual-machines/scripts/virtual-machines-windows-powershell-sample-copy-snapshot-to-same-or-different-subscription</a></p>  <p><a href=\""https://docs.microsoft.com/en-us/azure/virtual-machines/scripts/virtual-machines-windows-powershell-sample-create-vm-from-snapshot?toc=%2fpowershell%2fmodule%2ftoc.json\"" rel=\""nofollow noreferrer\"">https://docs.microsoft.com/en-us/azure/virtual-machines/scripts/virtual-machines-windows-powershell-sample-create-vm-from-snapshot?toc=%2fpowershell%2fmodule%2ftoc.json</a></p>""",azure-virtual-machine
56276686,"Cant create an Azure Web App Bot because of Resource Provider Registration Error <p>I am trying to create a bot on Azure. When I go to Home > Bot Services > Bot Service > Web App Bot > Web App Bot  and type in all of the information for my bot and click create I get an error saying \Resource provider 'Microsoft.Storage' not registered for the subscription\"". You can see this in the images below. <a href=\""https://i.stack.imgur.com/qge7Z.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/qge7Z.png\"" alt=\""enter image description here\""></a> <a href=\""https://i.stack.imgur.com/7QUN0.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/7QUN0.png\"" alt=\""enter image description here\""></a> I looked around for answers for a while and it seemed like I had to do what run the command <code>PS Azure:\\&gt; Register-AzureRmResourceProvider -ProviderNamespace Microsoft.Storage</code>. After that  when I ran <code>PS Azure:\\&gt; Get-AzureRmResourceProvider -ListAvailable | Select-Object ProviderNamespace  RegistrationState</code> to view its registration status it said \""Registering\"" (see image below). <a href=\""https://i.stack.imgur.com/GbexR.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/GbexR.png\"" alt=\""enter image description here\""></a> However  to my understanding it is only supposed to take a few minutes to register and I ran this command yesterday and it still says \""Registering\"" for me. Does anyone have any suggestions for things that I can try to solve this?</p>""",azure-storage
44743979,"Failed to install web app extension Application Insights <p>trying to install Application Insights extension on azure web service  it gives following error in portal </p>  <blockquote>   <p>Failed to install web app extension Application Insights to install   web app extension Application Insights. Heuristics indicate   WebApiClient request timed out. Uri:   <a href=\https://XXXXXXXX.azurewebsites.net/api/siteextensions/Microsoft.ApplicationInsights.AzureWebSites\"" rel=\""nofollow noreferrer\"">https://XXXXXXXX.azurewebsites.net/api/siteextensions/Microsoft.ApplicationInsights.AzureWebSites</a>   Timeout: 00:01:00</p> </blockquote>  <p>still it shows that extension is installed in the extension list.  but app does not works it gives <code>Service Unavailable HTTP Error 503. The service is unavailable.</code></p>  <p>details error json is </p>  <pre><code>{ \""authorization\"": null  \""caller\"": null  \""channels\"": null  \""claims\"": {}  \""correlationId\"": null  \""description\"": \""Failed to install web app extension Application Insights. Heuristics indicate WebApiClient request timed out. Uri: https://SITENAME.p.azurewebsites.net/api/siteextensions/Microsoft.ApplicationInsights.AzureWebSites\\r\\nTimeout: 00:01:00\""  \""eventDataId\"": null  \""eventName\"": null  \""eventSource\"": null  \""category\"": null  \""eventTimestamp\"": \""Sun Jun 25 2017 11:28:25 GMT+0530 (India Standard Time)\""  \""id\"": \""Web app extension installation failed_Sun Jun 25 2017 11:28:25 GMT+0530 (India Standard Time)\""  \""level\"": \""1\""  \""operationId\"": null  \""operationName\"": {     \""value\"": \""Web app extension installation failed\""      \""localizedValue\"": \""Web app extension installation failed\"" }  \""resourceGroupName\"": null  \""resourceProviderName\"": null  \""resourceType\"": null  \""resourceId\"": null  \""status\"": {     \""value\"": \""Error\""      \""localizedValue\"": \""Error\"" }  \""subStatus\"": null  \""submissionTimestamp\"": null  \""subscriptionId\"": null  \""properties\"": {     \""correlationIds\"": \""08c0d87b-0208-4896-8423-5c332176b0c4\"" }  \""relatedEvents\"": [] } </code></pre>  <p>Thanks</p>""",azure-web-app-service
52655284,How to map Azure Functions secrets from Key Vault automatically <p>I was wondering if it's possible to initialize the queue trigger or even the blob trigger off a connection string that is read from azure vault.  </p>  <p>Right now  we have to set these data connection via environment settings via blade properties.  However  I wanted to just use the service principal to retrieve the token for the azure key vault to get all these connection strings.</p>  <p>I'm trying to figure how to get this working in java.</p>  <p>Thanks  Derek</p>,azure-functions
47377829,VSTS change agent state from offline to online after installing it <p>i'm facing a problem with VSTS agent state is offline i installed the agent through cmd under the right pool and downloaded after that but it still offline any help please ?</p>,azure-devops
47021503,Copy and unzip archive as a part of a deployment process of a web app <p>I am developing a web application relying on SQLite database. My db file is supposed to be kept in App_Data directory. The size of the file is about 6 GB. It is not included in the project or the git repo. Deployment process should include copying a zip archive (~1 GB) with the database from azure file storage and unzipping it. How could it be done?</p>,azure-web-app-service
54682791,Setting IP Restrictions to all slots in an AppService Web App using powershell <p>I have a PS script which contains something like this to set IP restrictions on a Web App. This works great  however our PROD Web App has a Staging slot. How can I set the same restrictions in all slots? Unfortunately this is not yet supported by the portal..</p>  <pre><code># Update IP restrictions if modified $WebAppConfig.properties.ipSecurityRestrictions = $ArrayList $WebAppConfig | Set-AzureRmResource -ResourceGroupName  $ResourceGroupName -ResourceType Microsoft.Web/sites/config  -ResourceName $WebApp/web -ApiVersion $APIVersion -Force | Out-Null </code></pre>  <p>Huge thanks!</p>,azure-web-app-service
47278327,AppDynamics with Azure Functions <p>Has anybody solved to monitor Azure functions using AppDynamics ? I don't see any option to add a AppDynamics extension to the Azure functions app.</p>,azure-functions
28893546,"Set-AzureSubscription : Cannot bind parameter 'Certificate' becuase of illegal characters error <p>I am running this command on Windows 2012 server R2 with Azure Powershell</p>  <p>I am using following code for setting azure subscription </p>  <pre><code>C:\\PS&gt;$subID = &lt;Subscription ID&gt; C:\\PS&gt;$thumbprint = &lt;Certificate Thumbprint&gt;  </code></pre>  <p>Getting certificate thumbprint contain using</p>  <pre><code>C:\\PS&gt;$myCert = Get-Item cert:\\\\CurrentUser\\My\\$thumbprint | Out-String C:\\PS&gt;Set-AzureSubscription –SubscriptionName $subID –SubscriptionId $subID –Certificate `\$myCert`\"" </code></pre>  <p>But it is failing with following error</p>  <pre><code>Set-AzureSubscription : Cannot bind parameter 'Certificate'. Error: can't convert illegal characters  </code></pre>  <p>I have also tried with following code</p>  <pre><code>C:\\PS&gt;$myCert = Get-Item cert:\\\\CurrentUser\\My\\$thumbprint C:\\PS&gt;Set-AzureSubscription –SubscriptionName $subID –SubscriptionId $subID –Certificate $myCert </code></pre>  <p>Still it is failing with error Cannot bind parameter 'Certificate'</p>  <p>Thanks in advance </p>""",azure-storage
54656095,SqlClient not supported on this platform <p>I have a project for Azure Functions that has .net standard 2.0 as target framework. This project uses System.Data.Sqlclient to insert and fetch data from a db. It works fine when I deploy it to azure.</p>  <p>To be able to test my code I have created classes in this project that handle the business logic and is setup in the static function that azure executes.</p>  <p>My problem is that when I try to create a class library that is to contain unit tests  I always get an exception that says: System.Data.SqlClient is not supported on this platform. The code runs fine before that. I have tried both .net core and .net 4.6.1 as target framework but no luck.</p>,azure-functions
44289750,What is the best way to export application logs from Azure app service? <p>Our web app is hosted on Azure App Service. It generates application logs stored locally at /site/wwwroot/Log/. The logs are size limited so we have log.txt (latest)  log0.txt..log20.txt (0 is oldest). </p>  <p>I'd like to make the logs available to other members of the team without giving them ftp write access to the web application. </p>  <p>I explored providing ftp read access but that is not possible with Azure.</p>  <p>I am open to very simple solutions I can implement in a few hours as well as holistic solutions (log analysis solution  etc..). Budget is a concern.</p>  <p>We use staging slots as well so that may complicate matters but it's a secondary concern right now. </p>  <p>How can I best do this? </p>,azure-web-app-service
56809174,"How to achieve High Availability for multiple App Services in Azure <p>I have 2 same Web App and I have added them to application gateway's backed pool in Azure. I have one domain for the application Gateway and I can bind only one web app to it. Is there any way to add 2 Web App with the same domain of application gateway?</p>  <p>If not  then any other way to achieve high availability for Web Apps?</p>  <p>I want that if one Web App is not reachable  the traffic should go to other Web App. The Web Apps are not stateless and therefore ruled out the use of Traffic Manager Profile due to lack of Session Persistence.</p>  <p>I have gone through various questions mentioned below on the same topic  but none is related or have satisfactory solution. - <a href=\https://stackoverflow.com/questions/48079174/dns-high-availability-with-azure-web-apps-traffic-manager\"">DNS: High Availability with Azure Web Apps + Traffic Manager</a> - <a href=\""https://stackoverflow.com/questions/42440064/achieving-high-availability-using-azure-traffic-manager\"">Achieving High Availability using Azure Traffic Manager</a> - <a href=\""https://stackoverflow.com/questions/10257969/is-it-possible-that-one-domain-name-has-multiple-corresponding-ip-addresses\"">Is it possible that one domain name has multiple corresponding IP addresses?</a></p>""",azure-web-app-service
56258956,"How to prevent Socket Exhaustion on HttpClientHandler <p>Unlike other clients in the Microsoft.Azure.Management namespace (ie SubscriptionClient)  OperationalInsightsManagementClient does not take HttpClient as an argument in the constructor. This means I cannot use HttpClientFactory with dependency injection to prevent socket exhaustion in the normal manner. </p>  <p>(I used <a href=\https://github.com/tpeczek/HttpClientFactory.Azure.Functions\"" rel=\""nofollow noreferrer\"">https://github.com/tpeczek/HttpClientFactory.Azure.Functions</a> to implement httpclientfactory)</p>  <p>I am using Azure durable functions  fanning out to 100's of functions which all create this client each  causing the below error which I believe is caused by the above problem. The subscription Id's are often different or dynamic so I cannot reuse one OperationalInsightsManagementClient. </p>  <p>OperationalInsightsManagementClient does take a HttpClientHandler in the constructor  but how can I set this up correctly  share and manage this like a HttpClient to prevent the socket issues  assuming this is my problem.</p>  <p>The functions work fine on my local machine so far  this seems an issue when deployed to the cloud.</p>  <p>Example code:</p>  <pre><code>using Microsoft.Azure.Management.OperationalInsights;  .... operationalInsightsManagementClient = new OperationalInsightsManagementClient(myToken);  operationalInsightsDataClient.WorkspaceId = workspaceId;  try {     var response = await operationalInsightsDataClient.QueryAsync(query);     output = response?.Results; } catch (Exception e) { ...  </code></pre>  <p>Error Details from app insights:</p>  <p>Dependency duration<code>21.0 s</code><br> Remote dependency name <code>GET subscriptions/**REDACTED**/providers/Microsoft.OperationalInsights/workspaces</code></p>  <p>Failed method   <code>AzureTools.AzureClientsService+&lt;WorkSpacesAsync&gt;d__13.MoveNext</code></p>  <p>Exception type  <code>System.Net.Sockets.SocketException</code></p>  <p>Message: <code>\""A connection attempt failed because the connected party did not properly respond after a period of time  or established connection failed because connected host has failed to respond A connection attempt failed because the connected party did not properly respond after a period of time  or established connection failed because connected host has failed to respond\""</code></p>  <pre><code>Microsoft.Azure.WebJobs.Host.FunctionInvocationException:    at System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw (System.Private.CoreLib  Version=4.0.0.0  Culture=neutral  PublicKeyToken=7cec85d7bea7798e)    at Microsoft.Azure.WebJobs.Host.Executors.FunctionExecutor+&lt;ExecuteWithLoggingAsync&gt;d__19.MoveNext (Microsoft.Azure.WebJobs.Host  Version=3.0.8.0  Culture=neutral  PublicKeyToken=31bf3856ad364e35Microsoft.Azure.WebJobs.Host  Version=3.0.8.0  Culture=neutral  PublicKeyToken=31bf3856ad364e35: C:\\projects\\azure-webjobs-sdk-rqm4t\\src\\Microsoft.Azure.WebJobs.Host\\Executors\\FunctionExecutor.csMicrosoft.Azure.WebJobs.Host  Version=3.0.8.0  Culture=neutral  PublicKeyToken=31bf3856ad364e35: 321)    at System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw (System.Private.CoreLib  Version=4.0.0.0  Culture=neutral  PublicKeyToken=7cec85d7bea7798e)    at System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess (System.Private.CoreLib  Version=4.0.0.0  Culture=neutral  PublicKeyToken=7cec85d7bea7798e)    at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification (System.Private.CoreLib  Version=4.0.0.0  Culture=neutral  PublicKeyToken=7cec85d7bea7798e)    at System.Runtime.CompilerServices.TaskAwaiter`1.GetResult (System.Private.CoreLib  Version=4.0.0.0  Culture=neutral  PublicKeyToken=7cec85d7bea7798e)    at Microsoft.Azure.WebJobs.Host.Executors.FunctionExecutor+&lt;TryExecuteAsyncCore&gt;d__16.MoveNext (Microsoft.Azure.WebJobs.Host  Version=3.0.8.0  Culture=neutral  PublicKeyToken=31bf3856ad364e35Microsoft.Azure.WebJobs.Host  Version=3.0.8.0  Culture=neutral  PublicKeyToken=31bf3856ad364e35: C:\\projects\\azure-webjobs-sdk-rqm4t\\src\\Microsoft.Azure.WebJobs.Host\\Executors\\FunctionExecutor.csMicrosoft.Azure.WebJobs.Host  Version=3.0.8.0  Culture=neutral  PublicKeyToken=31bf3856ad364e35: 117) Inner exception System.Net.Http.HttpRequestException handled at System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw:    at Microsoft.Rest.RetryDelegatingHandler+&lt;SendAsync&gt;d__15.MoveNext (Microsoft.Rest.ClientRuntime  Version=2.0.0.0  Culture=neutral  PublicKeyToken=31bf3856ad364e35)    at System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw (System.Private.CoreLib  Version=4.0.0.0  Culture=neutral  PublicKeyToken=7cec85d7bea7798e)    at System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess (System.Private.CoreLib  Version=4.0.0.0  Culture=neutral  PublicKeyToken=7cec85d7bea7798e)    at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification (System.Private.CoreLib  Version=4.0.0.0  Culture=neutral  PublicKeyToken=7cec85d7bea7798e)    at System.Runtime.CompilerServices.ConfiguredTaskAwaitable`1+ConfiguredTaskAwaiter.GetResult (System.Private.CoreLib  Version=4.0.0.0  Culture=neutral  PublicKeyToken=7cec85d7bea7798e)    at System.Net.Http.HttpClient+&lt;FinishSendAsyncBuffered&gt;d__62.MoveNext (System.Net.Http  Version=4.2.1.0  Culture=neutral  PublicKeyToken=b03f5f7f11d50a3a)    at System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw (System.Private.CoreLib  Version=4.0.0.0  Culture=neutral  PublicKeyToken=7cec85d7bea7798e)    at System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess (System.Private.CoreLib  Version=4.0.0.0  Culture=neutral  PublicKeyToken=7cec85d7bea7798e)    at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification (System.Private.CoreLib  Version=4.0.0.0  Culture=neutral  PublicKeyToken=7cec85d7bea7798e)    at Microsoft.Azure.Management.OperationalInsights.WorkspacesOperations+&lt;ListWithHttpMessagesAsync&gt;d__12.MoveNext (Microsoft.Azure.Management.OperationalInsights  Version=0.19.0.0  Culture=neutral  PublicKeyToken=31bf3856ad364e35)    at System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw (System.Private.CoreLib  Version=4.0.0.0  Culture=neutral  PublicKeyToken=7cec85d7bea7798e)    at System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess (System.Private.CoreLib  Version=4.0.0.0  Culture=neutral  PublicKeyToken=7cec85d7bea7798e)    at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification (System.Private.CoreLib  Version=4.0.0.0  Culture=neutral  PublicKeyToken=7cec85d7bea7798e)    at Microsoft.Azure.Management.OperationalInsights.WorkspacesOperationsExtensions+&lt;ListAsync&gt;d__15.MoveNext (Microsoft.Azure.Management.OperationalInsights  Version=0.19.0.0  Culture=neutral  PublicKeyToken=31bf3856ad364e35)    at System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw (System.Private.CoreLib  Version=4.0.0.0  Culture=neutral  PublicKeyToken=7cec85d7bea7798e)    at System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess (System.Private.CoreLib  Version=4.0.0.0  Culture=neutral  PublicKeyToken=7cec85d7bea7798e)    at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification (System.Private.CoreLib  Version=4.0.0.0  Culture=neutral  PublicKeyToken=7cec85d7bea7798e)    at AzureTools.AzureClientsService+&lt;WorkSpacesAsync&gt;d__13.MoveNext (AzureTools  Version=1.0.0.0  Culture=neutral  PublicKeyToken=nullAzureTools  Version=1.0.0.0  Culture=neutral  PublicKeyToken=null: C:\\Users\\rspencer1\\source\\repos\\DrClaw_V2_AuditTool\\AzureTools\\AzureClientsService.csAzureTools  Version=1.0.0.0  Culture=neutral  PublicKeyToken=null: 94)    at System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw (System.Private.CoreLib  Version=4.0.0.0  Culture=neutral  PublicKeyToken=7cec85d7bea7798e)    at System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess (System.Private.CoreLib  Version=4.0.0.0  Culture=neutral  PublicKeyToken=7cec85d7bea7798e)    at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification (System.Private.CoreLib  Version=4.0.0.0  Culture=neutral  PublicKeyToken=7cec85d7bea7798e)    at AzureTools.AzureTenantService+&lt;GetUpdatesReports&gt;d__6.MoveNext (AzureTools  Version=1.0.0.0  Culture=neutral  PublicKeyToken=nullAzureTools  Version=1.0.0.0  Culture=neutral  PublicKeyToken=null: C:\\Users\\rspencer1\\source\\repos\\DrClaw_V2_AuditTool\\AzureTools\\AzureTenantService.csAzureTools  Version=1.0.0.0  Culture=neutral  PublicKeyToken=null: 56)    at System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw (System.Private.CoreLib  Version=4.0.0.0  Culture=neutral  PublicKeyToken=7cec85d7bea7798e)    at System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess (System.Private.CoreLib  Version=4.0.0.0  Culture=neutral  PublicKeyToken=7cec85d7bea7798e)    at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification (System.Private.CoreLib  Version=4.0.0.0  Culture=neutral  PublicKeyToken=7cec85d7bea7798e)    at DrClaw_V2_AuditTool.EndPoints.AzureService+&lt;GetUpdatesReports&gt;d__3.MoveNext (DrClaw_V2_AuditTool  Version=1.0.0.0  Culture=neutral  PublicKeyToken=nullDrClaw_V2_AuditTool  Version=1.0.0.0  Culture=neutral  PublicKeyToken=null: C:\\Users\\rspencer1\\source\\repos\\DrClaw_V2_AuditTool\\DrClaw_V2_AuditTool\\EndPoints\\AzureService.csDrClaw_V2_AuditTool  Version=1.0.0.0  Culture=neutral  PublicKeyToken=null: 41)    at System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw (System.Private.CoreLib  Version=4.0.0.0  Culture=neutral  PublicKeyToken=7cec85d7bea7798e)    at System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess (System.Private.CoreLib  Version=4.0.0.0  Culture=neutral  PublicKeyToken=7cec85d7bea7798e)    at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification (System.Private.CoreLib  Version=4.0.0.0  Culture=neutral  PublicKeyToken=7cec85d7bea7798e)    at System.Runtime.CompilerServices.TaskAwaiter`1.GetResult (System.Private.CoreLib  Version=4.0.0.0  Culture=neutral  PublicKeyToken=7cec85d7bea7798e)    at Microsoft.Azure.WebJobs.Host.Executors.FunctionInvoker`2+&lt;InvokeAsync&gt;d__10.MoveNext (Microsoft.Azure.WebJobs.Host  Version=3.0.8.0  Culture=neutral  PublicKeyToken=31bf3856ad364e35Microsoft.Azure.WebJobs.Host  Version=3.0.8.0  Culture=neutral  PublicKeyToken=31bf3856ad364e35: C:\\projects\\azure-webjobs-sdk-rqm4t\\src\\Microsoft.Azure.WebJobs.Host\\Executors\\FunctionInvoker.csMicrosoft.Azure.WebJobs.Host  Version=3.0.8.0  Culture=neutral  PublicKeyToken=31bf3856ad364e35: 52)    at System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw (System.Private.CoreLib  Version=4.0.0.0  Culture=neutral  PublicKeyToken=7cec85d7bea7798e)    at System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess (System.Private.CoreLib  Version=4.0.0.0  Culture=neutral  PublicKeyToken=7cec85d7bea7798e)    at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification (System.Private.CoreLib  Version=4.0.0.0  Culture=neutral  PublicKeyToken=7cec85d7bea7798e)    at System.Runtime.CompilerServices.TaskAwaiter`1.GetResult (System.Private.CoreLib  Version=4.0.0.0  Culture=neutral  PublicKeyToken=7cec85d7bea7798e)    at Microsoft.Azure.WebJobs.Host.Executors.FunctionExecutor+&lt;InvokeAsync&gt;d__27.MoveNext (Microsoft.Azure.WebJobs.Host  Version=3.0.8.0  Culture=neutral  PublicKeyToken=31bf3856ad364e35Microsoft.Azure.WebJobs.Host  Version=3.0.8.0  Culture=neutral  PublicKeyToken=31bf3856ad364e35: C:\\projects\\azure-webjobs-sdk-rqm4t\\src\\Microsoft.Azure.WebJobs.Host\\Executors\\FunctionExecutor.csMicrosoft.Azure.WebJobs.Host  Version=3.0.8.0  Culture=neutral  PublicKeyToken=31bf3856ad364e35: 584)    at System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw (System.Private.CoreLib  Version=4.0.0.0  Culture=neutral  PublicKeyToken=7cec85d7bea7798e)    at System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess (System.Private.CoreLib  Version=4.0.0.0  Culture=neutral  PublicKeyToken=7cec85d7bea7798e)    at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification (System.Private.CoreLib  Version=4.0.0.0  Culture=neutral  PublicKeyToken=7cec85d7bea7798e)    at System.Runtime.CompilerServices.TaskAwaiter.GetResult (System.Private.CoreLib  Version=4.0.0.0  Culture=neutral  PublicKeyToken=7cec85d7bea7798e)    at Microsoft.Azure.WebJobs.Host.Executors.FunctionExecutor+&lt;ExecuteWithWatchersAsync&gt;d__26.MoveNext (Microsoft.Azure.WebJobs.Host  Version=3.0.8.0  Culture=neutral  PublicKeyToken=31bf3856ad364e35Microsoft.Azure.WebJobs.Host  Version=3.0.8.0  Culture=neutral  PublicKeyToken=31bf3856ad364e35: C:\\projects\\azure-webjobs-sdk-rqm4t\\src\\Microsoft.Azure.WebJobs.Host\\Executors\\FunctionExecutor.csMicrosoft.Azure.WebJobs.Host  Version=3.0.8.0  Culture=neutral  PublicKeyToken=31bf3856ad364e35: 531)    at System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw (System.Private.CoreLib  Version=4.0.0.0  Culture=neutral  PublicKeyToken=7cec85d7bea7798e)    at System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess (System.Private.CoreLib  Version=4.0.0.0  Culture=neutral  PublicKeyToken=7cec85d7bea7798e)    at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification (System.Private.CoreLib  Version=4.0.0.0  Culture=neutral  PublicKeyToken=7cec85d7bea7798e)    at System.Runtime.CompilerServices.TaskAwaiter.GetResult (System.Private.CoreLib  Version=4.0.0.0  Culture=neutral  PublicKeyToken=7cec85d7bea7798e)    at Microsoft.Azure.WebJobs.Host.Executors.FunctionExecutor+&lt;ExecuteWithLoggingAsync&gt;d__25.MoveNext (Microsoft.Azure.WebJobs.Host  Version=3.0.8.0  Culture=neutral  PublicKeyToken=31bf3856ad364e35Microsoft.Azure.WebJobs.Host  Version=3.0.8.0  Culture=neutral  PublicKeyToken=31bf3856ad364e35: C:\\projects\\azure-webjobs-sdk-rqm4t\\src\\Microsoft.Azure.WebJobs.Host\\Executors\\FunctionExecutor.csMicrosoft.Azure.WebJobs.Host  Version=3.0.8.0  Culture=neutral  PublicKeyToken=31bf3856ad364e35: 467)    at System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw (System.Private.CoreLib  Version=4.0.0.0  Culture=neutral  PublicKeyToken=7cec85d7bea7798e)    at System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess (System.Private.CoreLib  Version=4.0.0.0  Culture=neutral  PublicKeyToken=7cec85d7bea7798e)    at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification (System.Private.CoreLib  Version=4.0.0.0  Culture=neutral  PublicKeyToken=7cec85d7bea7798e)    at System.Runtime.CompilerServices.TaskAwaiter.GetResult (System.Private.CoreLib  Version=4.0.0.0  Culture=neutral  PublicKeyToken=7cec85d7bea7798e)    at Microsoft.Azure.WebJobs.Host.Executors.FunctionExecutor+&lt;ExecuteWithLoggingAsync&gt;d__19.MoveNext (Microsoft.Azure.WebJobs.Host  Version=3.0.8.0  Culture=neutral  PublicKeyToken=31bf3856ad364e35Microsoft.Azure.WebJobs.Host  Version=3.0.8.0  Culture=neutral  PublicKeyToken=31bf3856ad364e35: C:\\projects\\azure-webjobs-sdk-rqm4t\\src\\Microsoft.Azure.WebJobs.Host\\Executors\\FunctionExecutor.csMicrosoft.Azure.WebJobs.Host  Version=3.0.8.0  Culture=neutral  PublicKeyToken=31bf3856ad364e35: 277) Inner exception System.Net.Sockets.SocketException handled at Microsoft.Rest.RetryDelegatingHandler+&lt;SendAsync&gt;d__15.MoveNext:    at System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw (System.Private.CoreLib  Version=4.0.0.0  Culture=neutral  PublicKeyToken=7cec85d7bea7798e)    at System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess (System.Private.CoreLib  Version=4.0.0.0  Culture=neutral  PublicKeyToken=7cec85d7bea7798e)    at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification (System.Private.CoreLib  Version=4.0.0.0  Culture=neutral  PublicKeyToken=7cec85d7bea7798e)    at System.Net.Http.ConnectHelper+&lt;ConnectAsync&gt;d__2.MoveNext (System.Net.Http  Version=4.2.1.0  Culture=neutral  PublicKeyToken=b03f5f7f11d50a3a) </code></pre>""",azure-functions
38132135,"Query Identities with VSTS client libraries <p>When I call ReadIdentitiesAsync on an IdentityHttpClient from the Microsoft.VisualStudio.Services.Client nuget package:</p>  <pre><code>using (var client = new IdentityHttpClient(baseUrl  credentials)) {     identities = await client.ReadIdentitiesAsync(IdentitySearchFilter.General  \user@company.com\""); } </code></pre>  <p>This exception is thrown:</p>  <blockquote>   <p>API resource location 28010c54-d0c0-4c89-a5b0-1c9e188b9fb7 is not registered on <a href=\""https://myaccount.visualstudio.com/\"" rel=\""nofollow\"">https://myaccount.visualstudio.com/</a></p> </blockquote>  <p>Is there another uri I should be using?</p>""",azure-devops
48180452,"How to define Functions trigger based on environment <p>I have an Azure Function App that has <code>ServiceBusTrigger</code> binding.</p>  <pre><code>public static void Run([ServiceBusTrigger(\my-queue\"")]string request  TraceWriter log) </code></pre>  <p>I would like to debug it locally without having to connect to an Azure Service Bus; however  there's no ASB Emulator available (<a href=\""https://stackoverflow.com/questions/37033345/using-azure-service-bus-in-local\"">Using Azure Service Bus in local</a>). Thus  my next effort is to switch to Storage Queue (as I am having Azure Storage Emulator running on my device) when debugging it locally only.</p>  <pre><code>public static void Run([QueueTrigger(\""my-queue\"")]string request  TraceWriter log) </code></pre>  <p>My question is: Do we have a way to define binding as such it will listen to Storage Queue on local environment  but will switch to Service Bus when deployed to production?</p>  <p>This sounds like XY problem  so if anyone has better idea to solve my X problem  I'm all ears.</p>""",azure-functions
46834697,"ThreadPool SetMinThreads - the impact of setting it <p>I am trying to understand the impact of setting <code>ThreadPool.SetMinthreads</code>. I have multiple virtual applications running in one Azure App Service. My understanding is that all these virtual applications will share the App Pool  and will have only one worker process (Assuming the App Pool's max worker process will be 1). </p>  <p>I have the below two questions. </p>  <ol> <li>In this setup  if I set <code>ThreadPool.SetMinThreads</code> to let's say 100 worker threads and IO threads  can I safely assume that each app domain will have 100 worker threads and 100 IO threads when it is loaded? To be precise  the ThreadPool.SetMinThreads applies within the AppDomain  or Worker Process or App Pool? What is the scope of ThreadPool?</li> <li>I also assume there is no limitation on the max threads the system can spawn as it is determined by the underlying host's capacity. This means  if I do not explicitly set ThreadPool.SetMaxThreads  the system will spawn new threads and will continue to do it if there is a continuous load till CPU/Memory spikes to the max. I am basing on the below statement to support my assumption:</li> </ol>  <blockquote>   <p>Process and threads  for example  require physical memory  virtual   memory  and pool memory  so the number of processes or threads that   can be created on a given Windows system is ultimately determined by   one of these resources  depending on the way that the processes or   threads are created and which constraint is hit first.   <strong><a href=\https://blogs.technet.microsoft.com/markrussinovich/2009/07/05/pushing-the-limits-of-windows-processes-and-threads/\"" rel=\""noreferrer\"">https://blogs.technet.microsoft.com/markrussinovich/2009/07/05/pushing-the-limits-of-windows-processes-and-threads/</a></strong></p> </blockquote>""",azure-web-app-service
45571138,"Azure Functions model binding <p>I've created an Azure Function and I'm running it locally:</p>  <pre><code>[FunctionName(\HttpTriggerCSharpSet\"")] public static async Task&lt;HttpResponseMessage&gt; Set([HttpTrigger(AuthorizationLevel.Anonymous  \""post\""  Route = null)] MyDocument req  TraceWriter log) {    // ... } </code></pre>  <p>Notice that <code>MyDocument</code> is the first parameter instead of <code>HttpRequestMessage</code>. I've read in the documentation that this approach should work  and it seems very similar to ASP.NET model binding (in my mind  anyway). <code>MyDocument</code> is a POCO with just 3 properties.</p>  <pre><code>public class MyDocument {     public string Name { get; set; }     public int ShoeSize { get; set; }     public decimal Balance { get; set; } } </code></pre>  <p>When I POST to the function like so (I'm using Postman):</p>  <p><a href=\""https://i.stack.imgur.com/Nw2Lv.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/Nw2Lv.png\"" alt=\""POST with Postman to Azure Function\""></a></p>  <p>I get an error message: <code>[8/8/2017 2:21:07 PM] Exception while executing function: Functions.HttpTriggerCSharpSet. Microsoft.Azure.WebJobs.Host: Exception binding parameter 'req'. System.Net.Http.Formatting: No MediaTypeFormatter is available to read an object of type 'MyDocument' from content</code> (which you can also see in the screenshot of Postman above)</p>  <p>I've tried form-data and x-www-form-urlencoded and even raw from Postman  same error every time. I've also tried switching back to <code>HttpRequestMessage</code> and using <code>req.Content.ReadAsAsync&lt;MyDocument&gt;</code>  and I get a similar error. Am I constructing my POST incorrectly  or am I writing my Azure Function incorrectly. In either case  what's the correct way?</p>""",azure-functions
12623271,Windows Azure Table Storage Take Issue <p>On Windows Azure table Storage I am executing the next query:</p>  <pre><code>CloudTableClient ctc=TableStorage.getTableClient(); String q1=TableQuery.generateFilterCondition(TableConstants.PARTITION_KEY  QueryComparisons.EQUAL  Long.toHexString(partitionId)); TableQuery&lt;Actividad&gt; rangeQuery=TableQuery.from(tableName  Actividad.class).where(q1).take(2); int e=0; for(Actividad ac:ctc.execute(query)){     e++; } System.out.println(e); </code></pre>  <p>But I am getting all rows on partition  not just the top 2 specified on take(2).</p>  <p>Any suggestion?</p>  <p>Answering smarx:</p>  <p>I use Wireshark to see the http requests:</p>  <p>The initial request is:</p>  <p><code>GET /actividadreciente?$filter=PartitionKey%20eq%20%2717%27&amp;$top=2&amp;timeout=60</code></p>  <p>There is a response from the service and then a lot of requests are made:</p>  <p><code>GET /actividadreciente? $filter=PartitionKey%20eq%20%2717%27&amp;$top=2&amp;NextRowKey=1%2124%21RkZGRkZFQzY2REYzMTA3Mw--&amp;timeout=60&amp;NextPartitionKey=1%214%21MTc-</code></p>  <p><code>GET /actividadreciente?$filter=PartitionKey%20eq%20%2717%27&amp;$top=2&amp;NextRowKey=1%2124%21RkZGRkZFQzY3Mjk2MEZEOA--&amp;timeout=60&amp;NextPartitionKey=1%214%21MTc-</code></p>  <p><code>GET /actividadreciente?$filter=PartitionKey%20eq%20%2717%27&amp;$top=2&amp;NextRowKey=1%2124%21RkZGRkZFQzY3Mjk5MzVGOQ--&amp;timeout=60&amp;NextPartitionKey=1%214%21MTc-</code></p>  <p>And so on.</p>,azure-storage
50567123,"While checkin in tfs  Gated checkin Builds are not getting prompted. Directly getting checked in. <p>I have gated check in TFS build   </p>  <p>While \checking in\"" in TFS its not bothering about gated check in and its directly getting checked in. What can be the reason for sudden change? </p>""",azure-devops
50738767,C# File Upload works locally; not on Azure <p>I have a C# web application which uploads an image file to Azure Blob Storage. I am passing the local path of image file from a textbox (no File Upload Controller). This application works locally as expected. But when I publish it on Azure  it throws exception.</p>  <blockquote>   <p>Could not find file (filename)</p> </blockquote>  <p>What changes should be made to run it on Azure?</p>  <p><strong>Code :</strong></p>  <pre><code>CloudBlobContainer container = Program.BlobUtilities.GetBlobClient.GetContainerReference(Container);// container              container.CreateIfNotExists();             container.SetPermissions(new BlobContainerPermissions             {                 PublicAccess = BlobContainerPublicAccessType.Blob             });             CloudBlobDirectory directory = container.GetDirectoryReference(foldername);             // Get reference to blob (binary content)             CloudBlockBlob blockBlob_image = directory.GetBlockBlobReference(imageid);                  using (var filestream = System.IO.File.OpenRead(image_path))                 {                     blockBlob_image.UploadFromStream(filestream);                 } </code></pre>,azure-storage
41066799,"Streaming Azure VM Diagnostics to EventHub <p>It is possible to stream Azure VM's diagnostics to EventHub. This article <a href=\https://docs.microsoft.com/en-us/azure/event-hubs/event-hubs-streaming-azure-diags-data\"" rel=\""nofollow noreferrer\"">https://docs.microsoft.com/en-us/azure/event-hubs/event-hubs-streaming-azure-diags-data</a> explain how to do it. The data I receive in EventHub is next: </p>  <pre><code>{ \""records\"" : [{ \""time\"" : \""2016-12-08T01:27:42.7908225Z\""  \""dimensions\"" : { \""DeploymentId\"" : \""45db964e-ae11-4f2b-a342-xxxxxxxx\""  \""Role\"" : \""IaaS\""  \""RoleInstance\"" : \""_xxxxserver01\"" }  \""metricName\"" : \""\\\\Processor Information(_Total)\\\\Processor Frequency\""  \""last\"" : 2397.0  \""timeGrain\"" : \""PT15S\"" } ] } </code></pre>  <p>There is no information about the subscription  resource group  or resource it came from  how can I get this information based on this data above? \""DeploymentId\"" looks promising but I couldn't find any information what it refers to.  If I send data to EventHub from two different resource groups but from the vms with the same names  how can I know where the perf log came from? Basically how can I correlate this perf log to actual azure vm (resource)?</p>  <p>Any guidance would be greatly appreciated.</p>""",azure-virtual-machine
42973885,How to use Go Get on azure web app <p>In theory  given that Azure now includes go support by default  I should be able to run:</p>  <p>go get github.com/etsy/hound/cmds/...</p>  <p>and have Azure pull down the necessary files but when I run that I get the following:</p>  <blockquote>   <p>D:\home\site\wwwroot   'go' is not recognized as an internal or external command    operable program or batch file.</p> </blockquote>  <p>If I cd to d:\program files\go\1.7\bin and run it again I get:</p>  <blockquote>   <p>D:\Program Files\Go\1.7\bin   go: cannot find GOROOT directory: c:\go</p> </blockquote>  <p>Is this simply a limitation of Azure web apps?</p>  <p>Thanks </p>  <p>Alex.</p>,azure-web-app-service
17090525,Queries to connect Azure Websites with SQL server in Windows Azure Virtual Machine <p>I had one requirements to migrate 1 web application and couples of databases (4) to windows azure. I had selected SQL Server standard edition to move all databases and moved my databases to sql server VM on windows azure by taking backup &amp; restore.<br> <strong>1)</strong> Is there any other method to migrate to sql server VM from on premises sql server?</p>  <p>I had selected Windows Azure websites to move web application so</p>  <p><strong>2)</strong> How can i connect above DBs to this website? Do i need to follow same steps like normal sql server by opening TCP port along with Mixed mode authentication?<BR> <strong>3)</strong> I think i do no need to create affinity group here because only 1 VM is there?<BR> <strong>4)</strong> In my web application i had used telerik controls so would it work in Windows Azure websites or Do I need to choose separate windows server on 2nd VM and follow installation step as did in normal server? <BR> <strong>5)</strong> In SQl server VM size display 127GB (os disk) so price of storage will be included in SQL server price or it will be calculated separately?<BR>  <strong>6)</strong> How can i take benefit of Virtual Network in above scenario?</p>  <p>Thanks for help in advance.</p>,azure-virtual-machine
51644301,"Upload an image to Azure Functions using HttpRequest from Postman <p>I'm having a hard time getting an image uploaded to Azure Functions using <code>HttpRequest</code>. I'm specifically using <code>HttpRequest</code> because that's what the VS templates use. I've simplified the problem to a simple test case with Postman.</p>  <p>Function:</p>  <pre><code>[FunctionName(\Function1\"")] public static async Task&lt;IActionResult&gt; Run(     [HttpTrigger(AuthorizationLevel.Anonymous  \""post\"")]HttpRequest req) {     return new CreatedResult(\""\""  req.Form.Files[0].OpenReadStream()); } </code></pre>  <p>Postman:</p>  <pre><code>Method: POST URL: [Function URL] Headers:     Content-Type: multipart/form-data Body: binary with image selected </code></pre>  <p>So what should happen is that I select a file to upload  I click \""Send\"" to upload it to the Azure Function  which should automatically return the stream and display the picture in the Postman response.</p>  <p>But when I call it from Postman  an exception is thrown when it tries to read the stream:</p>  <blockquote>   <p>\""System.IO.InvalidDataException: Missing content-type boundary.\\r\\n   at Microsoft.AspNetCore.Http.Features.FormFeature.GetBoundary(MediaTypeHeaderValue contentType  Int32 lengthLimit)\\r\\n   at Microsoft.AspNetCore.Http.Features.FormFeature.InnerReadFormAsync(CancellationToken cancellationToken)\\r\\n   at Microsoft.AspNetCore.Http.Features.FormFeature.ReadForm()\\r\\n   at Microsoft.AspNetCore.Http.Internal.DefaultHttpRequest.get_Form()\\r\\n   at [My code]\""</p> </blockquote>  <p>Now if I were to switch this to use <code>HttpRequestMessage</code> like the old Azure Function templates and use <code>req.Content.ReadAsStreamAsync()</code>  it works like a charm.</p>  <p>But since the new templates use <code>HttpRequest</code>  this question is focused on the use of <code>HttpRequest</code> and its correct use. So how can I use <code>HttpRequest</code> to get this to work?</p>""",azure-functions
47848744,"Angular5 deploy to Azure webapp: Content Security Policy <p>I want to deploy my angular5 app created with angular-cli to azure webapp service. What I did:</p>  <p>ng new testapp</p>  <p>ng build --prod --aot</p>  <p>cd dist</p>  <p>//dirty part for test case:</p>  <p>git init</p>  <p>git add *</p>  <p>git commit -m 'initial commit'</p>  <p>git remote add azure <a href=\https://user@xxx.scm.azurewebsites.net:443/xxx.git\"" rel=\""nofollow noreferrer\"">https://user@xxx.scm.azurewebsites.net:443/xxx.git</a></p>  <p>git push azure master</p>  <p>output:</p>  <blockquote>   <p>Finished successfully. remote: Running post deployment command(s)...   remote: Deployment successful. remote: App container will begin   restart within 10 seconds.</p> </blockquote>  <p>so everything seems fine. If I head to the URL after deployment is done I unfortunately receive: </p>  <p>Cannot GET/</p>  <p>with the error: </p>  <p>Content Security Policy: The page’s settings blocked the loading of a resource at self (“default-src <a href=\""http://xxx.azurewebsites.net\"" rel=\""nofollow noreferrer\"">http://xxx.azurewebsites.net</a>”). Source: ;!function(){var t=0 e=function(t e){ret.... xxx.azurewebsites.net:1</p>  <p>Every single tutorial or example I've seen so far did never bother with CSP or anything in that regard. Any help?</p>""",azure-web-app-service
52839744,"PUT request to Azure storage with shared key authorization <p>I am trying to make a put request to Azure storage  basically changing the storage properties. While I can able to make the GET request work by following the tutorial here <a href=\https://docs.microsoft.com/en-us/rest/api/storageservices/authorize-with-shared-key#Subheading2\"" rel=\""nofollow noreferrer\"">https://docs.microsoft.com/en-us/rest/api/storageservices/authorize-with-shared-key#Subheading2</a> but I dont see a proper one to construct a PUT request in there. </p>  <p>So  while searching I got this but with the get  <a href=\""https://stackoverflow.com/questions/49874783/cant-connect-to-azure-file-service-rest-api-by-python\"">can&#39;t connect to azure file service REST api by python</a> but this is again with a GET request. for the PUT request am always getting HTTP 403  I am not sure where it fails. here is the modified code from the link to depict what I am doing in my code.</p>  <pre><code>import requests import datetime import hmac import hashlib import base64  storage_account_name = 'strtest' storage_account_key = 'key' api_version = '2016-05-31' request_time = datetime.datetime.utcnow().strftime('%a  %d %b %Y %H:%M:%S GMT')  string_params = {     'verb': 'PUT'      'Content-Encoding': ''      'Content-Language': ''      'Content-Length': ''      'Content-MD5': ''      'Content-Type': 'application/xml'      'Date': ''      'If-Modified-Since': ''      'If-Match': ''      'If-None-Match': ''      'If-Unmodified-Since': ''      'Range': ''      'CanonicalizedHeaders': 'x-ms-date:' + request_time + '\\nx-ms-version:' + api_version + '\\n'      'CanonicalizedResource': '/' + storage_account_name + '/\\ncomp:properties\\nrestype:service' }  string_to_sign = (string_params['verb'] + '\\n'                   + string_params['Content-Encoding'] + '\\n'                   + string_params['Content-Language'] + '\\n'                   + string_params['Content-Length'] + '\\n'                   + string_params['Content-MD5'] + '\\n'                   + string_params['Content-Type'] + '\\n'                   + string_params['Date'] + '\\n'                   + string_params['If-Modified-Since'] + '\\n'                   + string_params['If-Match'] + '\\n'                   + string_params['If-None-Match'] + '\\n'                   + string_params['If-Unmodified-Since'] + '\\n'                   + string_params['Range'] + '\\n'                   + string_params['CanonicalizedHeaders']                   + string_params['CanonicalizedResource'])  signed_string = base64.b64encode(hmac.new(base64.b64decode(storage_account_key)  msg=string_to_sign.encode('utf-8')  digestmod=hashlib.sha256).digest()).decode()  headers = {     'x-ms-date' : request_time      'x-ms-version' : api_version      'Authorization' : ('SharedKey ' + storage_account_name + ':' + signed_string) }  url = ('https://' + storage_account_name + '.blob.core.windows.net/?restype=service&amp;comp=properties')  data = \""\""\""&lt;StorageServiceProperties&gt;&lt;/StorageServiceProperties&gt;\""\""\""  r = requests.put(url  headers = headers  data = data)  print(r.content) </code></pre>  <p>The content am trying to send is in XML format. While the code is working on GET request PUT is not. </p>""",azure-storage
33716805,Azure Windows VM - how can I find out what Resource Group it is in? <p>I have C# code running on an Azure Windows VM.  Is there a way for me to find out what Resource Group this VM is in?</p>  <p>VM has been deployed with Azure Resource Management API (new  not classic)</p>,azure-virtual-machine
53524019,"Azure dev ops -- Set Visual Studio 2017 (VS2017) as default for cloning project <p><strong>Azure dev ops -- Set Visual Studio 2017 (VS2017) as default for cloning project?</strong></p>  <p>I have multiple versions of Visual Studio installed  and for policy reasons  I need to keep them  at least for a while.</p>  <p>How do I set up Azure dev ops so that when it clones a project via \Visual Studio\"" (from the dropdown) it will automatically select VS2017 as opposed to an earlier version such as VS2015?</p>""",azure-devops
17787937,Securing Azure blob for only one user? <p>How do I secure a blob for only one user?</p>  <p>There are three options I can think of:</p>  <p>1) Shared access policy with a short expiry. - The link to the blob is accessible from anywhere for that expiry duration  and for the duration of each subsequent page request. </p>  <p>2) Have a proxy between the user request and blob storage and apply authentication here. - Though in reality there still is a publicly accessible blob for a short period of time. </p>  <p>3) We don't use blob storage for stuff that needs to be secured. </p>  <p>Am I missing a better option?</p>,azure-storage
48885511,"How to change azure portal virtual machine scale set scaling Instance count from c# code? <p>I want to increase or decrease scaling instance count from my asp.net MVC website or through power-shell command so that I can call power-shell command from website c# code.</p>  <p>I have no idea how to that. It will be great if anyone can help me through this.</p>  <p>Below attached snap will give you exact idea for what I need to increase or decrease. <a href=\https://i.stack.imgur.com/Iyn8r.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/Iyn8r.png\"" alt=\""enter image description here\""></a></p>""",azure-virtual-machine
45691251,Running Native python scripts (with arguments) using Django & controlling the underlying system using Django <p>I need some help with python  django &amp; an Windows Azure VM.</p>  <p>I have some python scripts on a Windows Server 2012 R2 VM hosted on azure that are supposed to run daily at 5am (I currently run them manually via RDP). These scripts query a web API  then receive JSON which they parse and insert into various MYSQL tables.</p>  <p>I would like to configure the Windows VM to run these python scripts daily at 5am (like a unix cron job) with arguments sourced from one of the MYSQL tables. These said arguments are used in querying the web API.</p>  <p>How do I automate the scripts such that I must not log into the VM via RDP to run them? </p>  <p>Also  I'd like to access the underlying database via django and use the same django web app to run the said repetitive scripts on demand (plus supply the arguments through the Django web app)  monitor the progress of the native python scripts and log errors  as well as control the system in entirety  edit the data on the database  etc. The Django web app will be hosted on the VM's local server. I'd like to be able to access this Django web app (using a domain/IP address) like we do normal websites hosted on cpanel Please advise me on how to go about this... </p>  <p>Thanks...</p>,azure-virtual-machine
57489132,Setting YAML variables depending on trigger branch <p>I'm trying to get my head around the yaml syntax for defining build pipelines in devops. </p>  <p>I'd like to set variables in the file dependent on which branch triggered the build. </p>  <pre><code># trigger:  batch: true  branches:    include:     - master     - develop     - staging   variables:     buildConfiguration: 'Release' # Can I set this according to the branch which triggered the build? </code></pre>  <p>I've tried the following but can't seem to define variables twice. </p>  <pre><code> variables:   solution: '**/*.sln'   buildPlatform: 'Any CPU'   variables:   condition: eq(variables['Build.SourceBranch']  'refs/heads/develop')   buildConfiguration: 'Develop'   variables:   condition: eq(variables['Build.SourceBranch']  'refs/heads/release')   buildConfiguration: 'Release' </code></pre>  <p>Thanks for your help :-)</p>,azure-devops
53686122,"How to deploy SSIS package to Azure? <p>guys. I know it is a general question. Let me give you my scenario: I have a client who sends a bunch of Excel files to me and I use my on-premise SSIS package to export it to a database located on Azure. My SSIS package does call stored procedures stored on the Azure SQL Server to manipulate the data.</p>  <p>I want to move the whole process to the cloud and I want to know what is the best way and how can we achieve it. I was thinking maybe I can use blob storage in a container and by providing a cloud folder located on Azure and let my client through the files there. Then my an app (service) such as Data Factory can detect those files and run my SSIS package that is deployed on Azure \Somehow\"". </p>  <p>Any ideas or sample code would be great.</p>  <p>Thanks!</p>""",azure-storage
50463376,"Can you delete Microsoft.Web/certificates? <p>I'm creating LetsEncrypt SSL certificates for each of our Web App Services  then binding it to the Web App and subsequently trying to delete the previous one from our Azure resources. I notice <a href=\https://docs.microsoft.com/en-us/powershell/module/azurerm.websites/remove-azurermwebappsslbinding?view=azurermps-6.0.0\"" rel=\""nofollow noreferrer\"">Remove-AzureRmWebAppSSLBinding</a> has a -DeleteCertificate flag after unbinding an SSL certificate  but I'd prefer not to unbind/delete until a new certificate has been obtained an bound.</p>  <p>Is there any other way that I can remove the certificates from Azure?</p>""",azure-web-app-service
54711117,How to setup a output variable on AzureDevOps from a npm task to pass it to other tasks? <p>Currently I'm executing a node.js task on a deploy pipeline on AzureDevops. The node task  internally  generates some data that would be helpful if could be able to output from the node task to a Pipeline variable  in order to use it on other tasks after the node.js task finishes.</p>  <p>Exists a way to do this?</p>,azure-devops
54687036,"Azure Function outgoing storage queue binding not available on context <p>I have a really simple Azure Function with the sole purpose of taking all messages included in a blob and put those messages on a storage queue.</p>  <p>I'm running Functions 2.x  the function is written in JavaScript and I've registered a blob trigger and an output binding for storage queues. </p>  <p>The problem I'm having is that the <strong>output binding isn't available</strong> in <code>ctx.bindings</code> in my function. I'm using a named output binding  because I will have multiple output bindings. When I change the output binding name to <code>$return</code> and return my data  the messages are written to the queue as expected  but when I set a different name the binding doesn't show up in the context. I can however see the binding definition in <code>ctx.bindingDefinitions</code>.</p>  <p>I'm running the code locally with Azure Function Host  with the proper extensions installed.</p>  <p>My code goes like this:</p>  <pre><code>import { Context } from '@azure/functions'  export async function run(ctx: Context   content: string): Promise&lt;void&gt; {   try {     const data = JSON.parse(content)      if (!ctx.bindings[data.queue]) {       throw new Error(`No output binding defined for queue '${data.queue}'`)     }      ctx.bindings[data.queue] = [...data.messages]   } catch (e) {     return Promise.reject(e)   } } </code></pre>  <p>And my function.json:</p>  <pre><code>{   \disabled\"": false    \""bindings\"": [    {     \""name\"": \""content\""      \""type\"": \""blobTrigger\""      \""direction\"": \""in\""      \""path\"": \""message-batches/{filename}.txt\""    }     {       \""type\"": \""queue\""        \""direction\"": \""out\""        \""name\"": \""message\""        \""queueName\"": \""message\""        \""connection\"": \""AZURE_STORAGE_CONNECTION_STRING\""     }   ]    \""scriptFile\"": \""index.js\""  } </code></pre>  <p>My incoming <code>content</code> binding is available as <code>ctx.bindings.content</code>. I'm thinking I might be missing something trivial here  but what could be the reason for the binding not to show up under <code>ctx.bindings</code>?</p>""",azure-functions
55574573,"Is there a way to remote debug a ASP.net App deployed to a virtual directory? <p>I have the need to debug an app that was deployed to a virtual directory on a azure app service. </p>  <p>Currentlly attaching the debugger from the cloud explorer attaches to the app in the root of the service and not the \child\"" app.</p>""",azure-web-app-service
56059275,"Issue mapping custom domain to Azure Web App <p>I own a domain name and am trying to map it to an Azure Web App that I successfully created.</p>  <p>I created an A record  C record  and Txt (as required by Azure) on Godaddy and configured Custom Domains in Azure (as pictured below).  The message I'm getting back now is:</p>  <blockquote>   <p>The resource you are looking for has been removed  had its name   changed  or is temporarily unavailable.</p> </blockquote>  <p>Any suggestions?</p>  <p><a href=\https://i.stack.imgur.com/6evmK.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/6evmK.png\"" alt=\""enter image description here\""></a></p>  <p><a href=\""https://i.stack.imgur.com/rQnBR.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/rQnBR.png\"" alt=\""enter image description here\""></a></p>""",azure-web-app-service
53813615,"Deploy Code from GitLab Repository to Azure Web App using PowerShell and Azure CLI <p>I would like to setup continuous deployment from a GitLab repository to an Azure App using a PowerShell script and the Azure CLI. There is already an answer for doing this using <a href=\https://stackoverflow.com/a/53729332/35483\"">the Azure RM module and Windows PowerShell</a>  but as these are <a href=\""https://docs.microsoft.com/en-us/powershell/azure/overview?view=azurermps-6.13.0\"" rel=\""nofollow noreferrer\"">now deprecated</a>  I am looking specifically for a solution that uses the new <a href=\""https://azure.microsoft.com/en-us/blog/azure-powershell-cross-platform-az-module-replacing-azurerm/\"" rel=\""nofollow noreferrer\"">Az module</a> and <a href=\""https://docs.microsoft.com/en-us/powershell/scripting/whats-new/what-s-new-in-powershell-core-60?view=powershell-6\"" rel=\""nofollow noreferrer\"">PowerShelll Core</a>.</p>  <p>The solution should give a a PowerShell (Core) script to setup a Continuous Deployment directly from GitLab to Azure. It must make use of the <a href=\""https://github.com/Azure/azure-powershell\"" rel=\""nofollow noreferrer\"">Az module</a>.  Once the setup script is run  each subsequent commit/merge to the GitLab repository should then automatically be deployed to Azure. Preferably  this PowerShell script should work for both public and private repositories that are hosted on GitLab  but I'm willing to accept solutions that only work on public repositories. </p>""",azure-web-app-service
39403657,How to delay an Azure Load Balancer Probe's first execution? <p>I have a custom azure load balancer probe which calls into our application code. The application is installed as part of creating the VM. It may take up to 10 minutes to install. In the mean time the probe is called by the load balancer  and if sufficient of the application is installed it corrupts the installation.</p>  <p>So  I would like to delay the first probe by 10 minutes. Is there a way to do this?</p>  <p>Note that I am using an ARM template to instantiate all the resources. So there may be a way to use dependsOn to have the probe be created after the last VM is available. Currently our dependency is load balancer (with Probe)  then Scale Set then VMs. That order is forced as far as I can see. </p>  <p>So is there a 'warm up' setting somewhere?</p>,azure-virtual-machine
48377018,"ES6Promise not defined with VSTS SDK <p>I have begin to work on VSTS widget (for TFS in my case). I could create/build/deploy them  and it works great.</p>  <p>But I am stuck with a problem  the SDK \VSS.SDK.min.js\"" call Promise.js and create an error when calling <code>ES6Promise.polyfill();</code> <a href=\""https://i.stack.imgur.com/iDsy5.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/iDsy5.png\"" alt=\""enter image description here\""></a></p>  <p>I have created my widgets in Typescript and the calls are made with require.js. </p>  <p>To resolve my problem I have tried to include \""es6-promise\"" in my project  include it in the call  set it to Auto-polyfill (with <code>require('es6-promise').polyfill();</code>) but the problem is still here.</p>  <p>My tsconfig.json is set with</p>  <pre><code>\""compilerOptions\"": {    \""target\"": \""es5\""     \""module\"": \""amd\""     \""lib\"": [      \""es5\""       \""es6\""       \""dom\""       \""es2015\""       \""es2015.promise\"" /* should be useless since es2015 is already here */    ]      \""strict\"": true       \""types\"": [       \""vss-web-extension-sdk\""        \""requirejs\""        \""jquery\""        \""es6-promise\""    ]  </code></pre>  <p>It's not an error that block me because the problem only appears on the debug console  but an error is still and error.</p>  <p>As <code>VSS.SDK.min.js</code> is running on the server  I am wondering if the problem is in my widget or if a configuration is missing on the TFS server.</p>  <p>I have the error on \""IE11 / Chrome / FF\"".</p>  <p>Any help would be welcome and if you need any more information to give me a hint  I will gladly upgrade my question.</p>  <p><strong>update</strong></p>  <p>The problem seems to be on the call <code>VSS.require(\""TFS/Dashboards/WidgetHelpers\""  function (WidgetHelpers) {</code></p>  <p>Maxime</p>""",azure-devops
47948706,Azure function to access AWS Elastic Search with IP access rules <p>I am trying to access elastic search instance from azure functions app  after adding the IP address into AWS access policy functions app supposedly lives on I get the error as if it indeed wasn't added. I know for sure this approach works I have other IPs in white-listed yet one from Azure just doesn't seem to work.</p>,azure-functions
40858448,how to access the azure web app application setting values in to typescript file <p>I had developed angular 2 application using visual studio 2015. then after I have published my angular2 web app into azure web app it's working everything fine but I am not able to get the azure web app application setting values into my typescript file of angular 2 web app.</p>  <p>Can you please share how to access the azure web app application setting values in to any typescript file.</p>  <p>-Pradeep</p>,azure-web-app-service
52146666,"Azure App Service - CORS OAUTH2 error when accessing PWA webmanifest.json <p>I'd like to add PWA functionality to my App Service. It's written in C# ASP.NET. However  Chrome is unable to access the manifest and Edge don't even get the favicon (which might be a separate issue). Other desktop browsers apparently don't have PWA functionality yet.</p>  <p>Chrome is the only browser that requests the manifest. Here's the error message in my console:</p>  <pre><code>Failed to load https://login.windows.net/b79fd714-9c54-449d-b377-3b59deb2d3b6/oauth2/authorize?response_type=code+id_token&amp;redirect_uri=https%3A%%{myappname}.azurewebsites.net%.auth%2Flogin%2Faad%2Fcallback&amp;client_id=67bedd5c-5478-44ec-ba13-85061c71114b&amp;scope=openid+profile+email&amp;response_mode=form_post&amp;nonce=df52b6dc64dd4c3393957675f365ae93_20180903064438&amp;state=redir%3D%252Fwebmanifest.json: Redirect from 'https://login.windows.net/b79fd714-9c54-449d-b377-3b59deb2d3b6/oauth2/authorize?response_type=code+id_token&amp;redirect_uri=https%3A%%{myappname}.azurewebsites.net%.auth%2Flogin%2Faad%2Fcallback&amp;client_id=67bedd5c-5478-44ec-ba13-85061c71114b&amp;scope=openid+profile+email&amp;response_mode=form_post&amp;nonce=df52b6dc64dd4c3393957675f365ae93_20180903064438&amp;state=redir%3D%252Fwebmanifest.json' to 'https://login.microsoftonline.com/b79fd714-9c54-449d-b377-3b59deb2d3b6/oauth2/authorize?response_type=code+id_token&amp;redirect_uri=https%3A%%{myappname}.azurewebsites.net%.auth%2Flogin%2Faad%2Fcallback&amp;client_id=67bedd5c-5478-44ec-ba13-85061c71114b&amp;scope=openid+profile+email&amp;response_mode=form_post&amp;nonce=df52b6dc64dd4c3393957675f365ae93_20180903064438&amp;state=redir%3D%252Fwebmanifest.json' has been blocked by CORS policy: No 'Access-Control-Allow-Origin' header is present on the requested resource. Origin 'https://{myappname}.azurewebsites.net' is therefore not allowed access. </code></pre>  <p><strong>It would appear that my AAD authentication  which I enabled in the App Service  is interfering with my browser's manifest request.</strong> </p>  <p>I understand that to resolve this issue quickly  Microsoft would have to add this application to their CORS. This is certainly not something I would expect to happen. However  I need some alternative way to let the browser access the manifest.</p>  <p>I have added the necessary mimeMaps to my <code>web.config</code>.</p>  <pre><code>&lt;staticContent&gt;   &lt;remove fileExtension=\.json\"" /&gt;   &lt;mimeMap fileExtension=\"".json\"" mimeType=\""application/json\"" /&gt;   &lt;remove fileExtension=\"".webmanifest\"" /&gt;   &lt;mimeMap fileExtension=\"".webmanifest\"" mimeType=\""application/json\"" /&gt; &lt;/staticContent&gt; </code></pre>  <p>Here's the top part of my <code>Head</code>:</p>  <pre><code>&lt;!DOCTYPE html&gt; &lt;html&gt; &lt;head&gt;     &lt;meta http-equiv=\""content-type\"" content=\""text/html; charset=utf /&gt;     &lt;meta name=\""viewport\"" content=\""width=device-width  initial-scale=&gt;      &lt;link rel=\""apple-touch-icon\"" sizes=\""180x180\"" href=\""/apple-touch-icon.png\""&gt;     &lt;link rel=\""icon\"" type=\""image/png\"" sizes=\""32x32\"" href=\""/favicon-32x32.png\""&gt;     &lt;link rel=\""icon\"" type=\""image/png\"" sizes=\""16x16\"" href=\""/favicon-16x16.png\""&gt;     &lt;link rel=\""manifest\"" href=\""/webmanifest.json\""&gt;     &lt;link rel=\""mask-icon\"" href=\""/safari-pinned-tab.svg\"" color=\""#5bbad5\""&gt;     &lt;meta name=\""apple-mobile-web-app-title\"" content=\""{myappname}\""&gt;     &lt;meta name=\""application-name\"" content=\""{myappname}\""&gt;     &lt;meta name=\""msapplication-TileColor\"" content=\""#da532c\""&gt;     &lt;meta name=\""theme-color\"" content=\""#ffffff\""&gt;       &lt;title&gt;@ViewBag.Title - {myappname}&lt;/title&gt; </code></pre>  <p>If I was using some kind of AJAX request  I'd follow one of the <a href=\""https://blogs.msdn.microsoft.com/aaddevsup/2018/05/09/receiving-cors-redirection-error-when-signing-into-app-service-using-azure-ad/\"" rel=\""nofollow noreferrer\"">tutorials</a> on the web. However  I have little to no control over the header  as far as I know.</p>  <p>Note: All occurrences of my app's name have been replaced with {myappname}. I really hope that those tokens are temporary...</p>  <hr>  <p>In the tutorial link above  there's a relevant block of text that explains my issue better than my question itself:</p>  <blockquote>   <p>In a typical scenario after a user authenticates to Azure AD to log   into an application  Azure App Service sets a cookie called   “AppServiceAuthSession” for that authenticated session with the client   browser. The web application may use XMLHttpRequest / AJAX request for   various functionality of the application and the request sent to Azure   App Service would also contain the AppServiceAuthSession cookie. When   this cookie is not present in the request  Azure App Service will   redirect the request to Azure AD for login. This redirection causes   the AJAX request to become a CORS request since the destination domain   changes and Azure AD by default does not allow cross origin request.</p> </blockquote>  <p>In my case the browser is sending a request for the manifest that does not contain the necessary header.</p>""",azure-web-app-service
40992865,How can we get messages from a particular event hub partition into azure function and how to automatically scale up number of azure function? <p>I can get the messages from all the partitions of event hub in azure function but I want to get messages from a particular event hub partition in azure function. Is there a way to do that ? And one other thing I want to do is to increase (scale out) the number of azure functions to process messages if there are large number of backlogs messages to process. How can I do that ? Is there any formulae to solve my second problem ?</p>,azure-functions
32329361,Is there way to create HYBRID CONNECTIONS for azure could service or azure VM? <p>I azure we can create Hybrid connection to local sql server from Web Sites and Mobile Service. But I need to create Hybrid service to My Local SQL server from VM or cloud service. Is there anyway to achieve this one?</p>,azure-virtual-machine
55098229,"Append data to existing file in Azure Datalake Storage Gen2 Using Rest API <p>Rest API available for Azure DataLake Gen2. the documentation is <a href=\https://docs.microsoft.com/vi-vn/rest/api/storageservices/datalakestoragegen2/path/update#request-body\"" rel=\""nofollow noreferrer\"">here</a>. Does anyone have examples for the postman or anything like that? </p>""",azure-storage
10040723,"Deploying web service from the Windows Azure toolkit for Windows Phone 7 <p>For a few days now I have been playing around with the Windows Azure toolkit for Windows Phone 7. I have recently been trying to deploy my web services to windows azure. I am having a problem with getting the certificate to work properly.</p>  <p>I have followed this walk through(minus the Apple Push Notification part) without any luck. <a href=\http://www.wadewegner.com/2011/05/deploying-your-services-from-the-windows-azure-toolkit-for-windows-phone-7/\"" rel=\""nofollow\"">http://www.wadewegner.com/2011/05/deploying-your-services-from-the-windows-azure-toolkit-for-windows-phone-7/</a></p>  <p>Everything deployed to the cloud fine but when I tested it on the phone  I pressed the \""install certificate\"" button and I always get an error saying the page cannot be found etc.</p>  <p>Any reason why this is doing this?</p>  <p>Thank you.</p>""",azure-storage
49549628,Enable Fusion logs Azure Web Job <p>I've a problem with an Azure Web Job  it runs locally  but it does not run on Azure. The problem is due to:</p>  <pre><code>Unhandled Exception: System.IO.FileLoadException: Could not load file or  assembly 'Newtonsoft.Json  Version=9.0.0.0  Culture=neutral   PublicKeyToken=30ad4fe6b2a6aeed' or one of its dependencies. The located  assembly's manifest definition does not match the assembly reference.  (Exception from HRESULT: 0x80131040) at  Microsoft.Azure.WebJobs.ConverterManager..ctor()nat  Microsoft.Azure.WebJobs.JobHostConfiguration..ctor(String  dashboardAndStorageConnectionString) </code></pre>  <p>I've installed <code>Newtonsoft 10.0.0</code> (this version is required by some libraries) and set up the assembly redirect in the app.config but it's not working.</p>  <p>Do you know how to enable Fusion on an Azure Web Job? Or how to investigate this kind of problems?</p>  <p>Thanks!</p>,azure-web-app-service
28997810,"Get storage account of Azure VM <p>I am trying to find PowerShell cmdlet which can retrieve information about which storage account Azure VM use.  Example  I want to supply name of VM and I would like to see which storage that VM use. Or it will be also good to query specific storage account and see which VMs use this storage account.</p>  <p>I am trying following cmdlets but I cannot see details about storage account:</p>  <pre><code>Select-AzureSubscription -SubscriptionName \name\"" Get-AzureVM -Name \""name\"" -ServiceName \""name\"" </code></pre>""",azure-virtual-machine
56975760,TFS Customized security groups at collection level <p>We have group of developers  Testers &amp; BA's who will work for more that 30 projects under collection  so instead of adding them for each project want to create security groups at collection level so everyone will have access to all the projects under collection. On TFS  we want to have customized groups like Developers  Testers  BA's  at collection level so they will have access to all the projects so that I don't need to add them for each project. </p>  <p>So instead of adding them for each project want to create security groups at collection level so everyone will have access to all the projects under collection? So how can I do that!!!</p>,azure-devops
53009587,Does a running Azure Function complete or terminated when you publish a new version? <p>Does anyone know What happens to a currently running Azure Function (.NET Core) if you Publish at the same time as it is running:</p>  <p>Does it: 1. Complete its work and first run with the updated code next time 2. Gets terminated in the middle of the run? 3. Something else?</p>  <p>My guess is 1 but countless Google search leave me without answer :-(</p>,azure-functions
21856363,"Server failed to authenticate the request. Make sure the value of Authorization header is formed correctly including the signature <p>I noticed that my computer timezone was set to <code>(UTC-08:00) Pacific Time (US &amp; Canada)</code>  so I changed it to <code>(UTC+08:00) Kuala Lumpur  Singapore</code>.<br> And then when I open Azure storage explorer  it shows up the error below.  </p>  <p><img src=\https://i.stack.imgur.com/Bwc9n.png\"" alt=\""enter image description here\"">  </p>  <p>I tried uninstalling Azure Storage Explorer  but the error still exist.</p>""",azure-storage
53638380,"How to install a PowerShell module on an Azure web app without administrator permissions? <p>I am working on an internal tool that is meant to automatize app deployment on Azure. It is actually an MVC application where a user can upload zip-packages containing other apps and afterwards those get deployed on Azure (each of them to its own app service). Until now I was using \Microsoft.Azure.Management.Fluent\"" in C# which made things easy. Unfortunately it didn't allow me to make the kind of configurations I needed to make especially on Application gateway. Fortunately PowerShell does. I have already wrote the script that does everything I need. I can publish that script in my azure web app. The problem is that <code>AzureRM</code> module (which is a required module) is missing there. Also  I am not able to install it since I get an \""You are not an administrator...\"" error (likely because I'm not an administrator on the actual Azure web app). Any ideas on how to install a PS module in an Azure web app?</p>  <p>Update: I know I can use Azure API in order to achieve my goal  but I would like to be able to run a normal PowerShell script (at least it's more readable).</p>  <p>Update 2 :) It seems like there is no way to install a PS module beside an web app since resources are shared and so on. I have decided to abandon using powershell with azureRM and execute api calls from my c# app.</p>""",azure-web-app-service
52115709,VSTS Deploy multiple pipelines <p>right now I have configured multiple pipelines  each pipeline has its own tasks and variables. To deploy all I need to manually deploy one by one. </p>  <p>Is it possible to create a pipeline that triggers other pipelines to combine my release definition so I could trigger all with single click ? </p>,azure-devops
55956292,"Error updating AppSetting with name is not allowed from Terraform <p>While updating an Azure App Service App Setting with Terraform we're getting the following error:</p>  <pre><code>{\Message\"":\""AppSetting with name 'HEALTHCHECKS-UI_HEALTHCHECKS_0_NAME' is not allowed.\""} </code></pre>  <p>However if we add it via the portal manual it works totally fine: <a href=\""https://i.stack.imgur.com/BR3Di.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/BR3Di.png\"" alt=\""enter image description here\""></a></p>  <p>I'm guessing it's something to do with the <code>0</code> or <code>-</code> but how do we escape these?</p>  <p>The Terraform code is pretty simple but here is a failing example:</p>  <pre><code>resource \""azurerm_resource_group\"" \""test\"" {   name     = \""example-resources\""   location = \""West Europe\"" }  resource \""azurerm_app_service_plan\"" \""test\"" {   name                = \""example-appserviceplan\""   location            = \""${azurerm_resource_group.test.location}\""   resource_group_name = \""${azurerm_resource_group.test.name}\""    sku {     tier = \""Standard\""     size = \""S1\""   } }  resource \""azurerm_app_service\"" \""test\"" {   name                = \""example-app-service\""   location            = \""${azurerm_resource_group.test.location}\""   resource_group_name = \""${azurerm_resource_group.test.name}\""   app_service_plan_id = \""${azurerm_app_service_plan.test.id}\""    site_config {     dotnet_framework_version = \""v4.0\""     scm_type                 = \""LocalGit\""   }    app_settings = {     \""HEALTHCHECKSUI_HEALTHCHECKS_0_NAME\""  = \""Self\""     \""HEALTHCHECKSUI_HEALTHCHECKS_0_URI\""   = \""https://${var.environment_name}-example-app-service/health-api\""   } } </code></pre>  <p>Dropping into the bash terminal in kudo and running <code>printenv</code> shows that setting it manually removes the <code>-</code>:</p>  <pre><code>HEALTHCHECKSUI_HEALTHCHECKS_0_NAME=https://example-app-service.azurewebsites.net/health-api </code></pre>""",azure-web-app-service
26073068,"Why can I programmatically connect to my Visual Studio Online Project without Credentials? <p>I have a ASP.NET application and wanted to display the last few changesets on a Page. With this Code I get the latest Changesets:</p>  <pre><code>TfsTeamProjectCollection projectCollection     = TfsTeamProjectCollectionFactory.GetTeamProjectCollection(     new Uri(\https://my.visualstudio.com/DefaultCollection\"")); var versionControl = projectCollection.GetService&lt;VersionControlServer&gt;();  var history = versionControl.QueryHistory(         path: \""$/project\""          version: VersionSpec.Latest          deletionId: 0          recursion: RecursionType.Full          user: String.Empty          versionFrom: null          versionTo: VersionSpec.Latest          maxCount: 5          includeChanges: false          slotMode: true);  foreach (Changeset change in history) {     [...] } </code></pre>  <p>I didn't expect it to work at first  but then it worked like a charm  without Credentials. This makes me slightly nervous as I didn't change any Permissions on the project let alone make it \""public\"" (if this is even possible). If I browse to the Project anonymously in a Browser I have to Login with my Live-ID.</p>  <p>So can anyone access my data if he has the adress? And how can I disable this?</p>""",azure-devops
54213322,"Query to update a table contents in azure table storage <p>Is it possible to update a column using Query in azure table storage ? The table has already 100 records and now I have added a new column. For the previous 100 records   the newly added column value is \null\"" as shown in the image. I just want to set a default value for all the 100 records. I need to know how to update the table. </p>  <p><a href=\""https://i.stack.imgur.com/brhHB.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/brhHB.png\"" alt=\""image\""></a></p>""",azure-storage
55411029,"Azure Powershell - Az module not working on Ubuntu hosted build agent <p>I have a build running in Azure DevOps  on an Ubuntu 16.04 hosted build agent. I'm using the latest version of the \Azure Powershell\"" task (version 4.* preview)  which is supposed to be multi-platform  support Powershell core  and support using the <a href=\""https://docs.microsoft.com/en-us/powershell/azure/new-azureps-module-az\"" rel=\""nofollow noreferrer\"">Azure Powershell Az module</a>.</p>  <p><a href=\""https://i.stack.imgur.com/2fFL7.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/2fFL7.png\"" alt=\""Azure Powershell Task Version 4\""></a></p>  <p>However  it doesn't quite work. Before running any of my script  it errors out with:</p>  <pre><code>##[section]Starting: Azure PowerShell script: InlineScript ============================================================================== Task         : Azure PowerShell Description  : Run a PowerShell script within an Azure environment Version      : 4.0.0 Author       : Microsoft Corporation Help         : [More Information](https://go.microsoft.com/fwlink/?LinkID=613749) ============================================================================== ##[warning]Can\\'t find loc string for key: GeneratingScript GeneratingScript [command]/usr/bin/pwsh -NoLogo -NoProfile -NonInteractive -ExecutionPolicy Unrestricted -Command . '/home/vsts/work/_temp/e66222aa-283d-4dfd-b5c1-f1d2a4a3ba9f.ps1' Could not find the module Az.Accounts with given version. If the module was recently installed  retry after restarting the Azure Pipelines task agent. At /home/vsts/work/_tasks/AzurePowerShell_72a1931b-effb-4d2e-8fd8-f8472a07cb62/4.0.0/InitializeAz.ps1:25 char:5 +     throw (\""Could not find the module Az.Accounts with given version. ... +     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ + CategoryInfo          : OperationStopped: (Could not find ...nes task agent.:String) []  RuntimeException + FullyQualifiedErrorId : Could not find the module Az.Accounts with given version. If the module was recently installed  retry after restarting the Azure Pipelines task agent.  ##[error]PowerShell exited with code '1'. ##[error]PowerShell wrote one or more lines to the standard error stream. ##[section]Finishing: Azure PowerShell script: InlineScript </code></pre>  <p>The Az Powershell module appears to work/load correctly on the Windows VS2017 hosted agent  but no luck on Ubuntu. Any recommendations on fixing this?</p>""",azure-devops
12694294,How to create subdomains for virtual machine on Azure <p>I have VM on myvmname.cloudapp.net. What I want is to create subdomain for this subdomain.myvmname.cloudapp.net. How can I do it? </p>,azure-virtual-machine
55318321,Notifications in my .netcore 2.1 MVC deployed on Azure Linux WebApp <p>My application is .Net Core 2.1 MVC. I am also using jQuery. This application is deployed as an Azure Linux WebApp.</p>  <p>The users can see this website from desktop-based browsers like IE  Chrome  Safari etc. as well as from Iphone  IPad and Android mobile devices.</p>  <p>My backend's database is Azure MySQL 5.7. I have created a notification table in MySQL. The backend populates this notification table. The notification records may be applicable to a specific user or a group of users.</p>  <p>If a user is online  they should see the live updates (count and notification text).</p>  <p>Is Azure SignalR service or Azure Notification Hub the right choice for implementing this?</p>,azure-web-app-service
53614701,"Docker containers takes too much time to process tasks <p>I am using 3 containers as microservices and RabbitMQ for communication b/w them. I am using azure VMs for running the container. The machine has <strong>64 GB ram and 32 cores</strong>. The architecture is given below <a href=\https://i.stack.imgur.com/AY3hR.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/AY3hR.png\"" alt=\""enter image description here\""></a></p>  <p>Container C1: A python web server just to receive request and small db operation Container C2: Processing but not intensive Container C3: Processing High Intensive tasks</p>  <p>When i try to process one web request it takes around 20 mins including all container (C3 takes around 90% of that). Then I tested with high cores machine (eg.  <strong>64 core  128 GB RAM and 72 cores and 144 GB RAM</strong>) I was shocked to see that time also increases but I guess it should be less because there are large cpu cores.</p>  <p>Using htop I can see that <strong>C3</strong> container uses all cores 100%. When i tried with multiple web requests (=10) time took to complete processing for one request is around 40-50 mins becuase they all are handled in parallel in C2 &amp; C3. I dont see the use of large number of cpu cores in docker containers. Is there is any thing wrong with the architecture or should i start new containers for ever web request (C2 &amp; C3).</p>""",azure-virtual-machine
40816302,"Connecting to Azure Storage Emulator always throws ArgumentNullException: Value cannot be null <p>Here is my code:</p>  <pre><code>CloudStorageAccount storageAccount = CloudStorageAccount.Parse(\UseDevelopmentStorage=true\"");  CloudBlobClient client = storageAccount.CreateCloudBlobClient();  CloudBlobContainer container = client.GetContainerReference(\""testname\""); </code></pre>  <p>I keep getting the following error:</p>  <pre><code>[ArgumentNullException: Value cannot be null. Parameter name: source]    Microsoft.WindowsAzure.Storage.Blob.CloudBlockBlob.UploadFromStreamHelper(Stream source  Nullable`1 length  AccessCondition accessCondition  BlobRequestOptions options  OperationContext operationContext) in c:\\Program Files (x86)\\Jenkins\\workspace\\release_dotnet_master\\Lib\\ClassLibraryCommon\\Blob\\CloudBlockBlob.cs:336    Microsoft.WindowsAzure.Storage.Blob.CloudBlockBlob.UploadFromStream(Stream source  AccessCondition accessCondition  BlobRequestOptions options  OperationContext operationContext) in c:\\Program Files (x86)\\Jenkins\\workspace\\release_dotnet_master\\Lib\\ClassLibraryCommon\\Blob\\CloudBlockBlob.cs:308    LSS.Infrastructure.Services.Storage.AzureBlobStorageService.UploadCompanyFile(Guid companyId  Guid documentId  Stream file) in M:\\Development\\IllinoisLendingCorp\\LoanServicingSystem\\LSS.Infrastructure\\Services\\Storage\\AzureBlobStorageService.cs:26    LSS.Admin.Areas.Loans.Controllers.LoanController.Detail(Guid id) in M:\\Development\\IllinoisLendingCorp\\LoanServicingSystem\\LSS.Admin\\Areas\\Loans\\Controllers\\LoanController.cs:107    lambda_method(Closure   ControllerBase   Object[] ) +122    System.Web.Mvc.ActionMethodDispatcher.Execute(ControllerBase controller  Object[] parameters) +14    System.Web.Mvc.ReflectedActionDescriptor.Execute(ControllerContext controllerContext  IDictionary`2 parameters) +157    System.Web.Mvc.ControllerActionInvoker.InvokeActionMethod(ControllerContext controllerContext  ActionDescriptor actionDescriptor  IDictionary`2 parameters) +27    System.Web.Mvc.Async.AsyncControllerActionInvoker.&lt;BeginInvokeSynchronousActionMethod&gt;b__39(IAsyncResult asyncResult  ActionInvocation innerInvokeState) +22    System.Web.Mvc.Async.WrappedAsyncResult`2.CallEndDelegate(IAsyncResult asyncResult) +29    System.Web.Mvc.Async.WrappedAsyncResultBase`1.End() +49    System.Web.Mvc.Async.AsyncControllerActionInvoker.EndInvokeActionMethod(IAsyncResult asyncResult) +32    System.Web.Mvc.Async.AsyncInvocationWithFilters.&lt;InvokeActionMethodFilterAsynchronouslyRecursive&gt;b__3d() +50    System.Web.Mvc.Async.&lt;&gt;c__DisplayClass46.&lt;InvokeActionMethodFilterAsynchronouslyRecursive&gt;b__3f() +225    System.Web.Mvc.Async.&lt;&gt;c__DisplayClass33.&lt;BeginInvokeActionMethodWithFilters&gt;b__32(IAsyncResult asyncResult) +10    System.Web.Mvc.Async.WrappedAsyncResult`1.CallEndDelegate(IAsyncResult asyncResult) +10    System.Web.Mvc.Async.WrappedAsyncResultBase`1.End() +49    System.Web.Mvc.Async.AsyncControllerActionInvoker.EndInvokeActionMethodWithFilters(IAsyncResult asyncResult) +34    System.Web.Mvc.Async.&lt;&gt;c__DisplayClass2b.&lt;BeginInvokeAction&gt;b__1c() +26    System.Web.Mvc.Async.&lt;&gt;c__DisplayClass21.&lt;BeginInvokeAction&gt;b__1e(IAsyncResult asyncResult) +100    System.Web.Mvc.Async.WrappedAsyncResult`1.CallEndDelegate(IAsyncResult asyncResult) +10    System.Web.Mvc.Async.WrappedAsyncResultBase`1.End() +49    System.Web.Mvc.Async.AsyncControllerActionInvoker.EndInvokeAction(IAsyncResult asyncResult) +27    System.Web.Mvc.Controller.&lt;BeginExecuteCore&gt;b__1d(IAsyncResult asyncResult  ExecuteCoreState innerState) +13    System.Web.Mvc.Async.WrappedAsyncVoid`1.CallEndDelegate(IAsyncResult asyncResult) +29    System.Web.Mvc.Async.WrappedAsyncResultBase`1.End() +49    System.Web.Mvc.Controller.EndExecuteCore(IAsyncResult asyncResult) +36    System.Web.Mvc.Controller.&lt;BeginExecute&gt;b__15(IAsyncResult asyncResult  Controller controller) +12    System.Web.Mvc.Async.WrappedAsyncVoid`1.CallEndDelegate(IAsyncResult asyncResult) +22    System.Web.Mvc.Async.WrappedAsyncResultBase`1.End() +49    System.Web.Mvc.Controller.EndExecute(IAsyncResult asyncResult) +26    System.Web.Mvc.Controller.System.Web.Mvc.Async.IAsyncController.EndExecute(IAsyncResult asyncResult) +10    System.Web.Mvc.MvcHandler.&lt;BeginProcessRequest&gt;b__5(IAsyncResult asyncResult  ProcessRequestState innerState) +21    System.Web.Mvc.Async.WrappedAsyncVoid`1.CallEndDelegate(IAsyncResult asyncResult) +29    System.Web.Mvc.Async.WrappedAsyncResultBase`1.End() +49    System.Web.Mvc.MvcHandler.EndProcessRequest(IAsyncResult asyncResult) +28    System.Web.Mvc.MvcHandler.System.Web.IHttpAsyncHandler.EndProcessRequest(IAsyncResult result) +9    System.Web.CallHandlerExecutionStep.System.Web.HttpApplication.IExecutionStep.Execute() +9765121    System.Web.HttpApplication.ExecuteStep(IExecutionStep step  Boolean&amp; completedSynchronously) +155 </code></pre>  <p>I'm not sure what I'm missing. My emulator is on and running.</p>  <p>Here is the rundown of my tool versions:</p>  <p>Emulator: 4.5.0.0 WindowsAzure.Storage Package: 7.2.1</p>""",azure-storage
54055520,"Flask /w SQLAlchemy - (sqlite3.OperationalError) database is locked.when deployed as Azure App Service <p>Attempting to deploy a Flask Web Application with a Log-In form using SQLAlchemy and SQLITE3. The application behaves as expected when running locally. However  when deployed as Azure Web Service  it is not possible to access or write to the database. Doint so results in follwing error output:</p>  <pre><code>500 Internal Server Error 2019-01-05T19:13:30.235301217Z [2019-01-05 19:13:30 198] ERROR in app: Exception on /register [POST] 2019-01-05T19:13:30.235339017Z Traceback (most recent call last): 2019-01-05T19:13:30.235343817Z   File  ... 2019-01-05T19:13:30.235502017Z   File \/home/site/wwwroot/antenv/lib/python3.7/site-packages/sqlalchemy/engine/base.py\""  line 724  in _commit_impl 2019-01-05T19:13:30.235505417Z     self.engine.dialect.do_commit(self.connection) 2019-01-05T19:13:30.235508817Z   File \""/home/site/wwwroot/antenv/lib/python3.7/site-packages/sqlalchemy/engine/default.py\""  line 462  in do_commit 2019-01-05T19:13:30.235512317Z     dbapi_connection.commit() 2019-01-05T19:13:30.235624616Z sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) database is locked (Background on this error at: http://sqlalche.me/e/e3q8) </code></pre>  <p>I have troubles investigating this error as it behaves as expected locally. The Azure Web App is in a resource group not visible to others so this can not be the source of a concurrency conflict.</p>  <p>models.py</p>  <pre><code>from flask_login import UserMixin from werkzeug.security import check_password_hash from werkzeug.security import generate_password_hash  from app.extensions import db from app.extensions import login   @login.user_loader def load_user(id):     return User.query.get(int(id))   class User(UserMixin  db.Model):     id = db.Column(db.Integer  primary_key=True)     username = db.Column(db.String(64)  index=True  unique=True)     password_hash = db.Column(db.String(128))      def set_password(self  password):         self.password_hash = generate_password_hash(password)      def check_password(self  password):         return check_password_hash(self.password_hash  password)      def __repr__(self):         return '&lt;User {}&gt;'.format(self.username) </code></pre>  <p>webapp.py</p>  <pre><code>from flask import Blueprint from flask import redirect from flask import render_template from flask import request from flask import url_for from flask_login import current_user from flask_login import login_required from flask_login import login_user from flask_login import logout_user from werkzeug.urls import url_parse  from app.extensions import db from app.forms import LoginForm from app.forms import RegistrationForm from app.models import User  server_bp = Blueprint('main'  __name__)   @server_bp.route('/') def index():     return render_template(\""index.html\""  title='Home Page')   @server_bp.route('/login'  methods=['GET'  'POST']) def login():     if current_user.is_authenticated:         return redirect(url_for('main.index'))      form = LoginForm()     if form.validate_on_submit():         user = User.query.filter_by(username=form.username.data).first()         if user is None or not user.check_password(form.password.data):             error = 'Invalid username or password'             return render_template('login.html'  form=form  error=error)          login_user(user  remember=form.remember_me.data)         next_page = request.args.get('next')         if not next_page or url_parse(next_page).netloc != '':             next_page = url_for('main.index')         return redirect(next_page)      return render_template('login.html'  title='Sign In'  form=form)   @server_bp.route('/logout') @login_required def logout():     logout_user()      return redirect(url_for('main.index'))   @server_bp.route('/register'  methods=['GET'  'POST']) def register():     if current_user.is_authenticated:         return redirect(url_for('main.index'))      form = RegistrationForm()     if form.validate_on_submit():         user = User(username=form.username.data)         user.set_password(form.password.data)         db.session.add(user)         db.session.commit()          return redirect(url_for('main.login'))      return render_template('register.html'  title='Register'  form=form)  @server_bp.route('/dynamic_chart'  methods=['POST'  \""GET\""]) def dynamicchart():     req_data = request.get_json()      hour1 = req_data[\""hour1\""]     return  hour1 </code></pre>  <p>Any idea  help is appreciated. Thank you for your time.</p>""",azure-web-app-service
56979970,how to do event hub event routing at scale based on custom logic <p>my application have multiple independent components which takes request/data over eventhub  do some processing and publish response data  which will be processed by another component (based on the event type).</p>  <p>I need to build a router  which will listen to event hubs of all the components and then based on event type and config value write the event to request event hub for next component.</p>  <p>Azure event grid has something similar for custom events  but i have to configure it from Azure portal and i can't configure from my code. I want routing to be my config driven  so that when new routes are added  it can be done through my app UI</p>  <p>Is azure funcitions a good option to build such a routing service  can i get high throughput and scale</p>  <p><code> </code></p>,azure-functions
44143724,"Premium (SSD) managed disks for Azure VM Scale Set <p>I've been trying to get Premium managed disks (SSD) enabled for Azure Virtual Machine Scale Sets  but I don't seem to get it setup.</p>  <p><a href=\https://i.stack.imgur.com/7X7E6.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/7X7E6.png\"" alt=\""Scaleset config\""></a></p>  <p>Standard (HHD) seems to work for managed disks.</p>  <p>Anybody got this working?</p>""",azure-virtual-machine
43775950,Azure webapp deployment fails after removing Composer SiteExtension <p>I had Composer Site extension installed till now on azure php webapp.  I need custom deployment that can run grunt tasks also. So I created the .deployment and deploy.sh files in project root. But that deploy.sh is not being picked up.</p>  <p>.deployment file contents:</p>  <pre><code>[config] command = bash deploy.sh </code></pre>  <p>Looking at the deployment logs  I find this</p>  <pre><code>2017-05-04T06:21:03.9301086Z Updating submodules. 8bc3029f-d77b-4c1e-860f-a3d439d7a354 0 2017-05-04T06:21:03.9926050Z Preparing deployment for commit id 'e2b45fb52b'. 61c286b1-5c00-4c11-ae14-54e0711d6857 0 2017-05-04T06:21:04.2632947Z Running custom deployment command... e71c397e-bc63-4357-abc4-acd49bc2041d 0 2017-05-04T06:21:04.3101663Z Running deployment command... 24db1c4f-8a51-463b-8c4a-ee040bc5dfd8 0     2017-05-04T06:21:04.3101663Z Command: D:\home\SiteExtensions\ComposerExtension\Hooks\deploy.cmd  0     2017-05-04T06:21:04.4039215Z The system cannot find the path specified.  1     2017-05-04T06:21:04.4195462Z The system cannot find the path specified.\r\nD:\Program Files (x86)\SiteExtensions\Kudu\62.60430.2807\bin\Scripts\starter.cmd D:\home\SiteExtensions\ComposerExtension\Hooks\deploy.cmd  2 </code></pre>  <p>Seems like somewhere the trigger for Composer site extension still remains which is being invoked during deployment.</p>  <p>How can I completely remove Composer site extension and use my custom deployment script deploy.sh? Thanks in advance.</p>,azure-web-app-service
24531458,Connection pooling on Azure Storage <p>I'm starting to use Azure Storage to save files to blobs on my application. Since my application could be accessing different containers on different storages I would like to know how to implement a connection pool that will optimize resources. </p>  <p>I want to keep the connection open to the different containers instead of opening a connection each time I try to download a blob</p>  <p>Can anyone provide me with the best approach to achieve this?</p>  <p>Thanks</p>,azure-storage
23021555,"Query metadata in Azure VM <p>What is the best way in Azure for a VM to query whether it is running in Azure vs AWS? How can you get other metadata such as instance type (size)? In AWS EC2  you can query <a href=\http://169.254.169.254/latest/user-data/\"" rel=\""nofollow noreferrer\"">http://169.254.169.254/latest/user-data/</a> inside a VM to get its metadata (<a href=\""https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-instance-metadata.html\"" rel=\""nofollow noreferrer\"">https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-instance-metadata.html</a>).</p>""",azure-virtual-machine
46401159,C# MVC LocalResource on Microsoft Azure <p>I have this line of code that uses the Azure.ServiceRuntime.LocalResource class:</p>  <pre><code>LocalResource localResources = RoleEnvironment.GetLocalResource(fileName); </code></pre>  <p>When I tried to access the controller that has this line it gives me the following error (not the specific action in the same controller)  essentially a 403 error:</p>  <pre><code>You do not have permission to view this directory or page. </code></pre>  <p>I am not sure if this how it should work on Microsoft Azure with my C# MVC5 application. I have also tried adding an Azure storage account (Storage Account - blob  file  table  queue) but it still didn't work. The file that I am trying to create is a pdf file.</p>  <p>Does anyone know how to solve this?</p>,azure-storage
51618822,Azure Virtual Machine Metrics <p>I am using the Azure Java SDK  I am trying to get the metrics for a Virtual Machine  My code is mentioned below </p>  <p>List  metricDefinitions = azure.metricDefinitions().listByResource(virtualMachine.id());</p>  <p>but the list size  i got is Zero.</p>  <p>Is it a issue with SDK or is my code wrong?</p>  <p>Please help me on this.</p>,azure-virtual-machine
30806791,"Getting error 400 bad request when accessing Azure blob storage - all latest components <p>I am running in to the \400 bad request\"" error that many have posted about when accessing Azure blob storage.  Most of the fixes relate to updating versions of the Azure SDK and of the Storage Emulator from late '13 or '14  but there have been several subsequent releases since then.</p>  <pre><code>        CloudStorageAccount storageAccount = CloudStorageAccount.Parse(\""blabla\"");         CloudBlobClient blobClient = storageAccount.CreateCloudBlobClient();         CloudBlobContainer container = blobClient.GetContainerReference(\""mycontainer\"");         CloudBlockBlob blockBlob = container.GetBlockBlobReference(id);         string x = blockBlob.DownloadText(); // &lt;-- Problem happens here </code></pre>  <p>I was running ok and then <em>something</em> changed to cause this error to start.</p>  <ul> <li>It does not appear to be a naming issue - my storage container is all lowercase and 12 characters</li> <li>It's not the emulator - I'm not even using it</li> </ul>  <p>Running Visual Studio 2013 Community Edition  Azure SDK 2.6  and version 4.3.0 of the NuGet package for the Windows Azure Storage library.  (I've tried going to the most recent 3.x release but same problem.)  </p>  <p>In addition  to be sure I was clean  I removed all versions of the Azure SDK and of the local tools and reinstalled the Azure SDK 2.6.</p>""",azure-storage
47431807,"502 error when redirecting stream from another site <p>In my WEB Api 2 controller I want to request file from one site and return this file from my controller. Here is the code</p>  <pre><code>public HttpResponseMessage GetLecture() {                 HttpWebRequest request = WebRequest.CreateHttp(\http://openmedia.yale.edu/cgi-bin/open_yale/media_downloader.cgi?file=/courses/spring11/phil181/mp3/phil181_01_011111.mp3\"");     request.Referer = @\""http://oyc.yale.edu/courses/\"";      var receivedResponse = request.GetResponse();      HttpResponseMessage response = new HttpResponseMessage(HttpStatusCode.OK);                         response.Content = new StreamContent(receivedResponse.GetResponseStream());     response.Content.Headers.ContentType = MediaTypeHeaderValue.Parse(receivedResponse.ContentType);     response.Content.Headers.ContentDisposition = new ContentDispositionHeaderValue(\""attachment\"");     response.Content.Headers.ContentDisposition.FileName = \""phil181_01_011111.mp3\"";     response.Content.Headers.ContentLength = receivedResponse.ContentLength;      return response; } </code></pre>  <p>Locally it works fine and I can download the file but when I deploy it to Azure I'm getting 502 Error. Web server received an invalid response while acting as a gateway or proxy server.</p>  <p><a href=\""https://i.stack.imgur.com/JrHLQ.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/JrHLQ.png\"" alt=\""enter image description here\""></a></p>  <p>Logging shows that it fails after returning response so no exceptions during method execution. </p>  <p>It's ~50MB file. For smaller files code works fine. </p>  <p>How can I make this code works on Azure for 50 MB files?</p>""",azure-web-app-service
42325021,Adding VMs To Azure Virtual Network <p>I am new to Azure and any trying to create a Virtual Network with 2 VM's in it. I have created the Virtual Network (VN) OK (see attached screenshot) and can also create the VMs but the Vis do not show up as resources on the VN and I cannot see where to sin them when creating the VM. I suspect its to do with subnets etc and IPs but I am now to this and cannot figure it out. See the screenshots attached showing the VM and the VN Resource list</p>  <p>I am using Azure Classic Portal as I need to set up Domain Services on my VN and am using the Select From Gallery option when creating my VMS.</p>,azure-virtual-machine
18344072,Azure table storage using repository pattern and unit of work pattern <p>I'm trying to build a reusable code for accessing Azure Table Storage using repository pattern and unit of work pattern.</p>  <p>What I want to achieve is to instantiate an unit of work and then use that for different repositories.</p>  <p>Something like this:</p>  <pre><code>MyUnitOfWork uow = new MyUnitOfWork(); uow.Users.Add(User user); uow.Users.GetAllUsers(); uow.Users.FindUser(User user); uow.Users.Delete(User user); ....... uow.Products.Add(Product product); uow.Products.Delete(Product product); ....... uow.Invoices.Add(Invoice invoice); ....... uow.Save(); </code></pre>  <p>I have some issues understanding how to implement this using TableServiceContext</p>  <p>Here is what I did so far ...</p>  <p>The model:</p>  <pre><code>   public class User : TableServiceEntity    {     public User(string partitionKey  string rowKey)         : base(partitionKey  rowKey)     {     }      public User()         : this(Guid.NewGuid().ToString()  String.Empty)     {     }      public string UserName { get; set; }     public string FirstName { get; set; }     public string LastName { get; set; }     } </code></pre>  <p>IRepository Interface:      </p>  <pre><code>  public interface IRepository&lt;T&gt; where T : TableServiceEntity   {     IQueryable&lt;T&gt; Query { get; }      //bool CreateIfNotExist();      //bool DeleteIfExist();      //void AddEntity(T obj);      //void AddEntity(IEnumerable&lt;T&gt; objs);      //void AddOrUpdateEntity(T obj);      //void AddOrUpdateEntity(IEnumerable&lt;T&gt; objs);      //void DeleteEntity(T obj);      //void DeleteEntity(IEnumerable&lt;T&gt; objs);     } </code></pre>  <p>Interface Unit Of Work:</p>  <pre><code>    public interface ITableUow     {     void Save();      IUserRepository Users { get; }     } </code></pre>  <p>Interface User Repository:</p>  <pre><code>    public interface IUserRepository: IRepository&lt;User&gt;     {     IQueryable&lt;User&gt; GetUsers();     } </code></pre>  <p>Azure Table Repository:</p>  <pre><code>     public class AzureTableRepository&lt;T&gt; : IRepository&lt;T&gt; where T : TableServiceEntity     {     public AzureTableRepository(TableServiceContext context)     {         if (context != null)         {             TableContext = context;         }     }      protected TableServiceContext  TableContext { get; set;    }      public IQueryable&lt;T&gt; Query     {         get { throw new NotImplementedException(); }     }      } </code></pre>  <p>User Repository:</p>  <pre><code>    public class UserRepository : AzureTableRepository&lt;User&gt;  IUserRepository     {     public UserRepository(TableServiceContext context)         : base(context)     {      }       public IQueryable&lt;User&gt; GetUsers()     {         throw new NotImplementedException();     }     } </code></pre>  <p>Azure Table Unit Of Work:</p>  <pre><code>     public class AzureTableUow: ITableUow     {      public void Save()     {      }      public IUserRepository Users     {         get { throw new NotImplementedException(); }     }     } </code></pre>,azure-storage
23794502,Visual Studio 2013 Ultimate Update2 - Load testing - Missing Manifest <p>I have created a Web/Load test and whilst running the newly created WebTest works as expected  if I add that to a Load test  locally it executes but does not testing.  If I push it up to TFS-Online I get a Manifest dialog error.</p>  <p>The path is long and does not exist but sits within appdata\local\assembly.  The end of it is CommonExtension\Microsoft\Webclient\TestServiceplugin\TestStatus.json not found.</p>  <p>I have repaired my new install of Visual Studio but still the same error  I have two references in the project: Microsoft.VisualStudio.QualityTools.LoadTestFramework  Microsoft.VisualStudio.QualityTools.WebTestFramework  am I missing anything?  </p>  <p>Possibly related is if I try to open Load Test Manager from the Load Test Menu  I get an Exception dialog of Exception has been thrown by the target of an invocation.</p>  <p>An online search has drawn a blank  anyone seen this or know how I can troubleshoot?</p>  <p>Steve.</p>,azure-devops
45811864,Azure scaleset private DNS <p>Is there any possibility to link a scaleset to an internal Azure Load Balancer? I want to have a private scaleset that's not opened to the public for increasing security.</p>  <p>Thank you!</p>,azure-virtual-machine
41596604,Reset Local Admin User on VM using AzureRM Rest api <p>I'm using the AzureRM rest api to communicate to the hypervisor.  One of the things I need to do is to reset the local admin password on a VM  however I can't figure out how to reset it.  </p>,azure-virtual-machine
55519012,"Will I have down time or slowness upgrading my storage to General-purpose v2 storage account? <p>I have some storage accounts that are under load right now. I saw the option to upgrade and I am very eager to do so as it is a little cheaper and has additional features. But I fear having down time or my users becoming slow.</p>  <p>I've found <a href=\https://docs.microsoft.com/en-us/azure/storage/common/storage-account-upgrade\"" rel=\""nofollow noreferrer\"">this article on Microsoft</a>  but it does not mention down time. Any ideas?</p>""",azure-storage
57727233,"PHP - Get all files in a folders with foreign characters <p>Is there a way to read all the files in a directory with umlaut characters using PHP?</p>  <p>For example  in our Directory  we have a file named \Köln.pdf\"". When we use scandir method  it returns 'K\""ln.pdf'.</p>  <p>Is there a way to retrieve the file names with those character?  We are using PHP7.2 in Azure App Service.</p>  <p>Thanks  Praveen</p>""",azure-web-app-service
51513947,"Error when trying to access Azure Function <p>I have an anonymous function on Azure  successfully deployed (.netstandard 2.0)  using Microsoft.NET.Sdk.Functions (1.0.13)  but for some reason suddenly it stopped working and when I call it the response is:</p>  <p><div class=\snippet\"" data-lang=\""js\"" data-hide=\""false\"" data-console=\""true\"" data-babel=\""false\"">  <div class=\""snippet-code\"">  <pre class=\""snippet-code-html lang-html prettyprint-override\""><code>&lt;ApiErrorModel xmlns:i=\""http://www.w3.org/2001/XMLSchema-instance\"" xmlns=\""http://schemas.datacontract.org/2004/07/Microsoft.Azure.WebJobs.Script.WebHost.Models\""&gt;  &lt;Arguments xmlns:d2p1=\""http://schemas.microsoft.com/2003/10/Serialization/Arrays\"" i:nil=\""true\""/&gt;  &lt;ErrorCode&gt;0&lt;/ErrorCode&gt;  &lt;ErrorDetails i:nil=\""true\""/&gt;  &lt;Id&gt;91fab400-3447-4913-878f-715d9d4ab46b&lt;/Id&gt;  &lt;Message&gt;  An error has occurred. For more information  please check the logs for error ID 91fab400-3447-4913-878f-715d9d4ab46b  &lt;/Message&gt;  &lt;RequestId&gt;0fb00298-733d-4d88-9e73-c328d024e1bb&lt;/RequestId&gt;  &lt;StatusCode&gt;InternalServerError&lt;/StatusCode&gt;  &lt;/ApiErrorModel&gt;</code></pre>  </div>  </div>  </p>  <p>How to figure that out?</p>  <p>EDIT: When I start AF environment locally and run the function it works as expected  without any issues  although what i see in console is a message in red:</p>  <p><a href=\""https://i.stack.imgur.com/nAEmg.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/nAEmg.png\"" alt=\""enter image description here\""></a></p>  <p>and searching for it  stumbled across this GitHub post: <a href=\""https://github.com/Azure/azure-functions-host/issues/2765\"" rel=\""nofollow noreferrer\"">https://github.com/Azure/azure-functions-host/issues/2765</a></p>  <p>where I noticed this part:</p>  <blockquote>   <p>@m-demydiuk noticed that azure function works with this error in the console. So this red error doesn't break function on the local machine. But I am afraid it may cause any problems in other environments.</p> </blockquote>  <p>and it bothers me. Can it be the problem?</p>  <p>I use a lib with a version that do not match my target framework  but again locally works fine  and also it was working fine before on Azure</p>  <p><a href=\""https://i.stack.imgur.com/GpghJ.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/GpghJ.png\"" alt=\""enter image description here\""></a></p>  <p><strong>My host version is \""Version=2.0.11651.0\""</strong></p>  <p>This is the entire function:</p>  <p><div class=\""snippet\"" data-lang=\""js\"" data-hide=\""false\"" data-console=\""true\"" data-babel=\""false\"">  <div class=\""snippet-code\"">  <pre class=\""snippet-code-html lang-html prettyprint-override\""><code>public static class Function1      {          [FunctionName(\""HTML2IMG\"")]          public static async Task&lt;HttpResponseMessage&gt; Run([HttpTrigger(AuthorizationLevel.Anonymous  \""get\""  \""post\""  Route = null)]HttpRequest req  TraceWriter log)          {              string url = req.Query[\""url\""];                byte[] EncodedData = Convert.FromBase64String(url);              string DecodedURL = Encoding.UTF8.GetString(EncodedData);                string requestBody = new StreamReader(req.Body).ReadToEnd();              dynamic data = JsonConvert.DeserializeObject(requestBody);              DecodedURL = DecodedURL ?? data?.name;              var api = new HtmlToPdfOrImage.Api(\""9123314e-219c-342d-a763-0a3dsdf8ad21\""  \""vmZ31vyg\"");                var ApiResult = api.Convert(new Uri($\""{DecodedURL}\"")  new HtmlToPdfOrImage.GenerateSettings() { OutputType = HtmlToPdfOrImage.OutputType.Image });                string BlobName = Guid.NewGuid().ToString(\""n\"");              string ImageURL = await CreateBlob($\""{BlobName}.png\""  (byte[])ApiResult.model  log);              var Result = new HttpResponseMessage(HttpStatusCode.OK);              var oJSON = new { url = ImageURL  hash = BlobName };              var jsonToReturn = JsonConvert.SerializeObject(oJSON);                Result.Content = new StringContent(jsonToReturn);              Result.Content.Headers.ContentType = new MediaTypeHeaderValue(\""application/json\"");                return Result;          }            private async static Task&lt;string&gt; CreateBlob(string name  byte[] data  TraceWriter log)          {              string accessKey = \""xxx\"";              string accountName = \""xxx\"";              string connectionString = \""DefaultEndpointsProtocol=https;AccountName=\"" + accountName + \"";AccountKey=\"" + accessKey + \"";EndpointSuffix=core.windows.net\"";              CloudStorageAccount storageAccount = CloudStorageAccount.Parse(connectionString);              CloudBlobClient client = storageAccount.CreateCloudBlobClient();              CloudBlobContainer container = client.GetContainerReference(\""images\"");                await container.CreateIfNotExistsAsync();                BlobContainerPermissions permissions = await container.GetPermissionsAsync();              permissions.PublicAccess = BlobContainerPublicAccessType.Container;              await container.SetPermissionsAsync(permissions);                CloudBlockBlob blob = container.GetBlockBlobReference(name);              blob.Properties.ContentType = \""image/png\"";                using (Stream stream = new MemoryStream(data))              {                  await blob.UploadFromStreamAsync(stream);              }                return blob.Uri.AbsoluteUri;          }</code></pre>  </div>  </div>  </p>  <p><strong><em>DOUBLE EDIT: I created empty V2 .net core AF in VS and published it straight away -> i get the same error... I even updated the Microsoft.NET.Sdk.Function to the latest 1.0.14 instead of 1.0.13 and still get the same error. Obviously something in Azure or Visual Studio (15.7.5) is broken?!?!</em></strong></p>""",azure-functions
53052321,I configured my DNS to resolve to my azure web app via CNAME pointing to my azurewebsites.net URL and got 404 <p>I configured my DNS to resolve to my azure web app via CNAME pointing to my azurewebsites.net URL.  However my site does not come up when I navigate to the URL  instead I see a 404 error.  </p>,azure-web-app-service
50462883,"Azure - Web API / App Service Plan - Performance Details not recorded <p>I have an app service plan which is hosting 2 Web APIs  the issue I am facing is that I am unable to view details such as: CPU Usage  Memory Percentage  Requests  Average Response time etc.</p>  <p>These can be found under the Overview tab for both App Service and App Service Plan but no data is being recorded  even if I retrieve data for the whole week rather than the last hour only.</p>  <p>I have also confirmed that I am hitting the correct App hosted on the correct Plan. Have I missed anything? Do I need to enable something?</p>  <p>I have also generated around 20k requests in the last few hours so I expect something to show up.</p>  <p><a href=\https://i.stack.imgur.com/AmQU9.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/AmQU9.png\"" alt=\""enter image description here\""></a></p>  <p><a href=\""https://i.stack.imgur.com/HkqRa.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/HkqRa.png\"" alt=\""enter image description here\""></a></p>""",azure-web-app-service
14447361,"Using IndexService in Simple Lucene <p>I have inherited some code that uses Simple Lucene. I know very little about Simple Lucene. Right now  the code relies on the <code>IndexService</code> to index entities. The following code is used:</p>  <pre><code>using (var indexService = GetIndexService()) {   indexService.IndexEntities(cachedResults  p =&gt;   {     var document = new Document();     document.Add(new Field(\Name\""  p.Name  Field.Store.YES  Field.Index.NOT_ANALYZED));     document.Add(new Field(\""ID\""  p.ID  Field.Store.YES  Field.Index.NOT_ANALYZED));     document.Add(new Field(\""Description\""  p.Description  Field.Store.YES  Field.Index.NOT_ANALYZED));     return document;   }); } </code></pre>  <p><code>GetIndexService</code> returns a <code>SimpleLucene.Impl.DirectorySerivce</code> instance. This approach was used to store the index on a local machine. However  now I need to move this to a Windows Azure Storage blob. In an attempt to do that  I'm relying on the library found at: <a href=\""https://github.com/richorama/AzureDirectory\"" rel=\""nofollow\"">https://github.com/richorama/AzureDirectory</a>.</p>  <p>The example shown here returns a <code>Lucene.Net.Index.IndexWriter</code>. I have no idea how to use this object with the approach that's there. The types seem entirely incompatible. All I wanted to do was use a different storage location for the index files. Is there a way to do this? If so  how. I'm completely up a creek here. Thanks!</p>""",azure-storage
40922244,dotnet core deployment to azure app service using teamcity <p>I have a dotnet core app. I am building a pipeline in teamcity. and once the teamcity detects the change in the cource code  It downloads the source code runs dotnet restore dotnet build</p>  <p>and copies the content in the output folder to Azure app service.</p>  <p>I believe to run the app i need to run the command dotnet nameoftheprojectdll.dll</p>  <p>but how can I run this command on the app service. and I need to run this command as part of a build script.</p>,azure-web-app-service
28143759,"Correct way to escape an Azure Storage Blob Name <p>I am uploading files from a windows systems to Azure storage blobs</p>  <p>The local file names may contain characters that are invalid in blob names</p>  <p>I need a way of encoding these names as to fulfill the requirements set out by MSDN on blob storage names  as shown below</p>  <blockquote>   <p><strong>A blob name must conforming to the following naming rules:</strong></p>      <ul>   <li>A blob name can contain any combination of characters.</li>   <li>A blob name must be at least one character long and cannot be more than 1 024 characters long.</li>   <li>Blob names are case-sensitive.</li>   <li>Reserved URL characters must be properly escaped.</li>   <li>The number of path segments comprising the blob name cannot exceed 254. A path segment is the string between consecutive delimiter characters (e.g.  the forward slash '/') that corresponds to the name   of a virtual directory.</li>   </ul> </blockquote>  <p>The pertinent information above is <strong>\Reserved URL characters must be properly escaped</strong>. However  what method is the \""standard\"" to use?</p>""",azure-functions
53398214,"Cannot bind parameter 'orchestrationContext' to type DurableOrchestrationContext while using DurableOrchestration with Azure Functions <p>I am trying to use the new Durable Functions extension in Azure Functions I installed this Nuget package on my Function project:</p>  <blockquote>   <p>Microsoft.Azure.WebJobs.Extensions.DurableTask</p> </blockquote>  <p>And then used the DurableOrchestrationContext in my function like that:</p>  <pre><code>[FunctionName(\StopVM\"")] public static void StopVM([TimerTrigger(\""0 */2 * * * *\"")]TimerInfo myTimer  ILogger log  ExecutionContext context  DurableOrchestrationContext orchestrationContext)     {     ....     } </code></pre>  <p>but when i run the function this error shown:</p>  <blockquote>   <p>Error indexing method 'FuncApp.StopVM' [20/11/2018   17:09:01] Microsoft.Azure.WebJobs.Host: Error indexing method   'FuncApp.StopVM'. Microsoft.Azure.WebJobs.Host: Cannot   bind parameter 'orchestrationContext' to type   DurableOrchestrationContext. Make sure the parameter Type is supported   by the binding. If you're using binding extensions (e.g. Azure   Storage  ServiceBus  Timers  etc.) make sure you've called the   registration method for the extension(s) in your startup code (e.g.   builder.AddAzureStorage()  builder.AddServiceBus()    builder.AddTimers()  etc.).</p> </blockquote>  <p>Do i missing some steps like adding any middle-ware to startup class or etc. cause the documentation not shown clearly how to use it?</p>""",azure-functions
12003790,Azure download with GetSharedAccessSignature of large file <p>Through a webpage  I want to allow users to download (very large) file stored on Azure Cloud storage. I use the GetSharedAccessSignature to allow users to download it (note: the Container is protected and not publicly readable). I use the following code:</p>  <pre><code>// get the file blob // CloudBlockBlob blob set previously and check (it exists)          string sas = blob.GetSharedAccessSignature(             new SharedAccessPolicy() {                  Permissions = SharedAccessPermissions.Read                  SharedAccessStartTime = DateTime.Now.AddMinutes(-5)                  SharedAccessExpiryTime = DateTime.Now.AddMinutes(54)              });          Response.Redirect(blob.Attributes.Uri.AbsoluteUri + sas); </code></pre>  <p>This works EXCEPT when the download takes more than 1 hour (as I said  very large files being downloaded over not so good internet connection...). If the download takes longer  a time-out occurs and the download stops as the Shared Access Expired Time has passed.</p>  <p>How can I solve this?</p>  <p>Kind regards  Robbie De Sutter</p>,azure-storage
47226532,SQL Server Backup to Azure Storage Issues <p>We are currently backing up SQL Server databases to an Azure URL as a page blob.  SQL Server version is 2012 SP3.  At times I need to get the backups to our Dev  Beta  and Test environments to be restored.  I'm having an issue with a large backup (~50 GB).  There are several smaller backups that are copied and restored okay but the one large backup is the problem.  I've tried using PowerShell scripts and AzCopy.  When attempting to restore it using the GUI  the backup is not recognized.  When attempting to RESTORE VERIFYONLY  I get the error - Msg 3013 (VERIFY DATABASE is terminating abnormally.)</p>  <p>If I do a restore verify from URL  the backup is valid.  If I try to restore from URL  it restores but takes forever (almost 6 hours).</p>  <p>Has anybody else had this problem?</p>,azure-storage
25989306,"Hosting fonts on Azure CDN for a Wordpress site on Ubuntu 14.0.4? CORS issues <p>I have an Azure storage account  with CDN setup to have 5 subdomains pointing to the storage account (cdn1.domain.com  cdn2.domain.com  -- cdn5.domain.com).</p>  <p>I use the W3 Total Cache plugin for performance  particularly to host static files on the Azure CDN. The plugin uploads all the files fine and the site can access images  css  scripts  etc... no problem. However  fonts don't load.</p>  <p><strong>Gets the following error:</strong></p>  <blockquote>   <p>Font from origin '<a href=\http://cdn1.domain.com\"" rel=\""nofollow\"">http://cdn1.domain.com</a>' has been blocked from   loading by Cross-Origin Resource Sharing policy: No   'Access-Control-Allow-Origin' header is present on the requested   resource. Origin '<a href=\""http://domain.com\"" rel=\""nofollow\"">http://domain.com</a>' is therefore not allowed access.</p> </blockquote>  <p>The wordpress site is hosted on DigitalOcean  using Apache on Ubuntu 14.0.4. I added the following to the apache2.conf:</p>  <pre><code>&lt;FilesMatch \"".(eot|ttf|otf|woff)\""&gt;     Header set Access-Control-Allow-Origin \""*\"" &lt;/FilesMatch&gt; </code></pre>  <p>That did not work. After some research it looks like Azure doesn't allow CORS by default  so I created a little C# app to <strong>change CORS rules on my storage account</strong>  like so:</p>  <pre><code>var storageAccount =     new CloudStorageAccount(         new Microsoft.WindowsAzure.Storage.Auth.StorageCredentials(\""accountname\""  \""accountkey\"")  true); var blobClient = storageAccount.CreateCloudBlobClient(); var blobServiceProperties = new ServiceProperties {     HourMetrics = null      MinuteMetrics = null      Logging = null  }; blobServiceProperties.Cors.CorsRules.Add(new CorsRule {     AllowedHeaders = new List&lt;string&gt; { \""*\"" }      AllowedMethods = CorsHttpMethods.Get      AllowedOrigins = new List&lt;string&gt; { \""*\"" }      ExposedHeaders = new List&lt;string&gt; { \""*\"" }      MaxAgeInSeconds = 3600 // 30 minutes  });  blobClient.SetServiceProperties(blobServiceProperties); </code></pre>  <p>This should basically open up the storage to all origins... but still get the same error. So I figured maybe it was caching of some kind. So I re-uploaded all the files to the same container  then waited about 6 hours.</p>  <p>The error still persists. I feel like I've tried all one should have to in order to get fonts loading from an Azure CDN.</p>  <p>What have I missed?</p>""",azure-storage
53875957,"Web sites denying access to a Azure VM <p>I have a VM at Azure  when I try to access some web sites I get a Denied Access message. It seems they understand the request is coming from a VM and don't allow access. I tried with Chrome  Chromium thru Python/Selenium and Edge.</p>  <p>Example: www.americanas.com.br</p>  <p>Error Message:  Access Denied You don't have permission to access \<a href=\""http://www.americanas.com.br/\"" rel=\""nofollow noreferrer\"">http://www.americanas.com.br/</a>\"" on this server. Reference #18.ac3c2b17.1545339126.29ba0fa7</p>  <p>The issue does not happens all the time  but for more than 50% of the number of accesses.</p>  <p>I have already tried without success:  - move the location of my VM from US Central/South to Brazil South  - use a VPN plug-in (Hola)  - used a fixed IP resource at Azure Portal</p>  <p>Thanks in advance Ricardo</p>""",azure-virtual-machine
55838251,Export logs from release stage to a git repo or some storage <p>I am creating a Azure Devops pipeline to build  test and export results for an ios application. After build->export artifacts-> In the release stage where I perform testing  I have trouble understanding exporting the logs and results. I want to export the results (a zip file) from the Release Stage to either local or a .git repository.</p>  <pre><code>(pipeline) Build IOS Application and Export Artifacts --&gt; (Release Stage)Download Artifacts and Perform XCUITests &amp; Export results </code></pre>  <p>I tried writing a small script to upload the results to a git repo but it fails because it is impossible for me to add the ssh keygen generated to github for promptless authentication.</p>  <pre><code>git clone https://madhukarbs@dev.azure.com/madhukarbs/Demo/_git/Test_Runs git remote add origin https://madhukarbs@dev.azure.com/madhukarbs/Demo/_git/Test_Runs git push -u origin --all </code></pre>  <pre><code>fatal: could not read Password for 'https://madhukarbs@dev.azure.com': terminal prompts disabled </code></pre>  <p>Do you have any better approach to make the results (Release Stage) in Azure DevOps Platform available over internet ?</p>,azure-devops
39847672,Azure Build Suddenly Fails to Publish Artifact Drop <p>I'm sure this question will get don voted but I'm rather desperate.  This morning my Visual Studio Team Services build which has ran fro months has suddenly failed with error:</p>  <pre><code>Publish build artifacts failed with error: Not found PathtoPublish: C:\a\1\s\$\My Path </code></pre>  <p>I do not have direct access to the Azure server but can liaise with support staff.</p>  <p>I can provide more info as required.</p>  <p>Can anyone help troubleshoot please?</p>,azure-devops
54990406,"Logging in Azure WebApp <p>I have created a .net 2.1 core mvc  and now ready to host it on Azure WebApp. I am yet to finalize logging.</p>  <p><a href=\https://stackify.com/azure-app-service-log-files/\"" rel=\""nofollow noreferrer\"">https://stackify.com/azure-app-service-log-files/</a></p>  <p>I read above link and found the below snapshot to configure Application logging and Web Server logging.  <a href=\""https://i.stack.imgur.com/qL756.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/qL756.png\"" alt=\""enter image description here\""></a></p>  <p>however in my WebApp all I can see is:</p>  <p><a href=\""https://i.stack.imgur.com/2eoiM.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/2eoiM.png\"" alt=\""enter image description here\""></a></p>  <p>Is this due to my app service plan?  How do I configure Application logging and Web server logging?</p>""",azure-web-app-service
56241022,"is it possible to customize the events that a blob within a storage account fires on blob creation? <p><strong>Is it possible to change the default event that is fired on <code>blobcreated</code>?</strong></p>  <p>Storage accounts have the ability to fire events when  blobs are deleted/created:</p>  <p><a href=\https://i.stack.imgur.com/Mlg6h.png\"" rel=\""noreferrer\""><img src=\""https://i.stack.imgur.com/Mlg6h.png\"" alt=\""enter image description here\""></a></p>  <p>If you add a new event subscription  you can choose between these three:</p>  <p><a href=\""https://i.stack.imgur.com/Io7fR.png\"" rel=\""noreferrer\""><img src=\""https://i.stack.imgur.com/Io7fR.png\"" alt=\""enter image description here\""></a></p>  <p>I'd like to be able to use the <strong>Custom Input Schema</strong>. However  there's no documentation on how to use it. </p>  <p><strong>How do we customize the custom input schema?</strong></p>  <p>The default schema looks something like this:</p>  <pre><code>{     \""topic\"": \""/subscriptions/xxxxxxxxxxx/resourceGroups/myresourcegroup/providers/Microsoft.Storage/storageAccounts/mystoraccount\""      \""subject\"": \""/blobServices/default/containers/xmlinput/blobs/myj.json\""      \""eventType\"": \""Microsoft.Storage.BlobCreated\""      \""eventTime\"": \""2019-05-20T18:58:28.7390111Z\""      \""id\"": \""xxxxxxxxxxxxxxxx\""      \""data\"": {         \""api\"": \""PutBlockList\""          \""clientRequestId\"": \""xxxxxxxxxxxxxxxx\""          \""requestId\"": \""xxxxxxxxxxxxxxxx\""          \""eTag\"": \""0x8D6DD55254EBE75\""          \""contentType\"": \""application/json\""            \""contentLength\"": 874636          \""blobType\"": \""BlockBlob\""          \""url\"": \""https://mystoraccount.blob.core.windows.net/xmlinput/myj.json\""          \""sequencer\"": \""00000000000000000000000000005FAC0000000000614963\""          \""storageDiagnostics\"": {             \""batchId\"": \""xxxxxxxxxxxxxxxx\""         }     }      \""dataVersion\"": \""\""      \""metadataVersion\"": \""1\"" } </code></pre>  <p>I'd like to ONLY return the file name  in this case it is a substring of the <code>subject</code>  <strong>myj.json</strong>.</p>  <p><strong>How do we customize the event that's being fired?</strong></p>  <p>Desired result:</p>  <pre><code>{   \""filename\"": \""myj.json\"" } </code></pre>""",azure-storage
38849225,Unable to view ftp externally <p>I've been trying to setup an ftp on a Azure VM for some time now and not able to get it to work externally. I can view the ftp locally but that's as far as I have got. </p>  <p>This is what I have currently in a nutshell</p>  <p><strong>Windows Server 2012 Azure VM</strong></p>  <ul> <li>Ftp site on IIS</li> <li>The IP address is unassigned on port 21</li> <li>Host name is blank </li> <li>Administrator and a user under FTP Authorzation rules with read  write permission</li> <li>Have a ftp folder on the root c: drive </li> <li>Given security rights to the user for read  write permission on folder level. </li> </ul>  <p><strong>Azure Portal</strong></p>  <ul> <li>Created inbound security rule for port 21 and port 80</li> <li>Created public ip address for my website and ftp</li> </ul>  <p><strong>Firewall on VM</strong></p>  <ul> <li>Allow ftp server to communicate through windows firewall server both private and public</li> <li>Inbound Rule: FTP Server  Local port 21</li> <li>Inbound Rule: FTP Server Passive  Local Portal 1024-65535</li> <li>Inbound Rule: FTP Server Secure  Local Port 990</li> <li>Outbound Rule: FTP Server  Local Portal 20</li> <li>Outbound Rule: FTP Server Secure  Local Portal 989</li> </ul>  <p>I can view my website via the external IP address but not the ftp.</p>,azure-virtual-machine
55044155,"Azure active DirectoryTenantID <p>While generating a token we are passing tenant id in the token en point URL</p>  <p>is it necessary to add? please find the below URL \<a href=\""https://login.microsoftonline.com/\"" rel=\""nofollow noreferrer\"">https://login.microsoftonline.com/</a>\""+ tenantId; Can we share tenantId while generating token to client?</p>  <p>will it not create any security problems</p>  <p>Is there any alternative</p>  <p>I have found \""common\""  but when i am giving that one it is raising an error </p>  <p>Could any one provide sample example by using \""common\"" instead of tenantid ?</p>  <p>Any help is appreciated</p>""",azure-functions
48303915,Azure Function and WindowsAzure.Storage version (DLL Hell) <p>With VS 2017 latest update I'm creating a Azure Function project. Apparently this has a hard reference to WindowsAzure.Storage 7.2.1 build from September 2016(!) that is also referring other packages like OData  JSON etc.</p>  <p>Is it really advisable to downgrade to 7.2.1? (to be safe I would downgrade OData  JSON as well). This is the workaround on various blogs. </p>,azure-functions
43410016,"How to customize workflow in Azure DevOps Service (VSTS online)? <p>I've read all the MSDN docs  but cannot find a way to edit the work item transitions in Azure DevOps Service (VSTS online).</p>  <p>I'm trying to:</p>  <ol> <li>Add a custom Reason to a State of a work item. (e.g. \resolved\""  \""won't fix\"")</li> <li>See/edit all the existing rules about how states transition.</li> </ol>""",azure-devops
56532843,Azure Vnet Blob Storage <p>I want to restrict access to my Blob storage account (that contains images) to only my web site deployed on azure app service (S1 Service plan). Below the steps I have done:</p>  <ul> <li>I have create a Vnet and enabled the storage service endpoint</li> <li>I have restricted the access to the storage to the vnet just created    </li> <li>I have added my web app to the Vnet (preview feature)</li> </ul>  <p>Unfortunately when I open the web site  images are not loaded because the below error : 403 This request is not authorized to perform this operation.</p>  <p>I have try to look on internet but with no luck. also what I'm trying to acheive I guess should be very simple </p>,azure-web-app-service
39698340,How to get deployment slot in runtime for node.js in azure web app <p>I need to get the deployment slot in runtime. For example I think of something like :</p>  <pre><code>process.env.ENVIRONMENT </code></pre>  <p>Is there a way to get that? Thanks</p>,azure-web-app-service
55391091,"How to Create App Service with a subType of api <p>In powershell and using the <code>new-azwebapp</code> to create a website in our app service plan. But it only ever seems to create a type of <code>app</code></p>  <p>I'm trying to create it with the type of <code>api</code> like you can when you select from the Azure Portal UI  but I can't see a setting in the configuration to do this.</p>  <p>After creating I set the AppSettings and then try to update the Type  but it doesn't seem to matter.</p>  <p>Hoping that I'm missing something simple.</p>  <pre><code>$siteName = \namegoeshere\"" $sitePlan = \""myplanname\"" $siteLocation  = \""Australia East\"" $siteResourceGroup = \""resourcegroupname\""  $createdSite = new-azWebApp -Name $siteName -ResourceGroupName $siteResourceGroup -AppServicePlan $sitePlan -Location $siteLocation  $newAppSettings = @{ \""name\""=\""value\""} Set-AzWebApp -Name $siteName -ResourceGroupName $siteResourceGroup -AppSettings $newAppSettings -AppServicePlan Grower  #-PhpVersion 0  $p = @{ 'type' = \""api\"" } $r = Set-AzResource -Name $siteName -ResourceGroupName $siteResourceGroup -ResourceType Microsoft.Web/sites  -PropertyObject $p -ApiVersion 2016-03-01 -Kind \""app\"" echo $r.Properties </code></pre>""",azure-web-app-service
48992248,"Unable to copy files using Azure Custom script extension <p>I want to install tools like NAGIOS inside an Azure virtual machine once it is provisioned. I want to use \Azure Custom Script\"" to install the tools. Below is the code that I am using. </p>  <p><strong>Powershell script that is being sent as custom script:</strong></p>  <pre><code>new-item \""C:\\newfile.txt\"" -Type file copy-item -Path \""\\\\xxx.xx.x.x\\c$\\Nagios for windows\"" -Destination \""C:\\nagios\"" -Recurse Start-Process \""c:\\nagios\\NSCP-0.4.3.143-x64.msi\"" /qn -Wait </code></pre>  <p>Problem: The first line of code is working (I have it as a sanity check to confirm that the script is indeed working). However  the second and third line is not working (the most important part). I am not seeing any errors in the logs as well. Can someone help me out  please?</p>""",azure-virtual-machine
52172941,"How can I reference {rand-guid} value from declarative binding in Azure function? <p>I have a C# script Azure function and am binding a blob as an output in function.json:</p>  <pre><code>\bindings\"": [     ...     {       \""type\"": \""blob\""        \""name\"": \""eventOutputBlob\""        \""path\"": \""event-receiver-queue-container/{rand-guid}\""        \""connection\"": \""DomBlobStorage\""        \""direction\"": \""out\""     }   ]    \""disabled\"": false } </code></pre>  <p>I'm having trouble figuring out how to reference the {rand-guid} parameter inside of my run.csx code so I can store it in a queue for later processing. Is this possible?</p>  <p>This doesn't work but is along the lines of what I was hoping to get in run.csx:</p>  <pre><code>public static async Task&lt;HttpResponseMessage&gt; Run(     HttpRequestMessage req      string rand-guid      Stream eventOutputBlob       TraceWriter log) { ... } </code></pre>""",azure-functions
52594306,"User column option disabled for user in Organization Settings -> Usage <p>I am trying to grant a user access to view the User column information underneath of Usage inside of Organization Settings  but that specific column is grayed out unless I elevate their permissions to Project Collection Administrator. Where is this permission controlled and can access to this information be granted without elevating the user to Project Collection Administrator?</p>  <p>I am able to see these options under Column Options:</p>  <p><a href=\https://i.stack.imgur.com/sC6Bu.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/sC6Bu.png\"" alt=\""enter image description here\""></a></p>  <p>The user can only see these options under Column Options:</p>  <p><a href=\""https://i.stack.imgur.com/s27v6.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/s27v6.png\"" alt=\""enter image description here\""></a></p>""",azure-devops
43912331,"How to Include Tasks as Backlog Items? <p>Using Visual Studio Team Services (Online version)  I would like to have a simple display for my \Backlog\"" and \""Board\"" :</p>  <ol> <li>Features</li> <li>Tasks</li> <li>Bugs</li> </ol>  <p>That's pretty much it. I don't want to do anything with  iterations  sprints  user stories  etc. </p>  <p>This is just a one man project and I'm just wanting to see all thing on the backlog/board so I can better manage the project.</p>  <p><strong>EDIT:</strong></p>  <p>Biggest issue I had with this... </p>  <p>My project was setup to use the \""Agile\"" process. I decided to try <strong>Scrum</strong> process instead and found this to be the deciding factor.</p>  <p>Once a project is set as Agile/Scrum  it cannot be cahnged... So  I Made a copy of \""Scrum\"" process  named it \""Scrum_custom\""  created a new project using this method  then just git pushed my existing project code to the new one.</p>  <p>I marked Daniel Mann's answer as correct seeing as it's what I ended up doing after changing to Scrum and it seems to be working just as I'd hoped! </p>  <p>Just in case anyone else reads this and is looking to do something similar  I would recommend this route...</p>""",azure-devops
56159950,"How to define autoscale rule on memory in Azure VMSS <p>I have create a VMSS in Azure Portal  to have the autoscale feature for my application. My application resided in Kubernetes cluster - around 10 microservices.</p>  <p>I want to create an Scale out rule  that if there is no enough memory   then increase the VM instance. But I don't see an option to set the rule based on memory. There are rules which we can define based on CPU utilization  disk space etc... But this won't help me to solve the problem. For my 10 microservice to work each service having 5 pods  i need to set a rule based on memory. If I set the rule based on CPU  the VM doesn;t scale up  as the CPU is not utilised much. Issue is with memory.</p>  <p>I get the error \0/3 nodes are available: 3 Insufficient pods. The node was low on resource: [MemoryPressure]. \""</p>  <p>I read that the memory rule is not available in host metrics in Azure  but it can enabled via guest metrics. To enable guest metrics  i see below link .</p>  <p><a href=\""https://docs.microsoft.com/en-us/azure/virtual-machine-scale-sets/virtual-machine-scale-sets-mvss-guest-based-autoscale-linux\"" rel=\""nofollow noreferrer\"">https://docs.microsoft.com/en-us/azure/virtual-machine-scale-sets/virtual-machine-scale-sets-mvss-guest-based-autoscale-linux</a></p>  <p>But I don't see an option to edit the template as defined in the above link. There is only \""export Template\"" option visible for VMSS  where you cannot edit the template.</p>  <p>Could anyone please help me on this issue   to define memory rule for VMSS in Azure ?</p>  <p>No option seen to enable guest metrics for VMSS. No option to edit the template  only \""export Template\"" option visible  where you cannot edit the template.</p>""",azure-virtual-machine
51971675,VSTS Assign following of a Task <p>Is there a way to set the people who are following a task?</p>  <p>I have Stakeholders who are not creating the user story  but I want to assign them as followers.</p>,azure-devops
42931965,Azure Functions Redirect Header <p>I want one of my Azure Functions to do an <strong>HTTP Redirection</strong>.</p>  <p>This is the current code of the function:</p>  <pre><code>module.exports = context =&gt; {   context.res.status(302)   context.res.header('Location'  'https://www.stackoverflow.com')   context.done() } </code></pre>  <p>But it does not work.</p>  <p>A request sent from Postman shows the response has:</p>  <ul> <li><code>Status</code>: 200</li> <li><code>Location</code> not set</li> </ul>  <p>Is this correct code? Or is it simply not allowed by Azure Functions?</p>,azure-functions
54594226,Data ingestion from Rest API using Azure <p>As part of a POC i need to get data from REST API end point that return JSON data as Response and then save it AS-IS into Azure SQL database.</p>  <p>This REST API will be used for both Historical (Around 10000 records expected) and incremental load that will be executing at some regular intervals. Rest API use OAuth 2.0 access token for Authorization</p>  <p>Please let me know the best options available for doing data ingestion in Azure   should i use ADF or Azure functions and what are the best practices for configuring REST API in ADF in particular to error handling.</p>  <p>If this POC works successfully i need to integrate few more API calls into the design as well.</p>,azure-functions
56989239,"How to publish testresults in Azure-devops using Readyapi <p>In ReadyApi we have a Testproject with 1 request and a DataSource Loop. This loop will trigger the same request. With each loop  different data will be used (each line of data is one scenario). But when we check the testresults in Azure-devops we only see 1 test passed/failed. This is because of the way we use ReadyApi. With only 1 request there will be only 1 testresult. </p>  <p>We have the testresults as rtf files in Azure-devops \Artifacts\"". </p>  <p>Is it possible to \""configurate\"" to these files  to get the real amount of tests?</p>""",azure-devops
53496330,"Deploying intellij maven project to azure web apps using FTP  getting a 500 server error <p>I have been trying to deploy a intellij java project to Azure Web Apps using FTP. The project is a simple REST api using Jetty and Maven. Running the api locally works fine.</p>  <p>I build a .war artifact  using intellij  of the project. <a href=\https://i.stack.imgur.com/DosLs.png\"" rel=\""nofollow noreferrer\"">.war artifact build in intellij</a></p>  <p>And used FileZilla to deploy it to an Azure Web App <a href=\""https://i.stack.imgur.com/xkDj6.png\"" rel=\""nofollow noreferrer\"">FileZilla</a></p>  <p><a href=\""https://i.stack.imgur.com/vtoBa.png\"" rel=\""nofollow noreferrer\"">The azure settings</a></p>  <p>But when I try to access my azure app  just by going to the URL (in browser and using postman with a simple GET request) I get an error 500 server error.</p>  <p>HTTP ERROR 500 Problem accessing /. Reason:</p>  <pre><code>Server Error </code></pre>  <p>Caused by: org.apache.jasper.JasperException: PWC6345: There is an error in invoking javac.  A full JDK (not just JRE) is required     at org.apache.jasper.compiler.DefaultErrorHandler.jspError(DefaultErrorHandler.java:92)     at org.apache.jasper.compiler.ErrorDispatcher.dispatch(ErrorDispatcher.java:378)     at org.apache.jasper.compiler.ErrorDispatcher.jspError(ErrorDispatcher.java:119)     at org.apache.jasper.compiler.Jsr199JavaCompiler.compile(Jsr199JavaCompiler.java:208)     at org.apache.jasper.compiler.Compiler.generateClass(Compiler.java:384)     at org.apache.jasper.compiler.Compiler.compile(Compiler.java:453)     at org.apache.jasper.JspCompilationContext.compile(JspCompilationContext.java:625)     at org.apache.jasper.servlet.JspServletWrapper.service(JspServletWrapper.java:375)     at org.apache.jasper.servlet.JspServlet.serviceJspFile(JspServlet.java:473)     at org.apache.jasper.servlet.JspServlet.service(JspServlet.java:377)     at javax.servlet.http.HttpServlet.service(HttpServlet.java:790)     at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:696)     at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:526)     at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)     at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:586)     at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:221)     at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1110)     at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:453)     at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:183)     at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1044)     at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)     at org.eclipse.jetty.server.Dispatcher.forward(Dispatcher.java:261)     at org.eclipse.jetty.server.Dispatcher.forward(Dispatcher.java:101)     at org.eclipse.jetty.servlet.DefaultServlet.doGet(DefaultServlet.java:552)     at javax.servlet.http.HttpServlet.service(HttpServlet.java:687)     at javax.servlet.http.HttpServlet.service(HttpServlet.java:790)     at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:696)     at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1568)     at org.eclipse.jetty.websocket.server.WebSocketUpgradeFilter.doFilter(WebSocketUpgradeFilter.java:164)     at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1539)     at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:524)     at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)     at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:568)     at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:221)     at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1110)     at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:453)     at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:183)     at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1044)     at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)     at org.eclipse.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:199)     at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:109)     at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:97)     at org.eclipse.jetty.server.Server.handle(Server.java:459)     at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:280)     at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:229)     at org.eclipse.jetty.io.AbstractConnection$1.run(AbstractConnection.java:505)     at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:607)     at org.eclipse.jetty.util.thread.QueuedThreadPool$3.run(QueuedThreadPool.java:536)     at java.lang.Thread.run(Unknown Source) Powered by Jetty://</p>  <p>When I try to access my endpoint  I receive an Error 404 Not Found.</p>  <p>HTTP ERROR 404 Problem accessing /login. Reason:</p>  <pre><code>Not Found </code></pre>  <p>Powered by Jetty://</p>  <p><a href=\""https://i.stack.imgur.com/SoETM.png\"" rel=\""nofollow noreferrer\"">Code with paths</a></p>  <p>I am sort of at my wits end here. Does anyboy know how to resolve this?</p>""",azure-web-app-service
45133313,Can't access to Azure Storage using Lucene.Net And Azure App Service <p>We Have search implemented using  Lucene.Net  Indexes are stored in Azure Storage Folder  Few days ago we moved our Web Application From Azure CloudService To Azure AppService. If we run this locally it works as expected  also works in CloudService But when we published our Web Application to Azure AppService we have below Exception:</p>  <blockquote>   <p>System.UnauthorizedAccessException: Access to the path 'D:\AzureDirectory' is denied.</p> </blockquote>  <p>tried to update AzureDirectory and Azure Storage packages but it's not working.</p>  <p>Any Idea?</p>,azure-storage
55364135,Does Azure Devops allow me to import and edit an excel file on the Wiki board? <p>Currently we're using Azure DevOps -> Wiki to capture some requirements. We're wondering if we can import an excel file on Wiki and be able to edit right on the Wiki board (instead of downloading -> update -> upload).</p>,azure-devops
12610853,"Is it possible to query a big Azure Table with specific search parameters but without PartitionKey? <p>Let say I have a table entity as it :</p>  <p>Partitionkey Rowkey table userid datecreated</p>  <p>Let's take a query which works great  with it I can retrieve all entries wich have a particular ID (which is used as the PartitionKey)</p>  <pre><code>Dim azt_query As CloudTableQuery(Of adlog) azt_query = azt_context.CreateQuery(Of adlog)(\adlog\"").Where(Function(e) (e.PartitionKey = \""myid\"" And e.table = \""mytable\"" And e.userid = \""myuserid\"" And e.datecreated &gt;= dateStart And e.datecreated &lt;= dateEnd)).AsTableServiceQuery() </code></pre>  <p>Now I would like to query the table without knowing the PartitionKey but based on the USERID</p>  <p>It would be like that :</p>  <pre><code>Dim azt_query As CloudTableQuery(Of adlog) azt_query = azt_context.CreateQuery(Of adlog)(\""adlog\"").Where(Function(e) (e.table = \""mytable\"" And e.userid = \""myuserid\"" And e.datecreated &gt;= dateStart And e.datecreated &lt;= dateEnd)).AsTableServiceQuery() </code></pre>  <p>But removing the e.PartitionKey = \""myid\"" now it takes forever. I think the query want to retrieve all the rows of the table and search in it with the parameter.</p>  <p>But there is millions of rows. Querying with the partitionkey is actually pretty fast.</p>  <p>Is there a way to query this ? Can I retrieve all the rows of a particular USERID or I'm I stuck to the partitionkey level ?</p>""",azure-storage
43729096,"Azure C# Deployment Scripts become inaccessible <p>I recently built &amp; deployed my first C# MVC website on Azure  but I am finding that the <a href=\http://lipstate.com/scripts/?v=8-nQ5fLPOWbFbJ3aNGN9S-Cax5jWLtBVGkIQKVKaKMc1\"" rel=\""nofollow noreferrer\"">scripts folder</a> is not accessible. The <a href=\""http://lipstate.com/styles?v=uN9B1hvN-FmZu5InjOI3atLl7v20twIOG8AC6McXPYw1\"" rel=\""nofollow noreferrer\"">CSS path</a> is OK. How do I set the permissions of the scripts folder in azure?</p>  <p>in a localhost version of the site  scripts are served as:</p>  <pre><code>&lt;script src=\""/scripts/jquery-3.1.1.js\""&gt;&lt;/script&gt; &lt;script src=\""/scripts/jquery.validate.js\""&gt;&lt;/script&gt; &lt;script src=\""/scripts/jquery.validate.unobtrusive.js\""&gt;&lt;/script&gt; &lt;script src=\""/scripts/jquery.timeago.js\""&gt;&lt;/script&gt; &lt;script src=\""/scripts/bootstrap.js\""&gt;&lt;/script&gt; &lt;script src=\""/scripts/frontend.js\""&gt;&lt;/script&gt; </code></pre>  <p>in the azure version  it is all turned into:</p>  <pre><code>&lt;script src=\""/scripts?v=8-nQ5fLPOWbFbJ3aNGN9S-Cax5jWLtBVGkIQKVKaKMc1\""&gt;&lt;/script&gt; </code></pre>  <p>to clarify on the original question  i can access the individual javascript files  if i <a href=\""http://lipstate.com/scripts/frontend.js\"" rel=\""nofollow noreferrer\"">address directly</a> to them. its just the azure-ified script tag that i can not access.</p>""",azure-web-app-service
48554680,"Why is my B1S (Ubuntu) Azure VM maxing at 10% CPU when running a processor-intensive task? <p>I am new to Azure  only exploring it right now (together with AWS &amp; GCP at the same time) to identify what I can use it for in my professional life.</p>  <p>So now I'm running a B1S (1 vCPU  1GB RAM) as part of the Free Trial. When I run a single long-running processor-intensive task (e.g. PDFCRACK)  this is what I noticed:</p>  <ol> <li><p>\top\"" will say that this task is using around 100% CPU.</p></li> <li><p>Azure Portal dashboard indicates the same thing (100% CPU)  but only for a while (2-3 minutes)  after that it goes down and stays at 10% CPU. At the same time  \""top\"" still says that the task is using 100% CPU.</p></li> </ol>  <p>And the performance is really roughly 10% compared to an equivalent GCP setup (PDFCRACK reports the number of tries it made per second).</p>  <p>Is there any explanation for this?</p>""",azure-virtual-machine
54587972,"Azure Get All Organzations in multi tenants <p>In this article <a href=\https://docs.microsoft.com/en-us/rest/api/resources/tenants/list\"" rel=\""nofollow noreferrer\"">https://docs.microsoft.com/en-us/rest/api/resources/tenants/list</a> I can get all the Tenants in my account. Now I want to get all the Organization in devops/vsts in each tenant or directory. Currently Im using this article <a href=\""https://docs.microsoft.com/en-us/rest/api/azure/devops/account/accounts/list?view=azure-devops-rest-5.0\"" rel=\""nofollow noreferrer\"">https://docs.microsoft.com/en-us/rest/api/azure/devops/account/accounts/list?view=azure-devops-rest-5.0</a> and the token I get in the tenants is not working in getting all the organizations. Is theres a way to list all the organization in each tenant in my account? Thanks!</p>""",azure-devops
48891630,"Azure web app crashes when initializing mongo DB client <p>I have created Cosmos DB account with MongoDB driver and want to access it from flask server. Here is the simplest example I'm trying:</p>  <pre><code>from flask import Flask from pymongo import MongoClient   url = 'monbodb://&lt;my_db_name&gt;.documents.azure.com:10255/?ssl=true username = '&lt;my_db_name&gt;' password = '&lt;my_password&gt;' client = MongoClient(url  username=username  password=password) app = Flask(__name__)   @app.route('/ping'  methods=['GET']) def ping():     return 'pong!'   if __name__ == '__main__':     app.run() </code></pre>  <p>I deploy it with git and at the end it says the deployment was successful. But really app has crashed because webpage is not accessible  saying \The page cannot be displayed because an internal server error has occurred.\"". I guess issue is with SSL  because removing '/?ssl=true' does allow access app webpage but it this case DB is not accessible! What is with issue and how can it be fixed?</p>""",azure-web-app-service
51624007,Azure cloud web apps slows load at start <p>Not sure if you are experiencing the slowness of Azure cloud web apps loading at start even though AlwaysOn has been turned on.</p>  <p>Looking for any idea to solve this issue.</p>  <p>Thanks  Riki</p>,azure-web-app-service
55469611,"How to fix \Azure Function Output Adapter failed to write events\"" <p>I have in my Azure IoT architecture a Stream Analytics (SA) connect to an Azure Function.</p>  <p>Sometimes I have this error of my SA:</p>  <pre><code>\""Send Events: Azure Function Output Adapter failed to write events\""  </code></pre>  <p>and in the JSON message of the error I find this description:</p>  <pre><code>\""Message\"": \""Failed to write events. Error encountered after writing [0] batches [...] \""Type\"": \""AzureFunctionOutputAdapterFailure\"" </code></pre>  <p>I don't have error on the Azure Function but it stopped work. Has anyone ever had the same problem?</p>""",azure-functions
45144120,"unable to get metric data of classic VM through ARM api <p>I am trying to fetch metric data of a classic VM through ARM API but i am getting error \Resource provider not found: [Microsoft.ClassicCompute]\"". I am sending GET request to <a href=\""https://management.azure.com/subscriptions/cc\"" rel=\""nofollow noreferrer\"">https://management.azure.com/subscriptions/cc</a>******-9605-4***********c0f/resourceGroups/dummy-test-vm/providers/Microsoft.ClassicCompute/virtualMachines/dummy-test-vm/providers/microsoft.insights/metrics?api-version=2016-06-01&amp;$filter = (name.value eq 'Network Out') and aggregationType eq 'Total' and startTime eq 2017-06-18 and endTime eq 2017-07-17 and timeGrain eq duration'P10D'. I don't know where i am going wrong?</p>""",azure-virtual-machine
54555915,"Polybase: Can't connect to Azure Blob from SQL Server <p>I am trying out the new <a href=\https://docs.microsoft.com/en-us/sql/relational-databases/polybase/polybase-configure-azure-blob-storage?view=sqlallproducts-allversions\"" rel=\""nofollow noreferrer\"">Polybase-Feature in SQL-Server by connecting to a CSV</a>. However I do not manage to connect to the Azure Blob Storage: </p>  <pre><code>CREATE EXTERNAL DATA SOURCE AzureBlob WITH (     TYPE = HADOOP      LOCATION = 'wasbs://myfolder@myblob.blob.core.windows.net'      CREDENTIAL = mycredential ); GO  </code></pre>  <p>I always get an error saying:</p>  <blockquote>   <p>Incorrect syntax near 'HADOOP'</p> </blockquote>  <p>My SQL Server runs on an Azure VM  however I am not sure which services are supposed to be running: <a href=\""https://i.stack.imgur.com/oIpd6.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/oIpd6.png\"" alt=\""enter image description here\""></a></p>  <p>I also checked TCP/IP is enabled.  <a href=\""https://i.stack.imgur.com/MnyVV.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/MnyVV.png\"" alt=\""enter image description here\""></a></p>  <p>I also tried using SSDT and dsql-files as suggested in <a href=\""https://stackoverflow.com/questions/32901234/polybase-create-external-datasource-giving-syntax-error\"">this post</a> - but the error doesn't go away.</p>""",azure-virtual-machine
48880878,"Unable to debug and publish Azure Function from Visual Studio 2017 <p>I used to debug and publish my Azure Function Project using Visual Studio 2017.</p>  <p>However suddenly everything stopped working. </p>  <p>When i tried to debug the project i got the error \A project with an Output Type of Class Library cannot be started directly.\"". When i tried to publish the project  the option to publish to Azure disappeared and i'm only offered to publish to a folder. When trying to create a profile i can also only choose the Folder Profile type.</p>  <p>I saw a similar behavior once in a Web Project when the \""Project Sdk\"" Attribute in the .csproj file was wrong but i doublechecked it with a newly created Azure Function Project and it was the same. When i create a new function project  i can publish to Azure as i could before.</p>  <p>I'm using the following packages:   </p>  <p>along with .NET Framework 4.7.1.</p>  <p>Also i'm referencing some other projects from my solution containing Business Logic.</p>  <p>I ended up creating a new function project  copying everything there and now it's working again as expected.</p>  <p>Does anybody know how this could happen and how to fix it without creating everything from scratch?</p>""",azure-functions
41983698,"Azure VM size not available <p>I'm currently working with Azure (benefit from my MSDN subscription) and trying to deploy three Centos 7.2 VMs (F8 Standard size) in one region.</p>  <p>Unfortunately I can only deploy two of those VMs. When I want to deploy the third VM I cannot select F8 Standard as the size. It is greyed out and says \Not available\"". What I can do is deploy another VM with size F8 Standard in another region.</p>  <p>What is the deal with it? I cannot go cross-region as I need one file share across the three VMs.</p>""",azure-virtual-machine
31679379,"Git commit showing in wrong branch <p>I'm working with Git through Visual Studio and I noticed a few commits that exist on <em>branch-a</em>  but are showing up in the history of my master branch. <em>branch-a</em> was never merged into master and I made sure that I have the latest code  so this is unexpected behavior.</p>  <p>The commits exist on master on Visual Studio Online  but not through VS's Team Explorer. I see the the commits when I run <code>git log</code> (in the command prompt) for master  and <em>branch-a</em> comes up when I run <code>git branch --merged master</code> .</p>  <p>Last strange piece of evidence: I manually searched the code for the changes made in these commits  and I see no trace of them. I searched my local code and the code on Visual Studio Online.</p>  <p>Can anyone please explain to me why this might be happening?</p>  <p>Much appreciated!</p>  <p>EDIT: Here are the results of<br> <code>git log --graph --decorate --oneline --boundary master...branch-a</code></p>  <pre><code>* dcb976b (HEAD  branch-a) Refactoring export method for CA Sick Hours Repor * dba6163 Added functional query to CA Sick Hours Report * 705d108 Adding CA Sick Hours Report under the reports dropdown. Placeholder va | *   95d2ac0 (origin/remote-checks-create-folder-on-project-save  origin/master | |\\ | | * cbf1dc7 (origin/project-payrun-list-report  project-payrun-list-report) Ad | | * 7bfd8b0 Adding Project Pay Run List report (replacing the one available on | * |   a83b229 Merge pull request 73 from mgmt-file-additions into master | |\\ \\ | | * | 9ca1710 Moving format string into a const variable | | * | 22baa60 Editing Management File: Parent Company column is now parent-mos | * | | 0fb1d1e Replacing Min with Max to handle case where only some cells were | * | |   fbbe9c7 Merge pull request 72 from hf-improve-db-connection-resiliency | |\\ \\ \\ | | |_|/ | |/| | | | * | 0b6d09c (origin/hf-improve-db-connection-resiliency) Refactoring some co | | * | 7f3d625 Replacing the last SqlConnection's with ReliableSqlConnection's. | | * | 9f1ed46 Logging retry attemtps to windows event log. | | * | 2069f5e Adding custom transient error detection for the ADO part of the | | * | 59550c6 Refactoring several methods to use the new ReliableSqlConnection | | * | d14a7ba Adding ReliableSqlConnection to JFA.DL. | | * | f53c2bd Removing manual transactions (EF). | | * | a2184e4 Adding resiliency execution strategy. | * | |   2a2cbc2 Merge pull request 70 from hf-p-and-w-custom-report into maste | |\\ \\ \\ | | |_|/ | |/| | | | * | 7665d98 (origin/hf-p-and-w-custom-report) Fixing several issues with the | | * | c5d5605 Adding logic to gather P&amp;W Cost Report data. | | * | 2a631d4 half-baked EOR report changes from call with Carlos | | * | 2cb9440 Adding method to generate P&amp;W Costs Report content. | | * | 03040f5 Adding code to print P&amp;W Costs Report. | | * | 85c76ee Adding P&amp;W custom report. | * | | 2d1b2b8 (tag: v1.9.4) Adding flat amount timesheet items to the sick hou | * | | 5a4f57f (origin/hf-sick-hours-accruing-unprocessed-timesheets) Hiding \P | * | | d3af8e5 Logging cause of application end. | * | | 49b7ca6 Using fully processed timesheets only to calculate sick hours. | * | | b98dc8e (origin/set-code-import  set-code-import) Fixing issue with cust | | |/ | |/| | * |   402e16f Merge pull request 71 from mgmt-report-add-parent-co-column into | |\\ \\ |/ / / | * | e023583 Adding parent company column to Management -&gt; Generate Payroll Fil | | o 0234afb Optimizing query (fringe deduction only). o | e1afdf9 (tag: v1.9.3) Fixing issue with the ADP QTRLY File CAPs. |/ o d383d04 (tag: v1.9.2) Fixing issue with exempt taxes. </code></pre>""",azure-devops
53262512,"Deploying Java Spring Boot Application to Azure Web App Linux <p>I struggle since 3 days with deprecated tutorials and not even working Microsoft docs.</p>  <p>After the Microsoft Docs did not really help me I tried to do the following:</p>  <p>Using the IntelliJ CE Plugin for Azure I try to deploy <a href=\https://github.com/bbenz/spring-boot-todo\"" rel=\""nofollow noreferrer\"">this</a> demo<br> to Azure App Service.</p>  <p>From the plugin I chose \""Run on Web App\""  which succeeds as:</p>  <pre><code>Stopping Web App... Getting Deployment Credential... Connecting to FTP server... Removing from FTP server: /site/wwwroot/webapps/TodoDemo-0.0.1-SNAPSHOT  Uploading artifact to: /site/wwwroot/webapps/TodoDemo-0.0.1-SNAPSHOT.war ... Uploading successfully... Logging out of FTP server... Starting Web App... Deploy successfully! URL: https://**********.azurewebsites.net/TodoDemo-0.0.1-SNAPSHOT </code></pre>  <p>Then  clicking the link \""URL\"" I end up at: <a href=\""https://i.stack.imgur.com/8K81R.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/8K81R.png\"" alt=\""Whitelabel Error Page\""></a></p>  <p>What step am I missing? </p>  <p>Here some more info about the environment:</p>  <p><a href=\""https://i.stack.imgur.com/8UEJs.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/8UEJs.png\"" alt=\""Application Settings\""></a></p>  <p>I did not change any other setting from the out-of-the-box Web App.</p>  <p>PS: If I deploy the same WAR to a VM on Azure  everything works fine. Happy to provide more info if necessary.</p>""",azure-web-app-service
50025144,"Testing an Azure Function Service Bus Trigger in the Portal with a Brokered Message <p>I've created an Azure Function that is using a Service Bus queue trigger to run. It's also using a <code>BrokeredMessage</code> as the queue item parameter because I need to get some data out of the custom User Properties of the message.</p>  <pre><code>public async static Task Run([ServiceBusTrigger(\myQueue\""  AccessRights.Manage  Connection = \""ConnString\"")]BrokeredMessage queueItem  TraceWriter log) {     string myProperty = queueItem.Properties[\""MyProperty\""].ToString();     ... // do stuff } </code></pre>  <p>This all works great and I've deployed it to Azure  but I'd like to test it through the portal. They provide a way to test your function:</p>  <p><a href=\""https://i.stack.imgur.com/xe0aD.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/xe0aD.png\"" alt=\""enter image description here\""></a></p>  <p>But it just asks for the request body. Is there a way to also add User Properties as well? </p>""",azure-functions
52709696,No Internet on Custom Image VM for Azure <p>I launched an Ubuntu 18.04 VM with Azure. I installed a bunch of stuff that I need. Then  I used the dashboard to create a custom image from this machine. After that  I checked that the image was okay by launching some machines with that image. Everything seemed to be working fine.</p>  <p>Today  I launched a new instance with my custom image. Then I tried to install a few things with <code>apt-get install</code> and I get the following error (e.g. for unzip):</p>  <pre><code>sudo: unable to resolve host ABCDEFG: Resource temporarily unavailable Reading package lists... Done Building dependency tree Reading state information... Done Package unzip is not available  but is referred to by another package. This may mean that the package is missing  has been obsoleted  or is only available from another source  E: Package 'unzip' has no installation candidate </code></pre>  <p>This same thing happens for any package I try to install. After testing some basic things with my repositories  I checked the internet connection with ping. E.g. <code>ping www.google.com</code> which is also not working. I launched a vanilla Ubuntu 18.04 instance and I am not having these problems with that machine.</p>  <p>I have also tried <code>sudo reboot</code> but no luck with that. I did notice that when the system booted it shows the following error  also indicating that something is wrong with the internet:</p>  <pre><code>Failed to connect to https://changelogs.ubuntu.com/meta-release-lts. Check your Internet connection or proxy settings </code></pre>  <p>Any help is greatly appreciated.</p>,azure-virtual-machine
40976441,"Azure - Connecting .NET web app with azure sql database <p>I have a team project and I'm trying to publish the app at Azure  which I successfully did. I was able to get our database to Azure SQL server  but now I'm struggling with connecting the app with this database.</p>  <p>Originaly the app is working with a .mdf file locally  but now  when I'm publishing the app  I want to use the DB at azure server. I changed all the connection strings of <code>.mdf</code> file </p>  <pre><code>(@\Data Source = (LocalDB)\\MSSQLLocalDB; AttachDbFilename =\"" + Path.GetFullPath(AppDomain.CurrentDomain.BaseDirectory + @\""..\\..\\..\\PATH\""))  </code></pre>  <p>in the code to the azure database connection string </p>  <pre><code>(@\""Data Source = Server=tcp:nameofserver.database.windows.net 1433;Initial Catalog=sqlmusicdb;Persist Security Info=False;User ID=...;Password=...;MultipleActiveResultSets=False;Encrypt=True;TrustServerCertificate=False;Connection Timeout=30;\"") </code></pre>  <p>but after publishing  the app is not connected to database  as it is writing </p>  <blockquote>   <p>AN ERROR OCCURRED WHILE PROCESSING YOUR REQUEST</p> </blockquote>  <p>Any help  please? Thanx.</p>""",azure-web-app-service
54908109,"Azure web app is throwing an error on put requests <p>I have an application that includes a JS client with an ASP.Net server  and is published as an Azure web app.</p>  <p>The application is working smoothly on local environment  however  when browsing to the web app  any PUT request returns with failure - error 500. That's despite the fact that the posted data is indeed saved successfully. Also when remote debugging the web app  the code is executed completely with no errors.</p>  <p>Looking at the diagnostic logs  I can see that the request fails on an IIS module called: ManagedPipelineHandler.</p>  <p>This is the error details:  <a href=\https://i.stack.imgur.com/Cz40n.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/Cz40n.png\"" alt=\""error details\""></a></p>  <p>How can I solve this issue?</p>""",azure-web-app-service
53409451,"Assigning \Test suite\"" for Azure Devops to WebdriverIO JUnit-style XML report file <p><strong>TL;DR:</strong></p>  <p>Which attribute in my XML report file do I have to set in what manner to obtain a populated <em>Test suite</em> in my Azure Devops build test results?</p>  <hr>  <p>I have a number of specification files <code>*.spec.js</code> that are run as UI tests by WebdriverIO and a custom reporter that outputs results to an XML file according to the JUnit scheme (there are slightly differing versions: <a href=\""https://github.com/windyroad/JUnit-Schema/blob/master/JUnit.xsd\"" rel=\""nofollow noreferrer\"">one linked by the Azure Devops doc</a>  and <a href=\""https://github.com/junit-team/junit5/blob/master/platform-tests/src/test/resources/jenkins-junit.xsd\"" rel=\""nofollow noreferrer\"">one on the JUnit Github page</a>).</p>  <p>Roughly  a file lookes like this:</p>  <pre><code>&lt;?xml version=\""1.0\"" encoding=\""UTF-8\""?&gt; &lt;testsuites&gt; &lt;testsuite name=\""Spec A\"" timestamp=\""[timestamp]\"" time=\""2.459\"" tests=\""6\"" failures=\""0\"" errors=\""0\"" skipped=\""0\""&gt;     &lt;testcase name=\""Spec A Section 1 Test a\"" classname=\""spec-A.spec.js\"" time=\""0.608\""/&gt;     ... &lt;/testsuite&gt; &lt;testsuite name=\""Spec B1\"" timestamp=\""[timestamp]\"" time=\""3.875\"" tests=\""9\"" failures=\""0\"" errors=\""0\"" skipped=\""0\""&gt;     &lt;testcase name=\""Spec B1 Section 1 Test a\"" classname=\""spec-B.spec.js\"" time=\""0.61\""/&gt;     ...     &lt;testcase name=\""Spec B1 Section 1 Subsection 1.1 Test a\"" classname=\""spec-B.spec.js\"" time=\""0.204\""/&gt;     ... &lt;/testsuite&gt; &lt;testsuite name=\""Spec B2\"" timestamp=\""[timestamp]\"" time=\""1.914\"" tests=\""9\"" failures=\""0\"" errors=\""0\"" skipped=\""0\""&gt;     &lt;testcase name=\""Spec B2 Section 1 Test a\"" classname=\""spec-B.spec.js\"" time=\""0.219\""/&gt;     ... &lt;/testsuite&gt; &lt;/testsuites&gt; </code></pre>  <p>When I <a href=\""https://docs.microsoft.com/en-us/azure/devops/pipelines/tasks/test/publish-test-results?view=vsts&amp;tabs=yaml\"" rel=\""nofollow noreferrer\"">publish these test results according to the Azure Devops doc</a>  I am only able to filter/group by <em>Test file</em>  e.g. <code>spec-A.spec.js</code></p>  <p><a href=\""https://i.stack.imgur.com/Byoew.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/Byoew.png\"" alt=\""enter image description here\""></a></p>  <p>but not by <em>Test suite</em>: all tests get grouped under “Unspecified”  even though I would expect the <code>name</code> attribute of the <code>&lt;testsuite&gt;</code> to show up there.</p>  <p><a href=\""https://i.stack.imgur.com/7nmlO.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/7nmlO.png\"" alt=\""enter image description here\""></a></p>""",azure-devops
39622580,"VSTS - How to add Bug using Scrum template - No dropdown <p>I am using Visual Studio Team Services  with the Scrum template. I can't figure out how to add a bug. I HAVE selected the option to treat bugs as backlog items. However  when I go to add a new backlog item  there is no dropdown for the Type (see below screenshot): </p>  <p><a href=\https://i.stack.imgur.com/JRVdV.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/JRVdV.png\"" alt=\""enter image description here\""></a></p>  <p>All the examples that I've seen online for adding a bug show a dropdown for \""Type\""  where you can choose \""Bug\""  but for me  there is no dropdown.</p>  <p>Note that if I add it as a regular Product Backlog Item  I can then edit it and change the type to \""Bug\""  but that is cumbersome. </p>""",azure-devops
56354856,"Try to build Azure function app in linux following error returns \No job functions found. Try making your job classes and methods public\"" <p>When I try to build azure functions in Linux(Ubuntu 18.04) Following error returns. Following are the steps I followed in the process.After cloning the repository from the git.</p>  <pre><code>dotnet build func start --build </code></pre>  <p>And following output returns </p>  <pre><code>[5/29/19 6:46:18 AM] No job functions found. Try making your job classes and methods public. If you're using binding extensions (e.g. Azure Storage  ServiceBus  Timers  etc.) make sure you've called the registration method for the extension(s) in your startup code (e.g. builder.AddAzureStorage()  builder.AddServiceBus()  builder.AddTimers()  etc.). [5/29/19 6:46:18 AM] Host initialized (49ms) [5/29/19 6:46:18 AM] Host started (55ms) [5/29/19 6:46:18 AM] Job host started Hosting environment: Production Content root path: /media/ishara/Data/MAS/SAGE/SageShipmentFunctions/SageShipmentFunctionsApp Now listening on: http://0.0.0.0:7071 Application started. Press Ctrl+C to shut down. [5/29/19 6:46:23 AM] Host lock lease acquired by instance ID '000000000000000000000000CAE400CD'. </code></pre>  <p>Below follows the information about my system </p>  <pre><code>.NET Core SDK (reflecting any global.json):  Version:   2.2.300  Commit:    73efd5bd87  Runtime Environment:  OS Name:     ubuntu  OS Version:  18.04  OS Platform: Linux  RID:         ubuntu.18.04-x64  Base Path:   /usr/share/dotnet/sdk/2.2.300/  Host (useful for support):   Version: 2.2.5   Commit:  0a3c9209c0  .NET Core SDKs installed:   2.2.300 [/usr/share/dotnet/sdk]  .NET Core runtimes installed:   Microsoft.AspNetCore.All 2.2.5 [/usr/share/dotnet/shared/Microsoft.AspNetCore.All]   Microsoft.AspNetCore.App 2.2.5 [/usr/share/dotnet/shared/Microsoft.AspNetCore.App]   Microsoft.NETCore.App 2.2.5 [/usr/share/dotnet/shared/Microsoft.NETCore.App]  To install additional .NET Core runtimes or SDKs:   https://aka.ms/dotnet-download  </code></pre>""",azure-functions
57041039,Calling Azure AD secure functions from Azure Data Factory <p>I recently secured my azure functions by Azure Active Directory. Hence you need access token set in auth header to enable you to call them. I am successfully able to do that from my Front end Angular apps. But in my backend I have Azure Data factory as well  How can i enable Azure Data factory to use Azure AD while calling functions and not host key?</p>,azure-functions
54147531,Need a help to identify the cost to create a virtual machine in Azure Dev-Test LAB as well the availability to install require software <p>I need to create a virtual machine regarding the development of Dynamics CRM. I need the below software into the Virtual Machine.</p>  <ol> <li>Visual Studio 2017 Community Edition</li> <li>Microsoft Dynamics CRM Report Authoring Extension</li> <li>Google Chrome Web Browser</li> <li>Microsoft Office</li> <li>Adobe Reader</li> </ol>  <p>Can someone help me to identify that? Can I install the above things into the Azure Virtual Machine in Azure DevTest Lab?</p>  <p>If yes  then how much would the cost be to use the above-configured virtual machine?</p>  <p>I need a virtual machine should have (4 cores and 8GB of RAM). Any help would much be appreciated.</p>,azure-virtual-machine
47995225,Web App Autoscaling - What actually happens when this occurs? <p>In Azure  you can auto scale your web app. You can create a rule that allows you to determine when to auto scale. When the auto scaling occurs one App Service instance is added (or removed). I'm curious what exactly this means. For example  say I currently have a web app using the S2 service tier. When the scaling occurs  is another S2 instance added? I suspect this is the case. And  if this is the case  what handles the load balancing between the two (or N) instances? Is this handled automatically?</p>,azure-web-app-service
52843564,"Azure Function Read local.settings.json to object <p>I know i could add all my environment vars under the values {} section of local.settings.json. I am however trying to keep a tidy home and would like if I could do something like this. </p>  <p>local.settings.json</p>  <pre><code>   { \IsEncrypted\"": false  \""Values\"": { \""AzureWebJobsStorage\"": \""UseDevelopmentStorage=true\""  \""AzureWebJobsDashboard\"": \""\""  \""Hello\"": \""world\""  }  \""ClientConfiguration\"": {     \""this\"": \""that\""      \""SubscriberEndpoint\"": \""\""      \""Username\"": \""\""      \""Password\"": \""\""      \""ObjectEndpoint\"": \""\""  } } </code></pre>  <p>in my code i have </p>  <pre><code> var config = JsonConvert.DeserializeObject&lt;myConnectionObject&gt; (Environment.GetEnvironmentVariable(\""ClientConfiguration\"")); </code></pre>  <p>No matter what I do I cannot get this to work. Why can't I at least get the contents of ClientConfiguration? Just keeps coming back null. </p>  <p>IF I add ClientConfiguration {} to the values like </p>  <pre><code>...\""Values\"" : { ...  \""Hello\"":\""world\""  \""ClientCOnfiguration\"" : {above} } </code></pre>  <p>I end up with an error saying azurewebjobsstorage can't be found and 'func settings list' is just empty </p>""",azure-functions
49281924,"What is the correct way to handle a null response from an asynchronous function? <p>I am working on an Azure function that communicates with my table and updates data in the table. I recently discovered that the <code>Microsoft.WindowsAzure.Storage</code> package only has Async functions now  and I am unfamiliar with those.</p>  <p>In my function I'm using for testing  I want to return true if the row exists  false if it doesn't. It works if the row exists  but the program hangs (because it's waiting for a response) if the row does not exist.</p>  <p>Can anyone help me?</p>  <p>Here is my code:</p>  <pre><code>public static bool rowExists(CloudTable table  string city  string state) {     TableOperation tOP = TableOperation.Retrieve&lt;SickCity&gt;(city  state);     Task&lt;TableResult&gt; result = table.ExecuteAsync(tOP);     if (result == null)         return false;     else         return true; } </code></pre>  <p>Edit:</p>  <p>Here is where I'm calling rowExists</p>  <pre><code>log.Info($\Does the row \\\""New York  NY\\\"" exist? {rowExists(sickTable  \""New York\""  \""NY\"")}\""); </code></pre>""",azure-functions
55964569,Messages going to dead letter rather than active queue <p>I have configured service bus and I am sending messages to a topic in it. I am observing a strange behavior that my messages are going to dead letter queue and not the active queue.</p>  <p>I have checked the properties for my topic like the auto delete on idle  default time to live but not able to figure out the reason. </p>  <p>I tried turning off my listener on this topic hoping some code failure causing the messages to go to dead letter. But still not able to figure out the reason.</p>,azure-storage
27245962,SSAS Tabular Model on Azure VM <p>I have an Azure VM with SSAS Tabular Model.<br> I understand that using Virtual Network it can be accessed from On-Premise.<br> But is it possible to access it using DAX queries without creating Virtual Network?  </p>,azure-virtual-machine
50985770,"Connect to Kafka HDInsight cluster via Azure webapp (Java) <p>I'm exploring Azure related technologies.</p>  <ol> <li>I have created Azure webapp using Java.</li> <li>Created Kafka HDInsight cluster on Azure.</li> </ol>  <p>How to connect to Kafka cluster(<em>See point 2</em>) through Azure Java WebApp(<em>See point 1</em>) ?</p>  <p>One thing I did is took host-names from <strong>Ambari-UI</strong> to configure Kafka in my webapp  but it seems not working.</p>  <p>Also how to view logs/data in Kafka HDInsight cluster ?</p>  <p>Webapp Code for connection : \<strong>10.0.0.13:9092</strong>\"" address is taken from Ambari UI</p>  <pre><code>    Properties properties = new Properties();     String servers = \""10.0.0.13:9092\"";     properties.put(\""bootstrap.servers\""  servers);     properties.put(\""key.serializer\""  \""org.apache.kafka.common.serialization.StringSerializer\"");     properties.put(\""value.serializer\""  \""org.apache.kafka.common.serialization.StringSerializer\"");      kafkaProducer = new KafkaProducer(properties); </code></pre>""",azure-web-app-service
43064946,Azure function proxy returns error 500 <p>Currently I am having Azure API app located in UK but I would like to create a Proxy in HK for my users in china to access the servers without much performance impact in connecting the DB server that's allocated in EU.</p>  <p>I just setting up the proxy functionality on Azure function  which is located in East Asia. Unfortunately  I kept getting error code 500 with the api request though postman.</p>  <p>How can I trace the error which is causing error code 500?</p>,azure-functions
46885319,"Azure Function Connection String with database First approch with Entity Framework <p>I have an Azure Function that uses database first approach connection string. The connection string is located in the <code>local.settings.json</code> file  which contains the sensitive data.</p>  <pre><code>{   \IsEncrypted\"": false    \""Values\"": {     \""AzureWebJobsStorage\"": \""UseDevelopmentStorage=true\""      \""AzureWebJobsDashboard\"": \""UseDevelopmentStorage=true\""   }    \""ConnectionStrings\"": {     \""MyConnectionString\"": \""data source=localhost\\\\sqlexpress;initial catalog=SampleQrCodes;user id=sa;password=****;MultipleActiveResultSets=True;App=EntityFramework\""   } }  </code></pre>  <p>If I try removing providerName it gives me the following exception:</p>  <blockquote>   <p>The context is being used in Code First mode with code that was generated from an EDMX file for either Database First or Model First development.  This will not work correctly.....you pass it to one of the base DbContext constructors that take a DbConnection</p> </blockquote>  <p><strong>Actual connection string</strong> (generated from EF):</p>  <pre><code>&lt;add name=\""DataContext\"" connectionString=\""metadata=res://*/EFModel.csdl|res://*/EFModel.ssdl|res://*/EFModel.msl;provider=System.Data.SqlClient;provider connection string=&amp;quot;data source=localhost\\sqlexpress;initial catalog=SampleQrCodes;user id=sa;password=***;MultipleActiveResultSets=True;App=EntityFramework&amp;quot;\"" providerName=\""System.Data.EntityClient\"" /&gt; </code></pre>  <p>Here is similar question <a href=\""https://stackoverflow.com/questions/41943907/load-connection-string-from-config-file-in-azure-functions\"">Load Connection String from Config File in Azure Functions</a> but it is not working for me how to define this connection string in <code>local.settings.json</code> via database first approach?</p>""",azure-functions
55796581,Exporting Users Within Web-Apps That Are Not AD-Group Managed <p>We have a LOT of web apps that have users assigned. Historically this was managed with AD Group membership  which made exportation of these users fairly straightforward. However  recently users have been assigned piece-meal. I am looking for a way to export all of these users into a spreadsheet for auditing purposes. Ideally this would be powershell based  but at this point I am fairly openminded to it being written in Cobalt if it works. </p>  <p>1) All of the web apps have the naming standard (first leading 4 characters are AMS-)  2) AD Groups on-prem shows about 15 groups tied to AMS-  there are closer to 75 web apps deployed in Azure with AMS-. 3) Approximately 60% are back-end services  40% are user facing. There is no naming standard differential between the two.* 4) The requirement for this audit is to capture 4a) Who has access to these web apps  4b) what level of permissions within the web app they possess.</p>  <p>*The reason I mention that is because the second portion of this audit is going to focus on differentiating between the two so that this audit is much simpler.</p>  <p>Thanks for any help! </p>  <p>Regards </p>,azure-web-app-service
15195773,Azure Table Storage - RowKey design for ordered data <p>I store large quantities of GPS data in storage tables.  Each partition can reach up to 1 million entities.  Each GPS entity that is inserted into the table is actually sequential to the previous data inserted  so order matters.</p>  <p>Sometimes I need to perform the following query:  </p>  <blockquote>   <p><em><strong>Get the previous/next 3 GPS entities from the current entity (within the same partition).</em></strong></p> </blockquote>  <p>Options for RowKey design:</p>  <ol> <li><p><strong>Create an incrementing integer.</strong>  But how do I track what the current size of the table is?  There is no way to get table row count  or to get the last inserted row.</p></li> <li><p><strong>Use DateTime Ticks.</strong>  But how do get the previous/next entity using ticks?</p></li> </ol>  <p>I'm using the SDK version 2.0 in C#.</p>,azure-storage
57218196,"Executing queries being timing out after having performed many queries <p>I am executing queries on a table asynchronously  and everything is fine for a while  but then all of a sudden the queries begin timing out. </p>  <p>In short I have a text file containing a number of IDs  for each of these IDs I want to execute a query in a table. The query itself should not take long  less than 5 seconds  however after having successfully executed many queries  all of a sudden the application starts timing out every single time. If I then restart my application and re-run the IDs that timed out  they now run perfectly without issues.</p>  <p>So say I have a list of 1000 IDs  then it starts timing out after having processed and successfully executed 200 IDs.</p>  <p>I have tried inserting a MaximumExecutionTime and setting it much higher than the standard 5 seconds  but it still times out. I have tried not sharing the CloudTableClients  and simply have each \thread\"" create a new instance.</p>  <p>The code is part of a larger project  so I will include the relevant bits here and omit some other code. I start by creating one CloudTableClient  this is shared between the different tasks  as if I have understood it correctly it is okay for it to be shared. I then have an ActionBlock that I post the ids to. I have limited the MaxDegreeOfParallelism to how many processors I have  I have had the best experience with this.</p>  <pre><code>CloudStorageAccount cloudStorage = CloudStorageAccount.Parse(_ParsedConnectionString); CloudTableClient tableClient = cloudStorage.CreateCloudTableClient();  var block = new ActionBlock&lt;int&gt;(   async id =&gt;   {     // Do stuff     var res = await executeQuery(id  tableClient);     // Do more stuff   }    new ExecutionDataflowBlockOptions   {     MaxDegreeOfParallelism = Environment.ProcessorCount   } );  StreamReader file = new StreamReader(someFile); string line; while ((line = file.ReadLine()) != null) {   block.Post(Convert.ToInt32(line)); } block.Complete(); block.Completion.Wait(); </code></pre>  <p>And in the executeQuery function:</p>  <pre><code>CloudTable table = tableClient.GetTableReference(_someTable);  var tableQuery = new TableQuery&lt;SomeEntity&gt; {   FilterString = \""some query\"" };  TableContinuationToken continuationToken = null; TableRequestOptions options = new TableRequestOptions {   MaximumExecutionTime = new TimeSpan(0  2  0) }; OperationContext context = new OperationContext();  do {   var tableQueryResult = await table.ExecuteQuerySegmentedAsync(tableQuery  continuationToken  options  context);   continuationToken = tableQueryResult.ContinuationToken;   // Do stuff } while (continuationToken != null); </code></pre>  <p>The query is fine  as if I re-run the application with an ID it previously timed out with  it runs as expected.</p>  <pre><code>The client could not finish the operation within specified timeout. at Microsoft.WindowsAzure.Storage.Core.Executor.Executor.EndExecuteAsync[T](IAsyncResult result) in c:\\Program Files (x86)\\Jenkins\\workspace\\release_dotnet_master\\Lib\\ClassLibraryCommon\\Core\\Executor\\Executor.cs:line 51    at Microsoft.WindowsAzure.Storage.Core.Util.AsyncExtensions.&lt;&gt;c__DisplayClass2`1.&lt;CreateCallback&gt;b__0(IAsyncResult ar) in c:\\Program Files (x86)\\Jenkins\\workspace\\release_dotnet_master\\Lib\\ClassLibraryCommon\\Core\\Util\\AsyncExtensions.cs:line 69 --- End of stack trace from previous location where exception was thrown ---    at System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw()    at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task)    at System.Runtime.CompilerServices.TaskAwaiter`1.GetResult()    at App.Parser.&lt;executeQuery&gt;d__25.MoveNext()` </code></pre>""",azure-storage
8974853,Do I need a sleep time in my worker role? <p>I have a worker role monitoring a queue.  As much as I would like it to be slammed  most of the time that queue will be empty.  I get a new item in the queue every couple of minutes.</p>  <p>I have:</p>  <pre><code> public override void Run()  {      while (true)      {          //Check the queue for new messages          //if there's a new message  do some stuff      }  } </code></pre>  <p>My question is  do I need to do a Thread.Sleep(x) if there isn't an item in the queue?  Or can I just keep checking it over and over?  If I do need to sleep  how long should I sleep for?  (milliseconds/seconds?)</p>  <p>My main concern is Azure charges.</p>,azure-storage
44630065,Configure Azure Traffic Manager for Load Balancing with Weighted method on same region 2 App Service <p>Trying to configure Traffic Manager for load balancing with Weighted method  both endpoints are at West US region using standard 2 plan. </p>  <p>Azure App Services: A(West US) - 50% Traffic B(West US) - 50% Traffic</p>  <p>First endpoint added successfully with 50 weight  When I am adding the second App Service as endpoint of traffic manager I'm getting this error:</p>  <blockquote>   <p>Failed to save configuration changes to Traffic Manager profile   '*****'. Error: Some of the provided Azure Website endpoints are not   valid: One or more conflicts detected in traffic manager   configuration. Multiple domains point to region 'West US':   a.azurewebsites.net  b.azurewebsites.net</p> </blockquote>,azure-web-app-service
12273835,"Azure Virtual Machine / Windows Server 2012 and \This web page is not available\"" error <p>I have just created an azure virtual server 2012 and made a simple html page. I installed IIS on it  and added an endpoint to my portal  called it web and set it to tsp  80  80  no load balanced.</p>  <p>But when I try to go to my domain  I get an error saying page not available. I can login to my virtual server and run the page inside. So it works.  But it's blocking outside access.</p>  <p>There is also a firewall rule on the server allowing incoming traffic on port 80.</p>  <p>I am probably missing a step somewhere  but I could not find any instructions on how to do it. It is mostly guess work on my side.</p>  <p>Can anyone help?</p>""",azure-virtual-machine
55277040,One build\release for all environments vs multiple biulds\releases for all environments <p>At my current setup this is what's happening </p>  <ul> <li>Build Dev</li> <li>Build Uat</li> <li>Build Production</li> </ul>  <p>and then </p>  <ul> <li>Release Dev</li> <li>Release Uat</li> <li>Release Production</li> </ul>  <p>Now the problem is that we only have 1 agent (not sure why)  it doesn't happens often but sometimes we need to build and release hot fixes quickly however each BUILD takes around 10+ minutes and can't run in parallel to other builds. Same for releases. So  for deploying a hotfix to production just takes painful process of 2 hours or so.</p>  <p><strong>Need for seperate builds:</strong></p>  <ul> <li><p>While building we are specifying the build command like this  </p>  <p>ng build -configuration --uat</p>  <p>ng build -configuration --prod</p></li> </ul>  <p>Why we shouldn't create One build\release for all environments ? Assuming there will work arounds to create different artifacts for different configurations or we may just use application settings on azure or soemthing like that.</p>,azure-devops
53335447,Azure Function deploy error: Your function app is targeting V1  but Azure host has function version V2  <p>I'am trying to deploy my new created function with .net core This is my project content and my function on azure is configured with version 2 and the FUNCTIONS_EXTENSION_VERSION is ~2.</p>  <pre><code>&lt;TargetFramework&gt;netcoreapp2.1&lt;/TargetFramework&gt; &lt;AzureFunctionsVersion&gt;v2&lt;/AzureFunctionsVersion&gt; </code></pre>  <p>If I do a deploy over my local repository it throws me this error. </p>  <pre><code>remote: Your function app is targeting V1  but Azure host has function version V2  remote: please change the version using the portal or update your 'FUNCTIONS_EXTENSION_VERSION' appsetting and retry </code></pre>  <p>Any ideas what I can do?</p>,azure-functions
45303993,"Ignore files within the 'Delete Files Task' <p>As part of my install scripts for Visual Studio Online (VSO / VSTS) I delete the files in my directory shortly after uninstalling the services.</p>  <p>We have configuration files and logs that I'd like to preserve but everytime I try to tell the 'Delete Files Task' to ignore those files it deletes them anyway.</p>  <p>What I want is for ALL files in the Bifrost directory to be deleted except for</p>  <ul> <li>The Logs folder</li> <li>App.Connections.Config</li> <li>App.Queues.Config</li> </ul>  <p>Can someone help please?</p>  <p><a href=\https://i.stack.imgur.com/H142f.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/H142f.png\"" alt=\""enter image description here\""></a></p>""",azure-devops
43629557,Check space used in azure storage accounts in my subscription <p>How can I check how much space I used in each of my azure storage accounts in my subscription resource group wise.</p>  <p>I am not able to find a way to check space used in azure storage account through PowerShell  CLI  portal...</p>,azure-storage
56427015,"Unable to join VM to AD - cannot complete this function <p>I am having a VMs in Azure and AD VM also in Azure. They are all in same network  although in different subnets.</p>  <p>I have provisioned the VM's by terraform and they are unable to join to AD  hence I am doing manually to see what the error is.</p>  <p>Commands to connect VM to AD is below:</p>  <pre><code>PS C:\\Users\\scmadmin&gt; $domain = \contoso.com\"" PS C:\\Users\\scmadmin&gt; $password = \""&lt;password here&gt;\"" | ConvertTo-SecureString -asPlainText -Force PS C:\\Users\\scmadmin&gt; $username = \""$domain\\scmadmin\"" PS C:\\Users\\scmadmin&gt; $credential = New-Object System.Management.Automation.PSCredential($username $password) PS C:\\Users\\scmadmin&gt; Add-Computer -DomainName $domain -Credential $credential </code></pre>  <p>The log output after the execution is below:</p>  <pre><code>Add-Computer : Computer 'erxprebussvc01' failed to join domain 'contoso.com' from its current workgroup 'WORKGROUP' with following error message: Cannot complete this function. At line:1 char:1 + Add-Computer -DomainName $domain -Credential $credential + ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~     + CategoryInfo          : OperationStopped: (erxprebussvc01:String) [Add-Computer]  InvalidOperationException     + FullyQualifiedErrorId : FailToJoinDomainFromWorkgroup Microsoft.PowerShell.Commands.AddComputerCommand </code></pre>  <p>At Virtual Network level  DNS Server IP is the IP (Private IP) of AD=10.112.1.4</p>  <p>I am able to ping domain </p>  <pre><code>PS C:\\Users\\scmadmin&gt; ping contoso.com  Pinging contoso.com [10.112.1.4] with 32 bytes of data: Reply from 10.112.1.4: bytes=32 time=1ms TTL=128 Reply from 10.112.1.4: bytes=32 time=1ms TTL=128 Reply from 10.112.1.4: bytes=32 time=1ms TTL=128 Reply from 10.112.1.4: bytes=32 time=1ms TTL=128  Ping statistics for 10.112.1.4:     Packets: Sent = 4  Received = 4  Lost = 0 (0% loss)  Approximate round trip times in milli-seconds:     Minimum = 1ms  Maximum = 1ms  Average = 1ms </code></pre>  <p>Windows Event viewer log reports the below error</p>  <pre><code>The machine erxprebussvc01 attempted to join the domain contoso.com but failed. The error code was 1355. </code></pre>  <p>Unable to understand what is the issue/how to troubleshoot and how to resolve it.</p>""",azure-virtual-machine
56787381,"Azure Storage - Request not being made for container listing <p>I'm attempting the following request from two different classes (Test class and Service class)-</p>  <pre><code>serviceURL.listContainersSegment(null  new ListContainersOptions()).blockingGet().body().containerItems().forEach(container -&gt; {         System.out.println(\createServiceUrl | Container \""+container.name());     }); </code></pre>  <p><strong><em>Test class results:</em></strong></p>  <p>The request gets executed as it should and I'm getting the names of the container in my Azure storage account. The request is made and verified using Wireshark</p>  <p><strong><em>Service class results:</em></strong></p>  <ul> <li>The request is not being made from this class  checked this using Wireshark.</li> <li>The thread gets blocked and no exception is being thrown or no other errors occur in any of the log files where logs are written.</li> </ul>  <p><strong>NOTE</strong>:  Service class is present as a jar and deployed as a Vertx verticle in another application.</p>  <p><strong>Code Details:</strong> This function will simply return the ServiceURL object. This method is called from another method onRequest (mentioned further) in the same class. </p>  <pre><code> * Create Service URL  * @param storageAccountName  * @param storageAccountKey  * @param endpointUrl  * @return  * @throws InvalidKeyException  * @throws MalformedURLException  */ private ServiceURL createServiceUrl(String storageAccountName  String storageAccountKey  String endpointUrl  String endpointProtocol) throws InvalidKeyException  MalformedURLException {     ServiceURL serviceURL = null;     try {         FlintLogger.JOB_LOGGER.info(\""createServiceUrl | Creating Service URL\"");         FlintLogger.JOB_LOGGER.debug(\""createServiceUrl | Creating Service URL with inputs: \\n\""+storageAccountName+\""\\n\""+storageAccountKey+\""\\n\""+endpointUrl+\""\\n\""+endpointProtocol);          // Use your Storage account's name and key to create a credential object; this is used to access your account.         SharedKeyCredentials credential = new SharedKeyCredentials(storageAccountName  storageAccountKey);         FlintLogger.JOB_LOGGER.info(\""createServiceUrl | Storage credentials created \""+credential.toString());          /*             Create a request pipeline that is used to process HTTP(S) requests and responses. It requires your accont             credentials. In more advanced scenarios  you can configure telemetry  retry policies  logging  and other             options. Also you can configure multiple pipelines for different scenarios.          */         HttpPipeline pipeline = StorageURL.createPipeline(credential  new PipelineOptions());         FlintLogger.JOB_LOGGER.info(\""createServiceUrl | Created Http pipeline \""+pipeline);          /*             From the Azure portal  get your Storage account blob service URL endpoint.             The URL typically looks like this:          */         URL url = new URL(String.format(Locale.ROOT  endpointProtocol+\""://%s.blob.\""+endpointUrl  storageAccountName));         FlintLogger.JOB_LOGGER.debug(\""createServiceUrl | Created Url with specified endpoint \""+url.toString());          // Create a ServiceURL object that wraps the service URL and a request pipeline.         serviceURL = new ServiceURL(url  pipeline);         FlintLogger.JOB_LOGGER.debug(\""createServiceUrl | ServiceUrl structure: \""+serviceURL.toURL().toString());           FlintLogger.JOB_LOGGER.info(\""createServiceUrl | Created service URL\"");      }catch(Exception e) {         FlintLogger.JOB_LOGGER.error(\""createServiceUrl | Exception: \"" e.getMessage());     }     return serviceURL; } </code></pre>  <p><strong><em>onRequest method:</em></strong></p>  <pre><code>try {             // Create Service URL             ServiceURL serviceUrl = createServiceUrl(storageAccountName  storageAccountKey  endpointUrl  endpointProtocol);             FlintLogger.JOB_LOGGER.debug(\""onRequest | serviceUrl \""+serviceUrl.toURL());             FlintLogger.JOB_LOGGER.debug(\""onRequest | serviceUrl Before request\""+serviceUrl.toURL());              try {             serviceUrl.listContainersSegment(null  new ListContainersOptions()).blockingGet().body().containerItems().forEach(container -&gt; {                 FlintLogger.JOB_LOGGER.debug(\""onRequest | Blocking get : \""+container.name());             });             }catch(Exception e) {                 FlintLogger.JOB_LOGGER.error(\""Error in thread blocking request \""  e.getLocalizedMessage());             } </code></pre>""",azure-storage
46950853,"Error MSB4057: The target \Build\"" does not exist in the project working with Continuous integration with MSbuild for U-SQL <p>I am working with integrating continous integration with vsts using MSBuild for U-SQL reffering the link : <a href=\""https://blogs.msdn.microsoft.com/azuredatalake/2017/10/24/continuous-integration-made-easy-with-msbuild-support-for-u-sql-preview/\"" rel=\""nofollow noreferrer\"">https://blogs.msdn.microsoft.com/azuredatalake/2017/10/24/continuous-integration-made-easy-with-msbuild-support-for-u-sql-preview/</a></p>  <p>But i am facing below issue while working with VSTS Build server</p>  <pre><code>Source\\TrainingUsql\\TrainingUsql\\TrainingUsql\\TrainingUsql.usqlproj (0  0) Source\\TrainingUsql\\TrainingUsql\\TrainingUsql\\TrainingUsql.usqlproj(0 0): Error MSB4057: The target \""Build\"" does not exist in the project. Process 'msbuild.exe' exited with code '1'. </code></pre>  <p>I have followed all the steps given in link and added the below MSBuild argument :</p>  <pre><code>/p:USQLSDKPath=$(Build.SourcesDirectory)/USQLMSBuild/packages/Microsoft.Azure.DataLake.USQL.SDK.1.3.1019-preview/build/runtime /p:USQLTargetType=SyntaxCheck /p:DataRoot=$(Build.SourcesDirectory) </code></pre>  <p>Any help would be appreciated.</p>""",azure-devops
19991984,"Best way to request and process a Web-API response that contains a file as a byte[]? <p>I am trying to return a pdf file from my REST API and have added a ReportController to my collection of controllers as follows.</p>  <pre><code>public class ReportController : ApiController {     public HttpResponseMessage Get(int id)     {         var result = new HttpResponseMessage(HttpStatusCode.OK);         string fileName = id.ToString();          MemoryStream memoryStream = GetStreamFromBlob(fileName);         result.Content = new ByteArrayContent(memoryStream.ToArray());         result.Content.Headers.ContentType = new MediaTypeHeaderValue(\application/pdf\"");          return result;     } } </code></pre>  <p>The other controllers all work fine  however this is the first that has been set to return a HttpResponseMessage rather than a serializable object or collection of objects.</p>  <p>However I am having difficulty consuming this from the client end.  Have tried a number of versions of code to do this however the controller code never gets hit  and there seem to be few complete examples of a successful way to call this. The following is my current version:-</p>  <pre><code>public async Task&lt;string&gt; GetPdfFile(int id) {     string fileName = string.Format(\""C:\\\\Code\\\\PDF_Client\\\\{0}.pdf\""  id);      using (HttpClient proxy = new HttpClient())     {         string url = string.Format(\""http://localhost:10056/api/report/{0}\""  id);         HttpResponseMessage reportResponse = await proxy.GetAsync(url);  //****         byte[] b = await reportResponse.Content.ReadAsByteArrayAsync();         System.IO.File.WriteAllBytes(fileName  b);     }     return fileName; } </code></pre>  <p>However the line <code>****</code> fails with the message <code>No connection could be made because the target machine actively refused it 127.0.0.1:10056</code>.  </p>  <p>As I say  other controllers at <code>http://localhost:10056/api/</code> work fine.</p>  <p>Is this the correct way to GET a file from a WEBAPI server method?</p>  <p>Do you have any advice as to other areas of the code that could be better such as use of await/async  or better ways for the controller to return a file?</p>""",azure-storage
44219190,SQL Server DB Mail attachment from App Service Folder <p>I have a web app running in Azure and one of its requirement is to send e-mail from SQL Server's DB Mail; however the attachments are stored in App Service environment. </p>  <p>My question is how can access the attachment in App Service folder?</p>  <p>My Setup:</p>  <ol> <li>Web App on Azure App Services </li> <li>SQL Server PAAS model </li> <li><strong>NO VMs used</strong></li> </ol>  <p>In App Service Editor  I have an URL for each file like </p>  <pre><code>https://xxxxx.scm.azurewebsites.net/dev/wwwroot/uploads/test.pdf; </code></pre>  <p>Can I use this URL? Or is there anyway I can use?</p>,azure-web-app-service
41233928,Stream Analytics: Dynamic output path based on message payload <p>I am working on an IoT analytics solution which consumes Avro formatted messages fired at an Azure IoT Hub and (hopefully) uses Stream Analytics to store messages in Data Lake and blob storage. A key requirement is the Avro containers must appear exactly the same in storage as they did when presented to the IoT Hub  for the benefit of downstream consumers. </p>  <p>I am running into a limitation in Stream Analytics with granular control over individual file creation. When setting up a new output stream path  I can only provide date/day and hour in the path prefix  resulting in one file for every hour instead of one file for every message received. The customer requires separate blob containers for each device and separate blobs for each event. Similarly  the Data Lake requirement dictates at least a sane naming convention that is delineated by device  with separate files for each event ingested.</p>  <p>Has anyone successfully configured Stream Analytics to create a new file every time it pops a message off of the input? Is this a hard product limitation?</p>,azure-storage
25670299,"Can we connect to secondary read access geo replicated blob storage account using 2.3 azure sdk? <p>Can we connect to secondary read access geo replicated blob storage for accessing the blob contents  using 2.3 azure sdk?</p>  <p>I am getting \The remote server returned an error: (400) Bad Request.\""</p>  <p>Any help would be greatly appreciated.</p>""",azure-storage
44578374,"I selected D1(shared) for 9$ option while setting custom domain in Azure. Now will I pay those 9$? <p>I created a free account in Azure.com.For custom domain I chose D1(shared) option for 9$. Now the issue is  my total free credit are still 200$ how? Will I pay 9$ from my credit card? Since it's totally free account and they will not charge unless I convert my account to Pay-As-You-Go subscription. Even they delete it after the trail. I tried to talk with their support they told me that it's free and you will not be charged  but my 200$ credits are still there. You can see in the image what option I chose: <a href=\https://i.stack.imgur.com/zftly.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/zftly.png\"" alt=\""Screeshot\""></a></p>""",azure-storage
14424248,Create azure VM on my local machine <p>Is it possible to create one or several azure VMs on my local machine? I want to create a web app and load test it locally  without the need of putting it in the cloud. I'm thinking at the following scenario: I have a local VM running a IIS server with my web app; I use a tool to generate a lot of load; I need to deploy the second VM containing the same things as the first VM. The downtime of the web app should be equal to 0(hopefully).</p>  <p><strong>Clarification(update):</strong> I want to achieve the following: create a web app and a monitoring app(CPU Memory) and deploy them on one VM. On a load test  if the VM cannot handle it(e.g. CPU goes above 80%)  I want to programmatically deploy a new VM(with the same configuration  having both the web app and the monitoring app)  such that no downtime occurs.</p>,azure-virtual-machine
48189631,Vsts Xamarin ios Build Ios Certificate <p>I have problem when i try to build my ios solution with Xamarin.Ios Build. I have this error :</p>  <pre><code>/Library/Frameworks/Mono.framework/External/xbuild/Xamarin/iOS/Xamarin.iOS.Common.targets(635 3): error : No iOS signing identities match the specified provisioning profile '09c40a99-c785-4410-a9bd-b161c511eb92'.  </code></pre>  <p>I don't know how to found the certificate Corresponding to ID. Any one can help me for found solution ?</p>  <p>Thanks in advance</p>,azure-devops
54237292,"Connect to Azure devops repo using sourcetree on MacOS <p>I've created a new project on azure devops and now I'm trying to add an account to sourcetree: </p>  <p>I've setup the opions in the following way:</p>  <p>Host: Azure devops</p>  <p>Link next to Host: <a href=\https://myuser@dev.azure.com/myuser\"" rel=\""noreferrer\"">https://myuser@dev.azure.com/myuser</a><br> Also tried with <a href=\""https://dev.azure.com/myuser\"" rel=\""noreferrer\"">https://dev.azure.com/myuser</a> </p>  <p>Auth Type: It's locked to private token  can't change it.</p>  <p>Username: Tried with my email  also enabled alternative credentials and tried with that username.</p>  <p>Password: Tried with the real password as well as the personal access token</p>  <p>Protocol: HTTPS</p>  <p>I keep getting the error: <code>We couldn't connect to Azure DevOps with your credentials.</code> What could be the cause of this? </p>""",azure-devops
54458216,"Azure functions blob trigger - Use same receipts for different host names and new versions of the function <p>I am using azure functions with the blob trigger and with the runtime 2.x. After the function being executed the runtime adds blob receipt into the location below (azure-webjob-hosts>blobreceipt>) <a href=\https://i.stack.imgur.com/UFpQt.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/UFpQt.png\"" alt=\""receipt path\""></a></p>  <p>Is there any way to make runtime to use the same hostnameid in the path (in this case it's 8a76f42c1c01-2137340777)? Because if run function locally or publish new version of the code it would use different host identifier (like macbook-id).</p>  <p>The main problem is when I run <code>func azure functionapp publish</code> it will requeue all the existing blobs with new version of the code even when the new version has the same func name because it will use different host/func identifier to check for receipts.</p>  <p>I know that in runtime v1 you could add <code>id</code> into host.json. I dont see such option in runtime v2.</p>  <p>Edit:</p>  <p>Another thing. Just this morning I found out that my function run over all the blobs again. When I looked into blobreceipts I see that the hostid has changed and there are new bunch of receipts for the new host id. Host Id has changed even though I didnt do any deployments. How is that possible? I have also reported the bug on coretools about hostid getting changed on publish. <a href=\""https://github.com/Azure/azure-functions-core-tools/issues/1012\"" rel=\""nofollow noreferrer\"">https://github.com/Azure/azure-functions-core-tools/issues/1012</a></p>  <p>App name is <code>altamente-prod-svc-shopify-background</code>. But the host id is <code>d7031c9b43fc-2137340777</code>. I have removed all receipts to do more tests for now but you can see in logs that the func was initiated again this morning by itself over all my 7 blobs. There is just one function for now (and also WarmUp func which appeared automatically). I have created the linux func app via Azure portal with no functions and then just did publish with core tools from my mac.</p>""",azure-functions
48821564,"Deploy web app error using eclipse plugin  connection reset on azure <p>I have just started to use Microsoft Azure to deploy my apps. But before deploying my original work i started out with the testing of a sample app given in the docs. </p>  <p>Please see the following link <a href=\https://docs.microsoft.com/en-gb/azure/app-service/app-service-web-get-started-java\"" rel=\""nofollow noreferrer\"">https://docs.microsoft.com/en-gb/azure/app-service/app-service-web-get-started-java</a> (which i followed to the line). </p>  <p>After installing <strong>azure plugin</strong> from <strong>eclipse(oxygen)</strong> in macOS(10.12.6) when i finally click on the deploy button it gives me an error saying \""Connection reset\"". I tried googling stack overflow for answers but unsuccessful till now. Any help would be really appreciated. Thanks in advance.</p>  <p><strong>Update:</strong></p>  <p>Screenshot:  <a href=\""https://i.stack.imgur.com/CHN97.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/CHN97.png\"" alt=\""enter image description here\""></a></p>""",azure-web-app-service
51539381,"az container exec when using Docker compose <p>Is it possible to execute command in a container which is running under Azure WebApp service by Docker Compose?</p>  <p>When I create single container by <code>az container create ...</code>  then it works. But when I create set of containers by Docker compose script using <code>az webapp create --multicontainer-config-type compose ...</code>  then it does not work.</p>  <p>From logs I see that there is running container <em>myWebApp_myContainer_1</em> so I try:</p>  <pre><code>az container exec -g myResourceGroup -n myWebApp_myContainer_1 --exec-command \/bin/bash\"" </code></pre>  <p>With this result: </p>  <blockquote>   <p><em>The Resource 'Microsoft.ContainerInstance/containerGroups/myWebApp_myContainer_1'   under resource group 'myResourceGroup' was not found.</em></p> </blockquote>  <p>Then I try:</p>  <pre><code>az container exec -g myResourceGroup -n myWebApp --container-name myWebApp_myContainer_1 --exec-command \""/bin/bash\"" </code></pre>  <p>With this result: </p>  <blockquote>   <p><em>The Resource 'Microsoft.ContainerInstance/containerGroups/myWebApp' under resource group 'myResourceGroup' was not found.</em></p> </blockquote>  <p><strong>Note</strong> that it is normally possible to execute commands in containers started by Docker compose script on local Docker (out of Azure).</p>  <p><strong>Update</strong> I don't like to install SSH server into Docker images. It is a bad approach. I'm looking for a way of direct exec like <code>az container exec</code> does.</p>  <p>Thank you for any hint.</p>""",azure-web-app-service
44173832,Get kubernetes credentials from Azure <ul> <li>I have created a <code>Azure container Service</code>  </li> </ul>  <p><code>orchestratorType : Kubernetes Group-Name : Mygrp DNS : MyDNs</code></p>  <ul> <li>Now I have to install kubectl on m/c and service   pods too</li> <li>For this I logged into my account from <code>azure CLI</code></li> <li>I need azure kubernetes credentials for <code>kubectl</code> and command for taht is </li> </ul>  <p><code>az acs kubernetes get-credentials --resource-group=&lt;cluster-resource-group&gt; --name=&lt;cluster-name&gt;</code></p>  <ul> <li><p>From above Info   I know <code>cluster-resource-group</code> is <code>Mygrp</code> (or I am wrong ?) but what will be <code>cluster-name</code> ? </p>  <ul> <li>Or their is something I have configure for this  ?</li> </ul></li> </ul>,azure-virtual-machine
54883768,Start/Stop Azure Function App using ADF Web Activity <p>Is there any provision to start/stop an azure function app via Azure Data Factory Web Activity.</p>,azure-functions
49693982,"Azure Web App: System.Security.Cryptography.CryptographicException: Keyset does not exist <p>My app encounters \System.Security.Cryptography.CryptographicException: Keyset does not exist\"" exception during the creation of a X509Certificate2. </p>  <p>Function to read cert from Azure Key Vault:</p>  <pre><code> private string GetEncryptSecret(string certConfigName)     {         var kv = new KeyVaultClient(GetToken);         var sec = kv.GetSecretAsync(WebConfigurationManager.AppSettings[certConfigName]).Result;         return sec.Value;     } </code></pre>  <p>How I create the new X509Certificate2 object:</p>  <pre><code> public X509Certificate2 GetCertificate(CertificatesEnum certificate)     {         switch (certificate)         {             case CertificatesEnum.Accounts:                 return new X509Certificate2(                     Convert.FromBase64String(GetEncryptSecret(Constants.Magda.Certificates.Accounts))                      string.Empty  X509KeyStorageFlags.MachineKeySet);         }      } </code></pre>  <p>After noticing that this was only working for the first 3-9 requests I've started an Azure Remote Debugging session and saw that the new certificate.Privatekey caused the \""System.Security.Cryptography.CryptographicException: Keyset does not exist\"" exception.</p>  <p>Temporary fixed this by the implementation of a waiting loop because after a couple of retries the new certificate will be created without exception.</p>  <pre><code>public X509Certificate2 GetCertificate(CertificatesEnum certificate)     {         switch (certificate)         {             case CertificatesEnum.Accounts:                 var accountCertRawData = Convert.FromBase64String(GetEncryptSecret(Constants.Magda.Certificates.Accounts));                 X509Certificate2 accountCert = null;                 for (int i = 0; i &lt; 20; i++)                 {                     try                     {                         accountCert= new X509Certificate2(accountCertRawData   string.Empty                              X509KeyStorageFlags.MachineKeySet);                         //set variable to test exception                         var accountCert = accountCert.PrivateKey;                         break;                     }                     catch (System.Security.Cryptography.CryptographicException)                     {                         Thread.Sleep(1000 * i);                     }                 }                 return accountCert;           }     } </code></pre>  <p>Does anyone has a proper solution for this and can explain what is happening in the background on the Azure Web app?</p>""",azure-web-app-service
55294850,Azure DevOps language of git repository? <p>I saw on github.com we can see the language used for each repository. Something similar exist for the projects section of Azure DevOps but I could not find anything more.</p>,azure-devops
40465726,"how to connect to a mysql server running on a linux virtual machine in azure <p>I searched a lot but not able to solve that problem. i am able to access MySQL server running on different windows machine. steps i have taken are</p>  <ol> <li>changing my.ini file bind address to 0.0.0.0</li> <li>creating user and granting permission by <code>GRANT ALL PRIVILEGES ON DATABASE.* TO user@'%' IDENTIFIED BY 'password';</code></li> <li>from command line to windows MySQL server <code>mysql -h windows server ip -u user -p</code></li> </ol>  <p>it works fine and from MySQL workbench i am able to connect for windows MySQL server from my machine. BUT when in Linux virtual machine i have done the same thing</p>  <ol> <li>changing my.cnf file and change bind address to 0.0.0.0.</li> <li>creating user and granting permission by <code>GRANT ALL PRIVILEGES ON DATABASE.* TO user@'%' IDENTIFIED BY 'password';</code></li> <li><p>From command line to LINUX MySQL server <code>mysql -h linux server ip -u user -p</code></p>  <p>but for that i am getting following error after giving password <strong>ERROR 2003 (HY000): Can't connect to MySQL server on 'linux server ip' (10060)</strong> also when connecting from c# by following connection string <code>&lt;add name=\MySqlConnection\"" connectionString=\""Server=LINUX_VM_SERVER_IP;Database=database;Uid=user;Pwd=password\"" providerName=\""MySql.Data.MySqlClient\"" /&gt;</code> i am getting <strong>Error : Unable to find and specified mysql host</strong></p></li> <li><p>i have checked in LINUX_VM that 0.0.0.0:3306 is in listening status.</p></li> <li><p>if i try to telnet LINUX_VM MYSQL Server service using <code>/&gt;telnet LINUX_VM_IP 3306</code> i got the <strong>ERROR : Connecting To LINUX_VM_IP...Could not open connection to the host  on port 3306:</strong></p></li> </ol>""",azure-virtual-machine
30308237,Azure Virtual Machines not holding Logged in User Session <p>I am developing a MVC4 application . We have hosted our application on Windows Azure IAAS Model . Right now we have configured 2 virtual machines and everything is working good. But we have an issue with maintaining User Loging . </p>  <p>If i login in virtual machine 1   its not getting carried over  when the next request is coming from Virtual machine 2 . We have mapped two virtual machines over load balance .</p>  <p>Should i look into Cache solutions . Any input will be greatly helpful ...</p>  <p>Thanks  Jaswanth </p>,azure-virtual-machine
53043400,"Configure default document for node on Azure app service <p>We have an Azure App Service where we deploy a simple web app  a SPA based on React. We have selected the Node.js stack (currently version 10.1) in the Azure Portal for the App Service configuration but at the moment we are only interested in serving the index.html page that drives the rest of the app. There are no serverside js code running.</p>  <p>How can I configure the Node.js stack to \redirect\"" an incoming request for the root (i.e. <a href=\""https://thesite.azurewebsites.net\"" rel=\""nofollow noreferrer\"">https://thesite.azurewebsites.net</a>) to actually serve the index.html content. Right now  when I request the root I'll get a 'Cannot GET /' response back which I suspect is from the generic Node.js hosting (iisnode perhaps?)</p>  <p>Requesting the root works great on my local dev machine when running <code>npm start</code> so I think it is a matter of getting the node.js stack configured wehn hosted on Azure.</p>  <p>I have tried to deploy a simple web.config in the hopes that it'll get picked up and perform a rewrite but it does not affect the root request.</p>  <pre><code>&lt;?xml version=\""1.0\"" encoding=\""utf-8\""?&gt; &lt;configuration&gt; &lt;system.webServer&gt;     &lt;rewrite&gt;         &lt;rules&gt;             &lt;rule name=\""DynamicContent\""&gt;                 &lt;match url=\""/*\"" /&gt;                 &lt;action type=\""Rewrite\"" url=\""index.html\""/&gt;             &lt;/rule&gt;         &lt;/rules&gt;     &lt;/rewrite&gt; &lt;/system.webServer&gt; &lt;/configuration&gt; </code></pre>  <p>Can anybody help me figure out what needs to be done to succeed with this?</p>""",azure-web-app-service
50883017,"Deploy webpack/npm to windows vm via VSTS fails <p>I've created a ReactJS app using webpack and building it via npm/node. This my first time working with any of these technologies so forgive me if I use the wrong terminology. I have a Continuous Integration build being done via VSTS. The build works though it is rather large (I'm working on code splitting) 56Mb zip file. The issue is when I go to deploy it. I'm again using VSTS to deploy it to IIS on a Windows VM hosted on Azure. The error I get tells me nothing and I haven't been able to find any info anywhere to help. Here is my error:</p>  <blockquote>   <p>2018-06-15T05:08:04.6837965Z   ============================================================================== 2018-06-15T05:08:04.6838094Z Task         : IIS Web App Deploy   2018-06-15T05:08:04.6838179Z Description  : Deploy a Website or Web   Application using WebDeploy 2018-06-15T05:08:04.6838275Z Version<br>   : 0.0.39 2018-06-15T05:08:04.6838346Z Author       : Microsoft   Corporation 2018-06-15T05:08:04.6838452Z Help         : <a href=\https://go.microsoft.com/fwlink/?linkid=866789\"" rel=\""nofollow noreferrer\"">More   Information</a>   2018-06-15T05:08:04.6838542Z   ============================================================================== 2018-06-15T05:08:32.0782958Z ##[error]Exit code -529697949 returned   from process: file name 'C:\\VSTSAgent\\externals\\node\\bin\\node.exe'    arguments   '\""C:\\VSTSAgent_work_tasks\\IISWebAppDeploymentOnMachineGroup_1b467810-6725-4b6d-accd-886174c09bba\\0.0.39\\deployiiswebapp.js\""'.</p> </blockquote>  <p>Could this error be due to the size? One other thing of note. Microsoft documentation shows using Gulp to build the application and I'm using npm so not sure if that makes a difference. Anyway  by all accounts and per Microsoft I should easily be able to deploy this to my VM and IIS. Any help would be greatly appreciated.</p>  <p>Here is my webpack.config.js if needed:</p>  <pre><code>var path = require('path'); var HtmlWebpackPlugin = require('html-webpack-plugin');  module.exports = {     entry: {       app: [\""./src/index.jsx\""]        silentRenew: [\""./silent_renew/index.js\""]     }      context: path.resolve(__dirname  \"".\"")      output: {       path: path.join(__dirname  \""dist\"")        filename: \""[name].js\""        chunkFilename: \""[name].chunk.js\""     }      resolve: {         extensions: ['.js'  '.jsx']     }      module: {       rules: [           {               test: /\\.jsx?$/                exclude: /(node_modules|bower_components)/                loader: 'babel-loader'                query: {                   presets: ['react'  'es2015'  'stage-3']               }           }            {               test: /\\.css$/                loader: ['style-loader'  'css-loader']           }            {               test: /\\.(eot|svg|ttf|woff|woff2)$/                loader: 'file?name=public/fonts/[name].[ext]'           }       ]     }      externals: {       'Config': JSON.stringify(require('./config.json'))     }      plugins: [       new HtmlWebpackPlugin({         template: './src/index.html'          filename: 'index.html'          inject: 'body'       })        new HtmlWebpackPlugin({         template: \""./silent_renew/silent_renew.html\""          filename: \""silent_renew.html\""          inject: 'body'        })     ]      devServer: {         historyApiFallback: true     } } </code></pre>  <p>Edit (adding detail debug log):</p>  <blockquote>   <p></p> </blockquote>  <pre><code>2018-06-18T14:51:49.9481397Z ##[debug]Evaluating condition for step: &gt; 'Deploy Client' 2018-06-18T14:51:49.9483383Z ##[debug]Evaluating: &gt; succeeded() 2018-06-18T14:51:49.9483610Z ##[debug]Evaluating &gt; succeeded: 2018-06-18T14:51:49.9483969Z ##[debug]=&gt; True &gt; 2018-06-18T14:51:49.9484274Z ##[debug]Result: True &gt; 2018-06-18T14:51:49.9484678Z ##[section]Starting: Deploy Client &gt; 2018-06-18T14:51:49.9489876Z &gt; ============================================================================== 2018-06-18T14:51:49.9490039Z Task         : IIS Web App Deploy &gt; 2018-06-18T14:51:49.9490144Z Description  : Deploy a Website or Web &gt; Application using WebDeploy 2018-06-18T14:51:49.9490246Z Version      &gt; : 0.0.39 2018-06-18T14:51:49.9490361Z Author       : Microsoft &gt; Corporation 2018-06-18T14:51:49.9490493Z Help         : [More &gt; Information](https://go.microsoft.com/fwlink/?linkid=866789) &gt; 2018-06-18T14:51:49.9490607Z &gt; ============================================================================== 2018-06-18T14:51:52.6671876Z &gt; ##[debug]agent.workFolder=C:\\VSTSAgent\\_work 2018-06-18T14:51:52.6814149Z ##[debug]loading inputs and endpoints &gt; 2018-06-18T14:51:52.6814411Z ##[debug]loading &gt; ENDPOINT_AUTH_PARAMETER_SYSTEMVSSCONNECTION_ACCESSTOKEN &gt; 2018-06-18T14:51:52.6814591Z ##[debug]loading &gt; ENDPOINT_AUTH_SCHEME_SYSTEMVSSCONNECTION 2018-06-18T14:51:52.6814783Z &gt; ##[debug]loading ENDPOINT_AUTH_SYSTEMVSSCONNECTION 2018-06-18T14:51:52.6814948Z ##[debug]loading &gt; INPUT_EXCLUDEFILESFROMAPPDATAFLAG 2018-06-18T14:51:52.6815124Z &gt; ##[debug]loading INPUT_PACKAGE 2018-06-18T14:51:52.6815285Z ##[debug]loading INPUT_REMOVEADDITIONALFILESFLAG 2018-06-18T14:51:52.6815445Z ##[debug]loading INPUT_SETPARAMETERSFILE &gt; 2018-06-18T14:51:52.6816129Z ##[debug]loading INPUT_TAKEAPPOFFLINEFLAG &gt; 2018-06-18T14:51:52.6816253Z ##[debug]loading INPUT_WEBSITENAME &gt; 2018-06-18T14:51:52.6816390Z ##[debug]loading INPUT_XMLTRANSFORMATION &gt; 2018-06-18T14:51:52.6816512Z ##[debug]loading &gt; INPUT_XMLVARIABLESUBSTITUTION 2018-06-18T14:51:52.6816628Z &gt; ##[debug]loaded 11 2018-06-18T14:51:53.7943817Z ##[debug]check path : C:\\VSTSAgent\\_work\\_tasks\\IISWebAppDeploymentOnMachineGroup_1b467810-6725-4b6d-accd-886174c09bba\\0.0.39\\task.json &gt; 2018-06-18T14:51:53.7972514Z ##[debug]set resource file to: &gt; C:\\VSTSAgent\\_work\\_tasks\\IISWebAppDeploymentOnMachineGroup_1b467810-6725-4b6d-accd-886174c09bba\\0.0.39\\task.json &gt; 2018-06-18T14:51:53.7972788Z ##[debug]system.culture=en-US &gt; 2018-06-18T14:51:53.8089699Z ##[debug]WebSiteName=Client &gt; 2018-06-18T14:51:53.8213309Z ##[debug]VirtualApplication=null &gt; 2018-06-18T14:51:53.8213582Z &gt; ##[debug]Package=C:\\VSTSAgent\\_work\\r2\\a\\Nightly Build and Deploy\\drop\\Client.zip 2018-06-18T14:51:53.8213822Z &gt; ##[debug]SetParametersFile=C:\\VSTSAgent\\_work\\r2\\a 2018-06-18T14:51:53.8214026Z ##[debug]RemoveAdditionalFilesFlag=true &gt; 2018-06-18T14:51:53.8214217Z ##[debug]ExcludeFilesFromAppDataFlag=true &gt; 2018-06-18T14:51:53.8214376Z ##[debug]TakeAppOfflineFlag=true &gt; 2018-06-18T14:51:53.8214530Z ##[debug]AdditionalArguments=null &gt; 2018-06-18T14:51:53.8214710Z ##[debug]XmlTransformation=false &gt; 2018-06-18T14:51:53.8214877Z ##[debug]JSONFiles=null &gt; 2018-06-18T14:51:53.8215054Z ##[debug]XmlVariableSubstitution=false &gt; 2018-06-18T14:51:53.8215393Z ##[debug]Finding files matching input: &gt; C:\\VSTSAgent\\_work\\r2\\a\\Nightly Build and Deploy\\drop\\Client.zip &gt; 2018-06-18T14:51:53.8758329Z &gt; ##[debug]SetParametersFile=C:\\VSTSAgent\\_work\\r2\\a 2018-06-18T14:51:53.8759197Z ##[debug]Absolute path for pathSegments: &gt; C:\\VSTSAgent\\_work\\r2\\a = C:\\VSTSAgent\\_work\\r2\\a &gt; 2018-06-18T14:51:53.8760607Z ##[debug]build.sourcesDirectory=undefined &gt; 2018-06-18T14:51:53.8761173Z &gt; ##[debug]system.defaultWorkingDirectory=C:\\VSTSAgent\\_work\\r2\\a 2018-06-18T14:51:54.2727713Z ##[debug]Absolute path for pathSegments: &gt; C:\\VSTSAgent\\_work\\r2\\a = C:\\VSTSAgent\\_work\\r2\\a &gt; 2018-06-18T14:51:54.4839589Z ##[debug]SetParametersFilepath supplied &gt; :false 2018-06-18T14:52:26.3782295Z ##[error]Exit code -529697949 &gt; returned from process: file name &gt; 'C:\\VSTSAgent\\externals\\node\\bin\\node.exe'  arguments &gt; '\""C:\\VSTSAgent\\_work\\_tasks\\IISWebAppDeploymentOnMachineGroup_1b467810-6725-4b6d-accd-886174c09bba\\0.0.39\\deployiiswebapp.js\""'. &gt; 2018-06-18T14:52:26.3818440Z &gt; ##[debug]Microsoft.VisualStudio.Services.Agent.ProcessExitCodeException: &gt; Exit code -529697949 returned from process: file name &gt; 'C:\\VSTSAgent\\externals\\node\\bin\\node.exe'  arguments &gt; '\""C:\\VSTSAgent\\_work\\_tasks\\IISWebAppDeploymentOnMachineGroup_1b467810-6725-4b6d-accd-886174c09bba\\0.0.39\\deployiiswebapp.js\""'. &gt; at &gt; Microsoft.VisualStudio.Services.Agent.ProcessInvoker.&lt;ExecuteAsync&gt;d__20.MoveNext() &gt; --- End of stack trace from previous location where exception was thrown ---    at &gt; System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw()    at &gt; System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task &gt; task)    at &gt; Microsoft.VisualStudio.Services.Agent.Worker.Handlers.DefaultStepHost.&lt;ExecuteAsync&gt;d__7.MoveNext() &gt; --- End of stack trace from previous location where exception was thrown ---    at &gt; System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw()    at &gt; System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task &gt; task)    at &gt; Microsoft.VisualStudio.Services.Agent.Worker.Handlers.NodeHandler.&lt;RunAsync&gt;d__6.MoveNext() &gt; --- End of stack trace from previous location where exception was thrown ---    at &gt; System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw()    at &gt; System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task &gt; task)    at &gt; Microsoft.VisualStudio.Services.Agent.Worker.TaskRunner.&lt;RunAsync&gt;d__24.MoveNext() &gt; --- End of stack trace from previous location where exception was thrown ---    at &gt; System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw()    at &gt; System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task &gt; task)    at &gt; Microsoft.VisualStudio.Services.Agent.Worker.StepsRunner.&lt;RunStepAsync&gt;d__1.MoveNext() &gt; 2018-06-18T14:52:26.3822693Z ##[section]Finishing: Deploy Client </code></pre>""",azure-devops
55092983,"Azure function : HttpTrigger and output queue returned \Internal Server Error\"" <p>I have the following code of function:</p>  <pre><code>public static class FunctionCheckEmail {     [FunctionName(\""FunctionCheckEmail\"")]     public static IActionResult Run(         [HttpTrigger(AuthorizationLevel.Function  \""post\""  Route = null)] HttpRequest req          [Queue(\""email-message-admin-confirmation\""  Connection = \""StorageConnectionString\"")]CloudQueue outputQueue          ExecutionContext context          ILogger log)     {         log.LogInformation(\""C# HTTP trigger function processed a request.\"");         return new AcceptedResult();     } } </code></pre>  <p>It returned <code>Internal Server Error</code>.</p>  <p>If I remove Queue binding then it works:</p>  <pre><code>public static class FunctionCheckEmail {     [FunctionName(\""FunctionCheckEmail\"")]     public static IActionResult Run(         [HttpTrigger(AuthorizationLevel.Function  \""post\""  Route = null)] HttpRequest req          ExecutionContext context          ILogger log)     {         log.LogInformation(\""C# HTTP trigger function processed a request.\"");         return new AcceptedResult();     } } </code></pre>  <p>Other function with Queue binding works fine:</p>  <pre><code>public static class FunctionWarningNotification {     [FunctionName(\""FunctionWarningNotification\"")]     public static void Run(         [QueueTrigger(\""emails-warning-notification\""  Connection = \""StorageConnectionString\"")]string myQueueItem          [SendGrid] out SendGridMessage message          ExecutionContext context          ILogger log)     {         //....     } } </code></pre>  <p>host.json:</p>  <pre><code>{   \""version\"": \""2.0\""    \""extensions\"": {} } </code></pre>  <p>local.settings.json:</p>  <pre><code>{   \""IsEncrypted\"": false    \""Values\"": {     \""AzureWebJobsStorage\"": \""UseDevelopmentStorage=true\""      \""AzureWebJobsDashboard\"": \""UseDevelopmentStorage=true\""      \""AzureWebJobsSendGridApiKey\"": \""XXXX\""      \""FUNCTIONS_WORKER_RUNTIME\"": \""dotnet\""      \""StorageConnectionString\"": \""DefaultEndpointsProtocol=https;AccountName=domainregistration;AccountKey=XXXX\""   } } </code></pre>  <p>what is wrong?</p>""",azure-functions
51177447,"JavaScript and CSS not loading in Azure PHP (Codeigniter) Web Application <p>I have deployed PHP Codeigniter Web Application in Microsoft Azure Web App. I have deployed the app successfully but it is not loading styles as it is doing in local server. Here is my new web app screenshot: <a href=\https://i.stack.imgur.com/utfRg.jpg\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/utfRg.jpg\"" alt=\""Azure Web Application\""></a></p>  <p>When I run it locally it displays the landing page like this: <a href=\""https://i.stack.imgur.com/jgXwF.jpg\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/jgXwF.jpg\"" alt=\""Local server\""></a></p>  <p>What could be the problem and how can I solve it? I would really appreciate your help. Than you.</p>""",azure-web-app-service
52835041,Add SSL bindings Custom domain in dynamically created web app service <p>I have created azure web app using the REST API. I want to add SSL certificate to my web app. My web app is created dynamically by using azure api. So when the web app created  also want to bind the SSL for each web app. Is there is any option to custom domain SSL bindings using rest api ?.</p>  <p>I am using wildcard SSL. </p>,azure-web-app-service
56962703,Azure App Service going to 100% scaling up and I turned everything off and restarted <p>I'm not sure what to do here or exactly how to debug this given the steps I've already taken. 1st off I'm running asp.net web apps and azure functions on this Service plan. Very light loads not public facing or anything and I haven't made any changes for days. Then at 12:30 this afternoon I don't know why it goes to 80-100% scaling up to 10 instances from 1.</p>  <p>So I looked and didn't really see anything. Then I restarted the app service plan  nothing. Then I turned off all by 6 apps 1 by 1 and their slots. Still 100% cpu. (data out is in the 40 mb as well  sorta strange). Then I restarted the service plan again. Still 100%. What can I do?</p>,azure-web-app-service
14213901,Subdomain mapping <p>I have shifted my <strong>word press</strong> blog on my website as its sub domain  but internal pages are still showing old blog's <strong>URL</strong>.  how can I resolve this problem ?</p>,azure-storage
56468975,"App Service restart when uploading content using ftp on site with .NET Core 2 <p>I have a main \App Service\"" with multiple sites on it. Some are based on .NET 4 and others in .NET Core 2. Even when I upload CSS or JS files through FTP on <strong>.NET Core sites</strong>  its restart all my sites even those on .NET 4  I try to turn off sites using App_Offline.htm but only uploading this file will restart all my sites.</p>  <p>I've tried the inverse thing  I upload files to a .NET 4 site and it does not restart any other site  even uploading App_Offline.htm or deleting it  there is no such behavior.</p>  <p>I don't know why this is happening with .NET Core sites   or if there is a way to avoid this behavior?</p>  <p>Thanks.</p>""",azure-web-app-service
39532958,How do you use custom NuGet feeds with Azure Functions? <p>I know you can create a <code>project.json</code> file to add NuGet packages to your functions  but how can I specify what feed I want them pulled from?</p>,azure-functions
18308706,Deploy after commit to git repository in Team Foundation Service <p>I have a web site in Azure Web Sites and its sources in a git repository under Team Foundation Service.</p>  <p>My goal is to have continuous integration: after each commit to repository I want the code to be built and deployed to Azure.<br> Unfortunately  this scenario is not supported directly for git (when using TF Source Control under <strong>TFS</strong> one can just tell Azure to do this).</p>  <p>Trying to make a workaround  I have successfully done the following.</p>  <ol> <li>Perform a build in TFS after each commit.</li> <li><p>Build and deploy the solution with MSBuild parameters (works when running locally from the command line):  </p>  <blockquote>   <p>msbuild path_to_solution_file /p:DeployOnBuild=True /p:PublishProfile=publish_profile_name /p:Configuration=Release /p:Password=MyPassword</p> </blockquote></li> </ol>  <p>Is it possible to successfully run the same command in TFS?<br> I specified the arguments in build definition (Process -> Advanced -> MSBuild Arguments). After any commit  the build is started. According to logs  the arguments are successfully passed to MSBuild. Build succeeds with no errors. But nothing is deployed.  </p>  <p>Any ideas how to make it work? Is that possible?</p>,azure-devops
56661165,Azure VM 408 Request Timeout when making large http requests <p>I’m currently building an app using Azure Linux VMs with .Net Core and I’m facing an issue when sending http requests from an Azure VM to a remote server.</p>  <p>When making a http request from an Azure Linux OR Windows VM (CURL and .NET Core) to a remote server (Debian Linux NOT in Azure) the request fails with 408 Request Timeout and the message “Server timeout waiting for the HTTP request from the client.”. When executing this same request locally using CURL  Postman or from .Net Core it succeeds. This requests also works fine when executed within a Linux VM in AWS and GCP. It even works in Azure Functions…</p>  <p>Here is my test setup:</p>  <p><strong>Request 1 (Small)</strong></p>  <p>HTTP Post with a request body that has a content length of 306<br> Average response time is 4s on my local machine with a response size of 20mb</p>  <p><strong>Request 2 (Large)</strong></p>  <p>HTTP Post with a request body that has a content length of 5962<br> Average response time is 5s on my local machine with a response size of 14mb</p>  <p>Locally both requests work fine.<br> In AWS and GCP Linux VMs both request work fine.<br> In Azure Linux VM (Standard B2s) the small consistently works and the large one consistently fails with 408<br> In Azure Windows VM (Standard DS1 v2) both consistently fail with 408<br> In Azure Functions both consistently work</p>  <p>All test machines as well as the remote endpoint that gets called are located in Europe.</p>  <p>This is why I currently suspect there must be something going on (or a misconfiguration on my side) in Azure VM or Azure Networking that causes this behavior. I already tried raising the Timeout of my HttpRequest in .Net Core without success (as expected as it also fails in CURL using SSH).</p>  <p>Is there anyone that can help me work around this or point me towards documentation? Is this a known issue?</p>,azure-virtual-machine
14959941,Azure Table Storage mirroring <p>I am proposing an Azure environment with the following:</p>  <ul> <li>VM SQL Server for core relational data</li> <li>Table Storage for bulk data</li> </ul>  <p>I want to mirror the SQL Server database to another server so that</p>  <ol> <li>Reports can be run on this server so to minimize data load on the primary database  and</li> <li>It can serve as a failover server in case the primary server goes down.</li> </ol>  <p>In order to achieve these 2 objectives I would also need to mirror the Azure Table Storage too.  I can't seem to find any information on this.  Is this even possible?</p>,azure-storage
29301628,"Error in VSO Release Management <p>I have created a simple release template using VSO to deploy on an Azure VM. The template has just one simple component to test.</p>  <p>When I start a release  the Accept Deployment and Predeployment steps are done ok. The deploy step seems to work also  the component is copied to the Azure VM in the C:\\Windows\\DtlDownloads folder (although I don't have a deployment script yet).</p>  <p>At some moment (I guess at the end of the deploy step) the RM Client pops up a toast with the error: {\ErrorMessage\"":\""'\\u001f'  hexadecimal value 0x1F  is an invalid character.\""}</p>  <p>The deploy step keeps the status Pending forever. When I try to open the Release in the RM client  I get the same error.</p>  <p>This is the stacktrace from the log file:</p>  <pre><code>3/27/2015 11:37:08 AM - Error - (10204  47808) - {\""ErrorMessage\"":\""'\\u001f'  hexadecimal value 0x1F  is an invalid character.\""}: \\r\\n\\r\\n   at Microsoft.TeamFoundation.Release.Common.ExtensionMethods.XmlExtensionMethods.ToXDocument(String value  Boolean preserveWhitespace)    at Microsoft.TeamFoundation.Release.Data.Model.ModelFactory.TransformXmlToModel[T](T model  String xml)    at Microsoft.TeamFoundation.Release.Data.Model.ModelFactory.Load[T](Int32 id)    at Microsoft.VisualStudio.Release.ViewModel.ViewModels.PipelineV2.ReleaseV2ViewModel.RefreshTimerTick(Object sender  EventArgs e)    at System.Windows.Threading.DispatcherTimer.FireTick(Object unused)    at System.Windows.Threading.ExceptionWrapper.InternalRealCall(Delegate callback  Object args  Int32 numArgs)    at System.Windows.Threading.ExceptionWrapper.TryCatchWhen(Object source  Delegate callback  Object args  Int32 numArgs  Delegate catchHandler) </code></pre>  <p>Any idea about the cause of this error?</p>  <p>And how to stop such a pending release? Can't find an option in the client to stop or delete it.</p>""",azure-devops
55586413,Best practices for writing/organising azure functions in project/solution <p>I have multiple azure functions created. Some are related a similar functionality and others different. Let say: 1. File Movement - TimerTrigger 2. Processing - HttpTrigger</p>  <p>For File Movement I have 2 functions and for Processing say another 2 functions. I have created 4 azure functions in the same project. Is it the right way?</p>  <ol> <li>Should I put FileMovement functions in same class file and Processing in different class file - same project/solution?</li> <li>Separate project for all azure functions?</li> </ol>  <p>Applications settings value must be shared across all the azure functions.</p>,azure-functions
54191747,Automating Azure Question for generating infrastructure <p>I want to make sure I am taking the right approach.</p>  <p>I am building virtual environments in Azure on a regular anywhere from 3 to 5 servers at a time.  Each server has 1 of 4 different resources (RAM/CPU/...) that it will need.  Obviously I could script out each VM and just use powershell to deploy each individual VM each time.</p>  <p>More over what I want is a utility or webpage where I can say I need to create x servers and here are the specifications for them  how much will it cost and make it start building them.</p>  <p>Is there any tool like this or what would be the best approach to this?  </p>,azure-virtual-machine
53636677,"Publishing updates via web deploy to Azure web app  confused on process and time it takes <p>This may seem like a stupid question but I've been deploying updates to a development site for a project I adopted using a web deploy publishing profile. </p>  <p>This always takes 15 minutes or so.</p>  <p>However  I wanted to test a more realistic example so in order to take the app offline I followed these instructions here:</p>  <p><a href=\https://docs.microsoft.com/en-us/previous-versions/aspnet/ee942158(v=vs.110)#how-to-automatically-take-an-app-offline-during-deployment\"" rel=\""nofollow noreferrer\"">https://docs.microsoft.com/en-us/previous-versions/aspnet/ee942158(v=vs.110)#how-to-automatically-take-an-app-offline-during-deployment</a></p>  <p>So I pushed another update and kept refreshing the development site and sure enough  it showed under construction  but only for about 1 minute  and then it was back up.</p>  <p>However  even as I type this question  almost 15 minutes later Visual Studio is still rattling out line by line of publishing updates in the build output window.</p>  <p>Can someone help me understand the lifecycle of web deploy publish from Visual Studio? </p>""",azure-web-app-service
18305817,Azure Virtual Machine Billing <p>I dont know if this is the right place  but I am assuming MSFT staff also answers these questions since the azure portal links to StackOverflow?</p>  <p>Questions:</p>  <ul> <li>I understand that Azure no longer bills me for a VM so long as it and its cloud service are stopped.  But what is unclear is am I going to be billed for the Cloud Service itself?  For example say i create a Virtual machine and by doing so i get a cloud service for it (with ip).  Then I turn off that virtual Machine and the cloud service.  Do i still get billed for the cloud service even though everything is turned off?</li> <li>Continuing on the question above.  Do i get billed storage fees for the Virtual Machines filesystem.  Currently windows vms are around 120GB in size.   How does the billing work out for virtual machines?  And how does it change if the machine is turned off. </li> <li>How are Custom Images billed?  Say i create my Windows 2012 Master image with IIS and a few other components installed.  Then I create my own Image so that I can bring up vms more rapidly.  Where is the VM image stored?  Will it be in my blob container under VHD's?  And again will microsoft charge me to store this image?  Will it be the full 120+ GB or the actual size of the image stored. </li> </ul>  <p>Sorry to ask these questions.  Tried my best to google around and all i could find was a post by Scott Gu where he stated VMs wont be billed and very little detail beyond that. </p>,azure-virtual-machine
46754924,"Azure Cosmos DB Functions - Delete a document <p>I can get a document response using <code>HTTP trigger in FunctionsApp</code> on Azure like a rest API  However  I cannot delete the document. </p>  <p>I'm selecting the <code>DELETE</code> as Selected <code>'HTTP methods'</code> but I am not clear what should I do for next step. In Input Parameters  when I write <code>'Delete from mydocument'</code> in <code>SQL Query (optional) textbox</code>  it doesn't work. Probably I need to change the <code>'run.csx'</code> code but how? </p>  <p>any clue?</p>  <p><a href=\https://i.stack.imgur.com/7Dm0E.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/7Dm0E.png\"" alt=\""enter image description here\""></a><a href=\""https://i.stack.imgur.com/dktnz.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/dktnz.png\"" alt=\""enter image description here\""></a><a href=\""https://i.stack.imgur.com/Ul0ss.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/Ul0ss.png\"" alt=\""enter image description here\""></a></p>""",azure-functions
57513063,"Poor Azure App Service performance using OWIN? <p>We recently deployed a .NET Framework 4.8 Web API 2 application to an Azure App Service.  We’re using the Azure S1 application service plan.</p>  <p>Unfortunately  we’re seeing very inconsistent response times when making API requests to this service – sometimes as long as 10 seconds.  The same application running on a VM takes less than a second.</p>  <p>Initially we assumed it was slow database query performance  but after doing some profiling it appears the queries actually run quickly and most of the time appears to be in “external code”.</p>  <p>Specifically  it appears that most of the time is spent in the OWIN request handler code:</p>  <p><img src=\https://i.imgur.com/T4QOtvx.png\"" alt=\""profiler\""></p>  <p>Here is our Startup.cs:</p>  <pre><code>app.UseCors(CorsOptions.AllowAll); app.UseOAuthAuthorizationServer(new OAuthAuthorizationServerOptions() {     AllowInsecureHttp = true      TokenEndpointPath = new PathString(\""/token\"")      AccessTokenExpireTimeSpan = TimeSpan.FromMinutes(AccessTokenExpirationInMinutes)      Provider = new CustomOAuthAuthorizationProvider() }); app.UseCustomSessionAuthentication(new CustomSessionAuthenticationOptions()); app.UseOAuthBearerAuthentication(new OAuthBearerAuthenticationOptions());  var config = GlobalConfiguration.Configuration;  WebApiConfig.Register(config); ServiceConfig.Register(config);  app.UseWebApi(config); </code></pre>  <p>Has anyone experienced issues using OWIN in an Azure App Service?  Is there special configuration or code changes needed?</p>  <p>Versions:</p>  <ul> <li>.NET Framework 4.8</li> <li>MVC 5.2.3</li> <li>Microsoft.Owin.* 3.0.1</li> </ul>""",azure-web-app-service
52712141,"How do I put a BLOB in root  not $root? <p>I'm trying to use the <code>WindowsAzure.Storage</code> C# NuGet package to upload a BLOB to the <em>root</em> of a container. If I do the following:</p>  <pre><code>var AZURE_CONNECTION_STRING_TEMPLATE = \DefaultEndpointsProtocol=http;AccountName={0};AccountKey={1};BlobEndpoint={2};\""; var string AZURE_ACCOUNT_NAME = \""devstoreaccount1\""; var string AZURE_ACCOUNT_KEY = \""abcd-redacted\""; var string AZURE_BLOB_ENDPOINT = \""http://127.0.0.1:10000/devaccount1/mycontainer\"";  var azureBlobConnectionString = string.Format(   AZURE_CONNECTION_STRING_TEMPLATE    AZURE_ACCOUNT_NAME    AZURE_ACCOUNT_KEY    AZURE_BLOB_ENDPOINT);  var container = serviceClient.GetRootContainerReference(); var blob = container.GetBlockBlobReference(Path.GetFileName(FILE_TO_UPLOAD)); </code></pre>  <p>The BLOB ends up in a container called <code>$root</code>  and it doesn't actually show in the \""root\"" of the container. If I try the following:</p>  <pre><code>var container = serviceClient.GetContainerReference(\""/\""); </code></pre>  <p>It ends up in a container called <code>&lt;no name&gt;</code>.</p>  <p>I want the file to be in the root of the container called <code>mycontainer</code>.</p>""",azure-storage
55032833,"Hashicorp Terraform - Storing Azure Storage account access key in Azure Key Vault <p>Just as a disclaimer  I'm quite new to Terraform  and I'm trying to figure out how to store my Azure Storage Account Access Key in my Azure Key Vault. (Referenced <a href=\https://docs.microsoft.com/en-us/azure/terraform/terraform-backend\"" rel=\""nofollow noreferrer\"">here</a>).</p>  <p>The specific command that is referenced is: </p>  <pre><code>export ARM_ACCESS_KEY=$(az keyvault secret show --name terraform-backend-key --vault-name myKeyVault --query value -o tsv) </code></pre>  <p>I get that the --vault value should be replaced with the name of my Key Vault  but what am I supposed to replace the --name value with?</p>  <p>And as importantly  in what file/config am I supposed to put the whole export ARM_ACCESS_KEY string?</p>  <p>Thanks so much  everyone!</p>""",azure-storage
51886492,"Does Azure have a way through REST API for getting a file from a VM? <p>Looking at <a href=\https://docs.microsoft.com/en-us/previous-versions/azure/reference/jj157206(v=azure.100)\"" rel=\""nofollow noreferrer\"">Operations on Virtual Machines</a>  I see that there are many management tasks that I can do through the REST API. Is there any way I can stream a file  e.g. something like <code>\""GET/{filePath}\""</code> where  <code>{filePath}</code> is like <code>d:\\stuff\\somefile.txt</code> or <code>\\\\somenetworkpath\\foo\\bar.html</code>?</p>""",azure-virtual-machine
35551678,How do I create a public virtual machine image using Azure ARM? <p>I want to create a virtual machine that anyone can launch using the ARM REST API.</p>  <p>How do I do that?  I cannot find instructions.</p>,azure-virtual-machine
43506691,"Deploy a simple VS2017 Django app to Azure - server error <p>I've been trying to create a Django web app using VS2017 Preview (which includes Python tools for Visual Studio)  and deploy the resulting app to Azure (I'm currently on the 30-day trial period to evaluate Azure).</p>  <p>I've done the following:</p>  <ul> <li><p>Start VS2017  create a new project with the \Django Web Project\"" template. This creates a Django webpage with the bootstrap template - simple  and everything works well locally.</p></li> <li><p>In VS  go to Connected Services => Publish  select \""Microsft Azure App Service\""  create a new App Service an an App Plan. The instances are created successfully.</p></li> <li><p>Click \""Publish\"" to publish via VS WebDeploy. Everything looks good in the console and it says <code>Publish: 1 succeeded  0 failed  0 skipped</code> at the end.</p></li> </ul>  <p>This results in the standard Azure Welcome-start-page <code>hostingstart.html</code> showing  not the Django page. Once I remove that html file  there's only a <code>The page cannot be displayed because an internal server error has occurred.</code>. I've tried various things: Going to portal.azure.com \""Application Settings\""  setting Python version from \""Off\"" to \""3.4\"" (I'd like 3.5 in fact  which one of MS's tutorial uses - but any will do for now) - then there's just a <code>hostingstart-python.html</code> showing  still no Django. I've tried adding a default web.config via \""Add => New Item => Azure web.config (FastCGI)\"" in VS. I've tried editing that web.config with various values of <code>WSGI_HANDLER</code> (e.g. <code>django.core.handlers.wsgi.WSGIHandler()</code>) and <code>DJANGO_SETTINGS_MODULE</code> (e.g. <code>mydjangopage.settings</code>)  I tried adding \""wfastcgi\"" to requirements.txt  etc. Always just getting a server error.</p>  <p>I have been trying to do this for several hours now and I've read every possible Deployment help page from Microsoft  their blogs  and the web. All the information seems outdated  having missing pieces of information  or is just not working. At this point I'm quite disappointed and ready to give up. Isn't it supposed to be so simple? Create a new project in VS  hit \""Publish\""  and it's supposed to work? (It's definitely not  I restarted from scratch multiple times and tried so many things.)</p>""",azure-web-app-service
53578322,TFS CD Error: The specified path  file name  or both are too long. <p>I'm implementing CI/CD for my application through TFS 2015  Windows server 2012 R2. My CI pipeline is success and my Release failed with error </p>  <blockquote>   <p>The specified path  file name  or both are too long. The fully   qualified file name must be less than 260 characters  and the   directory name must be less than 248 characters.</p> </blockquote>  <p>I tried with both VSBuild and MSBuild task in Release pipleine  still the same issue.Find the error log</p>  <pre><code>2018-12-01T14:39:03.3631640Z Downloading artifact from file share: \\xxxxxxxx\xxxxxxxxxxxx\drop  2018-12-01T14:40:42.8336659Z ##[section]Error: System.IO.PathTooLongException: The specified path  file name  or both are too long. The fully qualified file name must be less than 260 characters  and the directory name must be less than 248 characters.  2018-12-01T14:40:42.8346665Z    at System.IO.Path.LegacyNormalizePath(String path  Boolean fullCheck  Int32 maxPathLength  Boolean expandShortPaths)  2018-12-01T14:40:42.8346665Z    at System.IO.Path.InternalGetDirectoryName(String path)  2018-12-01T14:40:42.8356644Z    at Microsoft.TeamFoundation.Release.Windows.Implementation.FileSystem.WriteStreamToFile(Stream stream  String filePath)  2018-12-01T14:40:42.8356644Z    at Microsoft.TeamFoundation.Release.ArtifactRepository.FileShare.FileShareArtifact.DownloadArtifact(ArtifactDefinition artifactDefinition  String dropLocation  String localFolderPath)  2018-12-01T14:40:42.8356644Z    at Microsoft.TeamFoundation.Release.ArtifactRepository.Build.BuildArtifact.DownloadArtifact(BuildArtifact buildArtifact  ArtifactDefinition artifactDefinition  String localFolderPath  BuildHttpClient buildClient  Int32 buildId)  2018-12-01T14:40:42.8366844Z    at Microsoft.TeamFoundation.Release.ArtifactRepository.Build.BuildArtifact.Download(ArtifactDefinition artifactDefinition  String localFolderPath)  2018-12-01T14:40:42.8366844Z    at Microsoft.TeamFoundation.Release.ArtifactRepository.Common.AgentArtifactDownloader.Download(ArtifactDefinition artifactDefinition  Uri workingFolder)  2018-12-01T14:40:42.8366844Z    at Microsoft.TeamFoundation.DistributedTask.Plugin.Release.ReleaseJobExtension.&lt;&gt;c__DisplayClass19_1.&lt;DownloadArtifacts&gt;b__1()  2018-12-01T14:40:42.8376646Z    at Microsoft.TeamFoundation.Release.Windows.Implementation.RetryExecutor.Execute(Action action)  2018-12-01T14:40:42.8376646Z    at Microsoft.TeamFoundation.DistributedTask.Plugin.Release.ReleaseJobExtension.DownloadArtifacts(ITaskContext downloadArtifactTaskContext  IJobContext context  IList`1 agentArtifactDefinitions  Uri artifactsWorkingFolder  String teamProjectId  IDictionary`2 savedSettings)  2018-12-01T14:40:42.8376646Z    at Microsoft.TeamFoundation.DistributedTask.Plugin.Release.ReleaseJobExtension.DownloadArtifactsWrapper(IJobContext context  IJobRequest job  CancellationToken cancellationToken  ITaskContext downloadArtifactTaskContext  String teamProjectId  Uri artifactsWorkingFolder  Int32 releaseId  IDictionary`2 savedSettings)  2018-12-01T14:40:42.8456644Z ##[error]The specified path  file name  or both are too long. The fully qualified file name must be less than 260 characters  and the directory name must be less than 248 characters. </code></pre>  <p>Any help would be appreciated.</p>,azure-devops
55252061,python social auth change referrer address <p>I have an Azure Application Gateway (lets say example.com)  behind which I have a few Azure App Services (example1.com  example2.com  etc).</p>  <p>I am using python social auth to authenticate my django app. The issue is that when I click login from example.com  and it forwards that request to example1.com  the login request happens from example1.com. </p>  <p>If I specify a OAuth callback addresses as </p>  <blockquote>   <p>example.com/complete/azuread-oauth2   </p>      <p>example1.com/complete/azuread-oauth2  and</p>      <p>example2.com/complete/azuread-oauth2 </p> </blockquote>  <p>it doesn't work  social auth gives me the error:</p>  <pre><code>raise AuthStateForbidden(self) social_core.exceptions.AuthStateForbidden: Wrong state parameter given. </code></pre>  <p>This might be because of the referrer site being example.com  but the actual request going from example1.com  though I am not sure. Is there any way to fix it so that the redirection doesnt happen to example1.com  and I can hide example1.com behind example.com?</p>,azure-web-app-service
41054669,"What does the lifecycle of an Azure VM look like in terms of state transitions? <p>From what I can gather  the overall status of an Azure VM is composed of two parts: <code>provisioningState</code> and <code>powerState</code>.</p>  <p>For example  one can see statuses similar to the following during a VM boot:</p>  <pre><code>  \statuses\"": [     {       \""code\"": \""ProvisioningState/creating\""        \""level\"": \""Info\""        \""displayStatus\"": \""Creating\""     }      {       \""code\"": \""PowerState/stopped\""        \""level\"": \""Info\""        \""displayStatus\"": \""VM stopped\""     }   ] </code></pre>  <p>which may later turn into</p>  <pre><code>  \""statuses\"": [     {       \""code\"": \""ProvisioningState/creating\""        \""level\"": \""Info\""        \""displayStatus\"": \""Creating\""     }      {       \""code\"": \""PowerState/starting\""        \""level\"": \""Info\""        \""displayStatus\"": \""VM starting\""     }   ] </code></pre>  <p>and so on.</p>  <p>Now  I've searched the online Azure documentation but nowhere have I been able to find a detailed account of the lifecycle of a VM. I would both like to know the range of possible values for the states and the possible state transitions. I would love to see something similar to <a href=\""http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-instance-lifecycle.html\"" rel=\""nofollow noreferrer\"">Amazon's instance lifecycle</a>.</p>  <p>Any explanation or pointer to documentation would be truly appreciated.</p>""",azure-virtual-machine
28828229,Azure VM writing to a the filesystem from ASP.Net <p>I am newpie to Windows Azure. I have an application on my server that I moved to the VM not using the visual studio integration or packaging just copied the application and set all the things related to it  part of my application I write to a specific file   - I know it is not a good idea but I am doing it for the fun. The folder access is set such that everybody can write to it (Actually it was set such that the apppool can write to it then I made it such that everybody can write to it on the Azure).  The code is something like this </p>  <pre><code>using (FileStream stream = new FileStream(System.Web.HttpContext.Current.Server.MapPath(fileName)  FileMode.OpenOrCreate  FileAccess.ReadWrite)) {     stream.Position = stream.Length;     stream.Write(RawBytes  0  RawBytes.Length);     stream.WriteByte(13);     stream.WriteByte(10); } </code></pre>  <p>it works fine on my machine but on the azure VM for some reason it is not working I know that Azure using a different storage mechanism  can someone guide me to what to do exactly</p>,azure-storage
53781414,"Azure blob resource may have been removed <p>In my .core web app which uses Kendo file upload  I am trying to upload a 50 MB .mp4 file to Azure Blob storage.</p>  <p>Small files of sizes 5  10  20 MB upload just fine.</p>  <p>However big sized file such as 50 MB one  I am getting error</p>  <blockquote>   <p>The resource you are looking for has been removed  had its name changed  or is temporarily unavailable</p> </blockquote>  <p>Do I need to add anything in web.config?</p>  <p>I have </p>  <pre><code> &lt;system.web&gt;     &lt;httpRuntime maxRequestLength=\2147483647\""/&gt;  &lt;/system.web&gt; </code></pre>""",azure-storage
55291467,"DevOps linux agents - Run as admin <p>I have setup linux agents following the documentation here: <a href=\https://docs.microsoft.com/en-us/azure/devops/pipelines/agents/v2-linux?view=azure-devops\"" rel=\""nofollow noreferrer\"">https://docs.microsoft.com/en-us/azure/devops/pipelines/agents/v2-linux?view=azure-devops</a></p>  <p>When I run some scripts on devOps pipelines on these agents I get the permission denied error. </p>  <p>What is the DevOps way of handling this permission?</p>""",azure-devops
37771676,Why is Microsoft Azure Websites using block blobs instead of append blobs for logs <p>I am confused about why Microsoft Azure prefers 'block blob' to 'append blob' for application logging. </p>  <p>It is my understanding that with 'append blob' clients can simply append a line of text to the blob without downloading any chunks to the client.</p>  <p>Appending to 'block blob' involves downloading the blockids or content and appending to that clientside and then writing that back to the blob. More work is involved.</p>  <p>Why is Microsoft Azure not using the intended method of writing logs in their own implementation? Are there caveats to using 'append blob' for logging?</p>,azure-storage
55487426,"Azure Function and PowerShell: unable to set connection strings with Set-AzWebApp <p>For deployment purposes I created a PowerShell script to set App Settings. This works fine via</p>  <pre><code>$currentAppSettings = $app.SiteConfig.AppSettings  $appSettings = @{} # Add existing App Settings ForEach ($currentAppSetting in $currentAppSettings) {     $appSettings[$currentAppSetting.Name] = $currentAppSetting.Value }  # Add new App Settings $appSettings[\someKey\""] = \""someValue\""  # Update App Settings Set-AzWebApp -ResourceGroupName $resourceGroupName -Name $appName -AppSettings $appSettings </code></pre>  <p>As I am using now Entity Framework I also need to set the Connection Strings. First I thought this should work like with App Settings and just adding the ConnectionStrings Argument:</p>  <pre><code>$currentConnectionStrings = $app.SiteConfig.ConnectionStrings  $connectionStrings = @{}  ForEach ($currentConnectionString in $currentConnectionStrings) {     $connectionStrings[$currentConnectionString.Name] = $currentConnectionString.ConnectionString }  $connectionStrings[\""someKey\""] = \""someValue\""  Set-AzWebApp -ResourceGroupName $resourceGroupName -Name $appName -ConnectionStrings $connectionStrings </code></pre>  <p>But this fails with the error</p>  <blockquote>   <p>Set-AzWebApp : Cannot validate argument on parameter 'ConnectionStrings'. Connection string type value pair must be of type 'System.Collections.Hashtable'</p> </blockquote>  <p>despite the fact that <code>$connectionStrings</code> is of type <code>System.Collections.Hashtable</code></p>  <p>Also trying to work with Custom Objects  arrays and so on failed.</p>  <p><strong>How do I pass the connection strings correctly?</strong> <strong>And how do I specify the Type (e.g. SQLAZURE)?</strong></p>  <p>Thanks</p>""",azure-functions
48158191,"Choppy File Download using Powershell on Azure VM <p>I'm noticing some strange behavior on an Azure Virtual Machine when downloading a file using the <code>Invoke-WebRequest</code> command.  Seems like the download stream is super choppy.  Normally  Azure VMs download files super fast  so not sure what's causing this.  The file lives in azure blob storage in the same region as the VM.  When I download the file via web browser  it only takes 3 seconds.  Using powershell takes about a minute! <a href=\https://i.stack.imgur.com/AFyHy.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/AFyHy.png\"" alt=\""enter image description here\""></a></p>  <p>Here is a screen capture of the network when done using powershell.</p>  <p>To clarify  this is the code I'm using to download a file...</p>  <pre><code>$dest = \""$($buildDir)\\MyStuff.zip\"" Invoke-WebRequest \""https://mystorage.blob.core.windows.net/apps/$($using:buildNumber)/App/MyStuff.zip\"" -OutFile $dest </code></pre>  <p>I'm using whatever version of powershell comes on the 2016-Datacenter image in the azure gallery.</p>""",azure-virtual-machine
31916772,"Reserving static IP for existing Azure Virtual Machine <p>I have created 3 virtual machines which are already in operation and I forgot to first assign a static IP at time of creation. I am now encountering some issues when I am trying to do this.</p>  <p>I have created a reserved IP using the following powershell:</p>  <pre><code>New-AzureReservedIP “dmz-live” –Label “be-dmz-ip” –Location “North Europe” </code></pre>  <p>Following this post <a href=\http://prmdbaora.blogspot.in/2015/06/normal-0-false-false-false-en-us-x-none.html\"" rel=\""nofollow\"">http://prmdbaora.blogspot.in/2015/06/normal-0-false-false-false-en-us-x-none.html</a> I tried to delete the VM and reassign but when I use the following code:</p>  <pre><code>New-AzureVMConfig -Name \""be-dmz\"" -InstanceSize \""Standard_D11\"" –ImageName \""be-dmz-be-dmz-0-201508100952090393\"" | New-AzureVM -ServiceName \""be-dmz\"" –ReservedIPName \"" be-dmz-ip \"" -Location \""CloudVNET” </code></pre>  <p>I am getting an error:</p>  <pre><code>New-AzureVMConfig : Must specify MediaLocation or set a current storage account using Set-AzureSubscription. At line:1 char:1 + New-AzureVMConfig -Name \""be-dmz\"" -InstanceSize \""Standard_D11\"" -ImageName \""be-dmz ... +      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ + CategoryInfo          : NotSpecified: (:) [New-AzureVMConfig]  ArgumentException + FullyQualifiedErrorId : System.ArgumentException Microsoft.WindowsAzure.Commands.ServiceManagement.IaaS.NewAzure VMConfigCommand </code></pre>  <p>I have confirmed that the name of the disk is correct  after deleting the cloud service this disk was present but when I tried to run the command it deleted the disk and it is no longer showing in the list of disks</p>  <p>I want to add these machines to a virtual network called \""CloudVNET\"". Can anyone give me a pointer as to what I am doing wrong here please and how I can go about assigned these reserved IPs to the machines</p>""",azure-virtual-machine
33233054,"Azure VM - List Creator / Created By Detail? <p>I use Azure powershell to spin VMs in Azure. However there are so many people with me who do the same thing in the same subscription. All use powershell only for spinning the vms. I want to find out who has created which VM. Unfortunately we don't see any created by detail using Powershell (N.B. I use ASM approach for creating vms)-</p>  <p><code>Get-AzureVm \xxx\"" \""yyy\""</code></p>  <p>I am trying out to figure out a way to find out which VM is created by which person. I do think there is something in <code>Azure Portal &gt; Management Services &gt; Operation Logs</code> where I can see the operations performed by different users. But I prefer PowerShell so that I can use some logic and automate some kind of mechanism which can provide me a detail for the same with minimal effort. How this can be achieved? </p>""",azure-virtual-machine
23031051,Do Azure VM's have to use the same cloud service to be on the same virtual network? <p>I have created a virtual network  and created a VM <strong>woomph-live</strong> and added it to the virtual network. This went off without a hitch.</p>  <p>I now want to create a 2nd VM <strong>woomph-build</strong> and add it to my virtual network. If I do this and select a <em>different</em> cloud service to the one <strong>woomph-live</strong> is using  creating VM fails.</p>  <p>However  if I choose the same cloud service as <strong>woomph-live</strong>  it starts fine. Is this correct behaviour? And if so  how do I access the website each VM is serving on port 80 on each VM?</p>,azure-virtual-machine
51318220,"Azure portal application settings: \Failed to load settings\"" (ReadOnlyDisabledSubscription) <p>In the Azure portal I select my web app and then \""Application settings\"" and it shows this:</p>  <p><a href=\""https://i.stack.imgur.com/djSoo.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/djSoo.png\"" alt=\""Failed to load settings\""></a></p>  <p>An error message  \""Failed to load settings\""  for application settings and also for connection strings.</p>  <p>How do I fix this?</p>  <p>Additional information:<br> Another user with the same privileges than me is also experiencing this issue when going to the same Application settings page. Also I'm able to deploy so I have the privilege to modify web.config</p>  <p>Additional information #2:<br> So I used Chrome Inspector as suggested and its trying to get application settings with a POST to <a href=\""https://management.azure.com/subscriptions/xxxxxxxxxxx/resourceGroups/xxx/providers/Microsoft.Web/sites/xxx/config/appSettings/list?api-version=2015-08-01\"" rel=\""nofollow noreferrer\"">https://management.azure.com/subscriptions/xxxxxxxxxxx/resourceGroups/xxx/providers/Microsoft.Web/sites/xxx/config/appSettings/list?api-version=2015-08-01</a></p>  <p>This is the JSON response:</p>  <pre><code>{    \""error\"": {        \""code\"":\""ReadOnlyDisabledSubscription\""         \""message\"":\""The subscription 'xxxxxxxxxx' is disabled and therefore marked as read only. You cannot perform any write actions on this subscription until it is re-enabled.\""    } } </code></pre>""",azure-web-app-service
52013428,"Is is possible to browse an Azure App Service temp directory? <p>I am using the <a href=\https://azure.microsoft.com/en-us/blog/windows-azure-websites-online-tools-you-should-know-about/\"" rel=\""nofollow noreferrer\"">Kudu Dashboard</a> to browse the folder of my Azure App Service. Specifically  I am browsing the <code>D:\\local\\Temp\\</code> since that is supposed to be (as far as I understand) the folder used to store temporary files created by my web app. For reference  here is a screenshot of the Kudu dashboard:</p>  <p><a href=\""https://i.stack.imgur.com/66uOR.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/66uOR.png\"" alt=\""enter image description here\""></a></p>  <p>You can see from the screenshot that there is a file called <code>xyz.tmp</code>  this file is a file that I created manually trough the Kudu dashboard.</p>  <p>All this is good  however  when I try to read the file from my web app by using code such as:</p>  <pre><code>var fileContent = System.IO.File.ReadAllText(@\""D:\\local\\Temp\\xyz.tmp\""); </code></pre>  <p>I get an error stating that the file can't be found.</p>  <p>So my question is  what is going on? Why do I get the error? Also  I noticed that when I create a file in the same App Service temp director using code such as:</p>  <pre><code>var fn = System.IO.Path.GetTempFileName(); System.IO.File.WriteAllText(fn  \""abc123\""); </code></pre>  <p>and then I try browsing for the file using the Kudo dashboard I don't see it in the temp directory.</p>  <p>So essentially  it all seems to point to the temp folder being displayed by the Kudo dashboard not representing the real temp folder used by the App Service. So if that is not the case then how exactly are you supposed to be able to browser the App Service temp folder?</p>  <p>Thanks. </p>""",azure-web-app-service
35705014,"How do I delete all files in an Azure File Storage folder? <p>I'm trying to work how how to delete all files in a folder in Azure File Storage.</p>  <p><code>CloudFileDirectory.ListFilesAndDirectories()</code> returns an <code>IEnumerable</code> of <code>IListFileItem</code>. But this doesn't help much because it doesn't have a filename property or similar.</p>  <p>This is what I have so far:</p>  <pre><code>var folder = root.GetDirectoryReference(\myfolder\"");  if (folder.Exists()) {     foreach (var file in folder.ListFilesAndDirectories()) {          // How do I delete 'file'      } } </code></pre>  <p>How can I change an <code>IListFileItem</code> to a <code>CloudFile</code> so I can call <code>myfile.Delete()</code>?</p>""",azure-storage
20569547,"Eclipse Team Foundation Server plugin (Team Explorer Everywhere) giving null errors <p>I have been using the TFS plugin for eclipse with my companies TFS server for several months.  Last week  my laptop crashed while eclipse was open and a connection to the TFS was present.  Now  every time I launch eclipse  I get an error stating a connection could not be made to the server  throwing a NullPointerException.</p>  <p>To try to fix this  I cleaned eclipse from my system and removed the installed plugin and then reinstalled eclipse and the TFS plugin.  Now  I am no longer getting this connection error on launch.  I added the original TFS to the list of servers in eclipse and it can see all of the projects (see <a href=\http://i.imgur.com/SbgyuRx.png\"" rel=\""nofollow\"">http://i.imgur.com/SbgyuRx.png</a>).</p>  <p>However  trying to use any of the projects leads to a screen with an error message saying <code>Error querying workspaces: null</code>.  The error log shows the plugin in question as <code>com.microsot.tfs.client.common</code>  with the stack trace saying <code>An exception stack trace is not available</code>.</p>  <p>I am using the same exact plugin installation that I originally used.  I have no idea why I'm getting these errors.</p>""",azure-devops
14884605,"In Visual Studio  using Windows Azure Storage  where does \Remember Account Key\"" get saved? <p>Recently I reformatted my PC  which previously had Visual Studio installed on it. </p>  <p>In Visual Studio  under Server Explorer -> Windows Azure Storage  before reformatting  I had a storage account configured for one of my hosted services in Azure.  <strong>When I configured it  the \""Remember My Account Key\"" was checked.</strong></p>  <p><em>After reformatting</em>  this account was gone  as expected.  However  when I went to reconfigure the account  I noticed that it automatically populated the \""Account Key\"" field with the valid key.</p>  <p><strong>How does Visual Studio remember this option?</strong></p>""",azure-storage
33692173,"Azure VM TCP idle timeout <p>I have a problem with setting up a FTP Server on a Azure VM. In normal using the server runs great. Problem are coming with large file transfer over passive FTP connection.</p>  <p><strong>Setup</strong></p>  <p>FTP-Server software is a FileZilla Server. Azure VM endpoint  Windows Firewall and Filezilla are configurated to use port 10000-10009 for passive connections. The client is a 3rd party device.</p>  <p><strong>Problem</strong></p>  <p>On large file transfers with a duration over 4min the connection gets an idle timeout.</p>  <p>I found a Microsoft blog entry where is written:</p>  <p><em>\When FTP is transferring large files  the elapsed time for transfer may exceed 4 minutes  especially if the VM size is A0. Any time the file transfer exceeds 4 minutes  the Azure SLB will time out the idle TCP/21 connection  which causes issues with cleanly finishing up the FTP transfer once all the data has been transferred. [..] Basically  FTP uses TCP/21 to set everything up and begin the transfer of data. The transfer of data happens on another port. The TCP/21 connection goes idle for the duration of the transfer on the other port. When the transfer is complete  FTP tries to send data on the TCP/21 connection to finish up the transfer  but the SLB sends a TCP reset instead.\""</em></p>  <p>Now... for my 3rd party client is it not possible to set it up to send a TCP keepalive command to avoid idle timeout.</p>  <p><strong>Question</strong></p>  <p>How can I tell the Azure VM to not close idel TCP connection after 4min? </p>  <p>I even don't understand why this is happens because this violates the TCP specifications (<a href=\""http://filezilla-project.org/specs/rfc5382.txt\"" rel=\""nofollow\"">RFC 5382</a> makes this especially clear its 2h 4m in normal). In other words  Azure that is dropping idle connections too early cannot be used for long FTP transfers.</p>  <p>Please help!</p>  <p>Regards</p>  <p>Steffen</p>""",azure-virtual-machine
55089917,"Auto loading setting file depending on environment with Azure Functions 2.x and VS <p>I need to support multiple settings file for different environment  e.g. Dev  Prod  for Azure Functions.</p>  <p>Below is what I tried  I want to find out <strong>if it is possible to make the settings file loaded automicatlly without step 2  and 3</strong>  like ASP.NET CORE 2.x.</p>  <p>Step 1: The settings files below are defined </p>  <p>MyAppSettings.development.json</p>  <pre><code>{   ThirdParty: {      \Key\"": \""Key1\""    } } </code></pre>  <p>MyAppSettings.production.json</p>  <pre><code>{   ThirdParty: {      \""Key\"": \""Key2\""    } } </code></pre>  <p>Step 2: Define an environment variable that is used to load the settings file</p>  <pre><code>Settings_File_To_Load: MyAppSettings.development.json </code></pre>  <p>Is it possible to reuse a variable instead of creating a new one  e.g. <code>ASPNETCORE_ENVIRONMENT</code></p>  <p>Step 3: Read the value of \""<code>Settings_File_To_Load</code>\""  and load the content of the file.</p>  <p>Is it possible to let the file automicatlly loaded?</p>  <p>Again  is it possible to make the settings file loaded automicatlly without step 2  and 3?</p>  <p>Visual studio 2017</p>""",azure-functions
55503851,SQL Calls from Azure Functions <p>I've an Azure function which uses an event hub trigger to post data to Blob storage.  I'm reading the incoming payload to determine the folder structure of the Blob.  I'm inserting some values from the payload into a MS SQL Database.  However  these values have to be inserted every hour and not on every trigger.  How can I achieve this?</p>  <p>I'm reading the incoming message like this:</p>  <pre><code>var msg = JsonConvert.DeserializeObject&lt;DeviceInfo&gt;(Convert.ToString(myEventHubMessage)); </code></pre>  <p>and storing in the blob:</p>  <pre><code>using (var writer = binder.Bind&lt;TextWriter&gt;(new BlobAttribute(path))) {      writer.Write(myEventHubMessage); } </code></pre>  <p>Here I check to see if the record has been inserted in the Database.  If not I insert it.  But the method CurrentTimeUnprocessed() makes a call to the DB on every request.  I don't want to do it.</p>  <pre><code>if (CurrentTimeUnprocessed(parameter_array) == 0)      AddToUnprocessed(parameter_array); </code></pre>  <p>What's the best way to achieve this?</p>,azure-functions
51723244,"AccessControlException while trying to create a directory on Azure <p>I'm trying this to Create Directory in azureDataLake using azure data lake dependency </p>  <pre><code>&lt;dependency&gt;             &lt;groupId&gt;com.microsoft.azure&lt;/groupId&gt;             &lt;artifactId&gt;azure-data-lake-store-sdk&lt;/artifactId&gt;             &lt;version&gt;2.1.5&lt;/version&gt; &lt;/dependency&gt; </code></pre>  <p>Using the following method:</p>  <pre><code>private ADLStoreClient client;  public boolean createDirectory(String path) {         try {              // create directory             client.createDirectory(path);          } catch (ADLException ex) {             printExceptionDetails(ex);             return false;         } catch (Exception ex) {             log.error(\ Exception in createDirectory : {}\""  ex);             return false;         }         return true;     }  </code></pre>  <p>and I got this exception:</p>  <pre><code>Error creating directory /gx-zweappdhd004/home/azhdipaasssh2/ADH/Compta/1458/1533632735200/RAPPORTS/ Operation MKDIRS failed with HTTP403 : AccessControlException  </code></pre>  <p>I checked the permission and I have all of them  so it's not related to the permissions.</p>  <p><strong>Update</strong>:</p>  <p>To be more specefic the problem happening inside the method <a href=\""https://github.com/Azure/azure-data-lake-store-java/blob/master/src/main/java/com/microsoft/azure/datalake/store/HttpTransport.java#L98\"" rel=\""nofollow noreferrer\"">isSuccessfulResponse()</a>  and exactlly in this line <a href=\""https://github.com/Azure/azure-data-lake-store-java/blob/master/src/main/java/com/microsoft/azure/datalake/store/HttpTransport.java#L137\"" rel=\""nofollow noreferrer\"">HttpTransport.java#L137</a> because the httpResponseCode equals to 403  can anybody explain this.</p>  <p><strong>Update2</strong>:</p>  <p>I found that this line is returning the 403 status : <a href=\""https://github.com/Azure/azure-data-lake-store-java/blob/master/src/main/java/com/microsoft/azure/datalake/store/HttpTransport.java#L288\"" rel=\""nofollow noreferrer\"">HttpTransport.java#L288</a>  I also tried to evaluate <code>conn.getErrorStream().read()</code> and I got this <code>stream is closed</code>  FYI this is bug occures sometimes and not always.</p>""",azure-storage
44300906,How to build and release only the modified files using CI/CD pipeline in VSTS? <p>I am currently in the process of architecting a CI/CD pipeline using VSTS. Whenever a developer commits his changes to the solution in his local visual studio and syncs the changes with remote repository  it triggers the build and release process automatically. How do I release only the files modified by the developer to Azure platform? Is there a feature in VSTS to handle delta deployment?</p>,azure-devops
44846480,How to find what git repo an Azure Function is set up to pull from? <p>I have a few Azure functions and they are setup to deploy from my GitHub repos. How can I find what repo it is connect to in the portal?</p>,azure-functions
51970473,How to get the time since when my Azure VM is stopped through Rest api or Java sdk <p>I am working on a Java application and my requirement is </p>  <p><strong>1. To check if my Azure Virtual Machine is in stopped state.</strong></p>  <p><strong>2. Since when (Date/Time) it is in stopped state.</strong></p>  <p>Azure Java SDK is preference but Rest API will also suffice.</p>,azure-virtual-machine
54011206,Deserialize bot data azure storage <p>I have created a Microsoft bot (v3) and the data e.g. botId channelId  Data  UserId  is stored in the Azure Storage  in a table.</p>  <p>My aim is to deserialize the data found in the data column as it consists of binary data. </p>  <p>After converting the binary data into string  i want store this in an Azure SQL database.  What would be the best way to perform this? Can the deserialization be performed in the bot app? Or should i create a console app to deserialize this.Then import to Azure SQL? </p>  <p>I am using C#</p>,azure-storage
45788441,"Visual studio team services - Octopus does not work after agent update to version 2 <p><strong>Background:</strong></p>  <p>We are using the VSTS to build and Octopus integration to deploy our product. The Octopus step is configured as follows </p>  <p><a href=\https://i.stack.imgur.com/wmVLy.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/wmVLy.png\"" alt=\""enter image description here\""></a></p>  <p><strong>Issue</strong></p>  <p>Today VSTS Build was throwing following error </p>  <blockquote>   <p>No supported agent found in pool Default. All agents in this pool are   using a version that is deprecated. Migrate to the latest 2.x version   of agent. For more information  see   <a href=\""https://go.microsoft.com/fwlink/?linkid=851067\"" rel=\""nofollow noreferrer\"">https://go.microsoft.com/fwlink/?linkid=851067</a></p> </blockquote>  <p>As a result  the Agent was updated to the latest version   After the update the octopus step stopped working with following error </p>  <p><a href=\""https://i.stack.imgur.com/VGFU9.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/VGFU9.png\"" alt=\""enter image description here\""></a></p>  <p>Then issue seems to be the environment variables are not replaced in the step. </p>  <p>I would like to know if there is a work around to fix this issue.</p>""",azure-devops
39648651,"How to connect Azure Web Application (App Service/Website) to Network Security Group? <p>I'm not sure if I'm missing something simple  or if I'm trying to do the impossible.</p>  <p>I have a Tomcat site deployed on Azure using the Web+Mobile App Services model. This is NOT a VM. I would like to be able to apply firewall rules (network security group) to this App Service.</p>  <p>Here is what I have done within my Resource Group:</p>  <ol> <li>Taken my existing App Service (Tomcat) and upgraded it to S1 machine size.</li> <li>Created a VNET with default settings. This included creating a subnet named \default\"". All address space suggestions were left at Azure default prompts.</li> <li>Used the Network settings blade on the App Service to select the VNET I just created.</li> <li>Created a Network Security Group - added an incoming rule to deny  HTTP port 80 from ANY source.</li> <li>Associated NSG created above with the default subnet</li> <li>Waited for everything to propogate</li> <li>Tested hitting the App Service on HTTP Port 80  and got results returned.</li> </ol>  <p>This was not what I was hoping to see. To debug this I tested:</p>  <ol> <li>Create a Tomcat Virtual Machine</li> <li>On the VM Network blade  associated the VM with the \""default\"" subnet  and specifically removed the Network Security Group from the VM (leaving it on the subnet - just making sure it's not explicitly attached to the VM)</li> <li>Tested HTTP access to the VM - traffic rejected</li> <li>Tested HTTP access to the App Service - traffic still permitted</li> <li>Changed the Network Security Group rule to allow</li> <li>Tested HTTP access to the VM and traffic permitted</li> </ol>  <p>How do I get the App Service to use the Network Security Group the way the Virtual Machine does? Am I missing somewhere how to configure the subnet on the App Service? Is there another way to associate the NSG with the App Service?</p>  <p>I don't have budget/need to build an ASE. All I need to do is put a firewall in front of my App Service to block out the ports I'm not wanting to see used.</p>  <p>Thanks.</p>""",azure-web-app-service
36397017,"Elasticsearch on Azure virtual machine <p>I have installed elasticsearch on Azure virtual machine. I have installed the elasticsearch service which which automatically starts on system start up.</p>  <p>Everything works fine on VM. I can access the 9200 port of elasticsearch instance.</p>  <p>The problem is I can not access it with the help of dns name of the virtual machine i.e. xyz.cloudapp.net:9200</p>  <p>I have created endpoints for 9200 and 9300 port.</p>  <p><a href=\https://i.stack.imgur.com/HS35R.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/HS35R.png\"" alt=\""enter image description here\""></a></p>  <p>I want the Elasticsearch on just one VM for now. Am I missing any steps?</p>""",azure-virtual-machine
39881892,"Azure blob service  randomly 404-not found errors <p>We have a web app which processes external callbacks. To isolate our app from the external service  we use an azure blob to store the callback data (.json) and put a message to Azure Service bus for a processing service to pick up later.  The following code is used to write the data to blob storage:</p>  <pre><code>        var storageAccount = CloudStorageAccount.Parse(CloudConfigurationManager.GetSetting(\MyStorage\""));         var blobClient = storageAccount.CreateCloudBlobClient();         var container = blobClient.GetContainerReference(\""containername\"");         var dataFileName = Guid.NewGuid().ToString();         var blockBlob = container.GetBlockBlobReference(dataFileName);         blockBlob.UploadText(data);         blockBlob.Properties.ContentType = \""application/json\"";         blockBlob.SetProperties();          var connectionString = CloudConfigurationManager.GetSetting(\""serviceBusCS\"");         var queueName = \""MyQueue\"";         var client = QueueClient.CreateFromConnectionString(connectionString  queueName);          var payload = new MyCustomMessage {             Id = dataFileName         };         var message = new BrokeredMessage(payload);         client.Send(message); </code></pre>  <p>On the processing side  we have a web job reading the messages <em>one at a time</em> and retrieving the data as follow:</p>  <pre><code>            var storageAccount = CloudStorageAccount.Parse(\""MyCS\"");             var blobClient = storageAccount.CreateCloudBlobClient();             var container = blobClient.GetContainerReference(\""containername\"");             var blockBlob = container.GetBlockBlobReference(message.Id);             if (blockBlob == null) {                 return;             }             if (!blockBlob.Exists()) {                 return; ==&gt; FAILS HERE             }             // Process the message here...            // Once the processing is done  delete the blob   </code></pre>  <p>This design works well most of the time but we get a 404-NotFound from now and then (marked with <code>FAILED HERE</code> above).</p>  <p><strong>QUESTION</strong></p>  <p>The only way this code can fail is by having two messages with the same file name i.e: the same GUID which is nearly impossible or am I missing something?  Any idea why the blob data can't be found? </p>  <p><strong>EDIT 1</strong> Searching for the missing blob from the Azure portal shows that the blob is actually not there. Shouldn't <code>blockBlob.UploadText(data);</code> throw if it fails to write data to the blob container?</p>  <p><strong>EDIT 2</strong></p>  <p>Thanks to Jason for indicating where to look. We crawled our logs and found that the blob is getting written successfully. The web job kicks off and processes the message but one minute later  exactly one minute later we see the web job kicking off trying to process the very same message again and it won't find the blob which is expected as the first run cleared the blob and deleted it. </p>""",azure-storage
18662610,"Connecting existing asp.net application to azure sql server vm without SDK <p>I need to be moving an existing Asp.NET application to Azure  where I've also set up a virtual machine hosting sql server. Now  I obviously don't want to keep deploying all the time  and I haven't even configured Azure for the application to exist within yet. I only want to make sure I can get the application to connect to the sql server instance on the virtual machine.</p>  <p>I'm a complete newbie when it comes to Azure.  So I've absolutely no idea what I'm doing  but I'm using tutorials and good ol' Google to try and figure it all out.</p>  <p>I have the connection string in my web.config formatted the way listed on <a href=\http://msdn.microsoft.com/en-us/library/windowsazure/jj823135.aspx\"" rel=\""nofollow\"">this tutorial</a>  as follows:</p>  <pre><code>&lt;add name=\""AzureSqlServer\"" connectionString=\""Data Source=tcp:[internal-IP];  Initial Catalog=TestDb;User ID=[sql-user];Password=[sql-pass];Encrypt=true;  Trusted_Connection=false;TrustServerCertificate=true\""  providerName=\""System.Data.SqlClient\"" /&gt; </code></pre>  <p>This doesn't connect on its own  so there's obviously something else I have to do. Now  the tutorial follows this section with several steps which all require the Azure SDK to be installed  including setting up the Web Role to connect to the Azure-hosted VM with SQL Server on it. That's all fine and dandy  but there's one little tiny thing it doesn't say anything about: </p>  <p>As it turns out  the Azure SDK is only compatible with Windows Vista and up. So  I can do a Win7 virtual machine  but it would take a few extra days.</p>  <p>Are there any other ways to hook up an Asp.NET Web Application to an Azure-hosted SQL Server Virtual Machine  other than using the Azure SDK?</p>""",azure-virtual-machine
50846907,"What are the claims present in the VSTS OAuth token? <p>I am validating VSTS OAuth token  as <a href=\https://docs.microsoft.com/en-us/vsts/extend/develop/auth?view=vsts#net-framework\"" rel=\""nofollow noreferrer\"">explained here</a>. I <a href=\""https://docs.microsoft.com/en-us/vsts/pipelines/process/phases?view=vsts&amp;tabs=web#access-to-oauth-token\"" rel=\""nofollow noreferrer\"">enabled access to the OAuth token from my VSTS build phase</a>. </p>  <p>What are the claims present in the token? Where is this documented?</p>  <p>Note: the token is a JWT token so any claims will have the <a href=\""https://docs.microsoft.com/en-us/azure/active-directory/develop/active-directory-protocols-oauth-code#jwt-token-claims\"" rel=\""nofollow noreferrer\"">following keys</a>.</p>  <p>Related question: <a href=\""https://stackoverflow.com/questions/50976537/how-to-verify-the-publisher-of-a-message-to-a-service-bus-using-vsts-server-base\"">How to verify the publisher of a message to a service bus using VSTS server-based task?</a></p>""",azure-devops
55532368,Do i need point to site vpn with azure waf and web app <p>I have been messing around with Azure trying to get a web app up and running. My plan was to create a WAF and site the web app behind that  each in a seperate subnet and then to use the service endpoint tech to point the web app to a database.</p>  <p>I have been stopped in my tracks almost straight away with the revelation that if i want to use a WAF in front of the web app i have to configure the networking in the web app but when i choose a vnet it says that no gateway is configured for the selected VNET. </p>  <p>My question being is do i have to use point to site VPN to get this setup working? i thought that it would work like </p>  <p>INTERNET ---> VNET ----> subnet ----> WAF -----> subnet -----> web app ----> service endpoint ------> DB</p>  <p>but that doesnt seem to be the case. I am not keen on the idea of having to install a client certificate on every machine in our network that might want to access this website (it is currently internal). I suppose i am looking for the best of both worlds. Accessible from the internet but having the added comfort of having something like a WAF sat in front of it to make up for any security inadequacies which might exist somewhere in said app. </p>  <p>Thanks</p>,azure-web-app-service
48224516,"Azure Application gateway cannot upload pfx certificate <p>For Application gateway all documentation says to upload pfx certificate but when I go to http settings for backend pool it only allows \.cer\"" certificate and it wont allow \"".pfx\"" file to be uploaded  error displayed says wrong format ?  m i doing something wrong or somehow Azure has changed functionality but documentation is still not uploaded .  Strangely through this command I am able to upload PFX</p>  <pre><code>az network application-gateway ssl-cert create </code></pre>  <p>Screenshot attached</p>  <p><a href=\""https://i.stack.imgur.com/OJUen.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/OJUen.png\"" alt=\""enter image description here\""></a></p>  <p>Update : I am trying to do this for an existing Application Gateway Update 2 : Strangely when I am creating a gateway Azure shows me option for PFX but I dont know why it become cer if I am trying to do this for an existing one.</p>  <p>Is this one of Microsoft's easter eggs??</p>""",azure-virtual-machine
55231589,"Get VM name for an instance of Azure web app from REST API or PowerShell <p>I am trying to find a REST API / PowerShell cmdlet to retrieve the VM name(starts with RD) for an instance of Azure web app.</p>  <p>I found out that I can list the process Ids by Instance Id and then get Instance Process with <a href=\https://docs.microsoft.com/en-us/rest/api/appservice/webapps/getinstanceprocess\"" rel=\""nofollow noreferrer\"">Azure App Service</a>. This object has details including the Machine Name. I'm wondering if there is a better way of doing this  something with lesser API calls perhaps.</p>  <p>Background:</p>  <p>I need to restart a specific instance of a Azure Web app programmatically. Users calling restart can only see the VM name or Role Instance of a web App in Application insights. I found APIs to list instances but nothing to find mapping between instance Id and VM name directly. </p>""",azure-web-app-service
49809359,Azure function regenerating keys after publish <p>Is this expected? Why are my keys being regenerated after each publish? For context  I'm using a precompiled function with a publish profile I downloaded from the Azure portal  and publishing straight through Visual Studio 2017.</p>,azure-functions
50563446,"Azure DSC Configuration Issue <p>Basically I am just trying a very basic thing of accessing the VM details using Azure DSC. I have done the following</p>  <ul> <li>Added a new Credential(which holds the username and password) and Variable(which holds the subscriptionId) under Shared Resources of my automation account</li> <li>Have implemented the following DSC code for retrieving the VM details: I am able to complie this file in the portal it generates the .MOF file as well.  But when I try to apply this to a node in the portal I get the following error:    </li> </ul>  <p><em>PowerShell DSC resource    MSFT_ScriptResource failed to execute Set-TargetResource    functionality with error message: The term    'Get-AutomationPSCredential' is not recognized as the name of a    cmdlet  function  script file  or operable program. Check the    spelling of the name  or if a path was included  verify that the path    is correct and try again</em></p>  <p><strong>Please note that the code written inside the SetScript executes successfully in a runbook!!!!!!</strong></p>  <pre><code>    Configuration VMAzureDSCTasks     { param (     [Parameter()]     [System.String]     $NodeName = \rajeshserver\""       [Parameter()]     [System.String]     $ResourceGroupName = \""rajeshresourcegroup\""       [Parameter()]     [System.String]     $VMSize = \""Standard_D2s_v3\""       [Parameter()]     [System.String]     $CredentialAssetName = \""cred\"" )  Import-DscResource -ModuleName 'PSDesiredStateConfiguration'          Node $NodeName {             Script resizevm     {                          SetScript = {                      # Credentials and Subscription ID declaration                     $Cred = Get-AutomationPSCredential -Name $using:CredentialAssetName                        $null = Add-AzureRmAccount -Credential $Cred -ErrorAction Stop                 $SubId = Get-AutomationVariable -Name 'SubscriptionId'                 $null = Set-AzureRmContext -SubscriptionId $SubId -ErrorAction Stop                        try {                 $vm = Get-AzureRmVm -ResourceGroupName $using:ResourceGroupName -VMName $using:NodeName -ErrorAction Stop                 } catch {                 throw \""Virtual Machine not found!!!!!!\""                  exit                 }                  # Output current VM Size                 $currentVMSize = $vm.HardwareProfile.vmSize                  Write-Verbose -Message \""`nFound the specified Virtual Machine: $using:NodeName\""                 Write-Verbose -Message \""Current size: $using:currentVMSize\""          }         TestScript = {          return $false                         }         GetScript = {         }                 }    }  </code></pre>  <p>}</p>""",azure-virtual-machine
33210564,Visual Studio Team Explorer + VS Online Sync error <p>I'm using VS Online + Git for Version Control  and everything worked fine for a long time until yesterday  when I reinstalled windows  and installed VS 2015. I've opened VS and chose option Open from source control and connected to my VS online account  but when I tried to clone project to my PC I got error:</p>  <pre><code>Error encountered while fetching: Invalid redirect to a non-git endpoint </code></pre>  <p>I've tried few things (mostly randomly because I could not find anything helpful about this err) and nothing helped.</p>  <p>Then I've opened Git bash and manually cloned project to my PC and that wen without any problems. After that I opened project in VS and did some changes  committed dose changes locally without any problems  but when I tried to Sync my project I got same error again. Again  pushing code to server from Git bash went without any problems.</p>  <p>Also I've tried to clone project from another VS online account trough VS + Team Explorer and that went fine.</p>  <p>Could you please help me ?</p>,azure-devops
41849438,"Azure Publish Profile Download is disabled <p>I've created a an App Service using the Azure portal and wanted to download the Publish Profile (to import that into Visual Studio). But the download button is disabled. Any suggestions?</p>  <p><a href=\https://i.stack.imgur.com/XPsTO.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/XPsTO.png\"" alt=\""enter image description here\""></a></p>""",azure-web-app-service
26672752,"Issue fetching data from Azure storage table <p>We are trying to pull data from azure storage table using node.js application. This application uses table URI (along with URI it takes azure storage Accountname and Accesskey) to connect with storage account and queries the table entities. Here is the format of table URI: <a href=\https://azurestorageaccountname.table.core.windows.net\"" rel=\""nofollow\"">https://azurestorageaccountname.table.core.windows.net</a>  The storage has been created on MSDN subscribed azure account.</p>  <p>Issue:  Getting message invalid table URI when code try to get table service instance.</p>  <pre><code>&lt;error xmlns=\""http://schemas.microsoft.com/ado/2007/08/dataservices/metadata\""&gt;    &lt;code&gt;ResourceNotFound&lt;/code&gt;    &lt;message xml:lang=\""en-US\""&gt;The specified resource does not exist. RequestId:a9d162ee-0002-003a-75f1-8361ff000000 Time:2014-10-31T06:02:51.0164254Z    &lt;/message&gt; &lt;/error&gt; </code></pre>  <p>Please note I was able to pull the data using console application. Please reply to me if any pointers or does anyone has faced such issue before.</p>""",azure-storage
46048621,"path based routing for azure appservice web apps <p>I'd like to use path based routing to my azure app service web apps so that</p>  <p><a href=\http://mysite.mydomain.com/site1\"" rel=\""nofollow noreferrer\"">http://mysite.mydomain.com/site1</a> points to <a href=\""http://mysite1.azurewebsites.net\"" rel=\""nofollow noreferrer\"">http://mysite1.azurewebsites.net</a> <a href=\""http://mysite.mydomain.com/site2\"" rel=\""nofollow noreferrer\"">http://mysite.mydomain.com/site2</a> points to <a href=\""http://mysite2.azurewebsites.net\"" rel=\""nofollow noreferrer\"">http://mysite2.azurewebsites.net</a></p>  <p>What is the best way to do this? (I'd like to keep two app services. Not packing two apps in one as virtual directories)</p>  <p>I've tried using Azure Application Gateway which can be configured for this but then I couldn't configure the Web apps to accept traffic from the same custom domain.</p>  <p>In summary this is what I did:</p>  <ul> <li><p>The DNS record for mysite.mydomain.com points to the Application gateway's FQDN with a CNAME record</p></li> <li><p>Application Gateway is configured so that :</p>  <p><a href=\""http://mysite.mydomain.com/site1\"" rel=\""nofollow noreferrer\"">http://mysite.mydomain.com/site1</a> points to <a href=\""http://mysite1.azurewebsites.net\"" rel=\""nofollow noreferrer\"">http://mysite1.azurewebsites.net</a> <a href=\""http://mysite.mydomain.com/site2\"" rel=\""nofollow noreferrer\"">http://mysite.mydomain.com/site2</a> points to <a href=\""http://mysite2.azurewebsites.net\"" rel=\""nofollow noreferrer\"">http://mysite2.azurewebsites.net</a></p></li> <li><p>In order for the web apps to respond to this redirected request  they need to be configured with a custom domain. Since the CNAME record for mysite.mydomain.com points to the Application Gateway  I can't move this to the web apps. Because of this I've added a TXT record and added </p>  <p>awverify.mysite1 pointing to <a href=\""http://mysite1.azurewebsites.net\"" rel=\""nofollow noreferrer\"">http://mysite1.azurewebsites.net</a></p></li> </ul>  <p>This was enough to make the first route work. Now <a href=\""http://mysite.mydomain.com/site1\"" rel=\""nofollow noreferrer\"">http://mysite.mydomain.com/site1</a> happily returns responses from the 1st app service web app.</p>  <p>However  when I did a similar configuration for the second site. The 2nd web app refused to accept the same custom domain as the first one saying:</p>  <blockquote>   <p>Hostname is already being used in the following App: mysite1. Please   remove the Hostname from mysite1  and try again.</p> </blockquote>  <p>So how do I add the same custom domain to two app service web apps so that they can be used in a scenario like this?</p>""",azure-web-app-service
45746876,"CancellationToken doesn't get triggered in the Azure Functions <p>I've got this simple Azure Function:</p>  <pre><code>public static class MyCounter {     public static int _timerRound = 0;     public static bool _isFirst = true;      [FunctionName(\Counter\"")]     //[TimeoutAttribute(\""00:00:05\"")]     public async static Task Run([TimerTrigger(\""*/10 * * * * *\"")]TimerInfo myTimer  TraceWriter log  CancellationToken token)     {         try         {             log.Info($\""C# Timer trigger function executed at: {DateTime.UtcNow}\"");             if (_isFirst)             {                 log.Info(\""Cancellation token registered\"");                 token.Register(async () =&gt;                 {                     log.Info(\""Cancellation token requested\"");                     return;                 });                 _isFirst = false;             }             Interlocked.Increment(ref _timerRound);             for (int i = 0; i &lt; 10; i++)             {                 log.Info($\""Round: {_timerRound}  Step: {i}  cancel request:{token.IsCancellationRequested}\"");                 await Task.Delay(500  token).ConfigureAwait(false);             }         }         catch (Exception ex)         {             log.Error(\""hold on  exception!\""  ex);         }     } } </code></pre>  <p>What I'm trying to do is capturing the CancellationToken request event when the app stops or a code redeploy happened (host shutdown event).</p>  <p>BTW  I've also tried to check the IsCancellationRequested property in the for loop as well. Never turns true.</p>  <p>The main requirement is not to loose any operation/data during the function deployments  I want to know that the app is being stopped so that I persist some data to be processed once host started again after update.</p>""",azure-functions
51205429,"Parametrize runOnStartup in function.json <p>I have a Azure function with a timer trigger. I want the function to execute immediately  when I start the project locally for debugging purposes. This can be done by setting the <code>runOnStartup</code> property.</p>  <p>I cannot keep it in production  because it causes the trigger to fire twice every time it is scheduled  so I am trying to use an appropriate setting.</p>  <p>Snippet of <code>function.json</code>:</p>  <pre><code>{   \schedule\"": \""%TimerSchedule%\""    \""runOnStartup\"": %TimerRunOnStartup%    \""name\"": \""timer\""    \""type\"": \""timerTrigger\""    \""direction\"": \""in\"" } </code></pre>  <p>Snippet of <code>local.settings.json</code>:</p>  <pre><code>\""TimerSchedule\"": \""0 */5 * * * *\""  \""TimerRunOnStartup\"": true  </code></pre>  <p>The CRON expression is read from the settings file as expected  but parsing of <code>function.json</code> fails with the following error in case of the Boolean value:</p>  <blockquote>   <p>Unexpected character encountered while parsing value: %. Path 'bindings[0].runOnStartup'  line 6  position 22.</p> </blockquote>  <p>Is there a way to parametrize a Boolean value in <code>function.json</code>?</p>""",azure-functions
43080821,"Simulating WCF route in WEB API 2 <p>We currently have an old legacy WCF service that I really don't want to maintain but several clients still have access. We currently run all our API services in WEB API 2 in Azure. To enable backward compatibility I was hoping to simulate the WCF routing in WEB API using attribute routing like so:</p>  <pre><code>[RoutePrefix(\registration.svc\"")] public class RegistrationDeprecatedController : ApiController {      [HttpPost]     [Route(\""login\"")]     public async Task&lt;HttpResponseMessage&gt; Login(CredentialModel creds)     {... </code></pre>  <p>Locally this runs like a dream. As soon as I publish to an Azure AppService however all I get is 404 not found. The specific route in question:</p>  <pre><code>/registration.svc/login   </code></pre>  <p>My suspicion is that IIS hosting has the .svc route file associate to process the requests as a WCF call. An extensive search online failed to find anything on how I can change this association or even confirm if this is the case. Any ideas on how to fix or alternative solutions will be greatly appreciated.</p>  <p><strong>Update</strong></p>  <p>Found a solution but its not perfect. Found out that it is possible to directly connect to IIS on the AppService instance and change the Handler Mappings. This is not perfect as it would require a manual change when creating a new instance or deployment slot and I would prefer to automate the entire process.</p>  <p>If anyone else would like to do this you can follow a tutorial by <a href=\""https://blogs.msdn.microsoft.com/benjaminperkins/2014/08/05/configure-remote-iis-administration-for-microsoft-azure-web-sites/\"" rel=\""nofollow noreferrer\"">benjamin perkins</a>. I did have to install an <a href=\""https://www.microsoft.com/en-us/download/details.aspx?id=41177\"" rel=\""nofollow noreferrer\"">IIS Manager for remote administration</a>  extension on windows 10 however for this to work. I removed all mappings associated to *.svc and the routing is now working.</p>""",azure-web-app-service
53525927,"Getting 502 bad gateway when connecting to my SignalR webapp while app insights is on <p>I have a SignalR .NetCore Azure Web App with a Typescript front end. The site and SignalR launch and show the socket connection connect fine. But I've got some issue and I need to turn on App Insights so I can debug. </p>  <p>When I turn app insights on I then get 502 Bad Gateway. I have no idea why and can't find a solution anywhere.</p>  <p><a href=\https://i.stack.imgur.com/xm4VG.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/xm4VG.png\"" alt=\""Here is the console with App Insights off\""></a></p>  <p><a href=\""https://i.stack.imgur.com/FZ1og.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/FZ1og.png\"" alt=\""Here is the console with App Insights On\""></a></p>""",azure-web-app-service
53402701,"Access WCF service deployed as WebJob on Azure from whithin WebApp Sandbox <p>I have come across a document on Azure Sandbox mentioning we can communicate between processes within WebApp Sandbox over TCP as well as named pipes. I have WCF service deployed as WebJob  I can communicate between two WebJobs deployed within WebApp Sandbox over TCP as well as Named Pipe. Problem occurs when I try to communicate from WebApp. I get same error as mentioned in Sandbox Documentation (<a href=\https://github.com/projectkudu/kudu/wiki/Azure-Web-App-sandbox#local-address-requests\"" rel=\""nofollow noreferrer\"">https://github.com/projectkudu/kudu/wiki/Azure-Web-App-sandbox#local-address-requests</a>).</p>  <p>One strange thing I see in Kudu is there are two separate w3wp.exe running  one for Web App and other for SCM (WebJob etc). And somehow looks like there is no communication possible over port/named pipes between them.</p>  <p><a href=\""https://i.stack.imgur.com/MBpOc.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/MBpOc.png\"" alt=\""enter image description here\""></a></p>  <p>Does anyone have more details on how to access this service?</p>""",azure-web-app-service
43063938,"Specify ClientCertEnabled for a virtual application <p>For an Azure Web App  the only setting available for client certificates is \<strong>ClientCertEnabled</strong>\"". The problem is that it requires the certificate for the whole site. I can't find another way. I thought about creating a virtual App under the site  is it possible to enable this setting for a virtual App inside Azure? Any config in the ARM Template?</p>""",azure-web-app-service
2727667,Can I have an internal webservice running in Azure <p>I would like to know if   with Azure  it supports the ability to have webservice running on a specific port which is accessible only by a Site running in Azure. E.g. I want to create a Website hosted on azure but I want some of the services to come from a webservice which I dont want consumer facing.</p>  <p>Is this possible with Azure   if so do I need multiple instances or can this be achieved with one?</p>,azure-web-app-service
46803001,"Azure Functions  nuget package installation failed on West Europe region <p>I'm trying to use NuGet in azure function on West Europe region.<br> I can not install packages.<br> The reason is \The user name or password is incorrect\"".<br> But North Europe region was succeed.<br> I think this is a problem in the West Europe region.<br></p>  <p>I created a TimerTrigger(C#).<br> Upload project.json file</p>  <pre><code>{     \""frameworks\"": {         \""net46\"":{             \""dependencies\"": {                 \""Microsoft.ApplicationInsights\"": \""2.1.0\""                 }             }         } } </code></pre>  <p><br> log</p>  <pre><code>2017-10-17T15:11:11 Welcome  you are now connected to log-streaming service. 2017-10-17T15:11:35.816 Package references have been updated. 2017-10-17T15:11:35.816 Restoring packages. 2017-10-17T15:11:35.816 Starting NuGet restore 2017-10-17T15:11:37.535 Restoring packages for D:\\home\\site\\wwwroot\\TimerTriggerCSharp1\\project.json... 2017-10-17T15:11:37.914 GET https://api.nuget.org/v3-flatcontainer/microsoft.applicationinsights/index.json 2017-10-17T15:11:38.558 OK https://api.nuget.org/v3-flatcontainer/microsoft.applicationinsights/index.json 622ms 2017-10-17T15:11:38.587 GET https://api.nuget.org/v3-flatcontainer/microsoft.applicationinsights/2.1.0/microsoft.applicationinsights.2.1.0.nupkg 2017-10-17T15:11:38.606 OK https://api.nuget.org/v3-flatcontainer/microsoft.applicationinsights/2.1.0/microsoft.applicationinsights.2.1.0.nupkg 18ms 2017-10-17T15:11:38.868 Installing Microsoft.ApplicationInsights 2.1.0. 2017-10-17T15:11:41.577 The user name or password is incorrect. 2017-10-17T15:11:41.577  2017-10-17T15:11:41.577  2017-10-17T15:11:41.596 Packages restored. </code></pre>""",azure-functions
22917846,"Windows Azure - CloudStorageAccount parse error <p>I'm getting the following error when I try to get the account:</p>  <blockquote>   <p>System.Runtime.InteropServices.SEHException</p> </blockquote>  <p>The Conn in configurations are:</p>  <pre><code>&lt;?xml version=\1.0\"" encoding=\""utf-8\""?&gt; &lt;ServiceConfiguration serviceName=\""WindowsAzureProject3\"" xmlns=\""http://schemas.microsoft.com/ServiceHosting/2008/10/ServiceConfiguration\"" osFamily=\""2\"" osVersion=\""*\"" schemaVersion=\""2013-10.2.2\""&gt;   &lt;Role name=\""manager\""&gt;     &lt;Instances count=\""1\"" /&gt;     &lt;ConfigurationSettings&gt;       &lt;Setting name=\""Conn\"" value=\""DefaultEndpointsProtocol=https;AccountName=name;AccountKey=key\""&gt;&lt;/Setting&gt;     &lt;/ConfigurationSettings&gt;   &lt;/Role&gt;   &lt;Role name=\""detectrod\""&gt;     &lt;Instances count=\""1\"" /&gt;     &lt;ConfigurationSettings&gt;       &lt;Setting name=\""DataConnectionString\"" value=\""DefaultEndpointsProtocol=https;AccountName=name;AccountKey=key\""&gt;&lt;/Setting&gt;     &lt;/ConfigurationSettings&gt;   &lt;/Role&gt; &lt;/ServiceConfiguration&gt; </code></pre>  <p>(the account keys are correct)</p>  <p>and the line with error is:</p>  <pre><code>var account = CloudStorageAccount.Parse(RoleEnvironment.GetConfigurationSettingValue(\""Conn\"")); </code></pre>""",azure-storage
46457229,"Randomize a range of numbers with Azure Functions for Microsoft Flow <p>Within Flow and SharePoint  the request would be an Azure Function to <strong>accept the 2 numbers  randomize them  and return one number in between first number and second number.</strong></p>  <p>The goal would be to write an Azure Function and provide the URI and other info needed. This is the flow  and the HTTP Web Request is the where the Azure Function is called.</p>  <p><a href=\https://i.stack.imgur.com/jI0zF.jpg\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/jI0zF.jpg\"" alt=\""enter image description here\""></a></p>""",azure-functions
20659850,"How to get a CloudBlobDirectory pointing toward the container root? <p>With the <a href=\http://www.nuget.org/packages/WindowsAzure.Storage\"" rel=\""nofollow\"">WindowsAzure.Storage</a> library  I would like to create a <code>CloudBlobDirectory</code> that refers to the root of the container. The method <code>CloudBlobContainer.GetDirectoryReference(string)</code> unfortunately fails with an argument exception called with <code>String.Empty</code> as argument.</p>  <p>Is-it possible to have a <code>CloudBlobDirectory</code> referring to the root of the container?</p>""",azure-storage
20892187,Windows Azure Virtual Machine Static IP <p>I created a Windows Server 2012 virtual machine from gallery. In my effort to configure this VM as primary DNS server for my organization  I changed IP into <code>static IP</code> The moment it took place remote desktop got disconnected.</p>  <p>I am not able to connect to the VM neither using management portal nor using .RDP file which I saved earlier.</p>  <p>Have I lost control of this VM permanently? Am I left with only option to contact Microsoft support?</p>,azure-virtual-machine
47738507,Is it possible to reference external assembly with native dependencies in Azure function? <p>I'm getting following exception when doing aforementioned:</p>  <blockquote>   <p>2017-12-10T12:40:39.771 Exception during runtime resolution of assembly 'Affdex  Version=3.4.1.1320  Culture=neutral  PublicKeyToken=null': </p>      <p>'System.IO.FileLoadException: Could not load file or assembly 'Affdex  Version=3.4.1.1320  Culture=neutral  PublicKeyToken=null'        or one of its dependencies. Attempt to load an unverifiable executable with fixups (IAT with more than 2 sections or a TLS section.) (Exception from HRESULT: 0x80131019)</p>      <p>File name: 'Affdex  Version=3.4.1.1320  Culture=neutral  PublicKeyToken=null' ---> System.IO.FileLoadException: Attempt to load an unverifiable executable with fixups </p> </blockquote>  <p>Is there a location that Azure Function runtime looks for dependencies (like Sys32/Inetsrv in Windows)?</p>,azure-functions
31000313,How can I use Azure-provided DNS for Resource Manager VMs? <p>I've been migrating my Azure resources from the V1 Service Management API to the V2 Resource Manager API  but am not sure about Azure-provided DNS. Previously I could ping hosts within the same Cloud Service  however there are no more Cloud Services in V2. Hosts cannot ping each other within the same Resource Group either.</p>  <p>The only change I have made is adding the hostname to /etc/hosts  so a VM can ping itself (resolving to 127.0.0.1):</p>  <pre><code>127.0.0.1 localhost 127.0.0.1 myazurevmhostname  # The following lines are desirable for IPv6 capable hosts ::1 ip6-localhost ip6-loopback fe00::0 ip6-localnet ff00::0 ip6-mcastprefix ff02::1 ip6-allnodes ff02::2 ip6-allrouters ff02::3 ip6-allhosts </code></pre>  <p>The resolv.conf file is left as the default:</p>  <pre><code># Dynamic resolv.conf(5) file for glibc resolver(3) generated by resolvconf(8) #     DO NOT EDIT THIS FILE BY HAND -- YOUR CHANGES WILL BE OVERWRITTEN nameserver 10.0.2.2 nameserver 10.0.2.3 search reddog.microsoft.com </code></pre>  <p>So if I had the VMs <code>myvm1</code> and <code>myvm2</code>  I am expecting to be able to <code>nslookup myvm2</code> from <code>myvm1</code>  however this does not work. So how can I create a 'cloud only' network with Resource Manager  without having to provide my own DNS server?</p>  <p><strong>Update</strong> Since I asked this question originally  Microsoft have made changes on the backend to allow internal name resolution without a DNS server.</p>,azure-virtual-machine
17058324,"Write text to a file in Azure storage <p>I have a text file uploaded in my Azure storage account.Now  in my worker role   what i need to do is every time it is run  it fetches some content from Database  and that content must be written in the Uploaded text file  specifically   each time the content of Text file should be overwritten with some new content.</p>  <p><a href=\http://www.windowsazure.com/en-us/develop/net/how-to-guides/blob-storage/\"" rel=\""nofollow\"">Here</a>  they have given a way to upload a text file to your storage and also delete a file.But i don't want to do that   need to just MODIFY the already present text file each time.</p>""",azure-storage
55934707,"IHttpClientFactory intermittent error: An error occurred while sending the request via Azure Function Apps <p>The error below occurs intermittently when <code>_httpClientFactory.CreateClient()</code> is used to send request to external resources.</p>  <blockquote>   <p>System.Net.Http.HttpRequestException : An error occurred while sending   the request. ---> System.IO.IOException : The server returned an   invalid or unrecognized response.    at async   System.Net.Http.HttpConnection.SendAsyncCore(HttpRequestMessage   request CancellationToken cancellationToken)     End of inner   exception    at async   System.Net.Http.HttpConnection.SendAsyncCore(HttpRequestMessage   request CancellationToken cancellationToken)    at   System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw()    at   async   System.Net.Http.HttpConnectionPool.SendWithNtConnectionAuthAsync(HttpConnection   connection HttpRequestMessage request Boolean   doRequestAuth CancellationToken cancellationToken)    at   System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw()    at   async   System.Net.Http.HttpConnectionPool.SendWithRetryAsync(HttpRequestMessage   request Boolean doRequestAuth CancellationToken cancellationToken)<br>   at System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw()<br>   at async System.Net.Http.RedirectHandler.SendAsync(HttpRequestMessage   request CancellationToken cancellationToken)    at   System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw()    at   async System.Net.Http.DiagnosticsHandler.SendAsync(HttpRequestMessage   request CancellationToken cancellationToken)    at   System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw()    at   async   Microsoft.Extensions.Http.Logging.LoggingHttpMessageHandler.SendAsync(HttpRequestMessage   request CancellationToken cancellationToken)    at   System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw()    at   async   Microsoft.Extensions.Http.Logging.LoggingScopeHttpMessageHandler.SendAsync(HttpRequestMessage   request CancellationToken cancellationToken)    at   System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw()    at   async System.Net.Http.HttpClient.FinishSendAsyncBuffered(Task`1   sendTask HttpRequestMessage request CancellationTokenSource   cts Boolean disposeCts)    at   System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw()    at   async   IdentityModel.Client.HttpClientTokenRequestExtensions.RequestTokenAsync(??)</p> </blockquote>  <pre><code> public class WebHttpClient {          private readonly IHttpClientFactory _httpClientFactory;          public WebHttpClient(IHttpClientFactory httpClientFactory)         {             _httpClientFactory = httpClientFactory;         }          public async Task&lt;string&gt; WebRequestAsync(string url)         {             return await _httpClientFactory.CreateClient().WebRequestAsync(url);  //intermittent error: An error occurred while sending the request.         }      }      [assembly: WebJobsStartup(typeof(Startup))] public sealed class Startup : IWebJobsStartup {     public void Configure(IWebJobsBuilder webJobsBuilder)     {         webJobsBuilder.Services.AddHttpClient();     } } </code></pre>  <p>Any solution?</p>  <p>FYI</p>  <p>Static HttpClient has issues with DNS. This is why I try to avoid static if possible and if using IHttpClientFactory can resolve all issues.</p>  <p>But I am not sure if my issue is caused by DNS or something else.</p>  <p>Would a typed httpclient (or wrapper around httpclient) fix this issue? It is intermittent so it is not easy to reproduce.</p>  <p><a href=\https://docs.microsoft.com/en-us/aspnet/core/fundamentals/http-requests?view=aspnetcore-2.2#typed-clients\"" rel=\""nofollow noreferrer\"">https://docs.microsoft.com/en-us/aspnet/core/fundamentals/http-requests?view=aspnetcore-2.2#typed-clients</a></p>  <p><a href=\""https://docs.microsoft.com/en-us/aspnet/core/fundamentals/http-requests?view=aspnetcore-2.2#httpclient-and-lifetime-management\"" rel=\""nofollow noreferrer\"">https://docs.microsoft.com/en-us/aspnet/core/fundamentals/http-requests?view=aspnetcore-2.2#httpclient-and-lifetime-management</a></p>""",azure-functions
36410458,Resized Azure VM based on the Linux Docker+Rethinkdb image and the data was lost  is this to be expected? <p>Had about 20 documents in one Rethinkdb Database [Docker-based] on a Standard A1 and wasn't using it much so I decided to downsize it to Standard A0  after a few minutes the Rethinkdb server came back online completely empty (with only the test db)</p>  <p>The data was purely for test so no issue there  but is it expected to if someone upgrades a Linux + Docker + [container  Rethinkdb in this case] to lose data? Are there any steps to prevent that?</p>,azure-virtual-machine
48922041,How to Run two node app on single Ubuntu server having two public facing IP <p>My case is  I would like to use Single VM to serve more then 2 Node App and all will use different Public facing IP.</p>  <hr>  <p>Example 1:</p>  <p>Ubantu VM IP: 99.99.99.1 Additional IP1: 99.99.99.2 Additional IP1: 99.99.99.3</p>  <hr>  <p>App1.Js -> 99.99.99.2:80 port -> this can be access by abc.mydomain.com App2.Js -> 99.99.99.3:80 port -> this can be access by xyz.mydomain.com</p>  <hr>  <p>This will allow me to use Single VM and multiple sites running on 80 ports. </p>  <p>OR may me other case like</p>  <p>Example 2: VM1:99.99.99.2 App1.Js -> 99.99.99.2:81 port -> this can be access by abc.mydomain.com App2.Js -> 99.99.99.2:82 port -> this can be access by xyz.mydomain.com</p>  <p>I would love to go with Example 1.</p>  <p>Hosting Environment will be Azure.</p>  <p>Thanks Imran</p>,azure-virtual-machine
51525892,Monitoring instances in Azure Virtual Machine Scale Set (VMSS) using Python <p>I want to monitor and get information regarding the different instances in an Azure Virtual Machine Scale Set (VMSS). </p>  <p>I used the command (Python):</p>  <p>vmss = compute_client.virtual_machine_scale_sets.list(resource_group  scale_set_name)</p>  <p>But I am not able to get the result I am expecting.</p>  <p>Any suggestions what to do?</p>,azure-virtual-machine
47919553,"Azure App service can't start because it can't find swagger documentation xml using ASP.NET Core <p><strong>Update 2:</strong> The file does not get published. That is what is wrong. However  I can't figure out why one of my computers can publish it the right way and the other doesn't after the Visual studio upgrade.</p>  <p><strong>Update</strong>: Running the same solution on two different computers where the APIProject.xml file get's correctly published from one computer but not the other there are now only one difference left. The computer from which the publishing works runs the not updated version of Visual studio 2017 Enterprise. 15.5.2 does not work and 15.4.2 works. </p>  <p>I'm getting this error: </p>  <blockquote>   <p>FileNotFoundException: Could not find file   'D:\\home\\site\\wwwroot\\APIProject.xml'.</p> </blockquote>  <p>The file is placed in bin\\Debug\\netcoreapp2.0  It works locally but when published to Azure App service it crashes. </p>  <p>I'm publishing to the staging slot I created and haven't tried production yet. Publishing replaces all files at destination. </p>  <p>Here is my setup of Swagger but it used to work :)</p>  <pre><code>public void ConfigureServices(IServiceCollection services)     {         services.AddMvc();          // Register the Swagger generator  defining one or more Swagger documents         services.AddSwaggerGen(c =&gt;         {             c.SwaggerDoc(\v1\""  new Info             {                 Version = \""v1\""                  Title = \""Ecommerce/Product API\""                  Description = \""Handles API based shopping functionality\""                  TermsOfService = \""Terms of service should be contracted with inidividually\""                  Contact = new Contact { Name = \""Magnus\""  Email = \""magnus@secret\""  Url = \""\"" }                  License = new License { Name = \""Use under permission from our Group\""  Url = \""http://aboutno\"" }             });              // Set the comments path for the Swagger JSON and UI.             var basePath = PlatformServices.Default.Application.ApplicationBasePath;             var xmlPath = Path.Combine(basePath  \""APIProject.xml\"");             c.IncludeXmlComments(xmlPath);         });        } </code></pre>  <p>What has changed is I added the \""UseSetting\""-row in Program.cs to get errors of why it doesn't start. Before adding that row I did't get developer error  only got end user error page.</p>  <pre><code>public static IWebHost BuildWebHost(string[] args) =&gt;         WebHost.CreateDefaultBuilder(args)             .UseApplicationInsights()             .UseSetting(WebHostDefaults.DetailedErrorsKey  \""true\"")             .UseStartup&lt;Startup&gt;()             .Build(); </code></pre>  <p>I'm trying to publish with Debug mode. Also tried with Release as of one answer below but no difference.</p>  <p>I checked out the code in another computer and publishing from that computer works so the problem just got more weird to me!</p>""",azure-web-app-service
52820267,"Azure blobs - Store directly to archive tier <p>I followed the quickstart at <a href=\https://docs.microsoft.com/en-us/azure/storage/blobs/storage-quickstart-blobs-python\"" rel=\""nofollow noreferrer\"">https://docs.microsoft.com/en-us/azure/storage/blobs/storage-quickstart-blobs-python</a> to learn how to use python to upload files to Azure as blob storage.</p>  <p>As I want to use it as a DR solution and I want to minimize costs  I would like to use the Archive tier.</p>  <p>I know that I can set the tier of the blob immediately after I upload it using <CODE> def set_standard_blob_tier(self  container_name  blob_name  standard_blob_tier  timeout=None) </CODE></p>  <p>However  I prefer  if possible  to upload it directly to the archive tier (instead of uploading it to the default tier  which is hot or cool and then move it).</p>  <p>So I have few question:</p>  <ol> <li><p>Is it possible? if yes  how?</p></li> <li><p>As I'm pretty new to cloud  as there any difference in term of the total cost between the two options? (As you can understand  currently  each blob will be in the cool tier for few seconds before moving to the archive tier  so there might be a cost for that time  and in addition  a cost for the transfer between the tiers).</p></li> </ol>  <p>Thanks!</p>""",azure-storage
38150520,Android | Fresco / FrescoLib + Azure <p>I'm hosting my application in azure (Web service + file storage service).</p>  <p>I wish to use Fresco (SimpleDraweeView) in my application  the problem is that i can not give a direct url to the user  as the storage in azure is private.</p>  <p>The only thing i can do is to get the image as byte array (using my web service) and foward this byte array back to the android client.</p>  <p>How can one use simpledraweeview with a byte array instead of a direct link?</p>  <p>I have tried to set an endpoint in my webservice where the user is giving me the image id and the endpoint returns back the byte array  i have tried to use this endpoint as the url for the simpledraweeview.setImageUrl method but with no luck.</p>,azure-storage
44753704,"Azure App Service SSL certificate binding not automatically updated <p>We bought an SSL certificate through the Azure portal for an App Service and made it autorenew. A while ago the certificate had renewed as it should. This morning we noticed SSL didn't work anymore.  This was because the the wrong SSL certificate was bound to the App Service.</p>  <p>Do I really have to update the bindings manually every year?</p>  <p><a href=\https://i.stack.imgur.com/qgzY9.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/qgzY9.png\"" alt=\""enter image description here\""></a></p>""",azure-web-app-service
53778977,How to manage signed certificates with Azure Function V2 <p>I am working on Azure Functions App on Consumption Plan. The Func App required to load a specific signed certificate.</p>  <p>In local machine I setup the certificate as personal certificate and everything works fine.</p>  <p>After publishing on azure  I am getting this error:</p>  <blockquote>   <p>There are 0 certificates with the subject name cert.name in LocalMachine  MyUse scripts/certificates/ to generate this</p> </blockquote>  <p>Nothing helpful on SO or even in Azure Func documentation on how to use certificate with azure functions.</p>  <p>Anyone has experience with that?</p>,azure-functions
47294382,"Azure Functions Continuous Deployment Failing on Syncing Function Triggers Step <p>I have my continuous deployment configured to use Bitbucket and release on a push to master. This has been working perfectly up until today. Now even builds that have previously been successful are failing on the <code>Syncing Function Triggers</code> step...</p>  <p><a href=\https://i.stack.imgur.com/7FzMC.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/7FzMC.png\"" alt=\""enter image description here\""></a></p>  <p>The final step <code>Deployment Successful.</code> doesn't show up. I downloaded the deployment logs and noticed that there is an error on one of the calls to Kudu.</p>  <blockquote>   <p>2017-11-14T19:06:37.6185924Z Syncing 3 function triggers with payload size 485 bytes failed with System.Net.Http.HttpRequestException: Response status code does not indicate success: 500 (Internal Server Error).\\r\\n   at System.Net.Http.HttpResponseMessage.EnsureSuccessStatusCode()\\r\\n   at Kudu.Core.Helpers.PostDeploymentHelper.d__33.MoveNext()\\r\\n--- End of stack trace from previous location where exception was thrown ---\\r\\n   at System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess(Task task)\\r\\n   at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task)\\r\\n   at Kudu.Core.Helpers.PostDeploymentHelper.d__25.MoveNext() 808a1bcf-e2c6-4e71-a5ba-8ba6afbb5c10 0</p> </blockquote>  <p>I can only assume that Kudu updated their API and now something is breaking in azure the deployment configuration. Is there a way to see or edit the Kudu .deploy file to gain more insight?</p>""",azure-functions
40705537,"Azure vm stopped unexpectedly  says \Storage account xxxxxxxx not found ....\"" <p>My Azure VM with Windows server 2016 stopped unexpectedly today. When I tried RDP today in my vm  it was saying 'machine unavailable'. So I logged in to Azure portal  and the VM was actually running. But when I tried to restart it  I got a notification saying </p>  <p>\""Failed to restart virtual machine xxxxx. Error: Storage account xxxxxxxx not found. Ensure storage account is not deleted and belongs to the same location as the VM.\""</p>  <p>But  I was successfully using the vm till today. I didn't do anything in the Azure portal. The storage account with the vhd still exists (in the same resource group). I once deleted an unused storage account about 2 months ago  but the VM was running perfectly till today. I am not sure about anything that may have happened. The activity logs are empty.</p>""",azure-storage
42964377,"Azure DB Connection Issues from C# <p>I have a particular C# windows console app that runs roughly every five minutes from a Azure VM. Each run starts by connecting to my Azure SQL Server DB. Roughly every 5ish attempts (essentially every 25 mins). One of these attempts to reach the DB will fail with the following error:</p>  <blockquote>   <p>A network-related or instance-specific error occurred while establishing a connection to SQL Server. The server was not found or was not accessible. Verify that the instance name is correct and that SQL Server is configured to allow remote connections. (provider: Named Pipes Provider  error: 40 - Could not open a connection to SQL Server)   </p> </blockquote>  <p>This seems like a much to frequent re-occurring event. On the same VM  I also have a web service setup to connect to the same Azure SQL Server DB  which I use as a mobile backend for one of my iOS apps. Literally every other call to the web service  where the DB is involved  I will receive a same/similar error. </p>  <p>Why exactly would this be happening? Is there a better coding method or connecting method that I should be using??</p>  <p><strong>Update:</strong> I switched to using <a href=\https://msdn.microsoft.com/en-us/library/system.data.linq.datacontext(v=vs.110).aspx\"" rel=\""nofollow noreferrer\"">DataContext</a> which seemed to solve most of these issues. It still happens  just not as frequently. I wonder  would this have anything to do with issues when simultaneous connections are made from completely separate programs? Perhaps my SQL Server can't handle multiple connections properly?</p>""",azure-virtual-machine
9415510,Windows Azure staging <--> production causing conflicts & errors on table storage <p>We had a terrible problem/experience yesterday when trying to swap our staging &lt;--> production role.</p>  <p><strong>Here is our setup:</strong> </p>  <p>We have a workerrole picking up messages from the queue. These messages are processed on the role. (Table Storage inserts  db selects etc ). This can take maybe 1-3 seconds per queue message depending on how many table storage posts he needs to make. He will delete the message when everything is finished.</p>  <p><strong>Problem when swapping:</strong></p>  <p>When our staging project went online our production workerrole started erroring. </p>  <p>When the role wanted to process queue messsage it gave a constant stream of '<strong>EntityAlreadyExists</strong>' errors. Because of these errors queue messages weren't getting deleted. This caused the queue messages to be put back in the queue and back to processing and so on.... </p>  <p>When looking inside these queue messages and analysing what would happend with them we saw they were actually processed but not deleted. </p>  <p>The problem wasn't over when deleting these faulty messages. Newly queue messages weren't processed as well while these weren't processed yet and no table storage records were added  which sounds very strange.</p>  <p>When deleting both staging and producting and publishing to production again everything started to work just fine.</p>  <p><strong>Possible problem(s)?</strong></p>  <p>We have litle 2 no idea what happened actually.</p>  <ul> <li>Maybe both the roles picked up the same messages and one did the post and one errored?</li> <li>...???</li> </ul>  <p><strong>Possible solution(s)?</strong></p>  <p>We have some idea's on how to solve this 'problem'.</p>  <ul> <li>Make a poison message fail over system? When the dequeue count gets over X we should just delete that queue message or place it into a separate 'poisonqueue'.</li> <li>Catch the EntityAlreadyExists error and just delete that queue message or put it in a separate queue.</li> <li>...????</li> </ul>  <p><strong>Multiple roles</strong></p>  <p>I suppose we will have the same problem when putting up multiple roles? </p>  <p>Many thanks.</p>  <p><strong>EDIT 24/02/2012 - Extra information</strong></p>  <ul> <li>We actually use the <strong>GetMessage()</strong></li> <li>Every item in the queue is unique and will generate unique messages in table Storage. Little more information about the process: A user posts something and will have to be distributed to certain other users. The message generate from that user will have a unique Id (guid). This message will be posted into the queue and picked up by the worker role. The message is distributed over several other tables (partitionkey -> UserId  rowkey -> Some timestamp in ticks &amp; the unique message id. So there is almost no chance the same messages will be posted in a normal situation.</li> <li>The invisibility time out <strong>COULD be a logical explanation</strong> because some messages could be distributed to like 10-20 tables. This means 10-20 insert without the batch option. Can you set or expand this <strong>invisibility time</strong> out?</li> <li>Not deleting the queue message because of an exception <strong>COULD</strong> be a explanation as well because we didn't implement any poison message fail over YET ;). </li> </ul>,azure-storage
56892704,"Integration of Azure App Services with AD <p>I have four Azure AppServices which are complete independent applications. I want to provide a kind of a portal that aggregates those four. When a user logs in he sees all applications he has access to depending on his scope. From the portal he can navigate to the other applications and do the user management stuff like adding new users and grant access to a specific application.</p>  <p><a href=\https://i.stack.imgur.com/MhvTo.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/MhvTo.png\"" alt=\""enter image description here\""></a></p>  <p>Is the picture above a good pattern to do it?</p>  <p>If I would start from scratch  what would be a better idea?</p>""",azure-web-app-service
46458371,"Launch Azure Container Service on Upload to Blob Storage <p>I have a use case where I'd like to launch a job on an Azure Container Service cluster to process a file being uploaded to Blob storage. I know that I can trigger an Azure Functions instance from the upload  but I haven't been able to find examples in the documentation of starting a job within Functions.</p>  <p>This diagram illustrates the AWS equivalent of what I want:</p>  <p><a href=\https://i.stack.imgur.com/RHlrM.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/RHlrM.png\"" alt=\""enter image description here\""></a></p>  <p>Thanks!</p>""",azure-functions
51908568,How can i download only the files from last commit from git to a folder? <p>I am trying to get the files changed in the last commit in git and put them into a separate folder. Is there an ant script or shell script that does this job?</p>  <p>To give you a context  I am trying to implement a continous integration and delivery pipeline to release only the changed files in a git branch to  salesforce environment. I am making use of ant build.xml and force.com migration tool to achieve this. The git branch currently contains the full metadata of sandbox . I dont want to deploy the entire metadata when doing a release - hence the requirement to get only the changed files and deploy only those files to the target salesforce environment.</p>  <p>Any help would be appreciated. I am kind of blocked at this stage with no clue how to proceed. </p>,azure-devops
57579277,"Configure NLog to write log to Azure SQL server with manage Identity token <p>I am using NLog and writing log messages to the database using an ADO.NET provider. </p>  <p>I have enabled managed Identity for my Server and I want to connect with Managed Identity and write the logs in Azure SQL. I have SP in nlog configuration file. </p>  <p>How can I achieve this? What change is required in nlog configuration file?</p>  <ul> <li>NLog version: 4.6.6</li> <li>Platform: . .NET Core 2</li> <li>Need to log error with Managed Identity in Azure SQL</li> </ul>  <p>Edit-  Further I have tried to build the databasetarget by code.But not able to set up the accesstoken.  It is throwing error</p>  <blockquote>   <p>Keyword not supported: ' access_token'.</p> </blockquote>  <pre><code>LogManager.LoadConfiguration(String.Concat(Directory.GetCurrentDirectory()  \/nlog.config\"")); string connectionString = \""Data Source=servername.database.windows.net; Initial Catalog=dbname;\""; SqlConnection conn = new SqlConnection(connectionString); conn.AccessToken = accessToken; conn.Open(); var databaseTarget = (DatabaseTarget)LogManager.Configuration.FindTargetByName(\""database\""); databaseTarget.ConnectionString = string.Format(\""{0} access_token ={1}\""  connectionString  conn.AccessToken);  </code></pre>""",azure-virtual-machine
57543942,"Azure Devops : ##[error]Error: No package found with specified pattern: d:\\a\\r1\\a\\**\\*.zip <p>I have tried to Deploy an ARM template from GitHub with Azure DevOps Pipeline (CI/CD).  when i click the deploy button I get the following error.</p>  <p><a href=\https://developercommunity.visualstudio.com/content/problem/349729/error-no-package-found-with-specified-pattern-dar1.html\"" rel=\""nofollow noreferrer\"">https://developercommunity.visualstudio.com/content/problem/349729/error-no-package-found-with-specified-pattern-dar1.html</a></p>  <p>##[error]Error: No package found with specified pattern: d:\\a\\r1\\a***.zip</p>  <p>I did as per the suggestion in the following link but doesnt work for me . Added - task: PublishBuildArtifacts@1 to last line of the azure-pipelines.yml file</p>  <p>azure-pipelines.yml</p>  <pre><code>trigger: - master  pool:   vmImage: 'windows-latest'  variables:   solution: '**/*.sln'   buildPlatform: 'Any CPU'   buildConfiguration: 'Release'  steps: - task: NuGetToolInstaller@1  - task: NuGetCommand@2   inputs:     restoreSolution: '$(solution)'  - task: VSBuild@1   inputs:     solution: '$(solution)'     msbuildArgs: '/p:DeployOnBuild=true /p:WebPublishMethod=Package /p:PackageAsSingleFile=true /p:SkipInvalidConfigurations=true /p:DesktopBuildPackageLocation=\""$(build.artifactStagingDirectory)\\WebApp.zip\"" /p:DeployIisAppPath=\""Default Web Site\""'     platform: '$(buildPlatform)'     configuration: '$(buildConfiguration)'  - task: VSTest@2   inputs:     platform: '$(buildPlatform)'     configuration: '$(buildConfiguration)'  - task: PublishBuildArtifacts@1 </code></pre>  <p>Screenshot</p>  <p><a href=\""https://i.stack.imgur.com/8fGz5.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/8fGz5.png\"" alt=\""enter image description here\""></a></p>""",azure-devops
45597069,Copying azure VM from one account to another <p>I created an Azure VM some time back and need to copy it to another account as the new account has a subscription with more credit.  I am trying to copy the vm however cannot find the vhd uri.  I wanted to use AzCopy.  When I click on disks from the Settings menu I see a resource ID which is not a url.  Am I missing something here?</p>,azure-virtual-machine
44823243,"Skype for Business Server on Azure VM <p>We are planning to integrate Skype Video conferencing into our web application. We are not using <code>Azure AD</code> at the moment so <code>SfB Online</code> is not an option. So we are thinking of setting up <code>Skype for Business Server</code> on Azure VM.</p>  <p>Questions :</p>  <ol> <li><p>Is it possible to setup <code>SfB server</code> on <code>Azure VM</code>. I read in some posts that it is not supported by Microsoft . <a href=\https://support.microsoft.com/en-in/help/2721672/microsoft-server-software-support-for-microsoft-azure-virtual-machines\"" rel=\""nofollow noreferrer\"">Link</a> and <a href=\""https://insidemstech.com/2016/10/18/skype4b-key-planning-considerations-for-sfb-on-azure-iaas-part-iii/\"" rel=\""nofollow noreferrer\"">Link2</a>?</p></li> <li><p>Is <code>Azure AD</code> the only authentication option for <code>SfB Server</code> ? </p></li> <li><p>Any samples or guidance on how to proceed on this ?</p></li> </ol>""",azure-virtual-machine
53931787,"Azure DevOps Build - publish doesn't create .compiled files in bin folder on publish <p>I have a web project I am building and creating a published package from Azure-DevOps Build pipeline.</p>  <p>I am running with the issue that not getting .compile files in bin folder while publishing. when I am publishing from the direct build machine's VS 2015(<strong>on which azure-DevOps builds are also running</strong>) I am getting all .compile files.</p>  <p><strong>My .pubxml file</strong></p>  <pre><code>&lt;Project ToolsVersion=\4.0\"" xmlns=\""http://schemas.microsoft.com/developer/msbuild/2003\""&gt;   &lt;PropertyGroup&gt;     &lt;WebPublishMethod&gt;FileSystem&lt;/WebPublishMethod&gt;     &lt;LastUsedBuildConfiguration&gt;Release&lt;/LastUsedBuildConfiguration&gt;     &lt;LastUsedPlatform&gt;Any CPU&lt;/LastUsedPlatform&gt;     &lt;SiteUrlToLaunchAfterPublish /&gt;     &lt;LaunchSiteAfterPublish&gt;True&lt;/LaunchSiteAfterPublish&gt;     &lt;PrecompileBeforePublish&gt;True&lt;/PrecompileBeforePublish&gt;     &lt;EnableUpdateable&gt;False&lt;/EnableUpdateable&gt;     &lt;DebugSymbols&gt;True&lt;/DebugSymbols&gt;     &lt;WDPMergeOption&gt;CreateSeparateAssembly&lt;/WDPMergeOption&gt;     &lt;UseFixedNames&gt;True&lt;/UseFixedNames&gt;     &lt;ExcludeApp_Data&gt;False&lt;/ExcludeApp_Data&gt;     &lt;publishUrl&gt;E:\\DevOps\\agent\\vsts-agent-win-x64-2.136.1\\QAWeb_Artifacts&lt;/publishUrl&gt;     &lt;DeleteExistingFiles&gt;True&lt;/DeleteExistingFiles&gt;   &lt;/PropertyGroup&gt; &lt;/Project&gt; </code></pre>  <p><strong>Task configuration in Azure-DevOps pipeline</strong></p>  <p><a href=\""https://i.stack.imgur.com/SN7MO.jpg\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/SN7MO.jpg\"" alt=\""enter image description here\""></a></p>  <p>I found the same issue here - <a href=\""https://forums.asp.net/t/1984856.aspx\"" rel=\""nofollow noreferrer\"">https://forums.asp.net/t/1984856.aspx</a> but not answered.</p>  <p>Please Suggest what I am missing when I build and publish my website from azure-DevOps.</p>""",azure-devops
53466292,"Azure Devops Access with Azure AD client credential grant flow <p>I have successfully authenticated with Azure AD and received an access token. And I have given Azure AD App API permissions to Access Azure DevOps</p>  <p>I am using RestSharp Http Client do authenticate </p>  <pre><code>var client = new RestClient(\https://login.microsoftonline.com/{tenant}/oauth2/token\"");             var request = new RestRequest(\""\""  Method.POST);             request.AddParameter(\""grant_type\""  \""client_credentials\"");             request.AddParameter(\""client_id\""  \""00000f-0000-00-00-000000\"");             request.AddParameter(\""client_secret\""  \""][M.&amp;*******?*_5z)y${*[)\"");             request.AddParameter(\""resourse\""  \""https://tenant.onmicrosoft.com/4815c06b-7e28-4f88-9dc8-8fe3354d5909\"");             IRestResponse response = client.Execute(request);             var content = response.Content; // raw con </code></pre>  <p>I am happy up to this point. What I can't figure out is how to use the access token to access Azure DevOps What I have tried thus far</p>  <pre><code> var client = new RestClient(\""https://app.vssps.visualstudio.com/oauth2/token\"");         var request = new RestRequest(\""\""  Method.POST);         request.AddParameter(\""client_id\""  \""My APP code here\"";         request.AddParameter(\""client_secret\""  \""My ap secret here\"");         request.AddParameter(\""client_assertion_type\""  \""urn:ietf:params:oauth:client-assertion-type:jwt-bearer\"");         request.AddParameter(\""client_assertion\""  \""access token here\"");         request.AddParameter(\""grant_type\""  \""authorization_code\""); </code></pre>  <p>The error I am receiving is \""{\\\""Error\\\"":\\\""unsupported_grant_type\\\"" \\\""ErrorDescription\\\"":\\\""grant_type must be the ietf jwt-bearer type or refresh_token\\\""}\""</p>  <p>What am I missing?</p>""",azure-devops
56444146,How to read cookies from the request in azure function app using python <p>I created a azure HTTP triggered function app using python which accepts request and return response based on the request parameters. Now I want read the cookies from the request. How to read the cookie from request?</p>,azure-functions
41286479,"Service Fabric Application vmImageSku <p>When you deploy a Service Fabric Cluster as an ARM template you have the option of specify Windows Version (OS) of the Virtual Machine via the VmImageSku parameter. It is per default set to \2012-R2-Datacenter\"". I have not been able to find any examples of other values for this.</p>  <p>My real question is can a Service Fabric Cluster be deployed to a Server Core?</p>  <pre><code>\""vmImagePublisher\"": {   \""type\"": \""string\""    \""defaultValue\"": \""MicrosoftWindowsServer\""    \""metadata\"": {     \""description\"": \""VM image Publisher\""   } }  \""vmImageOffer\"": {   \""type\"": \""string\""    \""defaultValue\"": \""WindowsServer\""    \""metadata\"": {     \""description\"": \""VM image offer\""   } }  \""vmImageSku\"": {   \""type\"": \""string\""    \""defaultValue\"": \""2012-R2-Datacenter\""    \""metadata\"": {     \""description\"": \""VM image SKU\""   } }  \""vmImageVersion\"": {   \""type\"": \""string\""    \""defaultValue\"": \""latest\""    \""metadata\"": {     \""description\"": \""VM image version\""   } } </code></pre>  <p>usage:</p>  <pre><code>\""type\"": \""Microsoft.Compute/virtualMachineScaleSets\""    \""name\"": \""[variables('vmNodeType0Name')]\""      \""virtualMachineProfile\"": {       \""extensionProfile\"": {         \""extensions\"": [             \""storageProfile\"": {            \""imageReference\"": {               \""publisher\"": \""[parameters('vmImagePublisher')]\""                \""offer\"": \""[parameters('vmImageOffer')]\""                \""sku\"": \""[parameters('vmImageSku')]\""                \""version\"": \""[parameters('vmImageVersion')]\""         } </code></pre>""",azure-virtual-machine
2146080,WIndows Azure web project <p>I'd just like to know if its possible to deploy a web project  that usually runs on the windows azure cloud  to a normal windows server 2008 pc for testing purposes?</p>,azure-web-app-service
39540951,"Azure Functions - Shared classes <p>I want to use some shared classes on my Azure Functions to not duplicate code.</p>  <p>I have tried to create a empty C# function and create the classes inside the function and then import to the other functions with:</p>  <p><code>#r \../Shared/Class.cs\""</code></p>""",azure-functions
57166391,OPENROWSET from Ms Acess in Azure VM <p>We need to extract databases from multiple Access .mdb files into an Azure VM via SQL (on the Azure VM). Updated versions of the Access files are dumped into Azure on a daily basis.</p>  <p>Pre-Azure  we imported the data using OPENROWSET (we have nine of them  all identical  so set up a cursor to import and consolidate them into one) from Access files on our network  which was somewhat unwieldy  but worked as well as could be expected.</p>  <p>Having no experience with Azure  we naively assumed we would be able to use the same script there  but it looks as if Azure doesn’t include the necessary ACE 12.0 drivers?</p>  <p>I think we can get around it by running them in using the Import/Export Wizard  and saving as an SSIS package which can be run in a stored procedure  but before we rewrite the existing script  can anyone please confirm that I am correct in thinking the OPENROWSET approach will not be possible with Access files in an Azure VM?</p>  <p>Thanks</p>,azure-virtual-machine
53276947,"Could not load file or assembly System.Fabric with Azure Functions <p>Are there any restrictions with packages you can use with Azure Functions.  I have researched as much as I can and it doesn't seem so  however when I try creating an Azure Function that references the package \Microsoft.ServiceFabric\"" I get the following error:</p>  <blockquote>   <p>System.Private.CoreLib: Exception while executing function:   ScaleDownServiceFabrics. FunctionApp2: Could not load file or assembly   'System.Fabric  Version=6.0.0.0  Culture=neutral    PublicKeyToken=31bf3856ad364e35'. Could not find or load a specific   file. (Exception from HRESULT: 0x80131621). System.Private.CoreLib:   Could not load file or assembly 'System.Fabric  Version=6.0.0.0    Culture=neutral  PublicKeyToken=31bf3856ad364e35'.</p> </blockquote>  <p>I have tried both Azure Func and.1 and 2  and .Net Framework and .Net Core with no luck.</p>  <pre><code>using System; using Microsoft.Azure.WebJobs; using Microsoft.Azure.WebJobs.Host; using Microsoft.Extensions.Logging; using System.Fabric;  namespace FunctionApp5 {   public static class Function1   {     [FunctionName(\""Function1\"")]     public static void Run([TimerTrigger(\""*/5 * * * * *\"")]TimerInfo myTimer  ILogger log)     {       log.LogInformation($\""C# Timer trigger function executed at: {DateTime.Now}\"");       FabricClient client = new FabricClient();     }   } } </code></pre>  <p>Is this possible  or a limitation of Azure Functions in Visual Studio - if so  what packages are acceptable?</p>""",azure-functions
51344244,Azure App Service breaking on every restart <p>On every release to the app service or any restart of the app service  I get 502 error.</p>  <p>If I then modify a couple of the connectionStrings in the appsettings.json file the app starts working again.  When I say modify  I just changed the <code>initial catalog</code> from the demo DB to the dev DB and then back to the demo DB  the 502 error was solved.</p>  <p><strong>1st question</strong> has anybody seen this type issue where the app service breaks until the appsettings.json file is modified?</p>  <p><strong>2nd question</strong> this is probably related to the 1st issue.  I have a connection string that points to the DEMO Db but writes to the DEV Db.  Could there be corruption or something that relates to both of these issues?</p>  <p>Extra information  this is aspnetcore 2.1 app.  the connections strings point to SQL Server.</p>,azure-web-app-service
48516298,PNP PowerShell in Azure Function fails when to fast triggerd in a time intervall <p>I have an issue with my PNP PowerShell Azure function.</p>  <p>The Azure function will be triggerd by html or logic app and will connect to a SharePoint Site.</p>  <p>After the connection is open  the azure function will set different permissions on this site. But if the azure function is triggerd to fast from two sites the first on will fail with the following error msg. </p>  <p>Set-PnPListPermission : The object is used in the context different from the one associated with the object.</p>  <p>at run.ps1: line 51</p>  <ul> <li><p>Set-PnPListPermission</p></li> <li><hr>  <ul> <li><p>CategoryInfo          : WriteError: (:) [Set-PnPListPermission]  InvalidOperationException</p></li> <li><p>FullyQualifiedErrorId : EXCEPTION SharePointPnP.PowerShell.Commands.Lists.SetListPermission</p></li> </ul></li> </ul>  <p>If there are 20 seconds between the trigger action  the azure function will run successfully.</p>  <p>My first thought was that the reason for this is the instantiate of the azure function...</p>  <p>On local PC the PowerShell script runs smoothly.</p>  <p>Thanks and BR</p>,azure-functions
12210635,what to choose from website  cloud service & virtual machine on Windows Azure <p>I have already knowledge of windows azure and worked on cloud service storage &amp; WASD  Still there are plenty of ways to put our application on Azure including <strong>Website  Cloud Service  Virtual Machine</strong> so many developers have question regarding that what to choose when from above list? (Like me)</p>  <p>My purpose of this question is just expert guys of Azure can differentiate these terminology and <strong>In which situation what is best suitable one</strong>?</p>,azure-virtual-machine
53490873,"Azure VM: the user account used to connect to remote PC did not work <p>I have an Azure Virtual Machine connected with Azure Active Directory. A user from this AD is added to this machine as an admin. Other people can successfully RDP to the machine with this user's credential  but I get error saying \The user account used to connect to remote PC did not work. Try again\"". Well  I am trying the whole day. Does anyone know what can cause this?</p>  <p>The fun fact is  I can RDP to the machine using the local admin  but again it fails with AD user.</p>  <p>I tried connecting with Microsoft Remote Desktop for Mac  mstsc for Windows and with Remote Desktop Connection Manager. The same result everywhere.</p>  <p>I tried different usernames format: </p>  <ul> <li><code>alex.sikilinda@mydomain.com</code> - other people can successfully login using this format</li> <li><code>AzureAD\\alex.sikilinda@mydomain.com</code> - for windows client getting the same error  for Microsoft Remote Desktop for Mac getting \""Your session ended because of an error. If this keeps happening  contact your network administrator for assistance. Error code: 0x807\""</li> <li><code>AzureAD\\AlexSikilinda</code> mstsc error - \""Remote machine is AAD joined. If you are signing in to your work account  try using work email instead\""  Mac - \""Your session ended because of an error. If this keeps happening  contact your network administrator for assistance. Error code: 0x807\""</li> </ul>  <p>Microsoft Remote Desktop for Mac version <code>10.2.3 (1343)</code> Windows 10 version 16299 (also tried with 1803 on another machine  the same result).</p>""",azure-virtual-machine
54537785,"Delete old Windows Azure Diagnostics data from table storage (performance counters  etc.) <p>I have several Windows VMs running on Azure that are configured to collect performance counters and event logs.</p>  <p>All of this is configured in the \Diagnostic settings...\"" on the VM resource inside Azure Portal. There's a Windows Azure Diagnostics agent that collects this data on the VM and stores it into a storage account (inside Table Storage).</p>  <p>All of this collected data (performance counters  metrics  logs  etc.) doesn't have any retention policy and <strong>there doesn't seem to be any way of setting it up</strong>. So it just accumulates in the storage account's table storage forever.</p>  <p>This is where my problem is -- there's now too much data in these tables (several terabytes in my case) and it's costing a lot of money just to keep it. And it's only going to keep increasing over time.</p>  <p>The relevant storage account tables are tables like:</p>  <ul> <li><code>WADMetrics*</code> (Windows Azure Diagnostics Metrics Table)</li> <li><code>WADPerformanceCountersTable</code> (Windows Azure Diagnostics Performance Counters Table)</li> <li><code>WASWindowsEventLogsTable</code> (Windows Azure Diagnostics Windows Event Logs Table)</li> </ul>  <p>Is there some way <strong>how to delete old data</strong> in these tables so it wouldn't break anything? Or even better  is there some <strong>way to configure retention policy</strong> or set it up so that it doesn't keep accumulating forever?</p>""",azure-storage
38357295,"What triggers Azure Functions to reload the referenced assemblies? <p>I've been referencing external assemblies trying to work around the issue noted here: <a href=\https://stackoverflow.com/questions/38314334/how-do-i-reference-a-portable-net-assembly-from-an-azure-cloud-function\"">Azure Function Cannot Load Portable Assembly</a>.  However  often my function does not seem to reflect the changes made to the functionName\\bin assemblies.  I've intentionally referenced the wrong assemblies  and then reran the function.  I experience no change to what is logged (and I'm logging exceptions).  </p>  <p>How do I force a complete reload of the Azure function?  Can I somehow see what Azure functions has as its \""loaded\"" assemblies?</p>""",azure-functions
53320464,"Azure app service with python from a visual studio project <p>We have a python application (Flask) that we develop with Visual Studio. We push this to Azure DevOps as a git.</p>  <p>When I push it to our Azure App Service it only works when I only push the actual python files and not the <code>.vs</code> folder or the <code>.pyproj</code>  <code>.pyproj.user</code> files. This means I have a folder locally that I copy the files to and then push to app services. That is not the nicest solution as you can imagine.</p>  <p>My questions:</p>  <ol> <li>Why does app service not work with the \other\"" files?</li> <li>How would this work nicely that every time I push directly to the app service as well as our Azure DevOps?</li> </ol>""",azure-devops
50242027,"Dynamic IP Address Restrictions for .NET Core Web API Application on azure Web App <p>I have developed a Web API application using .net core 1.0 \version\"": \""1.0.5\"" and deploying on Azure web app.</p>  <p>Currently  I'm facing a problem with an API endpoint when the user hits the endpoint concurrently. So for my CPU/DTU percentage increase above 60 to 100.  For that  I should restrict that user when he hit's an API endpoint concurrently. I don't have any idea to restrict those IP. I'm very new to this issue.</p>  <p>Can anyone please help me to resolve this issue?</p>  <p>Note:- When he hit's the API endpoint concurrently I should block those IP for the limited duration.</p>  <p>Thanks </p>  <p>Parthiban.</p>""",azure-web-app-service
57633023,How to allow users over VPN to access Azure Web App <p>We have an Azure Web App and Azure VPN  we've locked down the web app so it's accessible internally only by granting/restricting access via IP addresses (via Access Restrictions page). However users over our VPN are not able to access the web app - when they connect over VPN  the user's external IP address is not from our internal network.  We do not want to whitelist everyone's IP address. </p>  <p>If we had the internal IP address of the web app  we have a few options we could try  but we assume this is not available to us.</p>  <p>How would we allow access to a web app for users over a VPN?<br> Is this something API Management would solve?</p>,azure-web-app-service
53816791,"Azure DevOps-Linux webapp doesnt show up <p>I've created a new web-app in <a href=\/questions/tagged/azure\"" class=\""post-tag\"" title=\""show questions tagged &#39;azure&#39;\"" rel=\""tag\""><img src=\""https://i.stack.imgur.com/9J8MK.png\"" height=\""16\"" width=\""18\"" alt=\""\"" class=\""sponsor-tag-img\"">azure</a> portal and using <code>Azure DevOps pipeline</code>.</p>  <p>I've chosen WebApp 'Azure App Service Deploy' task to deploy. I've authorized my subscription and when I try to select the webapp  I dont see my Linux webapp that i newly created.</p>  <p>I tried creating a new windows webapp with a new service plan and I was able to see that in the list.</p>  <p>Am i missing something here?</p>  <p><a href=\""https://i.stack.imgur.com/3s6ZW.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/3s6ZW.png\"" alt=\""Click here for the image\""></a></p>""",azure-devops
45957790,List my custom images Azure CLI <p>I'm using Azure CLI to managed my VMs. My VMs are created from a custom image. I forgot the name I was given to the image. I created the image using <code>az image create</code></p>  <p>Is there any way to list all my custom images name?</p>  <p>I tried using this command: <code>az vm image list -o table -g myGroup</code> but i got an exception that resource group parameter is not valid</p>,azure-virtual-machine
45074701,"Increasing request timeout of 110s <p>I cannot seem to extend the 110 second timeout for requests to my Azure Web App. I have done the following in order to increase this limit  but with no success.</p>  <p>ASP.NET's HTTP request execution timeout (web.config):</p>  <pre><code>&lt;system.web&gt;   &lt;httpRuntime executionTimeout=\600\"" /&gt; &lt;/system.web&gt; </code></pre>  <p>IIS connection timeout (web.config):</p>  <pre><code>&lt;system.applicationHost&gt;   &lt;webLimits connectionTimeout=\""00:10:00\"" /&gt; &lt;/system.applicationHost&gt; </code></pre>  <p>Kudu timeout before external commands are killed (site app setting):</p>  <pre><code>SCM_COMMAND_IDLE_TIMEOUT = 600 </code></pre>  <p>What am I missing?</p>""",azure-web-app-service
43047979,"Downloading from Blob Azure redirects wrong <p>When I press download and call this action  I get the result </p>  <blockquote>   <p>The resource you are looking for has been removed  had its name   changed  or is temporarily unavailable.</p> </blockquote>  <p>and directed to </p>  <blockquote>   <p><a href=\http://integratedproject20170322032906.azurewebsites.net/MyDocumentUps/Download/2020Resume.pdf\"" rel=\""nofollow noreferrer\"">http://integratedproject20170322032906.azurewebsites.net/MyDocumentUps/Download/2020Resume.pdf</a></p> </blockquote>  <p>Why does it link to above and not to </p>  <blockquote>   <p><a href=\""https://filestorageideagen.blob.core.windows.net/documentuploader/2020Resume.pdf\"" rel=\""nofollow noreferrer\"">https://filestorageideagen.blob.core.windows.net/documentuploader/2020Resume.pdf</a></p> </blockquote>  <p>as shown in the controller?</p>  <p>Here is my actionlink in the view</p>  <blockquote>   <p>@Html.ActionLink(\""Download\""  \""Download\""  \""MyDocumentUps\""  new { id =   item.DocumentId.ToString() + item.RevisionId.ToString() +   item.Attachment }  new { target=\""_blank\""}) |</p> </blockquote>  <pre><code>public ActionResult Download(string id)         {              string path = @\""https://filestorageideagen.blob.core.windows.net/documentuploader/\"";              return View(path + id);          } </code></pre>""",azure-storage
56937742,"Azure Managed Identity local debug authentication failure <p>I've got a very basic example that I just can't seem to get working. The user I'm using is a subscription owner so should have access to everything. If I run the following when it tries to actually get the blob text that is when it falls over with:</p>  <blockquote>   <p>StorageException: Server failed to authenticate the request. Make sure   the value of Authorization header is formed correctly including the   signature.</p> </blockquote>  <pre><code>using Microsoft.Azure.Services.AppAuthentication; using Microsoft.WindowsAzure.Storage.Auth; using Microsoft.WindowsAzure.Storage.Blob; using System; using System.Threading; using System.Threading.Tasks;  namespace testmsistorageaccess {     class Program     {         public static void Main()         {             AzureServiceTokenProvider azureServiceTokenProvider = new AzureServiceTokenProvider();             var tokenAndFrequency = TokenRenewerAsync(azureServiceTokenProvider                                                          CancellationToken.None).GetAwaiter().GetResult();              TokenCredential tokenCredential = new TokenCredential(tokenAndFrequency.Token                                                                      TokenRenewerAsync                                                                      azureServiceTokenProvider                                                                      tokenAndFrequency.Frequency.Value);              StorageCredentials storageCredentials = new StorageCredentials(tokenCredential);              var storageUri = new Uri(\https://mystorageaccount.blob.core.windows.net\"");             var client = new CloudBlobClient(storageUri  storageCredentials);             var container = client.GetContainerReference(\""bob\"");             string content = container.GetBlockBlobReference(\""bob.xml\"").DownloadTextAsync().Result;             Console.WriteLine($\""Got {content}\"");         }          private static async Task&lt;NewTokenAndFrequency&gt; TokenRenewerAsync(Object state  CancellationToken cancellationToken)         {             const string StorageResource = \""https://storage.azure.com/\"";             var authResult = await ((AzureServiceTokenProvider)state).GetAuthenticationResultAsync(StorageResource);             var next = (authResult.ExpiresOn - DateTimeOffset.UtcNow) - TimeSpan.FromMinutes(5);             if (next.Ticks &lt; 0)             {                 next = default(TimeSpan);             }             return new NewTokenAndFrequency(authResult.AccessToken  next);         }     } } </code></pre>  <p>Not sure what I'm doing wrong here  I've checked and the user it's trying to use and that appears correct and has the right AD Tenant ID:</p>  <p><a href=\""https://i.stack.imgur.com/Cp6fm.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/Cp6fm.png\"" alt=\""enter image description here\""></a></p>  <p>I saw mention of checking time on my local machine with UTCNow and confirmed it's correct with GMT time other than that I've found nothing else about how to debug this.</p>  <p>Any help appreciated</p>""",azure-storage
47600199,"Azure function get json from site and just pass it trough <p>I'm trying to pass data from link A to azure functions which just needs to get the data from link A and return that data on it's own.</p>  <p>So I get Json data from <code>A</code>  that data is served by an API. Now  I have a azure function and I need to grab the data from <code>A</code> and return <code>req.CreateResponse(HttpStatusCode.OK)</code>  with the data from <code>A</code>. That needs to be visible (exactly the same) on <code>B</code> and <code>B</code> here is my Azure url...</p>  <p>How can  do this?</p>  <p>I tried to do a <code>await req.Content.ReadAsStringAsync()</code>  but that doesn't do a thing.. </p>  <p>So  my function app looks like this now:</p>  <pre><code>[FunctionName(\CreateRadioAPI\"")]         public static async Task&lt;HttpResponseMessage&gt; CreateRadioAPIAsync([HttpTrigger(AuthorizationLevel.Anonymous  \""get\""  Route = \""v1/radio/stats/info\"")]HttpRequestMessage req  TraceWriter log)         {             try             {                 //dynamic body = await req.Content.ReadAsStringAsync();                  return req.CreateResponse(HttpStatusCode.OK);             }             catch (Exception ex)             {                 log.Error(\""An error occured: \""  ex);                 return req.CreateResponse(HttpStatusCode.InternalServerError);             }         } </code></pre>  <p>In here  I want to return the data from the other link which looks like this:</p>  <pre><code>{     \""data\"": {         \""listeners\"": 65          \""song\"": \""Ofenbach - Katchi (Ofenbach vs. Nick Waterhouse)\""          \""live_dj\"": \"".-RRxd-.\""          \""mini_rooster\"": []          \""song_history\"": [             {                 \""playedat\"": 1512154754                  \""title\"": \""Ofenbach - Katchi (Ofenbach vs. Nick Waterhouse)\""                  \""metadata\"": {                     \""tit2\"": \""Ofenbach - Katchi (Ofenbach vs. Nick Waterhouse)\""                 }             }              {                 \""playedat\"": 1512154548                  \""title\"": \""Cam'ron - Hey Ma\""                  \""metadata\"": {                     \""tit2\"": \""Cam'ron - Hey Ma\""                 }             }              {                 \""playedat\"": 1512154335                  \""title\"": \""San Holo - I Still See Your Face\""                  \""metadata\"": {                     \""tit2\"": \""San Holo - I Still See Your Face\""                 }             }              {                 \""playedat\"": 1512151761                  \""title\"": \""Sunnieday Mixtape Dyna (5)\""                  \""metadata\"": {                     \""tit2\"": \""Sunnieday Mixtape Dyna (5)\""                 }             }              {                 \""playedat\"": 1512151162                  \""title\"": \""Merk &amp; Kremont - Sad Story (Out Of Luck)\""                  \""metadata\"": {                     \""tit2\"": \""Merk &amp; Kremont - Sad Story (Out Of Luck)\""                 }             }              {                 \""playedat\"": 1512150866                  \""title\"": \""Martin Garrix - So Far Away\""                  \""metadata\"": {                     \""tit2\"": \""Martin Garrix - So Far Away\""                 }             }              {                 \""playedat\"": 1512150701                  \""title\"": \""John de Sohn - Hum With Me\""                  \""metadata\"": {                     \""tit2\"": \""John de Sohn - Hum With Me\""                 }             }              {                 \""playedat\"": 1512150345                  \""title\"": \""Zak Abel - All I Ever Do (Is Say Goodbye)\""                  \""metadata\"": {                     \""tit2\"": \""Zak Abel - All I Ever Do (Is Say Goodbye)\""                 }             }              {                 \""playedat\"": 1512150139                  \""title\"": \""Dua Lipa - New rules\""                  \""metadata\"": {                     \""tit2\"": \""Dua Lipa - New rules\""                 }             }              {                 \""playedat\"": 1512149995                  \""title\"": \""Garmiani - Fogo\""                  \""metadata\"": {                     \""tit2\"": \""Garmiani - Fogo\""                 }             }         ]     } } </code></pre>""",azure-functions
54202836,"Precompiled Azure Function Output to Blob Storage receiving 500 Internal Server Error <p>The final output of my C# Precompiled Azure Function is to write to a blob storage as a JSON file. Am I writing to the Blob storage wrong? I hit the breakpoints set on the curly brackets at to the end of the function and it looks like it exits the function. Around 20 seconds later I get the exception: </p>  <blockquote>   <p>Exception while executing function: ServiceBusTriggeredProcessAccepted. Microsoft.Azure.WebJobs.Host: Error while handling parameter outboundStringForBlobStorage after function returned:. Microsoft.WindowsAzure.Storage: The remote server returned an error: (500) Internal Server Error.</p> </blockquote>  <p>The Azure Function is a Service Bus triggered event. After processing fails the Service Bus queued item auto-increments and retries  a total of 10 times  before it's moved to the dead-letter queue. It should be noted the objects are large enough in size that regular Queue's are too small for them.</p>  <pre><code>public class SomeObject {     //15 Properties all string and boolean     public string Attachment{ get; set;}     public string AnotherProperty{ get; set;}     public bool IsConditionMet { get; set; }     //Maybe these aren't needed now since it's blob storage but it's part of the object currently     public string PartitionKey { get; set; }     public string RowKey { get; set; } }  [FunctionName(\ServiceBusTriggeredProcessAccepted\"")] public static void Run([ServiceBusTrigger(\""accepted\"")]  SomeObject someObject   TraceWriter log   [Blob(\""accepted-attachments/{Attachment}\""  FileAccess.Read)] Byte[] blobContent    [Blob(\""accepted-sent/{rand-guid}.json\"")] out string outboundStringForBlobStorage   ) {     someObject.PartitionKey = \""email\"";     someObject.RowKey = Guid.NewGuid().ToString();     //Business Logic to execute here     SomeService.SomeFunctionToSendBlobFile(someObject  blobContent)        outboundStringForBlobStorage  = JsonConvert.SerializeObject(someObject); } </code></pre>  <p>I am using: Azure Functions SDK NuGet Package 1.0.21<br> Microsoft.Azure.Webjobs 2.2.0<br> WindowsAzure.ServiceBus 5.0.0<br> DotNetFramework 4.6.1<br> Windows Azure Storage Emulator 5.8.0.0<br> Runtime Version=1.0.11702.0  </p>  <p>Does the serialization have to be sanitized somehow? I haven't had to sanitize in the past but the data in that object has changed and that is when the problems started to occur. I would expect that the file to get written to the blob storage immediately or return the exception immediately and not 20 seconds after exiting the function.</p>""",azure-functions
18615673,"How to get more than 1000 entities from an azure table storage query? <p>I have read that azure table storage queries give maximum of 1000 entities and we have to make use of continuation tokens to fetch the next set of entities. I am just looking for an easy way to do that. All I want to do is fetch all the entities that the query should actually return and not just the 1000 entities. I have read @smarx post <a href=\http://blog.smarx.com/posts/windows-azure-tables-expect-continuation-tokens-seriously\"" rel=\""nofollow\"">here</a>  and he mentions about <code>ExecuteAll</code> method in <code>TableStorageDataServiceQuery</code> but this seems to have deprecated as I cant find <code>TableStorageDataServiceQuery</code> in the storage client library. </p>  <p>I also found this <a href=\""http://msdn.microsoft.com/en-us/library/windowsazure/dd135718.aspx\"" rel=\""nofollow\"">msdn</a> documentation on how to handle the continuation tokens to fetch all the entities. I just want to know if this is the best way to get all the entities  I dont need any pagination. Or is there any ExecuteAll esque method that I can use?</p>""",azure-storage
16949957,"Is there a way to attach the same disk to multiple Azure VMs <p>I have created a VHD for data and attached it to one Virtual Machine instance. Is there a way to attach that disk again to another VM? I basically want a shared drive for multiple VMs.</p>  <p>I see an \attach VHD\"" option in Server Manager for 2008 R2  but the only location I have to put in is my URL  and that is obviously wrong. When I try to attach the disk to another vm using the Attach Disk option in the management portal  it doesn't show this vhd in the list of available vhds. I know there are utilities in powershell which can do things  does anyone know if that would work?</p>""",azure-virtual-machine
22489113,"Is using a TableEntity with only the desired property equivalent to a projection query? <p>I have a series of <code>Report</code>s represented by a TableEntity. It has many different properties  but often  I only need the <code>ReportID</code> property.</p>  <pre><code>public class ReportEntity : TableEntity {     public ReportIDEntity()     {}      internal ReportIDEntity(Guid reportID  .../*other properties*/)     {         ReportID = reportID;         //assign other properties     }      public Guid ReportID { get; set; }      //other properties } </code></pre>  <p>I've written a projection query for this  so that I won't have to retrieve the entire entity just to get the ID:</p>  <pre><code>const String __ID_COLUMN = \ReportID\""; //yuck IEnumerable&lt;Guid&gt; ids = _cloudTable_.ExecuteQuery( new TableQuery&lt;DynamicTableEntity&gt;().Where(     TableQuery.GenerateFilterCondition(         \""PartitionKey\""  QueryComparisons.Equal  partitionKey))     .Select(new[] { __ID_COLUMN })      (key  rowKey  timestamp  properties  etag) =&gt; properties[__ID_COLUMN].GuidValue.Value); </code></pre>  <p>However  this is pretty ugly (I need to specify the property name as a string to retrieve it  and the code is long).</p>  <p>What if I make a TableEntity that only has the <code>ReportID</code> property  and query for that? <strong>Will this retrieve all of the data  or will it be as lean (bandwidth-wise) as the projection query?</strong></p>  <pre><code>public class ReportIDEntity : TableEntity {     public ReportIDEntity()     {}      internal ReportIDEntity(Guid reportID)     {         ReportID = reportID;     }      public Guid ReportID { get; set; } }  public class ReportEntity : ReportIDEntity {     public ReportEntity()     {}      internal ReportEntity(Guid reportID  .../*other properties*/)      : base(reportID)     {         //assign other properties     }     //other properties } </code></pre>  <p>And then the query would be:</p>  <pre><code>IEnumerable&lt;Guid&gt; reportEntities = _cloudTable_.ExecuteQuery( new TableQuery&lt;ReportIDEntity&gt;().Where(     TableQuery.GenerateFilterCondition(         \""PartitionKey\""  QueryComparisons.Equal  partitionKey))) .Select(e =&gt; e.ReportID); </code></pre>""",azure-storage
54976871,"Azure WebApp not accepting larger JSON payload <p>I have a ASP.NET Core 2.1 WebAPI project hosted in Azure as a Windows App Service in Premium Tier.</p>  <p>This API has an endpoint that accepts a POST request with a JSON payload (Content-Tye=application/json).</p>  <p>When I call this API(from Postman or from C# console app using HttpClient) and pass a JSON payload of 100KB then it gives error <strong>\an existing connection was forcibly closed by the remote host\""</strong>. But when I call this same API with a smaller JSON payload like 20KB then it succeeds.</p>  <p>So is there any settings to increase request length in Azure WebApp?</p>""",azure-web-app-service
10888361,"What tools can provide scheduled backups of Azure blob storage? <p>I'm looking for the best way to prevent accidental deletion by IT - perhaps copying to disk or a separate Azure Storage account or Amazon.  What tools can do this?  <a href=\https://cloudservices.red-gate.com/\"" rel=\""noreferrer\"">Redgate Cloud Services</a> seems like the closest fit for what I want but it seems to require config per container.  I know of some other tools like <a href=\""http://www.cerebrata.com/products/cloudstoragestudio/\"" rel=\""noreferrer\"">Cloud Storage Studio</a> and <a href=\""http://azurestoragesynctool.powerybase.com/\"" rel=\""noreferrer\"">Azure Sync Tool</a> exist but I don't think they support scheduled backups of blob storage.  </p>""",azure-storage
17239848,Migrating on premises application to Azure Cloud query <p>We are in the process of moving into Windows Azure blob storage several thousand Seadragon image-pyramids that are currently stored in our on-premises SQL Server database.  We use Microsoft’s Deep Zoom Composer library (deepzoomtools.dll) to initially create the image tiles.  But since Deep Zoom Composer (DZC) generates the tiles in a hierarchy of folders  we subsequently traverse the directories DZC creates in order to harvest the image tiles.</p>  <p>But now we are trying to figure out how we can publish our image-tile-pyramids directly into Azure blob storage.  We tried to decompile the DeepZoomTools DLL to see if we might redirect its file system calls to Azure blob storage.But this task proved rather difficult and in consequence we are looking for another approach.</p>  <p>So for time being we have a virtual machine in Azure to leverage DeepZoomTool.dll and publish to the virtual machine’s hard drive.  From the VM’s hard drive  we can then harvest the tiles using a Window Service and put the tiles into Azure blob storage.  But this approach necessitates that we manually maintain both the virtual machine and the widows service.  And it also has some other drawbacks as well.  So we’re looking for a better approach.If you guys have any other alternative method or can offer any helpful suggestions  we would certainly appreciate your insights!</p>,azure-virtual-machine
55996769,"ASP.NET MVC membership login works locally  not on azure app service <p>My ASP.NET MVC application is deployed on Azure app service and was working until today.  It won't let me login anymore through the application which uses ASPNET membership.  If I run the application in Visual Studio locally pointing to the production azure sql db it works.  The deployed app can read data fine but it seems when it tries to login it doesn't while deployed on azure.  I haven't changed any code so I don't know why it stopped working on azure when it was.  It still allows for reading of data  it displays items in a browse page.  I saw this error when I disabled custom errors:</p>  <pre><code>A network-related or instance-specific error occurred while  establishing a connection to SQL Server. The server was not found  or was not accessible. Verify that the instance name is correct and  that SQL Server is configured to allow remote connections. (provider:  SQL Network Interfaces  error: 26 - Error Locating Server/Instance  Specified) </code></pre>  <p>I've checked these questions but they didn't seem to make it work:</p>  <p><a href=\https://blogs.msdn.microsoft.com/sql_protocols/2007/05/13/sql-network-interfaces-error-26-error-locating-serverinstance-specified/\"" rel=\""nofollow noreferrer\"">Azure SQL firewall</a></p>  <p><a href=\""https://stackoverflow.com/questions/25667763/sql-network-interfaces-error-26-using-windows-azure\"">Network interface azure</a></p>  <p><a href=\""https://devblogs.microsoft.com/aspnet/hash-passwords-with-asp-net-membership-providers/\"" rel=\""nofollow noreferrer\"">Azure passwords</a></p>  <p><a href=\""http://geekswithblogs.net/redwards/archive/2009/09/23/135036.aspx\"" rel=\""nofollow noreferrer\"">Hashed passwords</a></p>  <p><a href=\""https://stackoverflow.com/questions/8415822/asp-net-membership-login-works-locally-fails-on-azure\"">login works locally not on azure</a></p>  <p><a href=\""https://stackoverflow.com/questions/34292280/why-my-mvc-5-asp-net-app-works-locally-but-not-when-deployed-to-azure\"">azure debugging</a></p>  <p><a href=\""https://stackoverflow.com/questions/36346545/asp-net-cant-login-register-successfully-works-locally-but-not-on-azure\"">login register locally not on azure</a></p>  <p><strong>UPDATE</strong> I used remote debugging and it's failing in a razor view when I check the roles using this line:</p>  <pre><code>if (User.IsInRole(\""Administrator\"")) { </code></pre>""",azure-web-app-service
46716593,"How to receive an email notification on builds generated by scheduled triggers in VSTS? <p>Following is the screenshot for my scheduled build triggers in VSTS: <a href=\https://i.stack.imgur.com/0VRrj.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/0VRrj.png\"" alt=\""enter image description here\""></a></p>  <p>I do get an email when I manually queue a build or push anything to the branch. I didn't receive an email after the scheduled build trigger. Is there a setting which I need to enable to receive the email about the status of the build?</p>""",azure-devops
55394898,"Getting Exception message in application insights <p>I have a C# azure function that is throwing an exception:</p>  <pre class=\lang-cs prettyprint-override\""><code>[FunctionName(\""Function1\"")]         public static async Task&lt;IActionResult&gt; Run(             [HttpTrigger(AuthorizationLevel.Function  \""get\""  \""post\""  Route = null)] HttpRequest req              ILogger log)         {             throw new Exception(\""Helpful message\"");         } </code></pre>  <p>The exception is catched by the runtime and re thrown. In application insight this is logged with the message <code>Exception while executing function: Function1</code> and the call stack. I am unable to find the \""Helpful message\"" anywhere.</p>  <p>In Application Insights I see this and non of the Properties has the \""Helpful message\"" text: <a href=\""https://i.stack.imgur.com/vC5sd.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/vC5sd.png\"" alt=\""Application Insights of the exception\""></a></p>  <p>The callstack shows the location of the error:</p>  <pre><code>Microsoft.Azure.WebJobs.Host.FunctionInvocationException:    at System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw (System.Private.CoreLib  Version=4.0.0.0  Culture=neutral  PublicKeyToken=7cec85d7bea7798e)    at Microsoft.Azure.WebJobs.Host.Executors.FunctionExecutor+&lt;ExecuteWithLoggingAsync&gt;d__19.MoveNext (Microsoft.Azure.WebJobs.Host  Version=3.0.6.0  Culture=neutral  PublicKeyToken=31bf3856ad364e35Microsoft.Azure.WebJobs.Host  Version=3.0.6.0  Culture=neutral  PublicKeyToken=31bf3856ad364e35: C:\\projects\\azure-webjobs-sdk-rqm4t\\src\\Microsoft.Azure.WebJobs.Host\\Executors\\FunctionExecutor.csMicrosoft.Azure.WebJobs.Host  Version=3.0.6.0  Culture=neutral  PublicKeyToken=31bf3856ad364e35: 321)    at System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw (System.Private.CoreLib  Version=4.0.0.0  Culture=neutral  PublicKeyToken=7cec85d7bea7798e)    at System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess (System.Private.CoreLib  Version=4.0.0.0  Culture=neutral  PublicKeyToken=7cec85d7bea7798e)    at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification (System.Private.CoreLib  Version=4.0.0.0  Culture=neutral  PublicKeyToken=7cec85d7bea7798e)    at System.Runtime.CompilerServices.TaskAwaiter`1.GetResult (System.Private.CoreLib  Version=4.0.0.0  Culture=neutral  PublicKeyToken=7cec85d7bea7798e)    at Microsoft.Azure.WebJobs.Host.Executors.FunctionExecutor+&lt;TryExecuteAsyncCore&gt;d__16.MoveNext (Microsoft.Azure.WebJobs.Host  Version=3.0.6.0  Culture=neutral  PublicKeyToken=31bf3856ad364e35Microsoft.Azure.WebJobs.Host  Version=3.0.6.0  Culture=neutral  PublicKeyToken=31bf3856ad364e35: C:\\projects\\azure-webjobs-sdk-rqm4t\\src\\Microsoft.Azure.WebJobs.Host\\Executors\\FunctionExecutor.csMicrosoft.Azure.WebJobs.Host  Version=3.0.6.0  Culture=neutral  PublicKeyToken=31bf3856ad364e35: 117) Inner exception System.Exception handled at System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw:    at FunctionApp1.Function1+&lt;Run&gt;d__0.MoveNext (FunctionApp1  Version=1.0.0.0  Culture=neutral  PublicKeyToken=nullFunctionApp1  Version=1.0.0.0  Culture=neutral  PublicKeyToken=null: C:\\Users\\sschoof\\Documents\\Visual Studio 2017\\Projects\\FunctionApp1\\FunctionApp1\\Function1.csFunctionApp1  Version=1.0.0.0  Culture=neutral  PublicKeyToken=null: 20)    at System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw (System.Private.CoreLib  Version=4.0.0.0  Culture=neutral  PublicKeyToken=7cec85d7bea7798e)    at System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess (System.Private.CoreLib  Version=4.0.0.0  Culture=neutral  PublicKeyToken=7cec85d7bea7798e)    at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification (System.Private.CoreLib  Version=4.0.0.0  Culture=neutral  PublicKeyToken=7cec85d7bea7798e)    at System.Runtime.CompilerServices.TaskAwaiter`1.GetResult (System.Private.CoreLib  Version=4.0.0.0  Culture=neutral  PublicKeyToken=7cec85d7bea7798e)    at Microsoft.Azure.WebJobs.Host.Executors.FunctionInvoker`2+&lt;InvokeAsync&gt;d__10.MoveNext (Microsoft.Azure.WebJobs.Host  Version=3.0.6.0  Culture=neutral  PublicKeyToken=31bf3856ad364e35Microsoft.Azure.WebJobs.Host  Version=3.0.6.0  Culture=neutral  PublicKeyToken=31bf3856ad364e35: C:\\projects\\azure-webjobs-sdk-rqm4t\\src\\Microsoft.Azure.WebJobs.Host\\Executors\\FunctionInvoker.csMicrosoft.Azure.WebJobs.Host  Version=3.0.6.0  Culture=neutral  PublicKeyToken=31bf3856ad364e35: 52)    at System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw (System.Private.CoreLib  Version=4.0.0.0  Culture=neutral  PublicKeyToken=7cec85d7bea7798e)    at System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess (System.Private.CoreLib  Version=4.0.0.0  Culture=neutral  PublicKeyToken=7cec85d7bea7798e)    at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification (System.Private.CoreLib  Version=4.0.0.0  Culture=neutral  PublicKeyToken=7cec85d7bea7798e)    at System.Runtime.CompilerServices.TaskAwaiter`1.GetResult (System.Private.CoreLib  Version=4.0.0.0  Culture=neutral  PublicKeyToken=7cec85d7bea7798e)    at Microsoft.Azure.WebJobs.Host.Executors.FunctionExecutor+&lt;InvokeAsync&gt;d__27.MoveNext (Microsoft.Azure.WebJobs.Host  Version=3.0.6.0  Culture=neutral  PublicKeyToken=31bf3856ad364e35Microsoft.Azure.WebJobs.Host  Version=3.0.6.0  Culture=neutral  PublicKeyToken=31bf3856ad364e35: C:\\projects\\azure-webjobs-sdk-rqm4t\\src\\Microsoft.Azure.WebJobs.Host\\Executors\\FunctionExecutor.csMicrosoft.Azure.WebJobs.Host  Version=3.0.6.0  Culture=neutral  PublicKeyToken=31bf3856ad364e35: 584)    at System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw (System.Private.CoreLib  Version=4.0.0.0  Culture=neutral  PublicKeyToken=7cec85d7bea7798e)    at System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess (System.Private.CoreLib  Version=4.0.0.0  Culture=neutral  PublicKeyToken=7cec85d7bea7798e)    at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification (System.Private.CoreLib  Version=4.0.0.0  Culture=neutral  PublicKeyToken=7cec85d7bea7798e)    at System.Runtime.CompilerServices.TaskAwaiter.GetResult (System.Private.CoreLib  Version=4.0.0.0  Culture=neutral  PublicKeyToken=7cec85d7bea7798e)    at Microsoft.Azure.WebJobs.Host.Executors.FunctionExecutor+&lt;ExecuteWithWatchersAsync&gt;d__26.MoveNext (Microsoft.Azure.WebJobs.Host  Version=3.0.6.0  Culture=neutral  PublicKeyToken=31bf3856ad364e35Microsoft.Azure.WebJobs.Host  Version=3.0.6.0  Culture=neutral  PublicKeyToken=31bf3856ad364e35: C:\\projects\\azure-webjobs-sdk-rqm4t\\src\\Microsoft.Azure.WebJobs.Host\\Executors\\FunctionExecutor.csMicrosoft.Azure.WebJobs.Host  Version=3.0.6.0  Culture=neutral  PublicKeyToken=31bf3856ad364e35: 531)    at System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw (System.Private.CoreLib  Version=4.0.0.0  Culture=neutral  PublicKeyToken=7cec85d7bea7798e)    at System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess (System.Private.CoreLib  Version=4.0.0.0  Culture=neutral  PublicKeyToken=7cec85d7bea7798e)    at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification (System.Private.CoreLib  Version=4.0.0.0  Culture=neutral  PublicKeyToken=7cec85d7bea7798e)    at System.Runtime.CompilerServices.TaskAwaiter.GetResult (System.Private.CoreLib  Version=4.0.0.0  Culture=neutral  PublicKeyToken=7cec85d7bea7798e)    at Microsoft.Azure.WebJobs.Host.Executors.FunctionExecutor+&lt;ExecuteWithLoggingAsync&gt;d__25.MoveNext (Microsoft.Azure.WebJobs.Host  Version=3.0.6.0  Culture=neutral  PublicKeyToken=31bf3856ad364e35Microsoft.Azure.WebJobs.Host  Version=3.0.6.0  Culture=neutral  PublicKeyToken=31bf3856ad364e35: C:\\projects\\azure-webjobs-sdk-rqm4t\\src\\Microsoft.Azure.WebJobs.Host\\Executors\\FunctionExecutor.csMicrosoft.Azure.WebJobs.Host  Version=3.0.6.0  Culture=neutral  PublicKeyToken=31bf3856ad364e35: 467)    at System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw (System.Private.CoreLib  Version=4.0.0.0  Culture=neutral  PublicKeyToken=7cec85d7bea7798e)    at System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess (System.Private.CoreLib  Version=4.0.0.0  Culture=neutral  PublicKeyToken=7cec85d7bea7798e)    at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification (System.Private.CoreLib  Version=4.0.0.0  Culture=neutral  PublicKeyToken=7cec85d7bea7798e)    at System.Runtime.CompilerServices.TaskAwaiter.GetResult (System.Private.CoreLib  Version=4.0.0.0  Culture=neutral  PublicKeyToken=7cec85d7bea7798e)    at Microsoft.Azure.WebJobs.Host.Executors.FunctionExecutor+&lt;ExecuteWithLoggingAsync&gt;d__19.MoveNext (Microsoft.Azure.WebJobs.Host  Version=3.0.6.0  Culture=neutral  PublicKeyToken=31bf3856ad364e35Microsoft.Azure.WebJobs.Host  Version=3.0.6.0  Culture=neutral  PublicKeyToken=31bf3856ad364e35: C:\\projects\\azure-webjobs-sdk-rqm4t\\src\\Microsoft.Azure.WebJobs.Host\\Executors\\FunctionExecutor.csMicrosoft.Azure.WebJobs.Host  Version=3.0.6.0  Culture=neutral  PublicKeyToken=31bf3856ad364e35: 277)  </code></pre>  <p>My current workaround is:</p>  <pre class=\""lang-cs prettyprint-override\""><code>[FunctionName(\""Function1\"")]         public static async Task&lt;IActionResult&gt; Run(             [HttpTrigger(AuthorizationLevel.Function  \""get\""  \""post\""  Route = null)] HttpRequest req              ILogger log)         {             try             {                 throw new Exception(\""Helpful message\"");             }             catch (Exception e)             {                 log.LogError(e  e.Message);                 throw e;             }         } </code></pre>  <p>Is there an better way to get the \""Helpful message\"" than adding this to every function?</p>""",azure-functions
53205669,Azure VM RHEL Custom Script Extension: script.sh not found error <p>I've been trying to deploy a custom script extension to a RHEL VM in Azure. The script just contains 'mkdir testfolder'. And 'command to execute' is 'sh script.sh'. I keep getting an error 'script.sh can not be found'.</p>  <p>How do I properly execute custom script Extension in RHEL Azure VM?</p>  <p>On the menu blade of a RHEL azure vm  selected extensions  then chose custom script extensions from the list of extensions  then uploaded the shell script file(script.sh)  and in command to execute: sh script.sh</p>,azure-virtual-machine
47982383,How can I compare .dsql (Azure SQL DW and PDW) files in Visual Studio 2015? <p>If I invoke the file diff tool in Visual Studio 2015 on a text file with extension .dsql (Azure SQL DW and PDW SQL script) I get the error: </p>  <blockquote>   <p>Error occurred during difference operation: Cannot execute the configured tool</p> </blockquote>  <p>Diff works as expected for other text file extensions.</p>  <p>Visual Studio Professional 14.0.25431.01 Update 3 using VSTS source control.</p>,azure-devops
54300455,"ValueError: \hostingstart.app\"" could not be imported <p>Trying to create azure python web app for flask python  but getting the following error </p>  <pre><code>Error occurred while reading WSGI handler:  Traceback (most recent call last):   File \""D:\\Python34\\Scripts\\wfastcgi.py\""  line 711  in main     env  handler = read_wsgi_handler(response.physical_path)   File \""D:\\Python34\\Scripts\\wfastcgi.py\""  line 568  in read_wsgi_handler     return env  get_wsgi_handler(handler_name)   File \""D:\\Python34\\Scripts\\wfastcgi.py\""  line 551  in get_wsgi_handler     raise ValueError('\""%s\"" could not be imported' % handler_name) ValueError: \""hostingstart.app\"" could not be imported </code></pre>  <p>StdOut: </p>  <p>StdErr: </p>  <p>I tried to upgrade wfastcgi  after that i have changed to script location to new wfastcgi  it was throwing scripts handlers  scriptProcessor could not be found in  error</p>  <p>Folder structure:</p>  <pre><code>WWWroot  - hostingstart.py  - view.py  - web.config </code></pre>  <p>hostingstart.py</p>  <pre><code>from flask import Flask app = Flask(__name__)  import view wsgi_app = app.wsgi_app </code></pre>  <p>Web.Config</p>  <pre><code>&lt;configuration&gt;   &lt;appSettings&gt;     &lt;add key=\""PYTHONPATH\"" value=\""D:\\home\\site\\wwwroot\""/&gt;     &lt;add key=\""WSGI_HANDLER\"" value=\""hostingstart.app\""/&gt;     &lt;add key=\""WSGI_LOG\"" value=\""D:\\home\\LogFiles\\wfastcgi.log\""/&gt;   &lt;/appSettings&gt;   &lt;system.webServer&gt;      &lt;httpErrors errorMode=\""Detailed\""&gt;&lt;/httpErrors&gt;      &lt;handlers&gt;       &lt;add name=\""PythonHandler\"" path=\""*\"" verb=\""*\"" modules=\""FastCgiModule\""                scriptProcessor=\""D:\\Python34\\python.exe|D:\\Python34\\Scripts\\wfastcgi.py\""           resourceType=\""Unspecified\"" requireAccess=\""Script\"" /&gt;     &lt;/handlers&gt;   &lt;/system.webServer&gt; &lt;/configuration&gt; </code></pre>""",azure-web-app-service
17965779,"Azure: List OS Images <p>Im new to windows azure  Ive looked to this <a href=\http://msdn.microsoft.com/en-us/library/windowsazure/jj157191.aspx\"" rel=\""nofollow\"">documentation</a>  to me it works  Listing Images on gallery. <a href=\""https://management.core.windows.net/subscription-id/services/images\"" rel=\""nofollow\"">https://management.core.windows.net/subscription-id/services/images</a></p>  <p>But this isnt what Im looking for  Is there a way to list the My Images on my account and not the images on gallery.</p>""",azure-virtual-machine
55344396,"Buffer too many uploads? <p>I am trying to upload a large video file. I am using Azure Storage blob. Reading documentation there is warning about using IFormFile at <a href=\https://docs.microsoft.com/en-us/aspnet/core/mvc/models/file-uploads?view=aspnetcore-2.1\"" rel=\""nofollow noreferrer\"">https://docs.microsoft.com/en-us/aspnet/core/mvc/models/file-uploads?view=aspnetcore-2.1</a> It suggests that I stream my data. Is the follow code creating a buffer there will crash my server   or streaming directly to the storage?</p>  <p><strong>From the View</strong></p>  <pre><code> &lt;form asp-action=\""Create\"" enctype=\""multipart/form-data\""&gt;             &lt;div asp-validation-summary=\""ModelOnly\"" class=\""text-danger\""&gt;&lt;/div&gt;             &lt;div class=\""form-group\""&gt;                 &lt;label asp-for=\""Name\"" class=\""control-label\""&gt;&lt;/label&gt;                 &lt;input asp-for=\""Name\"" class=\""form-control\"" /&gt;                 &lt;span asp-validation-for=\""Name\"" class=\""text-danger\""&gt;&lt;/span&gt;             &lt;/div&gt;             &lt;div class=\""form-group\""&gt;                 &lt;label asp-for=\""Description\"" class=\""control-label\""&gt;&lt;/label&gt;                 &lt;input asp-for=\""Description\"" class=\""form-control\"" /&gt;                 &lt;span asp-validation-for=\""Description\"" class=\""text-danger\""&gt;&lt;/span&gt;             &lt;/div&gt;             &lt;div class=\""form-group\""&gt;                                 &lt;input asp-for=\""VideoAsFile\"" class=\""form-control\"" /&gt;                 &lt;span asp-validation-for=\""VideoAsFile\"" class=\""text-danger\""&gt;&lt;/span&gt;             &lt;/div&gt;             &lt;div class=\""form-group\""&gt;                 &lt;input type=\""submit\"" value=\""Create\"" class=\""btn btn-default\"" /&gt;             &lt;/div&gt;         &lt;/form&gt; </code></pre>  <p><strong>From the controller</strong></p>  <pre><code> public async Task&lt;IActionResult&gt; Create([Bind(\"" Name Description VideoAsFile\"")] VideoWithFileViewModel video)         {             if (ModelState.IsValid)             {                 string imageId;                 using (var stream = video.VideoAsFile.OpenReadStream())                 {                     imageId = videoServices.SaveVideo(stream);                  }                 var newVideo = new Video()                 {                     Name = video.Name                      Description = video.Description                      URL = imageId                  };                 repository.AddVideo(newVideo  User);                 repository.SaveAll();                 return RedirectToAction(nameof(Index));             } </code></pre>  <p><strong>From the VideoServices</strong></p>  <pre><code>public string SaveVideo(Stream videoStream)         {            CloudBlobClient blobClient=new CloudBlobClient(new Uri(baseUri)  credentials);             var imageId = Guid.NewGuid().ToString();             var container = blobClient.GetContainerReference(\""videos\"");             var blob = container.GetBlockBlobReference(imageId);             blob.UploadFromStreamAsync(videoStream);             return imageId;         } </code></pre>""",azure-storage
16305734,Rails server (command) not persisting once SSH connection is closed <p>I'm using a <strong>Windows Azure VM</strong> with Ubuntu to host my website in Rails.</p>  <p>Here's my <strong>problem</strong>: I open an SSH connection through PuTTY to start the server through the command</p>  <pre><code>me@example: ~/Sites/mysite$ rails server </code></pre>  <p>I can then view my website and everything is fine. However  when I close the SSH connection the server stops and my website goes down. How can I tell the VM (I suppose without an SSH connection?) that I want this command run persistently?</p>  <p>Thanks for reading  -Adam</p>  <p><em>tl;dr</em> - After closing the SSH connection to my Azure VM the rails server command stops.</p>,azure-virtual-machine
50404627,"Azure Functions SendGrid out binding does not show in SendGrid as a message <p>I am trying to use Azure Functions to send an email message through SendGrid. I have a function that has a storage queue trigger and an SendGrid output parameter. After adding a message in the queue the function runs but nothing else happens. When I login to Sendgrid it shows I have zero requests and delivered messages. Also I am not receiving any emails.</p>  <p>What could possibly be causing this? Is there any way to debug this further?</p>  <p>Here is my function code in C#:</p>  <pre><code>public static class SendChatEmail {     [FunctionName (\SendChatEmail\"")]     public static void Run ([QueueTrigger (\""decision-tree-emails\""  Connection = \""AzureWebJobsStorage\"")] ChatData myQueueItem  [SendGrid (ApiKey = \""SendGridApiKey\"")] out SendGridMessage message          TraceWriter log) {         log.Info ($\""C# Queue trigger function processed: {myQueueItem}\"");          message = new SendGridMessage ();         message.AddTo (\""matti.petrelius@gmail.com\"");         message.AddContent (\""text/html\""  \""Hello there!\"");         message.SetFrom (new EmailAddress (\""matti.petrelius@gmail.com\""));         message.SetSubject (\""Chat conversation\"");     } } </code></pre>  <p>I'm using:</p>  <pre><code>Azure Functions Core Tools (220.0.0-beta.0) Function Runtime Version: 2.0.11651.0 Microsoft Visual Studio Enterprise 2017 Version 15.7.1 Azure Functions and Web Jobs Tools - 15.0.40502.0 </code></pre>  <p>I've also tried to make a similar Function in Node.js without getting it to work any better. Maybe I'm using SendGrid somehow wrong?</p>""",azure-functions
55580599,Azure-DevOps permission to view history without access to code <p>Is it possible to provide a user with permissions to view the history of a project without giving that user access to the code?</p>,azure-devops
55789672,"Is NReco pdf generator supported in Azure? <p>I have created a C# Azure function for pdf generation and am using the NReco pdf generator  but it is not working on Aazure.</p>  <p>Could you please suggest a method to make it run in azure?</p>  <p>I have installed NReco Pdf generator through NuGet Package Manager Console and I am getting the following error:</p>  <blockquote>   <p>\Access to the path 'D:\\Program Files (x86)\\SiteExtensions\\Functions\\1.0.12599\\wkhtmltopdf' is denied.</p> </blockquote>  <p>This is the stacktrace of exception that is thrown: </p>  <pre><code>at System.IO.__Error.WinIOError(Int32 errorCode  String maybeFullPath) at System.IO.Directory.InternalCreateDirectory(String fullPath  String path  Object dirSecurityObj  Boolean checkHost) at System.IO.Directory.InternalCreateDirectoryHelper(String path  Boolean checkHost) at System.IO.Directory.CreateDirectory(String path) at NReco.PdfGenerator.HtmlToPdfConverter.EnsureWkHtmlLibs() at NReco.PdfGenerator.HtmlToPdfConverter.GeneratePdfInternal(WkHtmlInput[] htmlFiles  String inputContent  String coverHtml  String outputPdfFilePath  Stream outputStream) at NReco.PdfGenerator.HtmlToPdfConverter.GeneratePdfFromFile(String htmlFilePath  String coverHtml) at VRProductions.Repository.PdfGenerationRepository.&lt;SendMail&gt;d__1.MoveNext() </code></pre>  <p>This is the code am using for pdf generation:</p>  <pre><code>var htmlToPdf = new NReco.PdfGenerator.HtmlToPdfConverter(); var pdfBytes = htmlToPdf.GeneratePdfFromFile(blockBlob.Uri.AbsoluteUri  \""\""); </code></pre>""",azure-functions
55838538,How do I get the build number into the name of the build pipeline artifact in Azure DevOps? <p>I am building a .NET application in Azure DevOps  setting its version using GitVersion through Cake script  and then build it. It appears to get the Build number from this value created in GitVersion. I want the informational build number to populate part of my name. I am using the designer but for ease of use  here is the YAML file of the publish artifact step:</p>  <pre><code>#Your build pipeline references the ‘deployment.PPILDeployDirectory’ variable  which you’ve selected to be settable at queue time. Create or edit the build pipeline for this YAML file  define the variable on the Variables tab  and then select the option to make it settable at queue time. See https://go.microsoft.com/fwlink/?linkid=865971 #Your build pipeline references the ‘deployment.integration.environment’ variable  which you’ve selected to be settable at queue time. Create or edit the build pipeline for this YAML file  define the variable on the Variables tab  and then select the option to make it settable at queue time. See https://go.microsoft.com/fwlink/?linkid=865971  steps: - task: PublishBuildArtifacts@1   displayName: 'Publish Integration Artifact copy'   inputs:     PathtoPublish: '$(deployment.PPILDeployDirectory)'     ArtifactName: '$(deployment.integration.environment)_integration_drop' </code></pre>  <p>How do I suffix my ArtifactName with the informational build number (which includes the branch and build information)? What is the variable I need to grab? Are there any other variables related to build numbers that I should be aware of?</p>,azure-devops
32194071,"How to change the default endpoint of an azure vm? <p>I have create a new linux virtual machine on azure abcxyz.cloudapp.net. I have a webapp running on non standard port 12320. When a user goes to <a href=\http://abcxyz.coudapp.net\"" rel=\""nofollow\"">http://abcxyz.coudapp.net</a>  how can I point it to <a href=\""http://abcxyz.cloudapp.net:12320\"" rel=\""nofollow\"">http://abcxyz.cloudapp.net:12320</a>?</p>""",azure-virtual-machine
15809007,"Connect to visualstudio.com from Team Explorer Everywhere CLC <p>I'm trying to connect from Team Explorer Everywhere command line client on Windows to a Team Foundation Service project at visualstudio.com  but I get \access denied\"" messages. </p>  <p>The username and password I'm passing are definitely correct  and are the email and password from my microsoft live ID used to create the account. I have no problems accessing the service through the website  or via Visual Studio 2012 on a different machine.</p>  <pre><code>tf workspace /new /server:https://&lt;something&gt;.visualstudio.com/defaultcollection Username: example@microsoft.com Password: ******** </code></pre>  <p>Any ideas? One thought I had was that maybe the '@' character in the e-mail was causing the username to be interpreted as a Windows domain  or that maybe SSL wasn't being used correctly?</p>""",azure-devops
40710533,"Cannot migrate Azure VMs from Classic to ARM: RoleStateUnknown <p>I have successfully used this recipe in the past to migrate a virtual network including attached VMs: <a href=\https://docs.microsoft.com/en-us/azure/virtual-machines/virtual-machines-linux-cli-migration-classic-resource-manager\"" rel=\""nofollow noreferrer\"">https://docs.microsoft.com/en-us/azure/virtual-machines/virtual-machines-linux-cli-migration-classic-resource-manager</a></p>  <p>But today  and also when I tried last week  no matter the number of reboots  I get this error (Azure CLI):</p>  <pre><code>&gt; azure network vnet prepare-migration \""&lt;RG-NAME&gt;\"" info:    Executing command network vnet prepare-migration error:   BadRequest : Migration is not allowed for HostedService  &lt;CLOUD-SERVICE&gt; because it has VM &lt;VM-NAME&gt; in State : RoleStateUnknown. Migration is allowed only when the VM is in one of the  following states - Running  Stopped  Stopped Deallocated. </code></pre>  <p>The VM is in fact running smoothly  and so says the Azure portal. So any ideas how to get out of this mess?</p>""",azure-virtual-machine
4068635,Using lookup tables with Azure Table Storage- worth creating a worker service just to manage this? <p>I'm looking into doing some development for the Azure platform. I don't need the full Relational stuff that you get from SQL Azure and I would be quite interested to use Table Storage instead.</p>  <p>Now the one Relational thing I do need to be able to do is represent one-to-many and many-to-many relationships between tables in my storage.</p>  <p>I'm quite happy with how to use intermediate tables with partition and row keys to represent this  in much the way that regular databases represent them internally. </p>  <p>What I'm wondering is whether it is worth creating a worker service just to intermediate between the storage and anything that accesses it  in order to create a front end that could supervise the limited degree of referential integrity I'm looking for. </p>  <p>I could do this as part of the client easily enough  but I'm wondering whether having the service hosted in the cloud would mean lower network latency given that any query that goes across these references would be likely to need to talk to three different tables and presumably these requests should be a lot faster between a service and storage posted in the cloud  so there would only be one request from outside the cloud rather than several.</p>  <p>If this is a useful strategy  is there an existing tool to do it? If not what would work better or is there just no perceptible benefit? Should I just suck it down and go for SQL For Azure or some kind of heterogenous solution where I store my big data in Table Storage and my lookups and table references in SQL?</p>,azure-storage
31932909,Azure GUI for secondary storage <p>I am using Microsoft Azure as my Cloud Support. I found quite a few documents advertising or explaining how to enable geo-redundant (or geo-replicated) MS Azure storage accounts.I have enable to geo-redundant fetaure in the AZURE. I want to know the blobs which are saved in the secondary storage  Is there any GUI for the same? How do I ensure that my data redundancy is happening properly.  Thanks in advance</p>,azure-storage
48171078,TLS notificationmail - where to check version and change it? <p>I received a mail about TLS requirements for the webapps yesterday. Just wanted to check which for which apps the TLS version will be changed  but I cannot find it anywhere in the portal.</p>  <p>Is there an easy way to check this in the Azure Portal? Or are there any other ways to check.</p>  <p>This was some text in the mail: •   By April 30  2018:  o   Through the Azure portal and Azure Resource Manager templates  you’ll be able to select the minimum-required TLS version (1.1 or 1.2) for your app. o   We’ll configure App Service apps to require only newer TLS versions (1.1 and 1.2)—two months before the required date. •   After June 30  2018  all newly created App Service apps will be automatically configured to require TLS 1.2. You’ll still retain the option to configure earlier TLS versions for your apps  if necessary  for compatibility with older browser clients. </p>  <p>Thanks!</p>,azure-web-app-service
48288398,"In Visual Studio Online  when I add a new State  can I also add the new state's specific \Changed Date\"" as a column in queries? <p>When I view the Backlog in Visual Studio  I can add a Column  and there are Date-related columns like \""Closed Date\"" and \""Resolved Date\"" related to States Closed and Resolved. If I add my own States (which I have)  can I also get Date columns for when a ticket exited those states?</p>  <p>Because I want to show a Query that includes the date of all of those states (to easily track when each ticket exited those states.</p>  <p>So if I add a State called \""Spec Approved\""  then I also want a \""Spec Approved Date\"" column added. Is this possible?</p>""",azure-devops
57306448,"Azure Functions with java - How to get the logs written within the function? <p>I've deployed a queue triggered azure function with Java in Azure. I've added <code>logback-classic</code> and <code>lombok</code> in <code>pom.xml</code> for logging. But the logs are not displayed on the function's <code>monitor &gt; invocation details</code> or the <code>log-streaming service</code> in portal. But I could see the logs written with <code>context.getLogger()</code>. The logs writter with logback logger is not visible. Please let me know how to check my logs in function invocation.</p>  <p>Following is the queue triggerred azure function handle</p>  <pre><code>public class QueueHandlerFunction {    @FunctionName(\queuetriggertest\"")   public void queueMessageHandler(@QueueTrigger(name = \""msg\""        queueName = \""my-test-queue\""  connection = \""MyQStorage\"") final String payload        final ExecutionContext context) {      //Logs with this logger is visible     context.getLogger().info(\""Received Message From my-test-queue : \"" + payload);      MySampleService.handleQueueMessage(payload);   } } </code></pre>  <p>Following is the <code>MySampleService</code> class with lombok logger</p>  <pre><code>@Slf4j public class MySampleService {    public static void handleQueueMessage(final String payload) {      log.info(\""&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt; INSIDE THE SERVICE HANDLE &gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;\"");     if (StringUtils.isNotBlank(payload)) {         log.info(\""Received Payload : {}\""  payload); //This log not available         // TODO Work with incoming payload     } else {       log.info(\""Message payload is Blank.\""); //This log not available     }   }  } </code></pre>  <p>Following is he <code>logback.xml</code> placed in the resources folder of the maven project.</p>  <pre><code>&lt;?xml version=\""1.0\"" encoding=\""UTF-8\""?&gt; &lt;!DOCTYPE xml&gt; &lt;configuration&gt;    &lt;appender name=\""STDOUT\"" class=\""ch.qos.logback.core.ConsoleAppender\""&gt;       &lt;encoder&gt;          &lt;pattern&gt;%d{E MMM dd yyyy hh:mm:ss a} [%thread] %-5level %logger{36}                 - %msg%n&lt;/pattern&gt;       &lt;/encoder&gt;    &lt;/appender&gt;     &lt;logger name=\""com.isl.test\"" level=\""INFO\"" /&gt;    &lt;root level=\""INFO\""&gt;       &lt;appender-ref ref=\""STDOUT\"" /&gt;    &lt;/root&gt; &lt;/configuration&gt; </code></pre>  <p>And I've the following dependencies in the <code>pom.xml</code></p>  <pre><code>&lt;dependencies&gt;         &lt;dependency&gt;             &lt;groupId&gt;com.microsoft.azure.functions&lt;/groupId&gt;             &lt;artifactId&gt;azure-functions-java-library&lt;/artifactId&gt;             &lt;version&gt;1.3.0&lt;/version&gt;         &lt;/dependency&gt;         &lt;dependency&gt;             &lt;groupId&gt;org.apache.commons&lt;/groupId&gt;             &lt;artifactId&gt;commons-lang3&lt;/artifactId&gt;             &lt;version&gt;3.7&lt;/version&gt;         &lt;/dependency&gt;         &lt;dependency&gt;             &lt;groupId&gt;ch.qos.logback&lt;/groupId&gt;             &lt;artifactId&gt;logback-classic&lt;/artifactId&gt;             &lt;version&gt;1.2.3&lt;/version&gt;         &lt;/dependency&gt;         &lt;dependency&gt;             &lt;groupId&gt;org.projectlombok&lt;/groupId&gt;             &lt;artifactId&gt;lombok&lt;/artifactId&gt;             &lt;version&gt;1.16.20&lt;/version&gt;         &lt;/dependency&gt;     &lt;/dependencies&gt; </code></pre>  <p><strong>EDIT</strong>: Attached portal screenshot for the function invocation logs...</p>  <p><a href=\""https://i.stack.imgur.com/rHLTl.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/rHLTl.png\"" alt=\""Attached portal screenshot for the function invocation logs\""></a></p>  <p><strong>EDIT 2</strong>: Added screenshots of local execution and deployed one in portal.</p>  <ul> <li><p>Logs in command prompt when is executed locally <a href=\""https://i.stack.imgur.com/pfp6Y.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/pfp6Y.png\"" alt=\""Command prompt when executed the function locally\""></a></p></li> <li><p>Live streaming console service of the function from the portal for a new message in queue <a href=\""https://i.stack.imgur.com/vZM20.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/vZM20.png\"" alt=\""Portal Console with live streaming\""></a></p></li> <li>Invocation details of the function from the portal for a new message in queue <a href=\""https://i.stack.imgur.com/9HZyZ.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/9HZyZ.png\"" alt=\""Portal Invocation details\""></a></li> </ul>""",azure-functions
42285150,How do you have shared extension methods in Azure Functions without nesting classes? <p>I know how to include other <code>.csx</code> files via <code>#load</code>.  However  extension methods have to be defined in a top-level class  and <code>#load</code> nests the class  so it's not top-level and the function throws a compilation error.</p>  <p>How do I use shared code without having it nest inside the function's post-compiled class?</p>,azure-functions
42763173,"Where does Azure Functions store the connection string to my External Table binding? <p>I'm playing around with <a href=\https://azure.microsoft.com/en-us/services/functions/\"" rel=\""nofollow noreferrer\"">Azure Functions</a>' experimental External Table binding feature (binding type: \""apiHubTable\""). In my case I'm trying to output some data into a SQL Server table.</p>  <p>When I setup the output binding I create a new \""External Connection\"" which is basically my SQL Server connections string:</p>  <p><a href=\""https://azure.microsoft.com/en-us/services/functions/\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/QiGk9.png\"" alt=\""enter image description here\""></a></p>  <p>I can give that connection a \""Display Name\"" but when I'm done creating it  I find that the bindings 's \""External Table connection\"" is pointing to something called \""sql_SQL\"".</p>  <p><a href=\""https://i.stack.imgur.com/QiGk9.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/ba4tt.png\"" alt=\""enter image description here\""></a></p>  <p>Turns out that \""sql_SQL\"" is defined in the Function App's \""App settings\"" as a URL that looks like:</p>  <blockquote>   <p>Endpoint=<a href=\""https://logic-apis-westeurope.azure-apim.net/apim/sql/#REDACTED#/;Scheme=Key;AccessToken=#REDACTED#\"" rel=\""nofollow noreferrer\"">https://logic-apis-westeurope.azure-apim.net/apim/sql/#REDACTED#/;Scheme=Key;AccessToken=#REDACTED#</a></p> </blockquote>  <p>What is this sort of endpoint URL? Where does \""<a href=\""https://logic-apis-westeurope.azure-apim.net\"" rel=\""nofollow noreferrer\"">https://logic-apis-westeurope.azure-apim.net</a>\"" come from? And most importantly - How can I edit / review my connection once it's been saved and linked to this way?</p>""",azure-functions
53807687,How do I programmatically assign a User assigned managed identity to an Azure Web App Staging Slot? <p>I can assign the user assigned managed identity manually in the portal.</p>  <p>How do I do it during deployment to a staging slot as part of a deployment pipeline?</p>  <p>I can use PowerShell to set a system assigned managed identity via <code>Set-AzureRMWebAppSlot</code>however I cannot find a way to do it for User Assigned.</p>,azure-web-app-service
51186417,"FileTrigger binding not parsing <p>I have a file trigger pointing to a path to monitor files and I have set an appSetting value to use as a binding expressions:</p>  <pre><code>[FileTrigger(@\%KEY_NAME%\""  \""*\""  WatcherChangeTypes.Created  autoDelete: true)] string message  </code></pre>  <p>I have an appSetting value to match it:</p>  <pre><code>&lt;add key=\""KEY_NAME\"" value=\""KEY_VALUE\""/&gt; </code></pre>  <p>I have set the following:</p>  <pre><code>    var filesConfig = new FilesConfiguration(); #if DEBUG             filesConfig.RootPath = @\""C:\\Temp\\data\\\""; #endif             config.UseFiles(filesConfig); </code></pre>  <p>so that I can hit a local folder. The directory does exist and is spelt the same and if I use the value directly it works. When I run the WebJob like this I get the following error:</p>  <pre><code>    InvalidOperationException : Path 'C:\\Temp\\data\\%KEY_VALUE%' does not exist. </code></pre>  <p>It appears that the concatenating of the RootPath prevents the parsing of the binding expression. What I would actually like to do is something like:</p>  <pre><code>@\""%VALUE_ONE%\\%VALUE_TWO%\\{name}\"" </code></pre>  <p>so that I can make it work through our environments. Any advice available out there?</p>""",azure-storage
49603685,"Unable to get the PublishAssetURL in azure media Service <p>I am trying to upload the mp4 file from Controller into azure blob storage right after when i done uploading  i am creating asset from the same blob which i just uploaded every thing seems working fine but i don't know some how i am unable to get the publishAssetURL </p>  <p><code>var manifestFile = asset.AssetFiles.Where(x =&gt;                   x.Name.EndsWith(\.ism\"")).FirstOrDefault();</code></p>  <p>This issue is on this line the <code>manifestFile</code> is coming null.</p>  <pre><code>    public string CreateAssetFromExistingBlobs(CloudBlobContainer sourceBlobContainer  CloudStorageAccount _destinationStorageAccount  CloudMediaContext _context  AzureStorageMultipartFormDataStreamProvider provider )     {         CloudBlobClient destBlobStorage = _destinationStorageAccount.CreateCloudBlobClient();          // Create a new asset.          IAsset asset = _context.Assets.Create(\""NewAsset_\"" + Guid.NewGuid()  AssetCreationOptions.None);          IAccessPolicy writePolicy = _context.AccessPolicies.Create(\""writePolicy\""              TimeSpan.FromHours(24)  AccessPermissions.Write);          ILocator destinationLocator =             _context.Locators.CreateLocator(LocatorType.Sas  asset  writePolicy);          // Get the asset container URI and Blob copy from mediaContainer to assetContainer.          CloudBlobContainer destAssetContainer =             destBlobStorage.GetContainerReference((new Uri(destinationLocator.Path)).Segments[1]);          if (destAssetContainer.CreateIfNotExists())         {             destAssetContainer.SetPermissions(new BlobContainerPermissions             {                 PublicAccess = BlobContainerPublicAccessType.Blob             });         }          var blob = sourceBlobContainer.GetBlockBlobReference(provider.FileData.FirstOrDefault().LocalFileName);         blob.FetchAttributes();          var assetFile = asset.AssetFiles.Create(blob.Name);         CopyBlob(blob  destAssetContainer);         assetFile.ContentFileSize = blob.Properties.Length;         assetFile.Update();         asset.Update();          destinationLocator.Delete();         writePolicy.Delete();          // Set the primary asset file.         // If  for example  we copied a set of Smooth Streaming files           // set the .ism file to be the primary file.          // If we  for example  copied an .mp4  then the mp4 would be the primary file.          var ismAssetFile = asset.AssetFiles.ToList().             Where(f =&gt; f.Name.EndsWith(\"".mp4\""  StringComparison.OrdinalIgnoreCase)).ToArray().FirstOrDefault();          // The following code assigns the first .ism file as the primary file in the asset.         // An asset should have one .ism file.           if (ismAssetFile != null)         {             ismAssetFile.IsPrimary = true;             ismAssetFile.Update();         }          IAsset encodedAsset = EncodeToAdaptiveBitrateMP4Set(asset  _context);         return PublishAssetGetURLs(encodedAsset  _context);       }      private void CopyBlob(ICloudBlob sourceBlob  CloudBlobContainer destinationContainer)     {         var signature = sourceBlob.GetSharedAccessSignature(new SharedAccessBlobPolicy         {             Permissions = SharedAccessBlobPermissions.Read              SharedAccessExpiryTime = DateTime.UtcNow.AddHours(24)         });          var destinationBlob = destinationContainer.GetBlockBlobReference(sourceBlob.Name);          if (destinationBlob.Exists())         {             Console.WriteLine(string.Format(\""Destination blob '{0}' already exists. Skipping.\""  destinationBlob.Uri));         }         else         {              // Display the size of the source blob.             Console.WriteLine(sourceBlob.Properties.Length);              Console.WriteLine(string.Format(\""Copy blob '{0}' to '{1}'\""  sourceBlob.Uri  destinationBlob.Uri));             destinationBlob.StartCopy(new Uri(sourceBlob.Uri.AbsoluteUri + signature));              while (true)             {                 // The StartCopyFromBlob is an async operation                   // so we want to check if the copy operation is completed before proceeding.                  // To do that  we call FetchAttributes on the blob and check the CopyStatus.                  destinationBlob.FetchAttributes();                 if (destinationBlob.CopyState.Status != CopyStatus.Pending)                 {                     break;                 }                 //It's still not completed. So wait for some time.                 System.Threading.Thread.Sleep(1000);             }              // Display the size of the destination blob.             Console.WriteLine(destinationBlob.Properties.Length);          }     }      private IAsset EncodeToAdaptiveBitrateMP4Set(IAsset asset  CloudMediaContext _context)     {         // Declare a new job.         IJob job = _context.Jobs.Create(\""Media Encoder Standard Job\"");         // Get a media processor reference  and pass to it the name of the          // processor to use for the specific task.         IMediaProcessor processor = GetLatestMediaProcessorByName(\""Media Encoder Standard\"" _context);          // Create a task with the encoding details  using a string preset.         // In this case \""Adaptive Streaming\"" preset is used.         ITask task = job.Tasks.AddNew(\""My encoding task\""              processor              \""Adaptive Streaming\""              TaskOptions.None);          // Specify the input asset to be encoded.         task.InputAssets.Add(asset);         // Add an output asset to contain the results of the job.          // This output is specified as AssetCreationOptions.None  which          // means the output asset is not encrypted.          task.OutputAssets.AddNew(\""Output asset\""              AssetCreationOptions.None);          job.StateChanged += new EventHandler&lt;JobStateChangedEventArgs&gt;(JobStateChanged);         job.Submit();         job.GetExecutionProgressTask(CancellationToken.None).Wait();          return job.OutputMediaAssets[0];     }       public void JobStateChanged(object sender  JobStateChangedEventArgs e)     {         //Console.WriteLine(\""Job state changed event:\"");         //Console.WriteLine(\""  Previous state: \"" + e.PreviousState);         //Console.WriteLine(\""  Current state: \"" + e.CurrentState);         switch (e.CurrentState)         {             case JobState.Finished:                 //Console.WriteLine();                 //Console.WriteLine(\""Job is finished. Please wait while local tasks or downloads complete...\"");                 break;             case JobState.Canceling:             case JobState.Queued:             case JobState.Scheduled:             case JobState.Processing:                 //Console.WriteLine(\""Please wait...\\n\"");                 break;             case JobState.Canceled:             case JobState.Error:                  // Cast sender as a job.                 IJob job = (IJob)sender;                  // Display or log error details as needed.                 break;             default:                 break;         }     }       private IMediaProcessor GetLatestMediaProcessorByName(string mediaProcessorName  CloudMediaContext _context)     {         var processor = _context.MediaProcessors.Where(p =&gt; p.Name == mediaProcessorName).         ToList().OrderBy(p =&gt; new Version(p.Version)).LastOrDefault();          if (processor == null)             throw new ArgumentException(string.Format(\""Unknown media processor\""  mediaProcessorName));          return processor;     }       private string PublishAssetGetURLs(IAsset asset  CloudMediaContext _context)     {            // Create a 30-day readonly access policy.          // You cannot create a streaming locator using an AccessPolicy that includes write or delete permissions.         IAccessPolicy policy = _context.AccessPolicies.Create(\""Streaming policy\""              TimeSpan.FromDays(30)              AccessPermissions.Read);          // Create a locator to the streaming content on an origin.          ILocator originLocator = _context.Locators.CreateLocator(LocatorType.OnDemandOrigin  asset              policy              DateTime.UtcNow.AddMinutes(-5));          // Display some useful values based on the locator.         //Console.WriteLine(\""Streaming asset base path on origin: \"");         //Console.WriteLine(originLocator.Path);         //Console.WriteLine();          // Get a reference to the streaming manifest file from the           // collection of files in the asset.           var manifestFile = asset.AssetFiles.Where(x =&gt; x.Name.EndsWith(\"".ism\"")).FirstOrDefault();              // Create a full URL to the manifest file. Use this for playback         // in streaming media clients.          string urlForClientStreaming = originLocator.Path + manifestFile.Name + \""/manifest\"";        // Console.WriteLine(\""URL to manifest for client streaming using Smooth Streaming protocol: \"");        // Console.WriteLine(urlForClientStreaming);        // Console.WriteLine(\""URL to manifest for client streaming using HLS protocol: \"");         return urlForClientStreaming + \""(format=m3u8-aapl)\"";        // Console.WriteLine(\""URL to manifest for client streaming using MPEG DASH protocol: \"");        // Console.WriteLine(urlForClientStreaming + \""(format=mpd-time-csf)\"");        // Console.WriteLine();     } </code></pre>""",azure-storage
55648142,Login request gets blocked by azure waf <p>In Azure Application Gateway inside Web application firewall if I enable it our deployed Spring java applications on Azure VM throws ERR_EMPTY_RESPONSE after login page. All other pages which are not using spring security are working fine.</p>  <p>If I disabled the WAF my applications works perfectly fine.</p>  <p>It was working as expected earlier today(12th April)</p>  <p>PS: i tried disabling waf rules but not working.I also tried WAF on detection mode but again the same issue.</p>  <p>We have not got any firewall block logs. Also in access logs all looks perfectly fine. My application server(tomcat) logs are also looks perfectly fine.</p>  <p>Update: We also tried with Enabled: WAF but Disabled : All OWASP 3.0 and 2.2.9 rules but results are same application not working.</p>  <p>UPDATE: got update from azure support they have deployed update in my region on that day. Somehow the update have not worked as expected . So they rollback the updates. After rollback all things are working perfectly fine.</p>,azure-virtual-machine
46649016,"Can not set multi line string to environment variable <p>How can I set multi line string to environment variable on VSTS powershell task. Following code only save the first line of the string.</p>  <p><code>[string]$xmlstring = Get-Content -Encoding UTF8 -Path     \$(System.DefaultWorkingDirectory)/apiPolicy.xml\""  -Raw | Out-String; Write-Host (\""##vso[task.setvariable variable=policystring;]\""+$xmlstring) </code></p>""",azure-devops
44537845,"Migrating Azure Mobile Service to AppService and swapping apns certificate <p>Our team has migrated from Azure Mobile Service to AppService and all works fine  except now we need to swap the APNS cert as it's reaching its expiry date. </p>  <p>According to this article: <a href=\https://docs.microsoft.com/en-us/azure/app-service-mobile/app-service-mobile-migrating-from-mobile-services\"" rel=\""nofollow noreferrer\"">https://docs.microsoft.com/en-us/azure/app-service-mobile/app-service-mobile-migrating-from-mobile-services</a> it has to be done manually in the file system. </p>  <p>Can someone explain how to do it  using the legacy push? Is it the FTP that I need to use? or maybe something else?</p>""",azure-web-app-service
54923721,"Force Copy Task in Azure DevOps to retain folder structure <p>Trying to move my team over to Azure DevOps and we're hitting a slight snag with the Copy Task.</p>  <p>Currently the task takes all project files and chucks them into a single drop folder  however  I need it to retain the original folder structure:</p>  <pre><code>- Project 1   - bin       - Release           - ** </code></pre>  <p>As stated  it currently just does:</p>  <pre><code>- drop   - ** </code></pre>  <p>Appreciate any help as I'm not familiar with DevOps at this stage:</p>  <p><a href=\https://i.stack.imgur.com/HkdPn.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/HkdPn.png\"" alt=\""enter image description here\""></a></p>""",azure-devops
37871795,"restrict azure appservice / website to a domain <p>I have a WCF service running on a azure app service. I want to restrict this WCF to a few azure website  external IPs and some other deployments. I am using IPSecurity tag for that in my WCF web.config</p>  <p>My issue is the IP restrictions work  but the azure website domains that i allow access to  dont seem to work.</p>  <p>for exmaple  i have an azure website with a custom domain  abcdef.info. i am trying to give this domain access to wcf  but it doesnt seem to be working. below is my configuration.</p>  <pre><code>&lt;ipSecurity enableReverseDns=\true\"" allowUnlisted=\""false\""&gt;         &lt;add ipAddress=\""127.0.0.1\"" allowed=\""true\"" /&gt;          &lt;add ipAddress=\""xx.xx.xx.xx\"" allowed=\""true\"" /&gt;  (IP of azure website i got after nslookup)           &lt;add domainName=\""azurewebsitedomain.azurewebsites.net\"" allowed=\""true\"" /&gt;         &lt;add domainName=\""abcdef.info\"" allowed=\""true\"" /&gt; (custom domain tied to my azure website)     &lt;/ipSecurity&gt; </code></pre>  <p>i was assuming that one of the last 3 settings here will whitelist my wcf client running to azure website to access WCF but so far nothing.</p>  <p>Will appreciate any help. Thanks.</p>""",azure-web-app-service
6985921,Where can I find my Azure account name and account key? <p>I am starting with Windows Azure. I have an Azure account with Microsoft and would like to use it from my Visual Studio project</p>  <p>In the Azure management portal  I can see the primary access key and secondary access key. However Visual Studio needs the account name and account key. </p>  <p>Are these related or am I missing something? If so  how can I get my account name and account key from the Azure management portal?</p>,azure-storage
56801740,"Some File not found when publish to azure web app <p>I am created a HTML file and some js/css etc  and to publish to azure. It's only a single page web page. But after publish I got error  some files not found.</p>  <p><a href=\https://i.stack.imgur.com/2zFT4.jpg\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/2zFT4.jpg\"" alt=\""enter image description here\""></a></p>  <p>Missing file is I get from </p>  <p><a href=\""https://github.com/WebDevSimplified/Face-Detection-JavaScript/blob/master/models/face_landmark_68_model-shard1\"" rel=\""nofollow noreferrer\"">https://github.com/WebDevSimplified/Face-Detection-JavaScript/blob/master/models/face_landmark_68_model-shard1</a></p>  <p>It's working fine in local. The same issue I get when I use json files. So I just added in web config </p>  <pre><code>   &lt;staticContent&gt;         &lt;mimeMap fileExtension=\"".json\"" mimeType=\""application/json\"" /&gt;  &lt;/staticContent&gt; </code></pre>  <p>then json files are working fine. Any idea what I missing?</p>""",azure-web-app-service
57357667,"Updating Azure Function in Portal will get 401 Error <p>if I want to customize the configuration input or output of my Azure Function my customizations will be accepted at first sight  because I don't get any error messages or anything else. But when I reload the page I see that the adjustments have not been saved. If I wait in the developer mode of my browser for the response from the put method I get an error 401. I can't log in any other way than with my Azure account. Before that I was able to customize Azure functions without any problems. As a workaround I can set the inputs and outputs via the Kudu console  but that can't be the point.</p>  <pre><code>HTTP/1.1 401 Unauthorized WWW-Authenticate: Bearer error=\invalid_token\""  error_description=\""The signature key was not found\"" Request-Context: appId=cid-v1:a7d48c7c-dd82-4365-9dac-0eb8a6995292 Access-Control-Allow-Origin: https://functions.azure.com Access-Control-Allow-Credentials: true Date: Mon  05 Aug 2019 11:22:11 GMT Content-Length: 0 </code></pre>""",azure-functions
43920080,Use offset of Windowstart in azure data factory <p>I wish to incrementally copy data from azure table to azure blob. I have created linked services  datasets and pipelines. I wish to copy data from table to blob after every hour. The table has a timestamp column.I want to transfer data from table to blob in such a way that the data which gets added to the table from 7am to 8am should be pushed to blob in activity window starting at 8 am. In other words  I don't want to miss any data flowing into the table.</p>,azure-storage
56461391,Is it possible to mark a release as succeeded if a manual intervention task is rejected? <p>I am currently attempting to create an azure release pipeline for a service fabric deployment. I have a single stage for our test environment that contains multiple jobs/tasks.</p>  <p>After a deployment to the environment succeeds  we run integration tests and smoke tests.</p>  <p>After the smoke tests I have inserted a manual intervention task to allow Devs the option of running the regression tests (resume) or exiting the process (reject). <strong>I would like to mark the release pipeline as succeeded if all prior tasks (deploy  integration &amp; smoke) pass and the manual intervention is rejected.</strong></p>  <p>If the manual intervention is responded to with resume  then the outcome of the following tasks should determine the release pipeline result.</p>  <p>I cannot find an example of this  and therefore it feels like the incorrect approach. Would a better fit be to introduce an intermediate environment against which regression tests are run as a result of successful smoke tests?</p>,azure-devops
44147257,How can I clean out an older deployment on my App Service in Azure? <p>I have a new version of my web app and after a new deployment from a new Bitbucket repo the old version is still served. I've deleted the App Service and then created it again  but still the old stuff is served. Everything I've tried results in a successful deployment of the new code  but when I browse the site  the old version is served. To get rid of the old code can I go to the console and just delete everything in site/wwwroot? Is there a git repo in Azure I can initialize?</p>,azure-web-app-service
36318458,Does virtual machine extensions provisioned for existing VM? <p>We have a VM ARM template which runs a custom extension when we provision it. This extensions run fine and install framework correctly.</p>  <p>By looking at verbose log it seems like it runs the extension every time we run deployment script even if VM is already present. Is this correct?</p>  <p>Also if it does run the extension every time  is there anyway to avoid it?</p>,azure-virtual-machine
38583297,"Moving file from one container to other container in azure blob <p>We have a <code>azure blob</code> location  in that blob we have two containers one is \<code>container_one</code>\"" and \""<code>container_two</code>\"". I need to copy a file from one container to 2nd container.</p>  <p>Can you please help me how to achieve this functionality in <code>c#</code>.</p>""",azure-storage
47175123,"Error when signing PDF document with Azure Key Vault + Azure Function Apps + CA Certificate <p>I have built an Azure function app that is signing PDF document with iTextSharp. This function app uses a certificate that is stored in Azure Key Vault.</p>  <p>When using a self signed certificate  for example one that was generated inside that vault or on my local machine  everything works great and I can see the signature details in the PDF file  but when I try use a certificate from CA  for example   a .PFX file from COMODO or digiCert that I import into the vault  the PDF signature comes out with an error.</p>  <p>Meaning  that when I open the signed PDF file in and click on the signature details  I get the error :</p>  <blockquote>   <p>Error during signature verification.</p>      <p>Error encountered while validating:</p>      <p>Internal cryptographic library error.</p>      <p>Error Code: 0x2726</p> </blockquote>  <p>I tried to compare the working certificates with the CA certificates  and the only difference I have found  is that the keys of the working ones have the \Encrypt\"" key flagged and the CA ones  doesn't. This flag is not editable  or I just can't find a way to control this flag.</p>  <p>Please advice.</p>  <p>Edited :  Please find below links to sample files.</p>  <p><a href=\""https://drive.google.com/file/d/1vlISxvyvIAw-pzrDH2JkMshVb-Sbr-52/view?usp=sharing\"" rel=\""nofollow noreferrer\"">Working Azure key vault Certificate generated PDF</a></p>  <p><a href=\""https://drive.google.com/file/d/1_TsZcRtu5If4K5pSm7d7fRLZM-E6VVDv/view?usp=sharing\"" rel=\""nofollow noreferrer\"">Invalid CA Certificate generated PDF</a></p>  <p>The files have to be download and opened in Acrobat in order to see the signatures.</p>""",azure-functions
50482199,"Accessing Function App via App Service Authentication from Dynamics 365 Plugin <p>I am trying to access an Azure Function from Dynamics 365 Plugin via service to service call: <a href=\https://docs.microsoft.com/en-us/azure/active-directory/develop/active-directory-protocols-oauth-service-to-service\"" rel=\""nofollow noreferrer\"">https://docs.microsoft.com/en-us/azure/active-directory/develop/active-directory-protocols-oauth-service-to-service</a></p>  <p>This function is protected via <strong>App Service Authentication</strong>.</p>  <p>I created a Function App and enabled  App Service Authentication  under Platform Features -> Authentication/Authorisation. I enabled Azure Active Directory as the Auth Provider and set Management mode to Express</p>  <p><a href=\""https://i.stack.imgur.com/3hAyg.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/3hAyg.png\"" alt=\""enter image description here\""></a></p>  <p>I then got the generated Client ID and Client Secret from the Advanced Mode:</p>  <p><a href=\""https://i.stack.imgur.com/kUNrG.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/kUNrG.png\"" alt=\""enter image description here\""></a></p>  <p>Apparently this is all that is needed to make a token request for the Azure function based  based on article I need 4 required parameters:</p>  <p>Client ID</p>  <p>Client Secret</p>  <p>Grant Type</p>  <p>Resource</p>  <p>I make the following request to generate a token from a Dynamics 365 Plugin but get the following error:</p>  <pre><code>Invalid Plugin Execution Exception: Microsoft.Xrm.Sdk.InvalidPluginExecutionException: {\""error\"":\""invalid_client\"" \""error_description\"":\""AADSTS70002: Error validating credentials. AADSTS50012: Invalid client secret is provided.\\r\\nTrace ID: 06ddda7f-2996-4c9b-ab7e-b685ee933700\\r\\nCorrelation ID: d582e2f2-91eb-4595-b44b-e95f42f2f071\\r\\nTimestamp: 2018-05-23 06:30:58Z\"" \""error_codes\"":[70002 50012] \""timestamp\"":\""2018-05-23 06:30:58Z\"" \""trace_id\"":\""06ddda7f-2996-4c9b-ab7e-b685ee933700\"" \""correlation_id\"":\""d582e2f2-91eb-4595-b44b-e95f42f2f071\""}-The remote server returned an error: (401) Unauthorized. </code></pre>  <p>My code is :</p>  <pre><code>         var tokenendpoint = \""https://login.microsoftonline.com/de194c13-5ff7-4085-91c3-ac06fb869f28/oauth2/token\"";          var reqstring = \""client_id=\"" + Uri.EscapeDataString(\""5f315431-e4da-4f68-be77-4e257b1b9295\"");          reqstring += \""&amp;client_secret=\"" + Uri.EscapeDataString(\""/oK7nh8pl+LImBxjm+L7WsQdyILErysOdjpzvA9g9JA=\"");          reqstring += \""&amp;resource=\"" + Uri.EscapeUriString(\""https://keyvaultaccess.azurewebsites.net\"");          reqstring += \""&amp;grant_type=client_credentials\"";           //Token request          WebRequest req = WebRequest.Create(tokenendpoint);          req.ContentType = \""application/x-www-form-urlencoded\"";          req.Method = \""POST\"";          byte[] bytes = System.Text.Encoding.ASCII.GetBytes(reqstring);          req.ContentLength = bytes.Length;          System.IO.Stream os = req.GetRequestStream();          os.Write(bytes  0  bytes.Length);          os.Close();           //Token response          HttpWebResponse resp = (HttpWebResponse)req.GetResponse();          StreamReader tokenreader = new StreamReader(resp.GetResponseStream());          string responseBody = tokenreader.ReadToEnd(); </code></pre>  <p>I have made sure that I have the correct Client Secret and have also encoded it as I have read somewhere that '+' and '/' are no good.</p>  <p>I am getting the same error in Postman</p>  <p>Any ideas??</p>""",azure-functions
55864622,"Azure DevOps Variable secrets between tasks jobs issecret=true <p>My Keyvault secrets are appearing in clear text in the console  I tried to set the variable to a secret:</p>  <pre><code>echo \##vso[task.setvariable variable=nsg-list;issecret=true;isOutput=true]$(nsg-list)\"" echo \""##vso[task.setvariable variable=nsg-rules;issecret=true;isOutput=true]$(nsg-rules)\"" </code></pre>  <p>Now the build are failing  if I remove the <code>issecret=true</code> the builds work again.</p>  <p>I need to pass the variables between tasks and jobs  is there a better way of doing this ?</p>  <pre><code>pool:      vmImage: 'Ubuntu-16.04'    steps:      - task: AzureKeyVault@1        displayName: Read variables from keyvault        inputs:          azureSubscription: Sandbox          keyVaultName: \""sandbox\""          secretsFilter: '*'      - script: |          echo \""##vso[task.setvariable variable=backend_storage_account_name;issecret=true;isOutput=true]$(backend-storage-account-name)\""          echo \""##vso[task.setvariable variable=backend_storage_container_name;issecret=true;isOutput=true]$(backend-storage-container-name)\""          echo \""##vso[task.setvariable variable=backend_access_key;issecret=true;isOutput=true]$(backend-access-key)\""          echo \""##vso[task.setvariable variable=tenant-id;issecret=true;isOutput=true]$(tenant-id)\""          echo \""##vso[task.setvariable variable=app-id;issecret=true;isOutput=true]$(app-id)\"" </code></pre>""",azure-devops
42437128,"Choose Nuget Packager version in Visual Studio Team Services build step <p>Why I cannot choose nuget version in build step configuration in Visual Studio Team Services? It seems that for every other nuget build step (installer  publisher) I can choose between 3.3.0 and 3.5.0  but for this one I'm forced to download nuget.exe  check it into source control and provide a path to the exe.</p>  <p><a href=\https://i.stack.imgur.com/L5vAh.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/L5vAh.png\"" alt=\""enter image description here\""></a></p>  <p>Since nuget 3.3.0 cannot deal with making packages directly from project.json it would make so much sense to be able to choose the version in this step.</p>""",azure-devops
56587820,Deploy web app to Azure but still showing Microsoft page instead <p>I'm trying to deploy my web app to Microsoft Azure and everything goes fine in visual studio. But when it launches it shows: </p>  <blockquote>   <p>Hey  App Service developers!<br>   Your app service is up and running.<br>   Time to take the next step and deploy your code.</p> </blockquote>  <p>How can I show my web page instead of this page? </p>  <p>Here is the output I get in Visual Studio.</p>  <pre><code>------ Publish started: Project: RCMania  Configuration: Debug Any CPU ------ Transformed Web.config using C:\DDAC\Assignment\RCMania\RCMania\Web.Debug.config into C:\Users\Admin\AppData\Local\Temp\WebSitePublish\RCMania-1747672403\obj\Debug\TransformWebConfig\transformed\Web.config. Auto ConnectionString Transformed C:\Users\Admin\AppData\Local\Temp\WebSitePublish\RCMania-1747672403\obj\Debug\TransformWebConfig\transformed\Web.config into C:\Users\Admin\AppData\Local\Temp\WebSitePublish\RCMania-1747672403\obj\Debug\CSAutoParameterize\transformed\Web.config. Copying all files to temporary location below for package/publish: C:\Users\Admin\AppData\Local\Temp\WebSitePublish\RCMania-1747672403\obj\Debug\Package\PackageTmp. Start Web Deploy Publish the Application/package to https://rcmania.scm.azurewebsites.net/msdeploy.axd?site=rcmania ... Adding ACLs for path (rcmania) Adding ACLs for path (rcmania) Updating file (rcmania\Web.config). Adding ACLs for path (rcmania) Adding ACLs for path (rcmania) Publish Succeeded. Web App was published successfully http://rcmania.azurewebsites.net/ ========== Build: 1 succeeded or up-to-date  0 failed  0 skipped ========== ========== Publish: 1 succeeded  0 failed  0 skipped ========== </code></pre>,azure-web-app-service
45437569,Scaling out Azure App Service <p>I have my web app hosted on Azure App services which i would like to scale out now. </p>  <p><strong>I have OWIN cookie Authentication for this to work on scaled out infrastructure.. What all do i need to consider?</strong></p>,azure-web-app-service
51914398,"Azure function to load a blob and send it directly to context.res <p>I thought it would be quite easy to load a blob from an azure storage container and write it to the HTTP response  but I'm not able to get it working.</p>  <p>I've declared an input blob like this:</p>  <pre><code>{   \bindings\"": [     {       \""authLevel\"": \""function\""        \""type\"": \""httpTrigger\""        \""direction\"": \""in\""        \""name\"": \""req\""        \""route\"": \""resizeImage\""     }      {       \""type\"": \""http\""        \""direction\"": \""out\""        \""name\"": \""res\""     }      {       \""type\"": \""blob\""        \""name\"": \""imageBlob\""        \""path\"": \""images/{name}\""        \""connection\"": \""ng1_STORAGE\""        \""direction\"": \""in\""     }   ]    \""disabled\"": false } </code></pre>  <p>This is an HTTP trigger  so I just call the URL <code>resizeImage?name=image1.png</code> and that provides me with <code>context.bindings.imageBlob</code> as the blob data.</p>  <p>However first problem is the blob is the wrong size. I've tried outputting JSON for <code>imageBlob.length</code> with the following two images:</p>  <p>1) cat.png = 272228 bytes on disk  but imageBlob.length = 258032 bytes 2) dog.png = 15699604 bytes on disk  but imageBlob.length = 15173390 bytes</p>  <p>So</p>  <ul> <li>I definitely know the file is being found and loaded because these image sizes are close to what they're supposed to be</li> <li>I'm guessing <code>imageBlob</code> is some kind of stream object? (I see the C# signature is Stream). </li> <li>Why is the .length property only giving me about 95% of the image size on disk?</li> </ul>  <p>If I try to return it as-is like this then I get a content-length of <code>imageBlob.length</code>  but of course the image is incomplete.</p>  <pre><code>context.res = {               body: new Buffer(context.bindings.imageBlob  'binary')                 headers: {                  'Content-Type': 'image/png'               } </code></pre>  <p>I will be using the sharp image library to process it  but I can't even right now return the original image! How do I just return the blob as an HTTP response?</p>""",azure-functions
34016938,distribuited coordinator on windows azure <p>I'm using the DTC on windows azure SQL.  The Transaction coordinator works fine and I want to know if there's a way to use it with tablestorage or blob storage. The functionality can will very utils to have a unique transaction in more service.</p>,azure-storage
51416889,"What is the function of the open port 7654 on Azure Web Apps <p>We had a security scan of our application hosted on Azure Web Apps. They found some open ports that are listed in the image below:</p>  <p><a href=\https://i.stack.imgur.com/nJayr.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/nJayr.png\"" alt=\""openports\""></a></p>  <p>We can explain almost all open ports  except 7654. Does anyone know what this port is used for? Or is there any gihub repo or other place we can ask MS?</p>""",azure-web-app-service
39620183,Is it possible to delete old TFS change sets? <p>We would like to use the free OpsHub tool to migrate from TFS to VSTS but there is a 2500 change set limit. We have almost 5000 change sets from 4 years of check-ins. Is it possible to delete the oldest 1/2 of the change sets to allow use of this tool?</p>,azure-devops
14728081,Azure cloud service fails to run in development <p>I have a azure cloud service project running on my Windows 8 machine in Visual Studio 2012. It has a website and a few ddl projects. The solution is checked into Team Foundation Server.</p>  <p>When I run the project in Windows 7  its starts the emulator and works great.</p>  <p>When I run the project in Windows 8  the emulator starts  but the website never starts. Visual studio 2012 has a message as the bottom that says the following : The program '[4188] WaIISHost.exe: Managed (v4.0.30319)' has exited with code 0 (0x0). The operation was canceled.</p>  <p>How do I debug this and get it to work?</p>  <p>EDIT 14/04/2014 I am having the same problem with Visual Studio 2013.</p>,azure-web-app-service
29168998,"Listing the files  which are inside a Blob? <p>Just started working on with <code>Windows Azure</code> and <code>Mapreduce</code>. I've already created an <code>HDInsight</code> cluster within the <code>Azure Portal</code> and also created a <code>Block Blob</code> using the <code>Azure Explorer</code> named <code>BlobFiles</code>. </p>  <p>What I wanted to know is  is there a way of listing all the files within a <code>Blob</code> which is within a <code>Blob Container</code>? In other words if I'm uploading text files as well as images to the same <code>Blob</code>  how could I list those text files as well as those images programmatically or in another way?   </p>  <p>Searched for a solution  but still couldn't come across of one. I'm able to see the content of the file individually using the <code>Azure Explorer</code>  where as um unable to find a way to see or display the files within that particular <code>Blob</code>!</p>  <p><strong>Edited</strong>: This is what I've tried to display the Blobs:</p>  <pre><code>        // Retrieve storage account from connection string.         CloudStorageAccount storageAccount = CloudStorageAccount.Parse(             CloudConfigurationManager.GetSetting(\StorageConnectionString\""));          // Create the blob client.         CloudBlobClient blobClient = storageAccount.CreateCloudBlobClient();          // Retrieve reference to a previously created container.         CloudBlobContainer container = blobClient.GetContainerReference(\""fyptest1\"");          // Retrieve reference to a blob named \""myblob\"".         CloudBlockBlob blockBlob = container.GetBlockBlobReference(\""myblob\"");          lboxblob.ItemsSource = container.ListBlobs();//lboxblob is the name of my listbox </code></pre>  <p>When I tried the above code it displays something like <code>Microsoft.WindowsAzure.Storage.Blob.CloudBlockBlob</code>  and so on for a few number of times. </p>  <p>Any help would be appreciated. </p>""",azure-storage
47428085,"How can I fix deployment of node.js to azure app service that fails npm install? <p>I create a new app service with windows os  connect it to bitbucket and it checks out the code then fails on npm install. I feel like it should work and I cant understand how it is not working..</p>  <p>I put full error traces at the bottom.</p>  <p>First I got this error:</p>  <blockquote>   <p>Cannot find module 'sync-exec'</p> </blockquote>  <p>Well that seems like it is using the old node (my package.json has <code>\engines\"": { \""node\"": \""8.9.x\"" }</code> ) which I thought would be valid so I tried setting the environment variable <code>WEBSITE_NODE_DEFAULT_VERSION</code> to <code>8.9.0</code> but it still errors this time with this:</p>  <blockquote>   <p>EPERM: operation not permitted  scandir</p> </blockquote>  <p>I read in some posts to try running <code>npm cache clean</code> it says it should auto-clean so from the console I try <code>npm cache clean --force</code> then I rebuild and still get the error. Out of desparation I try <code>del /s /q node_modules</code> then rebuild and now get a worse error.</p>  <blockquote>   <p>Cannot read property '0' of undefined</p> </blockquote>  <p>Maybe delete this folder was crazy. If I need I can delete the web app and start over though. I created a linux web app and the npm install worked fine but I have other issues with linux so it would be good to get the windows one working.</p>  <p>Here are the full log outputs:</p>  <pre><code>Selected node.js version 8.9.0. Use package.json file to choose a different version. Selected npm version 5.5.1 Updating iisnode.yml at D:\\home\\site\\wwwroot\\iisnode.yml npm WARN lifecycle The node binary used for scripts is D:\\Program Files (x86)\\nodejs\\0.10.28\\node.exe but npm is using D:\\Program Files (x86)\\nodejs\\8.9.0\\node.exe itself. Use the `--scripts-prepend-node-path` option to include the path for the node binary npm was executed with.  &gt; microtime@2.1.6 install D:\\home\\site\\wwwroot\\node_modules\\microtime &gt; prebuild-install || node-gyp rebuild  prebuild-install info begin Prebuild-install version 2.2.1 prebuild-install info looking for local prebuild @ prebuilds\\microtime-v2.1.6-node-v11-win32-ia32.tar.gz prebuild-install info looking for cached prebuild @ D:\\local\\AppData\\npm-cache\\_prebuilds\\https-github.com-wadey-node-microtime-releases-download-v2.1.6-microtime-v2.1.6-node-v11-win32-ia32.tar.gz prebuild-install http request GET https://github.com/wadey/node-microtime/releases/download/v2.1.6/microtime-v2.1.6-node-v11-win32-ia32.tar.gz prebuild-install http 200 https://github.com/wadey/node-microtime/releases/download/v2.1.6/microtime-v2.1.6-node-v11-win32-ia32.tar.gz prebuild-install info downloading to @ D:\\local\\AppData\\npm-cache\\_prebuilds\\https-github.com-wadey-node-microtime-releases-download-v2.1.6-microtime-v2.1.6-node-v11-win32-ia32.tar.gz.5612-28c7359.tmp prebuild-install info renaming to @ D:\\local\\AppData\\npm-cache\\_prebuilds\\https-github.com-wadey-node-microtime-releases-download-v2.1.6-microtime-v2.1.6-node-v11-win32-ia32.tar.gz prebuild-install info unpacking @ D:\\local\\AppData\\npm-cache\\_prebuilds\\https-github.com-wadey-node-microtime-releases-download-v2.1.6-microtime-v2.1.6-node-v11-win32-ia32.tar.gz prebuild-install info unpack resolved to D:\\home\\site\\wwwroot\\node_modules\\microtime\\build\\Release\\microtime.node prebuild-install info unpack required D:\\home\\site\\wwwroot\\node_modules\\microtime\\build\\Release\\microtime.node successfully prebuild-install info install Successfully installed prebuilt binary!  &gt; node-sass@4.5.3 install D:\\home\\site\\wwwroot\\node_modules\\node-sass &gt; node scripts/install.js  Downloading binary from https://github.com/sass/node-sass/releases/download/v4.5.3/win32-ia32-11_binding.node Download complete Binary saved to D:\\home\\site\\wwwroot\\node_modules\\node-sass\\vendor\\win32-ia32-11\\binding.node Caching binary to D:\\local\\AppData\\npm-cache\\node-sass\\4.5.3\\win32-ia32-11_binding.node  &gt; uglifyjs-webpack-plugin@0.4.6 postinstall D:\\home\\site\\wwwroot\\node_modules\\webpack\\node_modules\\uglifyjs-webpack-plugin &gt; node lib/post_install.js   module.js:340     throw err;           ^ Error: Cannot find module 'sync-exec'     at Function.Module._resolveFilename (module.js:338:15)     at Function.Module._load (module.js:280:25)     at Module.require (module.js:364:17)     at require (module.js:380:17)     at Object.&lt;anonymous&gt; (D:\\home\\site\\wwwroot\\node_modules\\webpack\\node_modules\\uglifyjs-webpack-plugin\\lib\\post_install.js:9:14)     at Module._compile (module.js:456:26)     at Object.Module._extensions..js (module.js:474:10)     at Module.load (module.js:356:32)     at Function.Module._load (module.js:312:12)     at Function.Module.runMain (module.js:497:10) npm WARN Error: EPERM: operation not permitted  scandir 'D:\\home\\site\\wwwroot\\node_modules\\webpack\\node_modules\\uglify-js\\node_modules' npm WARN  { Error: EPERM: operation not permitted  scandir 'D:\\home\\site\\wwwroot\\node_modules\\webpack\\node_modules\\uglify-js\\node_modules' npm WARN   stack: 'Error: EPERM: operation not permitted  scandir \\'D:\\\\home\\\\site\\\\wwwroot\\\\node_modules\\\\webpack\\\\node_modules\\\\uglify-js\\\\node_modules\\''  npm WARN   errno: -4048  npm WARN   code: 'EPERM'  npm WARN   syscall: 'scandir'  npm WARN   path: 'D:\\\\home\\\\site\\\\wwwroot\\\\node_modules\\\\webpack\\\\node_modules\\\\uglify-js\\\\node_modules' } npm ERR! code ELIFECYCLE npm ERR! errno 8 npm ERR! uglifyjs-webpack-plugin@0.4.6 postinstall: `node lib/post_install.js` npm ERR! Exit status 8 npm ERR!  npm ERR! Failed at the uglifyjs-webpack-plugin@0.4.6 postinstall script. npm ERR! This is probably not a problem with npm. There is likely additional logging output above.  npm ERR! A complete log of this run can be found in: npm ERR!     D:\\local\\AppData\\npm-cache\\_logs\\2017-11-22T04_03_47_200Z-debug.log Failed exitCode=8  command=\""D:\\Program Files (x86)\\nodejs\\8.9.0\\node.exe\"" \""D:\\Program Files (x86)\\npm\\5.5.1\\node_modules\\npm\\bin\\npm-cli.js\"" install --production </code></pre>  <p>After setting the version environment variable the error is:</p>  <pre><code>Command: \""D:\\home\\site\\deployments\\tools\\deploy.cmd\"" Handling node.js deployment. KuduSync.NET from: 'D:\\home\\site\\repository' to: 'D:\\home\\site\\wwwroot' Start script \""built/project1/server.js\"" from package.json is not found. Missing server.js/app.js files  web.config is not generated Looking for app.js/server.js under site root. Node.js versions available on the platform are: 0.6.20  0.8.2  0.8.19  0.8.26  0.8.27  0.8.28  0.10.5  0.10.18  0.10.21  0.10.24  0.10.26  0.10.28  0.10.29  0.10.31  0.10.32  0.10.40  0.12.0  0.12.2  0.12.3  0.12.6  4.0.0  4.1.0  4.1.2  4.2.1  4.2.2  4.2.3  4.2.4  4.3.0  4.3.2  4.4.0  4.4.1  4.4.6  4.4.7  4.5.0  4.6.0  4.6.1  4.8.4  5.0.0  5.1.1  5.3.0  5.4.0  5.5.0  5.6.0  5.7.0  5.7.1  5.8.0  5.9.1  6.0.0  6.1.0  6.2.2  6.3.0  6.5.0  6.6.0  6.7.0  6.9.0  6.9.1  6.9.2  6.9.4  6.9.5  6.10.0  6.10.3  6.11.1  6.11.2  6.11.5  7.0.0  7.1.0  7.2.0  7.3.0  7.4.0  7.5.0  7.6.0  7.7.0  7.7.4  7.10.0  7.10.1  8.0.0  8.1.4  8.4.0  8.5.0  8.7.0  8.8.0  8.8.1  8.9.0. Selected node.js version 8.9.0. Use package.json file to choose a different version. Selected npm version 5.5.1 Updating iisnode.yml at D:\\home\\site\\wwwroot\\iisnode.yml  &gt; uglifyjs-webpack-plugin@0.4.6 postinstall D:\\home\\site\\wwwroot\\node_modules\\webpack\\node_modules\\uglifyjs-webpack-plugin &gt; node lib/post_install.js  npm ERR! path D:\\home\\site\\wwwroot\\node_modules\\fsevents\\node_modules npm ERR! code EPERM npm ERR! errno -4048 npm ERR! syscall scandir npm ERR! Error: EPERM: operation not permitted  scandir 'D:\\home\\site\\wwwroot\\node_modules\\fsevents\\node_modules' npm ERR!  { Error: EPERM: operation not permitted  scandir 'D:\\home\\site\\wwwroot\\node_modules\\fsevents\\node_modules' npm ERR!   stack: 'Error: EPERM: operation not permitted  scandir \\'D:\\\\home\\\\site\\\\wwwroot\\\\node_modules\\\\fsevents\\\\node_modules\\''  npm ERR!   errno: -4048  npm ERR!   code: 'EPERM'  npm ERR!   syscall: 'scandir'  npm ERR!   path: 'D:\\\\home\\\\site\\\\wwwroot\\\\node_modules\\\\fsevents\\\\node_modules' } npm ERR!  npm ERR! Please try running this command again as root/Administrator.  npm ERR! A complete log of this run can be found in: npm ERR!     D:\\local\\AppData\\npm-cache\\_logs\\2017-11-22T04_28_58_782Z-debug.log Failed exitCode=-4048  command=\""D:\\Program Files (x86)\\nodejs\\8.9.0\\node.exe\"" \""D:\\Program Files (x86)\\npm\\5.5.1\\node_modules\\npm\\bin\\npm-cli.js\"" install --production An error has occurred during web site deployment. Missing server.js/app.js files  web.config is not generated\\r\\nnpm ERR! path D:\\home\\site\\wwwroot\\node_modules\\fsevents\\node_modules\\r\\nnpm ERR! code EPERM\\r\\nnpm ERR! errno -4048\\r\\nnpm ERR! syscall scandir\\r\\nnpm ERR! Error: EPERM: operation not permitted  scandir 'D:\\home\\site\\wwwroot\\node_modules\\fsevents\\node_modules'\\r\\nnpm ERR!  { Error: EPERM: operation not permitted  scandir 'D:\\home\\site\\wwwroot\\node_modules\\fsevents\\node_modules'\\r\\nnpm ERR!   stack: 'Error: EPERM: operation not permitted  scandir \\'D:\\\\home\\\\site\\\\wwwroot\\\\node_modules\\\\fsevents\\\\node_modules\\'' \\r\\nnpm ERR!   errno: -4048 \\r\\nnpm ERR!   code: 'EPERM' \\r\\nnpm ERR!   syscall: 'scandir' \\r\\nnpm ERR!   path: 'D:\\\\home\\\\site\\\\wwwroot\\\\node_modules\\\\fsevents\\\\node_modules' }\\r\\nnpm ERR! \\r\\nnpm ERR! Please try running this command again as root/Administrator.\\r\\n\\r\\nnpm ERR! A complete log of this run can be found in:\\r\\nnpm ERR!     D:\\local\\AppData\\npm-cache\\_logs\\2017-11-22T04_28_58_782Z-debug.log\\r\\nD:\\Program Files (x86)\\SiteExtensions\\Kudu\\67.61109.3117\\bin\\Scripts\\starter.cmd \""D:\\home\\site\\deployments\\tools\\deploy.cmd\"" </code></pre>  <p>After deleting node_modules the error is:</p>  <pre><code>Command: \""D:\\home\\site\\deployments\\tools\\deploy.cmd\"" Handling node.js deployment. KuduSync.NET from: 'D:\\home\\site\\repository' to: 'D:\\home\\site\\wwwroot' Start script \""built/project1/server.js\"" from package.json is not found. Missing server.js/app.js files  web.config is not generated Looking for app.js/server.js under site root. Node.js versions available on the platform are: 0.6.20  0.8.2  0.8.19  0.8.26  0.8.27  0.8.28  0.10.5  0.10.18  0.10.21  0.10.24  0.10.26  0.10.28  0.10.29  0.10.31  0.10.32  0.10.40  0.12.0  0.12.2  0.12.3  0.12.6  4.0.0  4.1.0  4.1.2  4.2.1  4.2.2  4.2.3  4.2.4  4.3.0  4.3.2  4.4.0  4.4.1  4.4.6  4.4.7  4.5.0  4.6.0  4.6.1  4.8.4  5.0.0  5.1.1  5.3.0  5.4.0  5.5.0  5.6.0  5.7.0  5.7.1  5.8.0  5.9.1  6.0.0  6.1.0  6.2.2  6.3.0  6.5.0  6.6.0  6.7.0  6.9.0  6.9.1  6.9.2  6.9.4  6.9.5  6.10.0  6.10.3  6.11.1  6.11.2  6.11.5  7.0.0  7.1.0  7.2.0  7.3.0  7.4.0  7.5.0  7.6.0  7.7.0  7.7.4  7.10.0  7.10.1  8.0.0  8.1.4  8.4.0  8.5.0  8.7.0  8.8.0  8.8.1  8.9.0. Selected node.js version 8.9.0. Use package.json file to choose a different version. Selected npm version 5.5.1 Updating iisnode.yml at D:\\home\\site\\wwwroot\\iisnode.yml npm ERR! Cannot read property '0' of undefined Failed exitCode=1  command=\""D:\\Program Files (x86)\\nodejs\\8.9.0\\node.exe\"" \""D:\\Program Files (x86)\\npm\\5.5.1\\node_modules\\npm\\bin\\npm-cli.js\"" install --production </code></pre>""",azure-web-app-service
47774808,"Same method in Azure Function takes longer <p>I was curious about how much the response times would be improved when moving an intensive method to an Azure Function.  So I created 2 small applications. The first one is an ASP.NET MVC application (app service plan S1). The second one is an ASP.NET MVC application with 1 Azure Function (in a Function project)  App Service plan S1 combined with a Consumption plan for the FunctionApp. </p>  <p>Both applications are the same except for 1 method  which is moved to an Azure Function  the <code>MergeDocumentsAndExport</code>.  In my application a given number of <code>Document</code> records are created on application start. </p>  <pre><code>public class Document {     [Key]     public int Id { get; set; }     public string Name { get; set; }     public byte[] Content { get; set; }     public DateTime DateCreated { get; set; } } </code></pre>  <p>The enduser is able to download all the <code>Documents</code> in the database by clicking on a button in a view. When this button is clicked  the method <code>MergeDocumentsAndExport</code>is called. </p>  <h3>Without Azure Functions</h3>  <pre><code>public byte[] MergeDocumentsAndExport() {     var startmoment = DateTime.Now;     var baseDocument = new Spire.Doc.Document();     var documents = _documentDataService.GetAllDocuments();      foreach (var document in documents)     {         using (var memoryStream = new MemoryStream(document.Content))         {             var documentToLoad = new Spire.Doc.Document();             documentToLoad.LoadFromStream(memoryStream  FileFormat.Doc);              foreach (Section section in documentToLoad.Sections)             {                 baseDocument.Sections.Add(section.Clone());             }         }     }      byte[] byteArrayToReturn;      using (var memoryStream = new MemoryStream())     {         baseDocument.SaveToStream(memoryStream  FileFormat.Doc);         byteArrayToReturn = memoryStream.ToArray();     }      _responseLogger.Log(startmoment  DateTime.Now  nameof(MergeDocumentsAndExport);     return byteArrayToReturn; } </code></pre>  <p>The <code>_responseLogger.Log(..)</code> method logs the start and end of the method with the name of the method en determines the executiontime (maybe <code>responselogger</code> isn't the best name for this service). </p>  <h3>With Azure Functions</h3>  <p>The same method is transformed into an HTTP-triggered Azure Function. </p>  <pre><code>[DependencyInjectionConfig(typeof(DependencyConfig))] public static class MergeDocumentsAndExportFunction {     [FunctionName(\MergeDocumentsAndExportFunction\"")]     public static HttpResponseMessage Run(         [HttpTrigger(AuthorizationLevel.Function  \""get\""  Route = \""MergeDocumentsAndExport\"")]HttpRequestMessage req          TraceWriter log          [Inject]IDocumentDataService documentDataService          [Inject]IResponseLogger responseLogger)     {         var startmoment = DateTime.Now;         log.Info(\""MergeDocumentsAndExportFunction processed a request.\"");          var baseDocument = new Document();         var documents = documentDataService.GetAllDocuments();          foreach (var document in documents)         {             using (var memoryStream = new MemoryStream(document.Content))             {                 var documentToLoad = new Document();                 documentToLoad.LoadFromStream(memoryStream  FileFormat.Doc);                  foreach (Section section in documentToLoad.Sections)                 {                     baseDocument.Sections.Add(section.Clone());                 }             }         }          using (var memoryStream = new MemoryStream())         {             baseDocument.SaveToStream(memoryStream  FileFormat.Doc);             // Create response to send document as byte[] back.             var response = req.CreateResponse(HttpStatusCode.OK);             var buffer = memoryStream.ToArray();             var contentLength = buffer.Length;             response.Content = new StreamContent(new MemoryStream(buffer));             response.Content.Headers.ContentType = new MediaTypeHeaderValue(\""application/ms-word\"");             response.Content.Headers.ContentLength = contentLength;              responseLogger.Log(startmoment  DateTime.Now  \""MergeDocumentsAndExport\"");             return response;         }     } </code></pre>  <p>In the <code>MergeDocumentsAndExportFunction</code> a bit of code is added like creating and returning a <code>HttpResponseMessage</code>. I didn't implement async calls  because it was only for this minor test and I wanted to compare the synchronous execution time of the method <code>MergeDocumentsAndExport</code> in both environments. </p>  <p>The results I got  was not what I was expecting. In almost every case the execution time was about the same or was much longer for the Azure Function. I know there is a startup time for an Azure Function and I excluded those. Maybe because the dependency injection with Autofac can take some time? The outcome in seconds when 1000 Documents from the database are merged and exported:</p>  <p>Without Azure Function:</p>  <ul> <li>49 34</li> <li>50 21</li> <li>51 26</li> <li>49 00</li> <li>50 21</li> <li>50 68</li> <li>...and so on...  Average: 49 69 seconds. </li> </ul>  <p>With Azure Function:</p>  <ul> <li>133 64 (startup  excluded)</li> <li>77 68</li> <li>85 18</li> <li>66 46</li> <li>86 00</li> <li>65 17</li> <li>...and so on...  Average: 82 69 seconds. </li> </ul>  <p>The execution time of the same method in different environments can differ 30 seconds for merging 1000 documents into 1. How is it possible that the Azure Function takes longer to execute (+ 30 seconds)? Is it because I am using it wrong? Thanks. </p>""",azure-functions
10348439,"Uploading a photo stream from camera into azure blob in WP7 <p>I have the following simple application page that uses the phone camera to upload the taken photo to azure blob:</p>  <pre><code>public partial class AddReport : PhoneApplicationPage {     // blobs stuff     string storageAccount = \MYACCOUNT\"";     string storageKey = \""MYKEY\"";     string blobServiceUri = \""http://MYACCOUNT.blob.core.windows.net\"";     CloudBlobClient blobClient;      private Report newReport;     public AddReport()     {         InitializeComponent();        }      protected override void OnNavigatedTo(System.Windows.Navigation.NavigationEventArgs e)     {         //base.OnNavigatedTo(e);          newReport = new Report();         var credentials = new StorageCredentialsAccountAndKey(storageAccount  storageKey);         blobClient = new CloudBlobClient(blobServiceUri  credentials);     }      private void TakePhotoClick(object sender  EventArgs eventArgs)     {         //The camera chooser used to capture a picture.         CameraCaptureTask ctask;          //Create new instance of CameraCaptureClass         ctask = new CameraCaptureTask();          //Create new event handler for capturing a photo         ctask.Completed += new EventHandler&lt;PhotoResult&gt;(ctask_Completed);          //Show the camera.         ctask.Show();      }      void ctask_Completed(object sender  PhotoResult e)     {          if (e.TaskResult == TaskResult.OK &amp;&amp; e.ChosenPhoto != null)         {              WriteableBitmap CapturedImage = PictureDecoder.DecodeJpeg(e.ChosenPhoto);             UploadToBlobContainer(e.ChosenPhoto);         }         else         {             //user decided not to take a picture         }     }     private void UploadToBlobContainer(System.IO.Stream stream)     {         string containerName = \""reportsPhotos\"";         var container = blobClient.GetContainerReference(containerName);          container.CreateIfNotExist(true  r =&gt;             Dispatcher.BeginInvoke(() =&gt;             {                 var blobName = \""report\"" + newReport.ReportId.ToString();                 var blob = container.GetBlobReference(blobName);                 blob.Metadata[\""ReportId\""] = newReport.ReportId.ToString();                 blob.UploadFromStream(stream  r2 =&gt;                     Dispatcher.BeginInvoke(() =&gt;                     {                          newReport.Photo = container.Uri + \""/\"" + blobName;                     }));             }));      } } </code></pre>  <p>This is a simple case and I am not using SAS to authenticate  instead I save the key in the app itself (this is only for testing purposes) and also my blobs are publicly available. </p>  <p>when I run in debug mode it seems that everything is working  but the photo doesn't get uploaded to the blob. Also  I don't know how I can debug this to see if there was any error from the blob service.</p>  <p>Can anyone tell me what might be wrong ?</p>  <p>EDIT1: it seems that the container is not being created either. i've confirmed this using <a href=\""http://blobexplorer.codeplex.com/\"" rel=\""nofollow\"">azure blob explorer</a></p>  <p>EDIT2: I am getting a <code>System.Net.WebException : \""The remote server returned an error: NotFound.\""</code></p>""",azure-storage
46887227,"How to pass ConnectionString when deploying AzureRM Web App in TFS? <p>I am struggling to pass ConnectionString when deploying AzureRM Web App in TFS Release Manager. I have tried to put the ConnectionString in the \Additional Arguments\"" field and provided the correct variables from the \""Variables\"" section. However  I am getting the following error: </p>  <p><a href=\""https://i.stack.imgur.com/jGQ7t.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/jGQ7t.png\"" alt=\""enter image description here\""></a></p>  <p><code>[error] Error: Unrecognized argument '-connectionString'. Error count: 1.</code> </p>  <p>Does someone have experience in how to set up ConnectionString when working with AzureRM Endpoint to deploy Web Apps? As far as I know  the approach described above works fine when using Azure Web App Deployment with Azure Classic Endpoint.</p>""",azure-web-app-service
47823611,"Azure \Percentage CPU\"" metric on a VM <p>What exactly is it measuring?</p>  <p>I have an Debian VM in Azure with <strong>16 vCPUs</strong>. I am using it to run tensorflow. The metric \""<strong>Percentage CPU</strong>\"" on Azure Portal shows 33.5% average. My concern is that I might not fully utilize all the 16 vCPUs.</p>  <p>What really puzzles me is that the <strong><code>top</code></strong> command shows a dominating Python process of 600% CPU. Why is this number not consistent with Azure's 33.5%?</p>  <p>At one point  I was suspecting the number of tensflow threads is not enough. However  when I <a href=\""https://stackoverflow.com/questions/41233635/tensorflow-inter-and-intra-op-parallelism-configuration\"">increased the tensorflow threads from 5 to 15</a>  Azure \""Percentage CPU\"" remained unchanged at 33.5%. <code>top -H</code> did show the increased number of threads though.</p>  <p>UPDATE:</p>  <p>See the accepted answer below. In the <code>top</code> screen  type <code>1</code>  it shows all the CPUs are used:</p>  <p><a href=\""https://i.stack.imgur.com/qvftS.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/qvftS.png\"" alt=\""enter image description here\""></a></p>  <p>So Azure's \""Percentage CPU\"" metric is <code>%CPU</code> you see with <code>top</code> command. Average meaning the average <code>%CPU</code> of all the CPUs.</p>""",azure-virtual-machine
56743496,"Receiving 403 error when accessing Azure function app locked down by Azure AD B2C <p>We are using AD B2C for authentication on our web app. Last week we started receiving a 403.76 when calling our APIs that are hosted in Azure and locked down by Active Directory using our AD B2C tenant. </p>  <p>We haven't changed any config settings in AD when the change occurred. We rolled back all of our code which didn't help. We verified that our token is valid in jwt.io. We confirmed that our audience is correct and permissions was set properly in app registrations. We can see the easy auth error 403.76 when going in to \Diagnose and solve problems\"" section of the function app and drilling into 4xx errors. </p>  <p>The function app just does a GetAsync against Cosmos to get your user profile on sign in. However we aren't getting that far  as we are receiving a 403.76 when verifying our token with AD. </p>  <p>We should be able to do a GET against our API and receive data as we were before. Instead we get HTTP status 403 with a sub status of 76. </p>  <p>The error in \""Diagnose and solve problems\"" section: </p>  <p>EasyAuth:AuthorizationCheckFailed. For more details  refer to HTTP Status Codes by EasyAuth Module</p>""",azure-functions
48714124,How to query a database from an Azure function in js <p>I have an IOT hub getting some data. I also have an Azure function app in js that is triggered when an IOT event occurs. In the function app  I want to query the incoming data against a azure sql database.</p>  <p>In the azure function->application settings->connection string  I created a connection string x with value of the azure db connection string. My index.js file is as below.</p>  <pre><code>module.exports = function (context  IoTHubMessages) { context.log(`JavaScript eventhub trigger function called for message array ${IoTHubMessages}`);  IoTHubMessages.forEach(message =&gt; {     context.log(`Processed message ${message}`);   var sqlConnection = x;  });  context.done(); </code></pre>  <p>};</p>  <p>I get an error that x is not defined. How can I access x? Also how how to execute a select query from here.</p>  <p>Any help will be greatly appreciated.</p>,azure-functions
52376756,VSTS Getting Build Error with latest version of entityframeworkcore.sql server and asp.net core 2.1 mvc project <p>I'm getting an error when a asp.net core 2.1 MVC project hits the VSTS/Azure Dev OPS build pipeline.  I am able to build  run and interact with the database using entity framework without issue locally using a 2.1 Docker container.  When I check the project in and it hits the CI pipeline the build fails though.  Is this a known issue with VSTS or is there a configuration change I might need to make in the build pipeline?  Or will I need to revert to .net core 2.0?</p>  <blockquote>   <p>Package Microsoft.EntityFrameworkCore.SqlServer 2.1.3 is not   compatible with netcoreapp2.1 (.NETCoreApp Version=v2.1). Package   Microsoft.EntityFrameworkCore.SqlServer 2.1.3 supports: netstandard2.0   (.NETStandard Version=v2.0)       One or more packages are incompatible with .NETCoreApp Version=v2.1.</p> </blockquote>,azure-devops
6537925,"Questions on the Azure scalability targets and the use of multiple Azure storage accounts? <p>The <a href=\http://blogs.msdn.com/b/windowsazurestorage/archive/2010/05/10/windows-azure-storage-abstractions-and-their-scalability-targets.aspx\"" rel=\""nofollow\"">Windows Azure Storage Abstractions and their Scalability Targets</a> blog post indicates there is a 5 000 entities/second transaction limit for a single storage account  and there is a 500 entities/second limit for a single table partition. And to meet the first limit one should used multiple accounts  and for the partition limit one should design their partitions carefully.</p>  <p>I'd like to ask for others who have experience on the 5000 limit to a single storage account.  Right now  I'm designing a community of blogs/wikis and say one day the site becomes popular and attracts a lot of traffic.  Should I split the user related tables to one storage account and blog related tables to another account and yet wiki related tables to another to prevent this limit right now?  Or should I add more accounts as there is a need  by the way is there a way to transfer azure storage tables from one account to another?  The article says when you hit that limit you will get “503 server busy” responses  is there a way to know the limit is getting close so I could something in advance without accully resulting 503 errors?</p>""",azure-storage
46656798,"How to specify source branch name as the target folder in VSTS copy file task? <p>I would like to specify the target folder my packages as <code>c:\\{mybranchname}\\package</code>. </p>  <p><a href=\https://i.stack.imgur.com/9KTh5.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/9KTh5.png\"" alt=\""enter image description here\""></a></p>  <p>Does anybody know how to achieve this?</p>""",azure-devops
50563103,"Azure Function couldnt find document openXML <p>I am new in Azure Functions and i am try to discover some features of it.</p>  <p>So i created function blob trigger  added references of OpenXML sdk in project.json</p>  <pre><code>\frameworks\"": { \""net46\"":{   \""dependencies\"": {     \""WindowsAzure.Storage\"": \""7.0.0\""       \""Open-XML-SDK\"" : \""2.7.2\""      \""DocumentFormat.OpenXml\"" : \""2.8.1\"" </code></pre>  <p>And in run.csx i added next code</p>  <pre><code>using System; using System.IO; using Microsoft.Azure; using Microsoft.WindowsAzure.Storage; using Microsoft.WindowsAzure.Storage.Blob; using DocumentFormat.OpenXml.Presentation; using DocumentFormat.OpenXml.Packaging; using DocumentFormat.OpenXml;  public static  void Run (Stream myBlob  string name  TraceWriter log)  {             // *While we upload a blob  function start to execute*             StreamReader reader = new StreamReader(myBlob);             string S = reader.ReadToEnd();             int numberofSlides = CountSlides(S);             log.Info($\""Number of slides = {numberofSlides}\"");  }   // *here  using XML sdk we open our presentation without using Office*   public static int CountSlides(string presentationFile)         {  using (PresentationDocument presentationDocument =PresentationDocument.Open(presentationFile  false))             {                 return CountSlides(presentationDocument);             }         }          public static int CountSlides(PresentationDocument presentationDocument)         {             if (presentationDocument == null)             {                 throw new ArgumentNullException(\""presentationDocument\"");             }              int slidesCount = 0;              PresentationPart presentationPart = presentationDocument.PresentationPart;             if (presentationPart != null)             {                 slidesCount = presentationPart.SlideParts.Count();             }              return slidesCount;         } </code></pre>  <p>The problem is while i upload a .pptx   i have error in log </p>  <blockquote>   <p>Exception while executing function: Functions.BlobTriggerCSharp1. mscorlib: Exception has been thrown by the target of an invocation. DocumentFormat.OpenXml: Could not find document.</p> </blockquote>  <p>I upload a file .pptx using Microsoft Azure Storage Explorer and I can not understand why i have an error.</p>""",azure-functions
53738898,"Using callback with CosmosDb Node.js SDK? <p>I'm migrating an app from Azure Functions v1 to v2. The old app uses callbacks  and I prefer to stick to it so I won't mess up the app logic.  I need to get data as array  and then within the callback  perform the app logic. However  while using callbacks in Cosmosdb sdk v2.1.1 I get error <code>UnhandledPromiseRejectionWarning: Error: toArray takes no arguments</code>. Cosmosdb documentation doesn't have example of using callbacks in Node.js. Following is my code  could you please tell what's wrong in my code?</p>  <pre><code>const CosmosClient = require('@azure/cosmos').CosmosClient;;  let config = {}  const endpoint = process.env.HOST; const masterKey = process.env.COSMOS_DB_PRIMARY_KEY; config.db_account = process.env.COSMOS_DB_ACCOUNT; config.containerId = \games\""; config.gameCollectionPath = \""dbs/\"" + config.db_account + \""/colls/games\"";  const client = new CosmosClient({   endpoint: endpoint    auth: {     masterKey: masterKey   } });  module.exports = function (context  req  game) {  client.database(config.db_account).container(config.containerId).items.query(querySpec).toArray(function (err  results) {          if (err) {             context.res = {}             context.done();             return;         }         if (my_condition_is_met) {             context.res = {}             context.done();         } } } </code></pre>""",azure-functions
10332295,Azure CloubdBlob's Properties.Length returns 0 <p>The following code returns blob file size of 0:</p>  <pre><code>public long GetFileSize(string fileUrl) {     var blob = GetBlobContainer().GetBlobReference(fileUrl);     return blob == null ? 0 : blob.Properties.Length; } </code></pre>  <p>  its almost as it does not find the blob. But of I delete the blob I see that it gets deleted. This works when deleting:</p>  <pre><code>void DeleteFileFromBlob(string fileUrl  bool deleteSnapshots) {     var blob = GetBlobContainer().GetBlobReference(fileUrl);     if (deleteSnapshots)     {         var options = new BlobRequestOptions { DeleteSnapshotsOption = DeleteSnapshotsOption.IncludeSnapshots };         blob.DeleteIfExists(options);     }     else blob.DeleteIfExists(); } </code></pre>  <p>Its basically the same code as the one above  so it seems that the blob is found.</p>  <p>If I iterate through the blobs I get the correct blob file size  like I do when I calculate the total amount of stored bytes i my storage:</p>  <pre><code>public long GetStorageUsageByteSize() {     var blobClient = GetBlobClient();     return (from container in blobClient.ListContainers()                       select                       (from CloudBlob blob in                            container.ListBlobs(new BlobRequestOptions { UseFlatBlobListing = true })                        select blob.Properties.Length                       ).Sum()                      ).Sum();             } </code></pre>  <p>So  I cant figure out why the CloubdBlob::Properties.Length returns 0 when I use GetBlobReference with a url.</p>,azure-storage
25121267,"SAS Token failed with 403 error while generating for each request using ARR module <p>We are doing an e-Learning application  which plays a course on the browser (inside a div control). The course contains list of static contents such as html  js  css etc.  and media files .mp4. We are hosting the static contents (.html  .js  .css etc) into Azure blob storage and media files into Media Service and CDN. </p>  <p>When user triggers to take a course  the browser first request the Web Role with landing page (Ex: FirstPage.html) and with Course Unique Id - Ex: <a href=\https://cloudservice1.cloudapp.net/course/courseid/firstpage.html\"" rel=\""nofollow\"">https://cloudservice1.cloudapp.net/course/courseid/firstpage.html</a>. We have written a custom ARR Module (<a href=\""http://www.iis.net/learn/extensions/url-rewrite-module/developing-a-custom-rewrite-provider-for-url-rewrite-module\"" rel=\""nofollow\"">http://www.iis.net/learn/extensions/url-rewrite-module/developing-a-custom-rewrite-provider-for-url-rewrite-module</a>)  which receives the request  parse it and generate blob storage url with SAS token using C# code for each file. Then route to blob storage. (we have already passing storage account details to ARR Module using Web.config)</p>  <p>For single user  the course plays fine. But we do the load testing with > 400 user load (with 5 instances)  we are getting many 403 errors (and not all files). If the load is less than 200  we don’t get such issue. </p>  <p>Also  we are using REST code to generate the SAS token. When the SAS token expiration time extending more than 60 min  getting error “Access without signed identifier cannot have time window more than 1 hour”. As the code is exist in ARR Module  unable to refer the Storage Client assembly. This 60 min time interval is for each file request – so there could not be an issue on expiration  but feeling this might be an issue?</p>  <p>Can you please point me what could be the issue and how to solve this. Is the ARR Module caching the SAS token and providing the same even after the expiration time?</p>  <p>Many Thanks  Thirumalai M</p>""",azure-storage
3726543,What is the cheapest cloud non-BLOB storage? <p>I have an iPhone app that must use external cloud db to sync data between users. Data is structured  so BLOB storage will not do. So far the only alternatives that i see are</p>  <ul> <li>Amazon SimpleDB</li> <li>MS Azure Storage (Tables). I didnt get if i could use just Storage and no Azure instances.</li> </ul>  <p>Are there any other similar providers?</p>,azure-storage
57467443,"Deny Azure Disk Encryption decryption/disablement using Azure policy <p>I am trying to create a Deny policy to deny disk decryption (encrypted via Azure Disk Encryption)  but the Deny isn't taking effect. I do see the disks not in compliance though. </p>  <p>Here's the policy below:</p>  <pre><code>{   \properties\"": {      \""displayName\"": \""Prevent disk decryption on virtual machines\""       \""policyType\"": \""Custom\""       \""mode\"": \""All\""       \""description\"": \""VMs once encrypted  should not be allowed to be decrypted\""       \""metadata\"": {        \""category\"": \""Compute\""         \""createdBy\"": \""454393d8-e9f1-424d-8054-52d45c90cf6c\""         \""createdOn\"": \""2019-08-12T15:35:43.7697071Z\""         \""updatedBy\"": \""454393d8-e9f1-424d-8054-52d45c90cf6c\""         \""updatedOn\"": \""2019-08-12T18:41:36.6828893Z\""      }       \""parameters\"": {        \""effect\"": {          \""type\"": \""String\""           \""metadata\"": {            \""displayName\"": \""Effect\""             \""description\"": \""Enable or disable the execution of the policy\""          }           \""allowedValues\"": [            \""Deny\""             \""Disabled\""             \""Audit\""          ]           \""defaultValue\"": \""Deny\""        }      }       \""policyRule\"": {        \""if\"": {          \""anyOf\"": [            {              \""allOf\"": [                {                  \""field\"": \""type\""                   \""equals\"": \""Microsoft.Compute/disks\""                }                 {                  \""field\"": \""Microsoft.Compute/disks/encryptionSettingsCollection.enabled\""                   \""notequals\"": \""true\""                }              ]            }             {              \""allOf\"": [                {                  \""field\"": \""type\""                   \""equals\"": \""Microsoft.Compute/disks\""                }                 {                  \""field\"": \""Microsoft.Compute/disks/encryptionSettings.enabled\""                   \""notequals\"": \""true\""                }              ]            }             {              \""allOf\"": [                {                  \""field\"": \""type\""                   \""equals\"": \""Microsoft.Compute/virtualMachines\""                }                 {                  \""field\"": \""Microsoft.Compute/virtualMachines/storageProfile.osDisk.encryptionSettings.enabled\""                   \""notequals\"": \""true\""                }              ]            }          ]        }         \""then\"": {          \""effect\"": \""[parameters('effect')]\""        }      }    }     \""type\"": \""Microsoft.Authorization/policyDefinitions\""     \""name\"": \""ce6bfec6-c4db-46e0-a475-baf5b81063fc\""  } </code></pre>  <p>I see it as non-compliant  but the Deny doesn't take effect. I can still run \""az vm encryption disable\"". Is Lock the way to go here? Any unexpected issues with using lock on VM OS and Data disks.</p>""",azure-virtual-machine
36057736,Migrate classic Azure resources to new Azure resource manager <p>After switching to the new Azure portal  I see all resources of mine are listed as classic resources. I am googling around to see if it's possible to have classic VM and migrate it to ARM and just hadn't seen anything that stated it was possible.</p>  <p>I tried deleting the class VM but keep the VHD to check if I can attach it to the ARM VM. The result said it doesn't work. </p>  <p>Is there any way that can be used to achieve this ?</p>,azure-virtual-machine
29231558,"Azure VM with VS and SQL Server <p>I am trying to setup a development environment on an azure VM. I require Visual Studio 2013 and SQL Server 2012. The problem is that after installing the SQL Server the performance of the VM decreases drastically. After booting up the VM and opening Visual Studio for the first time I have to wait approx. 10 minutes. After that I can close VS and reopen it in a matter of seconds. I've tried some things described in here: <a href=\https://msdn.microsoft.com/en-us/library/azure/dn133149.aspx\"" rel=\""nofollow\"">https://msdn.microsoft.com/en-us/library/azure/dn133149.aspx</a> (separate disk for sql  disabled georeplication for the storage account  enabled locked pages  enabled instant file initialization)  but it does not seem to help. Oh  I'm using the G1 size (ssd disk).</p>  <p>Any suggestions how to improve the performance?</p>  <p>UPDATE: Further testing has shown that the Sql Server is responsible for the poor performance. Any clues how to make this faster?</p>""",azure-virtual-machine
33841535,"Visual Studio Online Build - web.config connection strings configSource <p>My project <strong>Web.config</strong> has connection strings defined in a separate file using the following construct:</p>  <pre><code>&lt;connectionStrings configSource=\ConnectionStrings.config\""&gt; &lt;/connectionStrings&gt; </code></pre>  <p>This is handy when collaborating on a project or when deploying the project. However  I was unable to get the VSO Build working as it shows me the following error:</p>  <blockquote>   <p>C:\\Program Files   (x86)\\MSBuild\\14.0\\bin\\Microsoft.Common.CurrentVersion.targets (4105    5) Could not copy the file   \""C:\\a\\1\\s\\MyProject\\ConnectionStrings.config\"" because it was not   found.</p> </blockquote>""",azure-devops
56712875,Cron that executes every 5min between 6PM and 8PM during weekdays <p>I wanted to build a cron expression for Azure function timer triggers that executes every 5 minutes interval between 6pm and 11pm during weekdays only.</p>  <p>This is for azure function timer triggered.</p>,azure-functions
50766009,"Azure Functions static SqlConnection - right way to scale? <p>I'm using Azure Functions with queue triggers for part of our workload. The specific function queries the database and this creates problems with scaling since the large concurrent number of function instances pinging the db results in maximum allowed number of Azrue DB connections being hit constantly. </p>  <p>This article <a href=\https://docs.microsoft.com/en-us/azure/azure-functions/manage-connections\"" rel=\""nofollow noreferrer\"">https://docs.microsoft.com/en-us/azure/azure-functions/manage-connections</a> lists HttpClient as one of those resources that should be made static. Should database access also be made static with static SqlConnection to resolve this issue  or would that cause some other problems by keeping the constant connection object?</p>""",azure-functions
47294646,Best way to archive an Azure VM? <p>I want to archive a Azure VM. It's currently deallocated  so we're not incurring compute charges  but we're still paying for the storage  even if it's not online. We want to move the storage to BLOB storage since it's cheaper  as we don't want to lose the data  but don't want to pay a premium to have it sit idle  either.</p>  <p>I tried to create an image  which then deleted the VM instance  but left the disks in-tact without a reference to them.</p>  <p>What's the best way to archive a VM?</p>,azure-virtual-machine
57088774,"Including a NuGet package in an Azure function written in the Portal <p>I have created a new Azure function in the portal  and wanted to use the <code>WindowsAzure.Storage</code> NuGet package.  Given that the default template is created with:</p>  <pre><code>#r \Newtonsoft.Json\"" </code></pre>  <p>I thought I could do this:</p>  <pre><code>#r \""WindowsAzure.Storage\""  </code></pre>  <p>However  when I do  I get the error:</p>  <pre><code>[Error] run.csx(2 1): error CS0006: Metadata file 'WindowsAzure.Storage' could not be found </code></pre>  <p>I can't see anywhere else that <code>Newtonsoft.Json</code> is being referenced.</p>  <p>How can I include this NuGet package in my function (without building this is VS or VS Code and deploying it). Also  what  exactly does the <code>#r</code> directive do  if not bring in external libraries and packages?</p>""",azure-functions
52097418,Azure API Management - Regression testing and Performance testing of APIs <p>Are there any built-in options to perform Regression testing and Performance testing of APIs in Azure API Management? If not  are there any options to do that within the Azure ecosystem (like VSTS Performance tests tool etc.)? Thanks!</p>,azure-devops
57641460,"Set env var for Node JS when launching through VS Code <p>I have Node JS Azure function that when I run locally needs the <code>NODE_TLS_REJECT_UNAUTHORIZED=0</code> environment variable needs setting for my code to work. This is because I am connecting to an emulated Cosmos DB running locally on my machine which require Node to allow for self signed certificates.</p>  <p>I only want this environment variable setting when I run locally as in production I will be using a real (i.e. non emulated) Cosmos DB instance. Rather than putting and <code>#if debug</code> in my code (or the equivalent for a Node Azure Function) I'd like my VS Code project to set the env var when it is launched.</p>  <p>I've trying following <a href=\https://stackoverflow.com/questions/43836861/vs-code-run-command-at-launch-json\"">this answers advice</a> but when VS Code launches the program the environment variable is not set as I get a runtime error in my code about self signed certificates not being authorised. My <code>launch.json</code> looks like this:</p>  <pre><code>{   \""version\"": \""0.2.0\""    \""configurations\"": [     {       \""name\"": \""Attach to Node Functions\""        \""type\"": \""node\""        \""request\"": \""attach\""        \""port\"": 9229        \""preLaunchTask\"": \""func: \""      }    ]    \""environment\"": [{     \""name\"": \""NODE_TLS_REJECT_UNAUTHORIZED\""      \""value\"": \""0\""     }]    }  </code></pre>  <p>If I set the env var directly in code using <code>process.env.NODE_TLS_REJECT_UNAUTHORIZED = 0</code> everything is fine. I don't know how I can get VS Code to set this  or if it is even possible.</p>""",azure-functions
53810316,"Deploy angular 6 app and Web API in same Azure Web app <p>I'm following <a href=\https://stackoverflow.com/questions/51041582/how-to-deploy-angular-6-with-net-core-2-0-web-api-application-to-microsoft-azur\"">this</a> strategy to deploy angular app and web api in the same Azure Web app.</p>  <p>I have Angular app development with VSCode and Web Api in VS 2017. So it's <strong>not</strong> a complete app as in Angular App template from VS 2017</p>  <p>I deployed web api with </p>  <pre><code>services.AddSpaStaticFiles(configuration =&gt; {     configuration.RootPath = \""ClientApp/dist\""; }); </code></pre>  <p>and</p>  <pre><code>app.UseSpa(spa =&gt; {     spa.Options.SourcePath = \""ClientApp\""; }); </code></pre>  <p>Copied built version of angular app to <code>ClientApp/dist</code> folder on Azure Web App. Set azure app's <code>WEBSITE_NODE_DEFAULT_VERSION</code> to <code>10.14.1</code> which available there.</p>  <p>But when I browse the website  I get errors in browser console - </p>  <pre><code>SyntaxError: expected expression  got '&lt;'[Learn More] runtime.js:1 SyntaxError: expected expression  got '&lt;'[Learn More] polyfills.js:1 SyntaxError: expected expression  got '&lt;'[Learn More] styles.js:1 SyntaxError: expected expression  got '&lt;'[Learn More] scripts.js:1 SyntaxError: expected expression  got '&lt;'[Learn More] vendor.js:1 SyntaxError: expected expression  got '&lt;'[Learn More] main.js:1  </code></pre>  <p>I see that  all the requests are getting index.html and not actual .js file.</p>  <p>It seems that angular app with node is not getting fired up.</p>""",azure-web-app-service
38097126,"How to display azure app service's web server log on Azure log Analytics? <p>I have an api application hosted on azure App services. For the web server log (iis logs) I've turned on web server logging from Azure portal. Look at the screenshot below. <a href=\https://i.stack.imgur.com/UnRWD.jpgas\"" rel=\""noreferrer\""><img src=\""https://i.stack.imgur.com/UnRWD.jpgas\"" alt=\""Azure diagnostics logs settings for web server\""></a></p>  <p>For storing web server logging</p>  <p>Server Logs are allowed to be stored on the Azure blob containers only. As per the configuration the logs are stored on blob container as expected. Now I want to use these logs to be displayed on Azure Log Analytics.</p>  <p>I've the following storage configurations on Log Analytics in Azure Web portal. <a href=\""https://i.stack.imgur.com/R8OPt.jpg\"" rel=\""noreferrer\""><img src=\""https://i.stack.imgur.com/R8OPt.jpg\"" alt=\""enter image description here\""></a></p>  <p>On Log Analytics explorer I can view logs from all other sources except the web server (iis logs). What I'm missing here?</p>""",azure-web-app-service
54025797,"SqlQuery in Azure Function ARRAY_CONTAINS not work <p>I defined a function in cosmo db defined as follows. In the editor the query works but when I run the function it return <em>500 Internal Server Error</em>.</p>  <p>My document:</p>  <pre><code>{     \user\"": \""428\""      \""year\"": \""2019\""      \""id\"": \""1\""      \""dataType\"": \""LineString\""      \""dataCategory\"": \""realPath\""      \""tripNumber\"": \""A02232\""      \""currentCoordinate\"": [         13.845224          43.02356     ]      \""deliveries\"": [         {             \""devNumber\"": \""001\""              \""unloadSeq\"": \""1\""              \""currentDev\"": \""1\""              \""email\"": \""punto1@mail.it\""              \""targetCoordinate\"": [                 13.965224                  43.95356             ]              \""coordinates\"": [                 [                     13.790663                      43.028926                 ]                  [                     13.791447                      43.029169                 ]                  [                     13.792198                      43.029561                 ]                  [                     13.793775                      43.030549                 ]                  [                     13.794601                      43.0312                 ]                  [                     13.795577                      43.031835                 ]                  [                     13.797047                      43.032737                 ]                  [                     13.797605                      43.033153                 ]                  [                     13.798249                      43.033647                 ]                  [                     13.798732                      43.03367                 ]                  [                     13.800126                      43.033678                 ]                  [                     13.801661                      43.033725                 ]                  [                     13.802755                      43.034172                 ]                  [                     13.845224                      43.02356                 ]             ]         }          {             \""devNumber\"": \""008\""              \""unloadSeq\"": \""2\""              \""currentDev\"": \""0\""              \""email\"": \""punto2@mail.it\""              \""targetCoordinate\"": [                 13.995224                  43.99356             ]              \""coordinates\"": []         }     ]      \""_rid\"": \""3pRjAIHZRNUBAAAAAAAAAA==\""      \""_self\"": \""dbs/3pRjAA==/colls/3pRjAIHZRNU=/docs/3pRjAIHZRNUBAAAAAAAAAA==/\""      \""_etag\"": \""\\\""00006b08-0000-0000-0000-5c2def460000\\\""\""      \""_attachments\"": \""attachments/\""      \""_ts\"": 1546514246 } </code></pre>  <p>Query in editor it's ok:</p>  <pre><code>SELECT * FROM Trip c where ARRAY_CONTAINS(c.deliveries  {\""currentDev\"": \""1\""  \""email\"": \""punto1@mail.it\""}  true) </code></pre>  <p>Query in function.json don't work:</p>  <pre><code>{   \""bindings\"": [     {       \""authLevel\"": \""function\""        \""name\"": \""req\""        \""type\"": \""httpTrigger\""        \""direction\"": \""in\""        \""methods\"": [         \""get\""          \""post\""       ]        \""route\"": \""getRoutes/{emailpar}\""     }      {       \""name\"": \""$return\""        \""type\"": \""http\""        \""direction\"": \""out\""     }      {       \""type\"": \""cosmosDB\""        \""name\"": \""inDocuments\""        \""databaseName\"": \""cdb-01\""        \""collectionName\"": \""myCollection\""        \""connectionStringSetting\"": \""mpn_COSMOSDB\""        \""direction\"": \""in\""        \""sqlQuery\"": \""SELECT * FROM Trip c where ARRAY_CONTAINS(c.deliveries  {currentDev: '1'  email: {emailpar}}  true)\""     }   ] } </code></pre>  <p>I think it's a syntax problem to defining the parameter and the object to be searched within the array through the brackets {}.</p>""",azure-functions
57407936,I'm trying to restrict access to my Azure webapp to a specific User group <p>My On-prem AD is in sync with Azure AD and Im trying to give access to my Azure hosted website (Webapp) to a specific set of user(AD groups) via seamless login</p>  <p>I alredy tried setting different option avail in App registration but none of them worked as expected</p>,azure-web-app-service
57480503,"Azure cloud based management system for virtual environments orchestration and life cycle management <p>So basically I've been working with the <a href=\https://labs-neway.com/\"" rel=\""nofollow noreferrer\"">Neway Labs</a> for a long time and I kept having issues with this software. For example you can't create an environment template and creating multiple environments for users can take up to 30-60 minutes of waiting.</p>  <p>I was wondering if there is another software like this one that works on Azure and basically does the same things only in which you have the ability to create an environment template and maybe a faster software?</p>""",azure-virtual-machine
50475333,"Add Azure Government storage account in HDInsight <p>I have an HDInsight cluster in Azure Government and want to add an additional storage account that resides in Azure Government. I’m attempting to do this via the portal’s <strong>Script Actions > + Submit New > Add an Azure Storage account</strong> and providing my Azure Government storage account’s name and key. This fails with the error (from the cluster’s output file in <code>/var/lib/ambari-agent/data/output-XXXX.txt</code>):</p>  <pre><code>Key encryption is enabled STORAGE ACCOUNT IS: testgovwebiaasdiag Validate storage account creds: Invalid Credentials provided for storage account ('Start downloading script locally: '   u'https://hdiconfigactions.blob.core.windows.net/linuxaddstorageaccountv01/add-storage-account-v01.sh') Fromdos line ending conversion successful ('Unexpected error:'  \('Execution of custom script failed with exit code'  139)\"") </code></pre>  <p>Looking at the documentation for “<a href=\""https://docs.microsoft.com/azure/hdinsight/hdinsight-hadoop-add-storage\"" rel=\""nofollow noreferrer\"">Add additional storage accounts to HDInsight</a>”  there is no indication that <a href=\""https://docs.microsoft.com/azure/hdinsight/hdinsight-hadoop-add-storage#the-script\"" rel=\""nofollow noreferrer\"">this script</a> supports Azure Government.  What is the recommended path forward? Should I download the script and modify it? If so  what modifications are needed to support Azure Government?</p>""",azure-storage
4874766,"generating images in Azure asp.net <p>I'm currently running a site of a dedicated server but want to scale up using Microsofts Azure cloud platform in the future but im unsure if a certin part of my code will work on azure.</p>  <p>The site consists of a gallery of items with an image for each item. The images are stored in a sqlserver database.</p>  <p>I have created a http handler that caches the images to disk and redirects the request to the image (as shown at the end of the post).</p>  <p>The images are saved into a virtual directory called \imagecache\"" inside my ASP.NET application. (i.e. ~/imagecache/ ).</p>  <p>As the web app will run in many virtual machine instances on the Azure platform the images will need to be shared between the instances right?</p>  <p>So my question really is.. What is the best way of achieving what I already have on that is compatible wit azure?</p>  <p>Thanks</p>  <p>Image gen code..</p>  <pre><code>public class getimage : IHttpHandler {       private static readonly log4net.ILog log = log4net.LogManager.GetLogger(System.Reflection.MethodBase.GetCurrentMethod().DeclaringType);      public void ProcessRequest (HttpContext context) {          try         {              string uniqueid = \""\"";              if(context.Request.QueryString[\""id\""]) uniqueid = context.Request.QueryString[\""id\""].ToString();              string dir = \""~/imagecache/\"";             string image_target_path = dir + \""image-file-\"" + uniqueid + \"".png\"";              byte[] data = null;             context.Response.ContentType = \""image/png\"";              if (!System.IO.File.Exists(context.Server.MapPath(image_target_path)))             {                 if (context.Request.QueryString[\""id\""] != null)                 {                     // get image data from the database                     data = ImageHelper.getDatabaseImageDataByID(Convert.ToInt32(uniqueid));                      using (System.Drawing.Image img = System.Drawing.Image.FromStream(new System.IO.MemoryStream(data)))                     {                         // save image to disk in the virtual dir                         img.Save(context.Server.MapPath(image_target_path));                     }                 }                 else                 {                     // set a sample image if no id is set                     image_target_path = \""~/images/noimage.png\"";                 }             }              // redirect request to image file             context.Response.Redirect(image_target_path  false);          }         catch (Exception ex)         {             log.Error(ex.Message  ex);         }     }      public bool IsReusable {         get {             return false;         }     }  } </code></pre>""",azure-storage
5737343,"How to filter Azure logs  or WCF Data Services filters for Dummies <p>I am looking at my Azure logs in the WADLogsTable and would like to filter the results  but I'm clueless as to how to do so.  There is a textbox that says:</p>  <blockquote>   <p>\Enter a WCF Data Services filter to limit the entities returned\""</p> </blockquote>  <p>What is the syntax of a \""WCF Data Services filter\""?  The following gives me an InvalidValueType error saying \""The value specified is invalid.\"":</p>  <pre><code>Timestamp gt '2011-04-20T00:00' </code></pre>  <p>Am I even close?  Is there a handy syntax reference somewhere?</p>""",azure-storage
55621162,"Azure File Service \PUT Range\"" REST API 'InvalidHeaderValue' error <p>I'm trying to upload a file to Azure File Service using the REST API. After creating the file  the 'put range' request fails with 'InvalidHeaderValue'</p>  <p>So far I've successfully created the file using the documentation found here. <a href=\""https://docs.microsoft.com/en-us/rest/api/storageservices/create-file\"" rel=\""nofollow noreferrer\"">https://docs.microsoft.com/en-us/rest/api/storageservices/create-file</a></p>  <p>After that  I try to put content into the newly created file following the documentation found here. <a href=\""https://docs.microsoft.com/en-us/rest/api/storageservices/put-range\"" rel=\""nofollow noreferrer\"">https://docs.microsoft.com/en-us/rest/api/storageservices/put-range</a></p>  <p>here is an example of the URI I'm using. It look correct next to the example in the doc.</p>  <pre class=\""lang-py prettyprint-override\""><code>uri = 'https://&lt;account&gt;.file.core.windows.net/&lt;share&gt;/&lt;directory&gt;/&lt;file&gt;?comp=range&amp;&lt;sas token&gt;' </code></pre>  <p>I get the content of the file with...</p>  <pre class=\""lang-py prettyprint-override\""><code>with open(file.txt  mode='rb') as fh:     data = fh.read() </code></pre>  <p>My headers look like this...</p>  <pre class=\""lang-py prettyprint-override\""><code>headers = {     'x-ms-write':'update'      'x-ms-date':'Wed  10  Apr 2019 22:14:17 GMT'      'x-ms-version':'2018-03-28'      'x-ms-range':'bytes=0-' + str(len(data))      'Content-Length':str(len(data) + 1) } </code></pre>  <p>Request...</p>  <pre class=\""lang-py prettyprint-override\""><code>requests.put(url  headers=headers  data=data) </code></pre>  <p>The response code I get back is a 400 and the return header is this...</p>  <pre><code>{ 'Content-Length': '322'   'Content-Type': 'application/xml'   'Server': 'Windows-Azure-File/1.0 Microsoft-HTTPAPI/2.0'   'x-ms-request-id': '23642a26-e01a-0049-35da-ef0109000000'   'x-ms-version': '2018-03-28'   'x-ms-error-code': 'InvalidHeaderValue'   'Date': 'Wed  10 Apr 2019 20:14:46 GMT' } </code></pre>  <p>Thanks for help in advance.</p>""",azure-storage
51288840,"How to set Application Insights AuthenticatedUserId for DependencyTelemetry? <p>Within an Azure Function I am submitting custom telemetry.</p>  <pre><code>//First an event EventTelemetry eventTelemetry = new EventTelemetry() {     Name = $\Authenticated user: {portalUser.FullName} - ({portalUser.Id})\"" };  ConfigureTelemetry(eventTelemetry);  TelemetryClient.TrackEvent(eventTelemetry);  //Then a dependency DependencyTelemetry dependencyTelemetry = new DependencyTelemetry() {     Type = \""SOAP\""      Name = name      Target = target      Data = data      Timestamp = DateTime.UtcNow      Success = success };  ConfigureTelemetry(dependencyTelemetry);  TelemetryClient.TrackDependency(dependencyTelemetry);  ...  //Set shared properties void ConfigureTelemetry(ITelemetry telemetry) {     telemetry.Context.Operation.Id = FunctionSettings.InvocationId;     telemetry.Context.Operation.ParentId = FunctionSettings.InvocationId;     telemetry.Context.Operation.Name = FunctionSettings.FunctionName;      telemetry.Context.User.Id = PortalUser.Id.ToString();     telemetry.Context.User.AuthenticatedUserId = PortalUser.Id.ToString(); } </code></pre>  <p>The event and dependency are succesfully tracked in Application Insights  however the <code>DependencyTelemetry</code> is missing the <code>Id</code> and <code>AuthenticatedUserId</code> information.</p>  <p>Is <code>user_id</code> and <code>user_authenticatedid</code> supported for dependencies?</p>  <hr>  <p>In response to questions:</p>  <blockquote>   <p>Do you any TelemetryInitializer or TelemetryProcessor which is   modifying these fields as well?</p> </blockquote>  <p>No. Just what is shown in the code above.</p>  <blockquote>   <p>How do you create the instance of TelemetryClient?</p> </blockquote>  <pre><code>return new TelemetryClient() {     InstrumentationKey = ApplicationSettings.ApplicationInsightsKey }; </code></pre>  <blockquote>   <p>In my opinion you have to set the context for the instance</p> </blockquote>  <p>I have also tried that but same result  in which case my code looks more like this:</p>  <pre><code>void ConfigureTelemetry() {     ...     TelemetryClient.Context.User.Id = PortalUser.Id.ToString();     TelemetryClient.Context.User.AuthenticatedUserId = PortalUser.Id.ToString(); } </code></pre>  <blockquote>   <p>please also share an example for the event and dependency shown in Application Insights's analytics view</p> </blockquote>  <p>In these examples I wasn't trying to set `user_id' but that does work for events.</p>  <p>customEvents</p>  <pre><code>timestamp [UTC] | 2018-07-11T16:14:15.48Z    name | Authenticated user: Cenajog2 Cenajog2 - (127a897f-d16f-e811-810a-3863bb343b78)    itemType | customEvent   operation_Name | TestOperation operation_Id | c03d657f-6b0b-483e-9a32-c592fd2af701  operation_ParentId | c03d657f-6b0b-483e-9a32-c592fd2af701    user_AuthenticatedId | 127a897f-d16f-e811-810a-3863bb343b78  client_Type | PC     client_IP | 0.0.0.0  client_City | London     client_StateOrProvince | England     client_CountryOrRegion | United Kingdom  cloud_RoleInstance | RD00155D8C9B54  appId | 824c86f8-29be-4a01-b242-44bfe1915520     appName | dev iKey | 9921a9e7-0c07-49fd-bd71-a9e76b9906bc  sdkVersion | dotnet:2.5.1-172    itemId | 7b2708c1-8525-11e8-a89a-2fa60245d417    itemCount | 1 </code></pre>  <p>dependencies</p>  <pre><code>timestamp [UTC] | 2018-07-11T16:14:15.48Z    id | yP475Jc3ZwY=    target | Development     type | SOAP  name | RetrieveMultiple  success | True   performanceBucket | &gt;=5min   itemType | dependency    operation_Name | TestOperation operation_Id | c03d657f-6b0b-483e-9a32-c592fd2af701  operation_ParentId | c03d657f-6b0b-483e-9a32-c592fd2af701 client_Type | PC client_IP | 0.0.0.0 client_City | London client_StateOrProvince | England client_CountryOrRegion | United Kingdom cloud_RoleInstance | RD00155D8C9B54 appId | 824c86f8-29be-4a01-b242-44bfe1915520 appName | dev iKey | 9921a9e7-0c07-49fd-bd71-a9e76b9906bc sdkVersion | dotnet:2.5.1-172 itemId | 7b2708c0-8525-11e8-a89a-2fa60245d417 itemCount | 1 </code></pre>""",azure-functions
55079642,Azure Function Timeout with Entity Framework <p>I am trying to create a basic timer function that writes data to a database using Entity Framework  however I get the error:</p>  <blockquote>   <p>System.Data.SqlClient: There is already an open DataReader associated with this Command which must be closed first.</p> </blockquote>  <p>This error occurs when I call <code>context.SaveChanges();</code> </p>,azure-functions
50671880,Azure. Connection to 40.117.211.214 closed by remote host <p>I am currently trying to access the VM on Azure for my Big Data course. I have already set up HortonWorks on Azure. When I try to access the VM from my Ubuntu command line with my password  I get the following error(s):'</p>  <pre><code>isaac@isaac-HP-Laptop-15-bs0xx:~$ ssh isaacaktam@40.117.211.214 isaacaktam@40.117.211.214's password:  Permission denied  please try again. isaacaktam@40.117.211.214's password:  System is booting up. See pam_nologin(8) Connection to 40.117.211.214 closed by remote host. Connection to 40.117.211.214 closed. </code></pre>  <p>And the following too:</p>  <pre><code>isaac@isaac-HP-Laptop-15-bs0xx:~$ ssh -p 8888 isaacaktam@40.117.211.214 ssh_exchange_identification: Connection closed by remote host </code></pre>  <p>So  what do I need to do to solve this? Both of the above ports have everything as Any and *.</p>  <p>Thanks</p>,azure-virtual-machine
29245078,"Convert legacy Azure storage configurationsettingpublisher <p>I am trying to update legacy code  which has been leveraging pre-2.0 WindowsAzure.Storage. In the Application_Start  there is the following:</p>  <pre><code>    protected void Application_Start(object sender  EventArgs e)     {         var connectionString = \\"";          CloudStorageAccount.SetConfigurationSettingPublisher(           (configName  configSettingPublisher) =&gt;           {                connectionString = RoleEnvironment.IsAvailable                   ? RoleEnvironment.GetConfigurationSettingValue(configName)                   : ConfigurationManager.AppSettings[configName];               configSettingPublisher(connectionString);           });     } </code></pre>  <p>Not sure how this is to be converted to the new method...</p>""",azure-storage
52976449,Azure Application Insights with Azure Function. Log Debug not showing up <p>My Azure function is currently logging to Application Insights.</p>  <p>While Logs generated by logger.logInformation line is showing up on Application Insights  logs generated by logger.logDebug line is not showing up.</p>  <p>I heard there is a way to temporarily enable logging through this line by enabling certain logging levels for application insights.</p>  <p>Can someone help me achieve this or direct me towards some documentation?</p>  <p>Thanks :)</p>,azure-functions
48307861,"Read values from local.setting.json while debugging test <p>i don't seem to be able to read anything from this file in an azure functions when running or debugging a test  however it works fine when debugging the whole application locally.. can anyone explain why at all ?</p>  <pre><code>{   \IsEncrypted\"": false    \""Values\"": {     \""xyz\"": 123   } }  var res = ConfigurationManager.AppSettings.Get(\""xyz\""); </code></pre>  <p>ty..</p>  <p>my suspicious is that it is due to the 'debug' being initiated from another project (Test project)  and the local.settings.json does not get bundled up with the project being tested ?</p>""",azure-functions
53398429,"Xamarin build pipeline (ios-android) azuredevops multienvironment <p>I would like to build and deploy a Xamarin app in both iOS and Android. Release in stages to 3 environments (Dev-UAT-Production)</p>  <p>When in release it will distribute to appcenter.</p>  <p>I have added a step in the pipeline before the build takes place to change the value of a constant in class that defines what kind of build I am doing EG \Dev\"" or \""Production\"" etc..</p>  <p>however I cannot find a way in the release pipeline to have some sort of condition</p>  <ol> <li>if(Dev) execute DevStage </li> <li>if(UAT) execute  UAT Stage </li> <li>if(Production) execute  Production Stage </li> </ol>  <p>If the above is not possible I would have to 3 pipelines one of each stage.</p>  <p>Any ideas -link how to achieve the above?</p>""",azure-devops
42534897,"Azure Storage TableQuery result to ArrayList performance (Java) <p>I need to retrieve 50.000 entities from my Azure Storage Table and the result should be put in a <code>List</code>. Retrieving the entities does not take much time but putting them from an <code>Iterable</code> into a <code>List</code> takes relatively long  around 10 seconds. How can I do this in less time?</p>  <p>The following code retrieves the entries and puts them into an <code>ArrayList</code>:</p>  <pre><code>Iterable&lt;T&gt; items = table.execute(tableQuery);  ArrayList&lt;T&gt; result = new ArrayList&lt;T&gt;(); if (items != null) {     for (T item : items) {         result.add(item.getContents());     } } </code></pre>  <p>Only 1000 entries at a time are retrieved but the <code>Iteratable</code> handles this automatically from my understanding. This also seems to be the time consuming part  getting the next 1000 entries each time.</p>  <p>I also tried this with <code>executeSegmented</code> and <code>ResultContinuation</code> tokens:</p>  <pre><code>ArrayList&lt;T&gt; result = new ArrayList&lt;T&gt;(); ResultContinuation token = null;          do {     ResultSegment&lt;T&gt; segment = table.executeSegmented(tableQuery  token);     result.addAll(segment.getResults());     token = segment.getContinuationToken(); } while (token != null); </code></pre>  <p>Here the <code>executeSegmented</code> takes a lot of time.</p>  <p>So these options are both to slow. How can I get higher performance to create this <code>List</code> faster?</p>  <p><strong>Edit</strong></p>  <p>The query is as following:</p>  <pre><code>TableQuery&lt;T&gt; tableQuery = TableQuery.from(classAzure).where(TableQuery.generateFilterCondition(\MerchantId\""  QueryComparisons.EQUAL  merchantId)); </code></pre>""",azure-storage
38026563,"Azure table delete pattern - delete old items <p>I'm working with Azure Table (storage) in order to store information about websites I'm working with. So  I planned this structure:</p>  <ol> <li>Partition Key - domain name</li> <li>Row key - Webpage address</li> <li>Valid until (date time) - after this date  the record will be deleted.</li> <li>Other crucial data here...</li> </ol>  <p>Those columns will be stored in a table called as the website address (e.g. \cnn.com\"").</p>  <p>I have two main use case (high to low):  1. Check if URL \""x\"" is in the table - find by combination of Partition Key and Row Key - very efficient.   2. Delete old data - remove all expired data (according to \""Valid until\"" column). This operation is taking place every mid-night and possibly delete millions of row - very heavy.</p>  <p>So  our first task (check if URL exists) is implemented in efficient way with this data model. <em>The second task  not.</em> I want to avoid batch deletion.</p>  <p>I also worry about making \""hot-spots\""  which will make me low performance. This because the Partition Key. I expect that in some hours  I will query more question for specific domain. This will make this partition hotspot and hit my performance. In order to avoid this  I thought to use hash-function (on the URL) and the result will be the \""partition key\"". Is this good idea?</p>  <p>I also thought about other implementation way and it's looks like they have some problems:</p>  <ul> <li>Storing the rows in table that named with the deletion date (e.g. \""cnn.com-1-1-2016\""). This provide us great deleting performance. But  bad searching experience (the row can be exists in more then one table. e.g. \""cnn.com-1-1-2016\"" or \""cnn.com-2-1-2016\""...). </li> </ul>  <p>What is the right solution for my problem?</p>""",azure-storage
53851749,"Can't seem to add attestation statuss to controls inside Azsk tool in my azure devops pipeline <blockquote>   <p><strong>Context of my environment</strong>: I have run an custom organisation policy where i add these to my azure devops ci/cd pipeline.    Next to that i added the resource group AzSKRG and with the command <code>Get-AzSKAzureServicesSecurityStatus</code>  Been adding attestation statusses to some of the controls I found it not necessary to fail the pipeline. But with the last step I have some problems</p> </blockquote>  <p>I am trying to make some of the manual and verify controls to \passed\"" so that my developing team can run this flawless in the pipeline and i just verify the controls once every 90 days (the expiration days). The problem i have ATM is that i can't add attestation statusses to these controlID's</p>  <p>Azure_APIManagement_AuthZ_Restrict_Caller_IPs Azure_APIManagement_DP_Restrict_Critical_APIs_Access Azure_KeyVault_AuthZ_Grant_Min_Access_policies Azure_APIManagement_DP_Use_Secure_TLS_Version Azure_APIManagement_DP_Dont_Reveal_Backend_Info Azure_APIManagement_AuthZ_Enable_Requires_Approval</p>  <p>for the keyvault i have no clue why i can't add the attestation status. this is my output of my powershell command</p>  <pre><code>================================================================================ AzSK Version: 3.8.0  ================================================================================ Method Name: Get-AzSKAzureServicesSecurityStatus (GRS) Input Parameters:  Name                  Alias Value                                          ----                  ----- -----                                          SubscriptionId        s     xxxxxxxxxxxxxxxxxxxxxxxxxxxxx          DoNotOpenOutputFolder dnof  True                                           ResourceType          rt    Microsoft.KeyVault/vaults                      ResourceGroupNames    rgns  xxxxxxxxxx                            ControlIds            cids  Azure_KeyVault_AuthZ_Grant_Min_Access_policies ControlsToAttest      cta   All                                            AttestationStatus     as    NotAnIssue                                     JustificationText     jt    Quarterly check   You can also use: grs -s xxxxxxxxxxxxxxxxx -dnof  -rt Microsoft.KeyVault/vaults -rgns xxxxxxxx Azure_KeyVault_AuthZ_Grant_Min_Access_policies -cta All -as NotAnIssue -jt Quarterly check   ================================================================================ Running AzSK cmdlet using security policy... Number of resources: 1 Number of resources for which security controls will be evaluated: 1 ================================================================================ Starting analysis: [FeatureName: KeyVault] [ResourceGroupName: xxxxxxxxx] [ResourceName: xxxxxxxxxx]  -------------------------------------------------------------------------------- Checking: [KeyVault]-[All Key Vault access policies must be defined with minimum required permissions to keys and secrets] -------------------------------------------------------------------------------- Completed analysis: [FeatureName: KeyVault] [ResourceGroupName: xxxxxxxxxxxx] [ResourceName: xxxxxxxx]  ================================================================================ Summary  Total Verify -------  ----- ------ High         1      1 ------  ------ ------ Total        1      1 ------  ------ ------ ================================================================================ ** Next steps ** Look at the individual control evaluation status in the CSV file.         a) If the control has passed  no action is necessary.         b) If the control has failed  look at the control evaluation detail in the LOG file to understand why.         c) If the control status says 'Verify'  it means that human judgement is required to determine the final control stat us. Look at the control evaluation output in the LOG file to make a determination.         d) If the control status says 'Manual'  it means that AzSK (currently) does not cover the control via automation OR A zSK is not able to fetch the data. You need to manually implement/verify it.  Note: The 'Recommendation' column in the CSV file provides basic (generic) guidance that can help you fix a failed control. Y ou can also use standard Azure product documentation. You should carefully consider the implications of making the required c hange in the context of your application.  Control results may not reflect attestation if you do not have permissions to read attestation data from AzSKRG -------------------------------------------------------------------------------- Status and detailed logs have been exported to path - C:\\Users\\xxxxxxxx\\AppData\\Local\\Microsoft\\AzSKLogs\\xxxxxxxx\\20181218_171945_GRS\\ ================================================================================ ################################################################################  Starting Control Attestation workflow in bulk mode... -------------------------------------------------------------------------------- Warning:  Please use utmost discretion when attesting controls. In particular  when choosing to not fix a failing control  you are taki ng accountability that nothing will go wrong even though security is not correctly/fully configured.  Also  please ensure that you provide an apt justification for each attested control to capture the rationale behind your deci sion. Do you want to continue (Y/N): Y -------------------------------------------------------------------------------- No. of candidate resources for the attestation: 1 ================================================================================ Info: Starting attestation [1/1]- [FeatureName: KeyVault] [ResourceGroupName: xxxxxx] [ResourceName: xxxxxxxx]  -------------------------------------------------------------------------------- No. of controls that need to be attested: 1 -------------------------------------------------------------------------------- ControlId            : Azure_KeyVault_AuthZ_Grant_Min_Access_policies ControlSeverity      : High Description          : All Key Vault access policies must be defined with minimum required permissions to keys and secrets CurrentControlStatus : Verify  -------------------------------------------------------------------------------- Attestation summary for this resource:  ControlId                                      EvaluatedResult EffectiveResult AttestationChoice ---------                                      --------------- --------------- ----------------- Azure_KeyVault_AuthZ_Grant_Min_Access_policies          Verify          Passed NotAnIssue           Committing the attestation details for this resource... Commit succeeded. -------------------------------------------------------------------------------- Completed attestation: [FeatureName: KeyVault] [ResourceGroupName: xxxxxxx] [ResourceName: xxxxxx]  </code></pre>  <p>```</p>  <p>As for the api management controlID's   I've looked inside my powershell module folder inside <code>C:\\Program Files\\WindowsPowerShell\\Modules\\AzSK\\3.8.0\\Framework\\Configurations\\SVT\\Services</code> And searched for the control ID's in the apimanagement.json But couldn't find it in the json files  Maybe inside the powershell module these control's  are not present and inside the azsk pipeline task they are .</p>""",azure-devops
42750248,How do I setup an azure local domain zone space <p>Is there a way to create a local domain name (i.e. .cloud) inside my azure account to point to internal IPs? (10.0.0.0/16)</p>  <p>Thanks</p>,azure-virtual-machine
48303056,"Issue with APP Service Plan in a Resource Group <p>I'm not trying to delete any App Service Plan or App Service  But I'm seeing “<strong>This resource has a 'delete' lock that prevents us from deleting the resource. Please remove the lock and try again.</strong>” message on our App Service Plans under one Resource Group  Other Resource Group App Service Plans are fine. All App Services are working fine under faulty Resource Group.</p>  <p>While Creating Dashboard using Faulty Resource Group  App Service Plans and App Services are not visible.</p>  <p>Please guide fixing this issue.</p>  <p><a href=\https://i.stack.imgur.com/QmBKt.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/QmBKt.png\"" alt=\""This resource has a &#39;delete&#39; lock that prevents us from deleting the resource.Please remove the lock and try again.\""></a></p>  <p><a href=\""https://i.stack.imgur.com/m6PtO.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/m6PtO.png\"" alt=\""App Service Plans and App Services not Populating here\""></a></p>""",azure-web-app-service
47220441,How does code push cordova get the path of the cordova project in visual studio team services? <p>How does code push cordova get the path of the cordova project in visual studio team services for the step to execute cordova prepare command?</p>,azure-devops
30220613,"Querying Azure Storage - Code issues <p>I am having a problem with the first few lines of code that setup an Azure Table Storage Query.</p>  <p>My code is:</p>  <pre><code>CloudStorageAccount account;  string CloudStorageAccountName = ConfigurationManager.AppSettings[\StorageConnectionString\""];  // Create the table client. Microsoft.WindowsAzure.StorageClient.CloudTableClient tableClient = account.CreateCloudTableClient(); // conflicting  // Create the CloudTable object that represents the \""people\"" table. CloudTable table = tableClient.GetTableReference(\""people\""); // conflicting </code></pre>  <p>The third and fourth lines of code (not comments) call the <code>CreateCloudTableClient()</code> and <code>GetTableReference()</code> respectively. I cannot get these to resolve at the same time. </p>  <p>For the first statement  <code>CreateCloudTableClient()</code> returns a <code>CloudTableClient</code> from the <code>WindowsAzure.StorageClient.dll</code>.  The second statement returns a <code>CloudTable</code> from the same DLL. However  the DLL does not include a class called <code>CloudTable</code>  only the <code>WindowsAzure.Storage.Table.dll</code> does  so there is a compiling error on the line that runs <code>GetTableReference()</code>.</p>  <p>If I change the <code>CloudTableClient</code> assembly to <code>Storage.Table.dll</code>  that throws a compile error on <code>CreateCloudTableClient()</code>. So one way or the other  I can't get it to work  these two DLLs are fighting. This code is referenced my multiple <a href=\""https://stackoverflow.com/a/13647480/1168189\"">articles</a> so I'm not sure what I'm doing wrong. I have tried using <code>var</code> instead of the class references but I have the same problem. Somehow the compiler interprets <code>var</code> as <code>Storage.Table.CloudTable</code> - why? beyond me. I am using the latest version of the SDK (2.7).</p>""",azure-storage
44546073,ASP.NET Core memory consumption while uploading a file to Azure Blob <p>When I upload a file to an Azure Blob  the memory consumption seems quite high. The data below is from a 200 MB file upload. </p>  <pre><code>public async Task&lt;IActionResult&gt; PostFile(IFormFile file) {     var filePath = Path.GetTempFileName();      using (var stream = new FileStream(filePath  FileMode.Create))     {         -&gt; Memory used: 108 MB          await file.CopyToAsync(stream);          -&gt; Memory used: 308 MB          await blockBlob.UploadFromStreamAsync(stream);          -&gt; Memory used: 988 MB     } } </code></pre>  <p>Since the file is already loaded in the stream  I cannot understand the sharp increase in consumed memory caused by UploadFromStreamAsync(). I am using Microsoft.WindowsAzure.Storage 8.1.4 and .NET Core 1.1.</p>  <p>Am I doing anything wrong or is this expected behavior?</p>,azure-storage
57686681,"Azure DevOps build pipeline with hosted agent failing <p>I am pretty new to Azure and TFS and related. So please excuse me if I mix up the terms here.</p>  <p>I am testing the capabilities of Microsoft Team Foundation Server with an on-premise installation. I am not the admin of the server itself  I have admin access to one of the projects inside. </p>  <p>I have a git repo with some python code in this project and I am trying to set up CI build pipeline for this. I am also manually configuring an agent to run this build pipeline. For the timebeing  I am configuring the windows machine that I am working on to run as an agent. I was able to set it up to listen for jobs and also it picks up the job when submitted from the TFS server. (I am running the agent from a cmd.exe window) However  I couldn't get it do even the simplest of command line tasks as part of the build pipeline.</p>  <p>Below is the output of <code>where python</code>:</p>  <pre><code>2019-08-27T14:41:15.1614046Z ##[section]Starting: Find python version 2019-08-27T14:41:15.1623937Z ============================================================================== 2019-08-27T14:41:15.1624042Z Task         : Command Line 2019-08-27T14:41:15.1624091Z Description  : Run a command line script using cmd.exe on Windows and bash on macOS and Linux. 2019-08-27T14:41:15.1624157Z Version      : 2.146.1 2019-08-27T14:41:15.1624203Z Author       : Microsoft Corporation 2019-08-27T14:41:15.1624258Z Help         : [More Information](https://go.microsoft.com/fwlink/?LinkID=613735) 2019-08-27T14:41:15.1625058Z ============================================================================== 2019-08-27T14:41:15.6151701Z Cannot invoke method. Method invocation is supported only on core types in this language mode. 2019-08-27T14:41:15.6151921Z At line:1 char:1 2019-08-27T14:41:15.6151968Z + . ([scriptblock]::Create('if (!$PSHOME) { $null = Get-Item -LiteralPa ... 2019-08-27T14:41:15.6152019Z + ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 2019-08-27T14:41:15.6152077Z     + CategoryInfo          : InvalidOperation: (:) []  RuntimeException 2019-08-27T14:41:15.6152123Z     + FullyQualifiedErrorId : MethodInvocationNotSupportedInConstrainedLanguage 2019-08-27T14:41:15.6152156Z   2019-08-27T14:41:17.7569608Z Cannot invoke method. Method invocation is supported only on core types in this language mode. 2019-08-27T14:41:17.7569833Z At line:1 char:740 2019-08-27T14:41:17.7570630Z + ... Continue' ; Invoke-VstsTaskScript -ScriptBlock ([scriptblock]::Create ... 2019-08-27T14:41:17.7571090Z +                 ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 2019-08-27T14:41:17.7572452Z     + CategoryInfo          : InvalidOperation: (:) []  RuntimeException 2019-08-27T14:41:17.7574051Z     + FullyQualifiedErrorId : MethodInvocationNotSupportedInConstrainedLanguage 2019-08-27T14:41:17.7574178Z   2019-08-27T14:41:17.8271008Z ##[error]Exit code 1 returned from process: file name 'C:\\Windows\\System32\\WindowsPowerShell\\v1.0\\powershell.exe'  arguments '-NoLogo -Sta -NoProfile -NonInteractive -ExecutionPolicy Unrestricted -Command \. ([scriptblock]::Create('if (!$PSHOME) { $null = Get-Item -LiteralPath ''variable:PSHOME'' } else { Import-Module -Name ([System.IO.Path]::Combine($PSHOME  ''Modules\\Microsoft.PowerShell.Management\\Microsoft.PowerShell.Management.psd1'')) ; Import-Module -Name ([System.IO.Path]::Combine($PSHOME  ''Modules\\Microsoft.PowerShell.Utility\\Microsoft.PowerShell.Utility.psd1'')) }')) 2&gt;&amp;1 | ForEach-Object { Write-Verbose $_.Exception.Message -Verbose } ; Import-Module -Name 'C:\\TOOLS\\agent\\_work\\_tasks\\CmdLine_d9bafed4-0b18-4f58-968d-86655b4d2ce9\\2.146.1\\ps_modules\\VstsTaskSdk\\VstsTaskSdk.psd1' -ArgumentList @{ NonInteractive = $true } -ErrorAction Stop ; $VerbosePreference = 'SilentlyContinue' ; $DebugPreference = 'SilentlyContinue' ; Invoke-VstsTaskScript -ScriptBlock ([scriptblock]::Create('. ''C:\\TOOLS\\agent\\_work\\_tasks\\CmdLine_d9bafed4-0b18-4f58-968d-86655b4d2ce9\\2.146.1\\cmdline.ps1'''))\""'. 2019-08-27T14:41:17.8301183Z ##[section]Finishing: Find python version </code></pre>  <p>This command runs fine when I execute it from a commandline interactively in my machine.</p>  <p>Why is the PowerShell getting invoked when the pipeline runs? And why such a long command to execute something so simple?</p>  <p>Thanks in advance for any suggestions you can give.</p>""",azure-devops
30163495,Socket Timeout between Azure websites and Azure VM <p>We have a Azure website and a Linux VM on the Azure Infrastructure.</p>  <p>The Websites opens a socket to the VMs. We have found that from time to time a connection is refused with the following error: ERRTIMEOUT  once this happens  all connections from the same Website affinity to the same VM are refused. Reseting the VM Application or the Reseting the Website application by scaling it up and then down solves the problem.  </p>  <p>Suggestions and solutions are welcomed.</p>,azure-virtual-machine
57478512,"Can't access dockerized python azure function through api? <p>I'm trying access HTTP trigger python function that's running inside Azure container. I've followed the below url </p>  <p><a href=\https://docs.microsoft.com/en-us/azure/azure-functions/functions-create-function-linux-custom-image\"" rel=\""nofollow noreferrer\"">https://docs.microsoft.com/en-us/azure/azure-functions/functions-create-function-linux-custom-image</a></p>  <p>When I'm testing my azure function in python  I'm getting HTTP ERROR 401. How to resolve it and the following is my docker run command</p>  <pre><code>docker run -p 8000:80 -it &lt;dockerid&gt;/mydockerimage:v1.0.0 </code></pre>""",azure-functions
47015802,"What is the certification number for Microsoft VSTS? <p>I want to get certified in Microsoft VSTS. If exists  what's the exam code?</p>  <p>I've seen the TFS ALM: <strong><a href=\https://www.microsoft.com/en-in/learning/exam-70-498.aspx\"" rel=\""nofollow noreferrer\"">70-498</a> [Delivering Continuous Value with Visual Studio Application Lifecycle Management]</strong>. </p>  <p>Does it serve the purpose? Please suggest</p>""",azure-devops
45079077,"Creating a Storage Container from an ARM context <p>I'm trying to setup a new resource group complete with a storage account and a container. All steps work except the container part. From resources online I've read that this API functionality is not ported to the new ARM cmdlets -- are there workarounds available?</p>  <p><strong>Attempt #1</strong></p>  <pre><code>Login-AzureRmAccount  Set-AzureRmContext -SubscriptionName \Visual Studio Professional\""  $resourceGroup = \""MyResourceGroup4\"" $location = \""West Europe\""  New-AzureRmResourceGroup -Name $resourceGroup -Location $location  Write-Host \""Created resource group\""  New-AzureRmStorageAccount -ResourceGroupName $resourceGroup -AccountName \""xzcczxda\"" -Type Standard_RAGRS -Location $location -AccessTier Cool -Kind BlobStorage New-​Azure​Storage​Container -Name \""images\"" -Permission Off </code></pre>  <p>Error:</p>  <blockquote>   <p>New-​Azure​Storage​Container : The term 'New-​Azure​Storage​Container' is not recognized as the name of a cmdlet  function  script file  or operable program. Check the spelling of the name  or if a path was included  verify that the path is correct and try    again.</p> </blockquote>  <p><strong>Attempt #2 (based on <a href=\""https://github.com/Azure/azure-powershell/issues/2100\"" rel=\""nofollow noreferrer\"">this</a>)</strong></p>  <p>same as before but adding <code>Import-Module AzureRM.Storage</code> and using <code>New-​AzureRm​Storage​Container</code> instead.</p>  <p>Error:</p>  <blockquote>   <p>New-​AzureRm​Storage​Container : The term 'New-​AzureRm​Storage​Container' is not recognized as the name of a cmdlet  function  script file  or operable program. Check the spelling of the name  or if a path was included  verify that the path is correct and    try again.</p> </blockquote>  <p><strong>Attempt #3 (based on <a href=\""https://blogs.msdn.microsoft.com/cloud_solution_architect/2016/01/04/fun-with-azure-storage-and-powershell/\"" rel=\""nofollow noreferrer\"">this</a> and <a href=\""https://stackoverflow.com/a/32955678/1864167\"">this</a>)</strong></p>  <pre><code>Login-AzureRmAccount  Set-AzureRmContext -SubscriptionName \""Visual Studio Professional\""  $resourceGroup = \""MyResourceGroup9\"" $location = \""West Europe\"" $storageAccountName = \""teststorageaccount\""  New-AzureRmResourceGroup -Name $resourceGroup -Location $location  Write-Host \""Created resource group\""  New-AzureRmStorageAccount -ResourceGroupName $resourceGroup -AccountName $storageAccountName -Type Standard_RAGRS -Location $location -AccessTier Cool -Kind BlobStorage  Write-Host \""Fetching storage account information\"" $storageKey = (Get-AzureStorageKey -StorageAccountName $storageAccountName).Primary $storageContext = New-AzureStorageContext -StorageAccountName $storageAccountName -StorageAccountKey $storageKey  New-​Azure​Storage​Container -Name \""images\"" -Permission Off -Context $storageContext </code></pre>  <p>Error:</p>  <blockquote>   <p>Get-AzureStorageKey : ResourceNotFound: The storage account 'teststorageaccount' was not found.   New-AzureStorageContext : Cannot validate argument on parameter 'StorageAccountKey'. The argument is null or empty. Provide an argument that is not null or empty  and then try the command again.   New-​Azure​Storage​Container : The term 'New-​Azure​Storage​Container' is not recognized as the name of a cmdlet  function  script file  or operable program. Check the spelling of the name  or if a path was included  verify that the path is correct and try    again.</p> </blockquote>  <p><strong>Attempt #4 (based on <a href=\""http://windowsitpro.com/azure/get-storage-keys-using-powershell-azurerm\"" rel=\""nofollow noreferrer\"">this</a>)</strong></p>  <pre><code>Login-AzureRmAccount  Set-AzureRmContext -SubscriptionName \""Visual Studio Professional\""  $resourceGroup = \""MyResourceGroup10\"" $location = \""West Europe\"" $storageAccountName = \""dasdaaadmb\""  New-AzureRmResourceGroup -Name $resourceGroup -Location $location  Write-Host \""Created resource group\""  New-AzureRmStorageAccount -ResourceGroupName $resourceGroup -AccountName $storageAccountName -Type Standard_RAGRS -Location $location -AccessTier Cool -Kind BlobStorage  Write-Host \""Fetching storage account information\"" $storageKey = (Get-AzureRmStorageAccountKey -Name $storageAccountName -ResourceGroupName $resourceGroup).Value[0] $storageContext = New-AzureStorageContext -StorageAccountName $storageAccountName -StorageAccountKey $storageKey  New-​Azure​Storage​Container -Name \""images\"" -Permission Off -Context $storageContext </code></pre>  <p>Error:</p>  <blockquote>   <p>New-​Azure​Storage​Container : The term 'New-​Azure​Storage​Container' is not recognized as the name of a cmdlet  function  script file  or operable program. Check the spelling of the name  or if a path was included  verify that the path is correct and try    again.</p> </blockquote>  <p><strong>Attempt #5 (based on <a href=\""https://stackoverflow.com/a/33226724/1864167\"">this</a>)</strong></p>  <pre><code>Login-AzureRmAccount  Set-AzureRmContext -SubscriptionName \""Visual Studio Professional\""  $resourceGroup = \""MyResourceGroup11\"" $location = \""West Europe\"" $storageAccountName = \""addadadsadad\""  New-AzureRmResourceGroup -Name $resourceGroup -Location $location  Write-Host \""Created resource group\""  New-AzureRmStorageAccount -ResourceGroupName $resourceGroup -AccountName $storageAccountName -Type Standard_RAGRS -Location $location -AccessTier Cool -Kind BlobStorage Set-AzureRmCurrentStorageAccount -StorageAccountName $storageAccountName -ResourceGroupName $resourceGroup  New-​Azure​Storage​Container -Name \""images\"" -Permission Off </code></pre>  <p>Error:</p>  <blockquote>   <p>New-​Azure​Storage​Container : The term 'New-​Azure​Storage​Container' is not recognized as the name of a cmdlet  function  script file  or operable program. Check the spelling of the name  or if a path was included  verify that the path is correct and try    again.</p> </blockquote>  <hr>  <p>At this point I'm out of ideas. How can I create a storage container from an ARM context? <a href=\""https://social.msdn.microsoft.com/Forums/sqlserver/en-US/9d045e4c-3634-479a-9785-219a12fa84e3/cant-set-default-subscription-throws-error?forum=azurescripting\"" rel=\""nofollow noreferrer\"">This</a> seems to indicate the issue is because I'm mixing ASM and ARM which I hoped would've been resolved by passing around the context (see attempt 3 &amp; 4)</p>""",azure-storage
53593929,"Custom deployment with Azure template <p>I am trying to create a virtual machine from a template in Azure  there are two fields which is blocking me (CIDR field)  can someone please have a look into it. unable to by-pass the notion.</p>  <p><a href=\https://i.stack.imgur.com/r8Qpx.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/r8Qpx.png\"" alt=\""enter image description here\""></a></p>""",azure-virtual-machine
52767300,"How to move azure linked VSTS/DevOps to another account/azure subscription <p>I'm trying to move an VSTS/DevOps instance from one azure environment to another. Is this possible and if it is how do I do this?</p>  <p>So for example Azure environment \A\"" owned by me has resource group \""mydevops\"" with \""devops\"" instance. I want to move this to Azure environment \""B\"" which is owned by a different person/account perhaps if needed including resource group.</p>""",azure-devops
38580186,"Issue running Node app on Azure App Service with engines greater than 6.0.0 <p>There seems to be an Azure issue running Node apps with engines greater than 6.0.0.</p>  <p>It comes up with an error similar to the following:</p>  <pre><code>Error: Not Found at \\\\100.72.114.39\\volume-10-default\\bc07ff16757397422510\\c76bdd71a9f84626a73576980337b6ce\\site\\wwwroot\\config\\express.js:36:15 at Layer.handle [as handle_request] (\\\\100.72.114.39\\volume-10-default\\bc07ff16757397422510\\c76bdd71a9f84626a73576980337b6ce\\site\\wwwroot\\node_modules\\express\\lib\\router\\layer.js:95:5) at trim_prefix (\\\\100.72.114.39\\volume-10-default\\bc07ff16757397422510\\c76bdd71a9f84626a73576980337b6ce\\site\\wwwroot\\node_modules\\express\\lib\\router\\index.js:312:13) at \\\\100.72.114.39\\volume-10-default\\bc07ff16757397422510\\c76bdd71a9f84626a73576980337b6ce\\site\\wwwroot\\node_modules\\express\\lib\\router\\index.js:280:7 at Function.process_params (\\\\100.72.114.39\\volume-10-default\\bc07ff16757397422510\\c76bdd71a9f84626a73576980337b6ce\\site\\wwwroot\\node_modules\\express\\lib\\router\\index.js:330:12) at next (\\\\100.72.114.39\\volume-10-default\\bc07ff16757397422510\\c76bdd71a9f84626a73576980337b6ce\\site\\wwwroot\\node_modules\\express\\lib\\router\\index.js:271:10) at methodOverride (\\\\100.72.114.39\\volume-10-default\\bc07ff16757397422510\\c76bdd71a9f84626a73576980337b6ce\\site\\wwwroot\\node_modules\\method-override\\index.js:65:14) at Layer.handle [as handle_request] (\\\\100.72.114.39\\volume-10-default\\bc07ff16757397422510\\c76bdd71a9f84626a73576980337b6ce\\site\\wwwroot\\node_modules\\express\\lib\\router\\layer.js:95:5) at trim_prefix (\\\\100.72.114.39\\volume-10-default\\bc07ff16757397422510\\c76bdd71a9f84626a73576980337b6ce\\site\\wwwroot\\node_modules\\express\\lib\\router\\index.js:312:13) at \\\\100.72.114.39\\volume-10-default\\bc07ff16757397422510\\c76bdd71a9f84626a73576980337b6ce\\site\\wwwroot\\node_modules\\express\\lib\\router\\index.js:280:7 </code></pre>  <p><strong>Steps to reproduce:</strong></p>  <ol> <li>Follow this <a href=\https://azure.microsoft.com/en-us/documentation/articles/app-service-web-nodejs-get-started/\"" rel=\""nofollow\"">tutorial</a></li> <li>Site runs normally with no <code>engines</code> specified (defaults to 4.2.3 as of this post)</li> <li>Change the <code>engines</code> field to <code>6.2.2</code> or <code>6.3.0</code> --> fails.</li> </ol>  <p>FYI it runs OK with <code>6.0.0</code></p>""",azure-web-app-service
45131880,"Azure Function Queue Trigger falling way behind <p>I'm working on a demo for azure functions using queue triggers.  I created a recursive Sudoku solver to show how to take depth first search and convert to using queued recursion.  The code is on <a href=\https://github.com/spelltwister/Sudoko\"" rel=\""nofollow noreferrer\"">github</a>.</p>  <p>I was expecting it to scale out and process an insane number of messages per second  but it is barely processing 30/s.  The queue is filling up and the utilization seems minimal.</p>  <p><a href=\""https://i.stack.imgur.com/JWRcR.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/JWRcR.png\"" alt=\""Minimal utilization\""></a></p>  <p>How can I get better performance from this?   I tried increasing the batch size in the host.json  but didn't seem to help.  I have over <strong>200k</strong> messages in the queue and it's growing.</p>  <p><strong>Update 1</strong> I tried setting the host.json file as</p>  <pre><code>{   \""queues\"": {     \""visibilityTimeout\"": \""00:00:10\""      \""batchSize\"": 32      \""maxDequeueCount\"": 5      \""newBatchThreshold\"": 100   } } </code></pre>  <p>but request per second remained the same.</p>  <p>I deployed the same function to another instance  but tied it to S4 service plan.  This is able to process about 64 requests per second  but still seems slow.</p>  <p>I can serial process the messages locally way faster than this.</p>  <p><strong>Update 2</strong></p>  <p>I scaled the S4 to 10 instances and each instance is handling about 60-70 requests per second.  But that's insanely expensive to still not be able to process as fast as I can with a single core locally.  The queue used with the service plan functions has <strong>500k</strong> messages piled up.</p>""",azure-functions
17614947,How can I update Azure VM BIOS settings? <p>I have created an AZURE VM with Windows Server 2012 and started RDS installation. </p>  <p>I got stuck while it is asking me to Enable Hardware-Assisted Virtualization on the server  as I could not access BIOS through RDP.</p>  <p>How can I update Azure VM BIOS settings?</p>  <p>Any answers would be appreciated. Thanks in advance.</p>,azure-virtual-machine
40804183,"Release step in VSTS <p>I'm trying to release an ASP.NET MVC application to Azure App Services  I created an Azure Resource Manager Endpoint for that and I end up with this error:</p>  <p><a href=\https://i.stack.imgur.com/SVf11.jpg\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/SVf11.jpg\"" alt=\""enter image description here\""></a></p>  <p>I nead a clear walkthrough of how to deploy an ASP.NET MVC application to Azure from Visual Studio Team Services.</p>""",azure-devops
47396949,Deploy website on iis using VSTS <p>I want to deploy multiple websites on IIS using a single task in VSTS.  How to achieve this? Using a release definition i included a task which deploys the website on IIS. But in this arrangement i need to create as many tasks as many websites are there. what are the ways in which i can use either a JSON file or something and create a single task which reads the website names and port numbers etc from the Json and deploys all websites in one go.</p>,azure-devops
49385776,"Installing Application Insights as an Azure App Service Extension or via NuGet? <p>It's possible to install Application Insights via the extensions section in Azure App Services  but it's also possible to just install the packages via NuGet and define the <code>APPINSIGHTS_INSTRUMENTATIONKEY</code> application setting. You can also do both.</p>  <p>What is the difference?</p>  <p>Edit:</p>  <p>I have found what the differences are between installing the extension or the NuGet packages:</p>  <blockquote>   <p>You can configure monitoring by instrumenting the app in either of two ways:</p>      <p>Run-time - You can select a performance monitoring extension when your web app is already live. It isn't necessary to rebuild or re-install your app. You get a standard set of packages that monitor response times  success rates  exceptions  dependencies  and so on.</p>      <p>Build time - You can install a package in your app in development. This option is more versatile. In addition to the same standard packages  you can write code to customize the telemetry or to send your own telemetry. You can log specific activities or record events according to the semantics of your app domain.</p> </blockquote>  <p>Source: <a href=\https://docs.microsoft.com/en-us/azure/application-insights/app-insights-azure-web-apps#run-time-or-build-time\"" rel=\""nofollow noreferrer\"">https://docs.microsoft.com/en-us/azure/application-insights/app-insights-azure-web-apps#run-time-or-build-time</a></p>  <p>But what if you do both? Will there be anything beneficial about it?</p>""",azure-web-app-service
51803531,"How do I add Authentication/Authorization to an Azure App Service from a .NET desktop app <p>there are lots of \quick starts\"" on how to add authentication/authorization to mobile apps  web pages...but I write desktop apps in WPF and UWP(less frequently). I have written an Azure App Service (webapi from VS 2017) but have not added authentication. It's supposed to be somewhat integrated within the app service but I need a quick start from a WPF app (logging in  passing tokens  setting up the Startup class in my webapi…) That's what I really need.</p>  <p>M</p>""",azure-web-app-service
25164510,Preventing users from uploading malicious files <p>My question is this - When using Azure Storage  is this handled for me or do I have to make sure the user doesnt upload something that could compromise the server?</p>  <p>What should I be protecting myself against when dealing with files and Azure Storage?</p>,azure-storage
50250900,"MFA support for Azure VM connect using Remote desktop <p>We have planned to enable MFA for Azure VM.  We need to know the possibilities for achieve the MFA while connect the Azure VM using Remote desktop connection. </p>  <p>Questions:</p>  <ol> <li>Can we achieve the MFA Security authentication for Azure VM using RDP? <a href=\https://docs.microsoft.com/en-us/azure/active-directory/authentication/multi-factor-authentication\"" rel=\""nofollow noreferrer\"">https://docs.microsoft.com/en-us/azure/active-directory/authentication/multi-factor-authentication</a></li> <li>Is there any Step by step functional tutorials to enable MFA for Azure VM?</li> </ol>  <p>Regards  Mathan Kumar</p>""",azure-virtual-machine
17257377,"Upload to Azure Blob Storage with Shared Access Key <p><strong>UPD: Here is my <a href=\http://tech.trailmax.info/2013/07/upload-files-to-azure-blob-storage-with-using-shared-access-keys/\"" rel=\""noreferrer\"">implemented solution to this problem</a></strong></p>  <p>I'm trying to upload to Azure blob storage via Azure.Storage library (not REST API) and authenticating via Shared Access Key. </p>  <p>I have seen this <a href=\""http://blog.smarx.com/posts/shared-access-signatures-are-easy-these-days\"" rel=\""noreferrer\"">blog post</a>  but the API has changed since the post and now I can't get the same result. </p>  <p>Here is what I have: </p>  <pre><code>var blobClient = new CloudBlobClient(new Uri(blobWithSas.BaseUri)  new StorageCredentials(blobWithSas.Sas));   // here I receive 404 error var blob = blobClient.GetBlobReferenceFromServer(new Uri(blobWithSas.AbsoluteUri));  using (var stream = new FileStream(fullFilePath  FileMode.Open)) {     blob.UploadFromStream(stream); } </code></pre>  <p>Having: </p>  <p><code>blobWithSas.BaseUri</code> = <code>http://127.0.0.1:10000/devstoreaccount1/a6dc9274-6ce1-4095-be6b-e84d1012cb24</code> (Guid is name of the container  already exist  created somewhere else.)</p>  <p><code>blobWithSas.Sas</code> = <code>?sv=2012-02-12&amp;se=2013-06-23T03%3A04%3A53Z&amp;sr=b&amp;sp=w&amp;sig=NaMqgXRMXDFvLAp8LTskgplAKp%2B9LCZzq8WK9Zo35x8%3D</code> (also issued somewhere else in the code)</p>  <p><code>blobWithSas.AbsoluteUri</code> = <code>http://127.0.0.1:10000/devstoreaccount1/a6dc9274-6ce1-4095-be6b-e84d1012cb24/foldername/filename.txt</code></p>  <p>The blob does not exist  I want to upload new file and create a blob. I have \""Server\"" application holding Access Key to Azure Storage Account. Server would issue SAS to clients and clients upload files directly to Azure. So SAS would be only to write  no reading and clients will be creating files where server tells them to (container  folder names)</p>  <p>The problem comes up on <code>GetBlobReferenceFromServer</code> - I get 404 error from Azure Storage. Yes  the blob does not exist and there is no reference. So given CloudBlobClient  how can I upload a file to a blob?</p>  <p>p.s. I realise there is REST API for these things. But I've used <code>Microsoft.WindowsAzure.Storage</code> library before and would like to avoid REST service if possible.</p>""",azure-storage
48057324,"Fault tolerance in Copy Activity by skipping incompatible rows <p>I use Azure Fucntion with Azure SDK and Azure Data Factory  <strong>is there any way to get value of skippedRowCount</strong> of Activity Window when applying \log the incompatible rows\"" in Copy Activity (Source: Blob Storage  Sink: SQL Data Warehouse)?</p>""",azure-functions
51910156,v2 Function no longer sees function when running <p>Had an Azure Function in the v2 preview. It used to work just fine and recently just stopped working without me making any changes. When I run it locally it only shows my Http functions  and if I have no Http functions I'll get an </p>  <blockquote>   <p>No job functions found. Try making your job classes and methods public. If you're using binding extensions (e.g. ServiceBus  Timers  etc.) make sure you've called the registration method for the extension(s) in your startup code (e.g. config.UseServiceBus()  config.UseTimers()  etc.).</p> </blockquote>,azure-functions
54858701,"Azure Function  returning status code + JSON  without defining return in every part of logic <p>I have an Azure Function 2.x that reside on a static class that looks like this</p>  <pre><code>[FunctionName(\Register\"")] public static async Task&lt;IActionResult&gt; Run([HttpTrigger(AuthorizationLevel.Anonymous  \""post\"")]HttpRequest req  ILogger log) {     MyTypeClass defReturn = new MyTypeClass();     HttpStatusCode defCode = HttpStatusCode.BadRequest;      /*     * Logics that might or might not changes     * defReturn and defCode value     */      return StatusCode((int) defCode  JsonConvert.SerializeObject(defReturn)) } </code></pre>  <p>How can i achieve the <code>return StatusCode((int) defCode  JsonConvert.SerializeObject(defReturn))</code> part ? is there any such method or equivalent in Azure Functions 2.x ? </p>  <p>in Azure Functions 1.x i can do the equivalent with <code>req.CreateResponse(defCode  defReturn)</code> where <code>req</code> is <code>HttpRequestMessage</code>   but i'm trying to stick with 2.x template/standard</p>  <p>Additional explanation : The said Code should return <code>HTTP 400 Bad Request</code> with the <code>defReturn</code> as it's response body to the client. But when i change the <code>defCode</code> to <code>HttpStatusCode.Accepted</code>  it should return <code>HTTP 202 Accepted</code> with the same response body. How can i achieve this ?</p>  <p>Additional explanation#2 : (If i remember correctly) in ASP.NET Core 1.x i can exactly do like that  returning <code>IActionResult</code> by calling a static method <code>StatusCode</code> not <code>StatusCodes</code> (which is a static class that contains HTTP codes constants</p>  <p>Thank you</p>""",azure-functions
5942326,"Azure Table and Entity Inheritance <p>Let's say I'm building a database for vets and animals they care for. I have following entities:</p>  <p>class Animal : TableServiceEntity<br> class Dog : Animal<br> class Cat : Animal</p>  <p>Dog and Cat each has unique properties. And I have a Azure Table called Vets with vet.Guid as partition key and \Dog_\"" + dog.Guid or \""Cat_\"" + cat.Guid as row key. If I were to retrieve everything by using AsTableServiceQuery() can I then cast an animal entity to Dog or Cat with those unique properties intact?</p>  <p>In broader sense  what's everyone's take on the trade offs in these kinds of situations? Between keeping Dog and Cat in one table for efficient querying but extra step in business layer and have separate tables with extra query but less messy code?</p>""",azure-storage
46810265,"How does the extension get the secret information about the build task in Team Foundation Server extension <p>Reading the vsts document  using nodejs to develop a build task extension   but can not get the task related to the confidential configuration information.</p>  <ol> <li>I configured a remote git build task in tfs server  global variables only get git url and branch no git username and password.How to get other infomation.below code</li> </ol>  <p>```</p>  <pre><code>import tl = require('vsts-task-lib/task');  console.log(tl.getVariables()); </code></pre>  <ol start=\2\""> <li><p>There is no password type due to the build task configuration option in the variable configuration which adds a variable and encryption then get $(password) is null.How do I define a ciphertext configuration in plain text to my plugin processing code.</p></li> <li><p>Task with a dynamic property getting data from an endpoint REST data source How to send post requests  and how handle the different data format returned by endpoint server.<a href=\""https://docs.microsoft.com/zh-cn/vsts/extend/develop/service-endpoints\"" rel=\""nofollow noreferrer\"">endpoint demo</a></p></li> </ol>  <p>sorry many question</p>""",azure-devops
44325221,Virtual Machine Scale Sets <p>I have a test azure subscription  I have created a Virtual Machine Scale Sets.</p>  <p>There are no errors in the scale set.</p>  <p>How do I connect to VM's and make my server to put in a load?</p>  <p>Can I connect with RDP to my Scale set VM's ? is this allowed?</p>,azure-virtual-machine
53918988,"how to enforce singleton behavior on a timer-triggered function? <p>I want my Azure Function to look at an SFTP folder  and move new files to their parent folders. </p>  <p>My scaffolding looks like this. </p>  <pre><code>public static class OnMoveFilesHttpTriggered {     [FunctionName(\OnMoveFilesHttpTriggered\"")]     public static void Run([TimerTrigger(\""0 */5 * * * *\"")]TimerInfo myTimer  ILogger log)     {         log.LogInformation($\""C# Timer trigger function executed at: {DateTime.Now}\"");     } } </code></pre>  <p><strong>How do we enforce that there will be one and only one instance of this function running at any given time?</strong></p>""",azure-functions
55481074,"Azure App Service Plan - What does minutes/day mean? <p>I have ASMX webservice with 1 MSSQL Database and a Single Table. I have currently deployed it to Azure in the <strong><em>App Service</em></strong> I have upgraded from Free Trial to Pay Per Use Plan. I'm really confused with the <strong><em>App Service Plan</em></strong></p>  <p><a href=\https://i.stack.imgur.com/KIAfY.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/KIAfY.png\"" alt=\""enter image description here\""></a></p>  <p>The ASMX Service is called by a Desktop application and it only has a few methods just to fetch and return data from database.At max 100 users will be using it and may be a maximum of 1000 method calls may be made.</p>  <p>What does 60 minutes/day mean? The webservice can function for only 60 minutes? I'm really confused.Please advice</p>""",azure-web-app-service
42489962,Azure Functions Billing Async Methods <p>When using Azure Functions based on a Consumption Based Plan that preform an <code>async</code> task  are you billed at the same rate if you <code>await</code> them vs. not <code>awaiting</code>?</p>,azure-functions
50566909,Visual Studio Online Build - nuget restore works on one agent  fails on another <p>I have two build servers  registered as agents in Visual Studio Online.</p>  <p>They both build everything but one solution just fine.</p>  <p>I have a git repo with dotnet core2 code  that references some nuget packages in a private nuget feed. The private nuget feed is confirmed working from both servers.</p>  <p>One server runs in interactive mode (server a)  the other as a service (server b).</p>  <p>Server a - everything works. Server b - build always fails with this error:</p>  <blockquote>   <p>error NU1101: Unable to find package . No packages exist with this id in source(s): Microsoft Visual Studio Offline Packages  nuget.org [C:\Agent_work\13\s\MyProject\MyProject.APIWeb.Tests\MyProject.APIWeb.Tests.csproj]</p> </blockquote>  <p>I get this same error once for every project in the solution  that uses said nuget package.</p>  <p>Q: What am I missing here? Why is it trying to restore from a local cache on one server  but not the other one? Is there a kind of configuration  I need to make?</p>,azure-devops
54879762,"How to check if multiple files exists in azure container <p>To check if single blob exists in azure container we have below solution  </p>  <pre><code>public bool DoesFileExistsInContainer(string fileName  string containerName)     {         try         {             if (fileName == null)             {                 throw new ArgumentException(\File name to be moved is empty\"");             }             CloudBlobContainer containerReference = blobClient.GetContainerReference(containerName);             CloudBlockBlob blob = containerReference.GetBlockBlobReference(fileName);              bool isFileExist = blob.Exists();                             return isFileExist;         }         catch (StorageException ex)         {             Logger.LogError(\""error while checking if blob exists : {0}\"" + ex);             throw;         }     } </code></pre>  <p>But I want to check if multiple files do exists in azure container or not? </p>  <p>string[] filesToSearchInBlob = {\""file1.xml\""  \""file2.xml\""  \""file3.xml\""};</p>  <p>IS there an efficient way to check other than in foreach loop.. ?  using LINQ? can we do it in better way? </p>  <p>Thanks in advance</p>  <p>Vinu</p>""",azure-storage
55187593,Setup data used by Azure Log Analytics with Azure Fucntions <p>I have questions on setting up data used Azure Log Analytics for Azure Functions.</p>  <p>I cannot see options related to setting up Log Analytics or see information about it within Azure Functions.</p>  <p>But I can open Log Analytics where I can enter query to return data.</p>  <p>I created a Log Analytics Workspace  but am not sure if it is useful for Azure Functions with Log Analytics.</p>  <p><strong>Questions</strong></p>  <p>1 What data is Log Analytics based on by default?</p>  <p>2 Do I need to specify or turn on the logging data Log Analytics is based on?</p>  <p>Put it simply  how to setup for Log Analytics with Azure Functions.</p>,azure-functions
49161601,"Function host is not running <p>I have a Function App in azure and when I hit the URL of the function app it says \Function host is not running.\"" I am not sure where I have to check and what needs to be changed. I tried restart but still no luck.</p>""",azure-functions
44663652,Creating Azure Storage Account VerySlow <p>We are testing a set of PS scripts to create several Azure artifacts: - Storage Accounts - SQL Servers - Service Bus - App Services - AppInsights - IOT Hub</p>  <p>The performance is very variable.  For example  sometimes creating the StorageAccounts take a second or three (we create 2)  and sometimes it takes 20 minutes+.  All our resources are in US East; we are using the <code>New-AzureRmxxx</code> PS commands.</p>  <p>Is this typical?  How do others investigate such issues in addition to confirming there are no outages via the Azure Health dashboards?</p>,azure-storage
53227281,"Azure storage's Python module not found when running in PyCharm debugger <p>When I debug some code in PyCharm I encounter a module not found error  even though the package is installed and the import is valid:</p>  <pre><code>from azure.storage.blob.blockblobservice import BlockBlobService  ModuleNotFoundError: No module named 'azure.storage' </code></pre>  <p>The above does not happen when I launch the code from PyCharm (i.e. Run instead of Debug)  so my initial suspicion is that this is something particular to the debugger. The <code>azure-storage</code> package is the only one I've seen to cause this trouble so it may be that the packaging is somehow goobered and causing the problem. (I suspect this because <a href=\https://github.com/Azure/azure-storage-python/issues/262\"" rel=\""nofollow noreferrer\"">I'm not the first to experience something like this.</a>)</p>  <p>I can successfully run the above import command in PyCharm's Python Console  as well as when using vanilla Python within a terminal window (i.e. this issue seems to be specific to only the PyCharm debugger).</p>  <p>I have installed <a href=\""https://github.com/Azure/azure-storage-python\"" rel=\""nofollow noreferrer\"">azure-storage</a> via PyPI into the Anaconda virtual environment used by the PyCharm project. I can see the package(s) when I list the installed packages:</p>  <pre><code>$ conda list | grep azure azure-common              1.1.16                    &lt;pip&gt; azure-storage-blob        1.3.1                     &lt;pip&gt; azure-storage-common      1.3.0                     &lt;pip&gt; azure-storage-nspkg       3.0.0                     &lt;pip&gt; </code></pre>  <p>What's interesting is that none of the azure packages show up in the listing of installed packages for the project's interpreter in PyCharm. So in a sense  the packages aren't found by PyCharm  even though they're clearly installed in the Anaconda virtual environment being used as the interpreter for the project.</p>  <p>I have installed and reinstalled <code>azure-storage</code> a number of ways suggested in other SO posts and GitHub issue comments  and finally going with the PyPI installation described on the main project page has led to no better results.</p>  <p>I am seeing this behavior on Ubuntu 18.04  the Python version is 3.6.</p>  <p>Can anyone advise as to what may be causing this issue  and/or a way around it? Thanks in advance for your insight/suggestions.</p>""",azure-storage
33361826,"Connection reset at java.net.SocketInputStream.read(Unknown Source) - Node.js - Azure File Service <p>We are try to create a service using node.js in Azure to download. We are sending writeStream in response. </p>  <p>Updated:</p>  <pre><code>var option = new Object(); option.disableContentMD5Validation = true; option.maximumExecutionTimeInMs = 20 * 60000; fileService.getFileToStream(shareName  dirPath  fileName  response  option  function (error  result  response) {     if(!error) {         if(response.isSuccessful) {       console.log(\Success!\"");   }     } }); </code></pre>  <p>While downloading files less than 4MB its working fine. But while downloading more than 4MB its giving error.</p>  <pre><code>java.net.SocketException: Connection reset at java.net.SocketInputStream.read(Unknown Source) at java.net.SocketInputStream.read(Unknown Source) at sun.security.ssl.InputRecord.readFully(Unknown Source) at sun.security.ssl.InputRecord.read(Unknown Source) at sun.security.ssl.SSLSocketImpl.readRecord(Unknown Source) at sun.security.ssl.SSLSocketImpl.readDataRecord(Unknown Source) at sun.security.ssl.AppInputStream.read(Unknown Source) at java.io.BufferedInputStream.fill(Unknown Source) at java.io.BufferedInputStream.read1(Unknown Source) at java.io.BufferedInputStream.read(Unknown Source) at sun.net.www.MeteredStream.read(Unknown Source) at java.io.FilterInputStream.read(Unknown Source) at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(Unknown Source) at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(Unknown Source) at FileserviceTest.sendGET(FileserviceTest.java:58) at FileserviceTest.main(FileserviceTest.java:18) </code></pre>  <p>Below is the sample java client code.</p>  <pre><code>    public static void sendGET() throws IOException {     FileOutputStream fos = null;      URL obj = new URL(\""https://crowdtest-fileservice.azure-mobile.net/api/files/\"");     HttpURLConnection con = (HttpURLConnection) obj.openConnection();     con.setRequestMethod(\""GET\"");     con.setRequestProperty(\""sharename\""  \""newamactashare\"");     con.setRequestProperty(\""directorypath\""  \""MaheshApp/TestLibrary/\"");     con.setRequestProperty(\""filename\""  \""Test.apk\"");      int responseCode = con.getResponseCode();     System.out.println(\""GET Response Code :: \"" + responseCode);     if (responseCode == HttpURLConnection.HTTP_OK) { // success         fos = new FileOutputStream(\""C:/Users/uma.maheshwaran/Desktop/Test.mt\"");         InputStream iin = con.getInputStream();          byte[] buffer = new byte[4096]; // declare 4KB buffer         int len;          // while we have availble data  continue downloading and storing to         // local file         while ((len = iin.read(buffer)) &gt; 0) {             fos.write(buffer  0  len);         }         iin.close();         fos.close();          // print result         System.out.println(\""Done\"");     } else {         BufferedReader br = new BufferedReader(new InputStreamReader(con.getErrorStream()));         String line = \""\"";         while ((line = br.readLine()) != null) {             System.out.println(line);         }         System.out.println(\""GET request not worked\"");     }  } </code></pre>  <p>Can we convert write stream to buffer stream. If so how can we send that in response. Or is there any other way to send a large stream of data in response. Please help me on this. I am new to node.js.</p>""",azure-storage
41923827,Can you do in-place updating/upgrading of Azure VM Operating System? <p>Is there a way to do in-place update the OS of an Azure VM  from within the Azure Portal?<br/> <em>i.e.</em> from Windows Server 2012 R2 to Windows Server 2016</p>,azure-virtual-machine
36402899,Same Table  Notification Hub and server for two apps <p>We got caught by Microsoft's abandonment of Silverlight and focus on UWP. This has ended up with us having to develop two dually focused apps (UWP and Silverlight)  which has left us with two apps that cannot be bundled/packed together. We have therefore decided to have of the apps as a companion app. </p>  <p>Both apps use authentication  at present time it is with Microsoft authentication. The services used for authentication is of the type <code>Azure App Service - Mobile</code>. The services besides authentication also provides interfaces to a notification hub  blob storage and SQL storage. </p>  <p>The question is therefore is it possible to have one <code>App Service - Mobile</code> (not mobileservice)  and authenticate two different apps using the same service? Additionally can the same Notification Hub be used to send notifications towards different apps?</p>  <p>Or is it needed that we create two different services for each application to facilitate the use of authentication and push messages. Then we can link the same database to the two <code>App Service - Mobile</code> ? But this would leave the issue of the notification hubs not having the same registrations ?</p>,azure-web-app-service
48296871,Referencing .NET 4.7.1 library using Azure Storage from ASP.NET Core 2 MVC App <p>In my solution I have an ASP.NET Core 2 MVC app using Razor pages  a Web API 2 app and a .NET 4.7.1 class library containing services and their definitions that use Azure Table Storage from the Azure Storage NuGet (v8.7.0). I'm using autofac for dependency injection.</p>  <p>I have hooked up both my web apps to use classes from my library using Autofac's dependency injection. The Web API app works fine but the Core app doesn't. When I build <strong>without</strong> installing the Azure Storage NuGet package into the Core app I get the following error:</p>  <blockquote>   <p>X.Library' with identity 'X.Library  Version=1.0.0.0  Culture=neutral    PublicKeyToken=null' uses 'Microsoft.WindowsAzure.Storage    Version=8.7.0.0  Culture=neutral  PublicKeyToken=31bf3856ad364e35'   which has a higher version than referenced assembly   'Microsoft.WindowsAzure.Storage' with identity   'Microsoft.WindowsAzure.Storage  Version=8.1.4.0  Culture=neutral    PublicKeyToken=31bf3856ad364e35</p> </blockquote>  <p>Which leads me to believe that ASP.NET Core 2 apps have Azure Storage pre-installed - I can't find any reference to it in the project though! Weird.</p>  <p>So I have tried to fixed this by installing the Azure Storage (v8.7.0) package which matches the version installed in the library I am using into my Core app. The app now builds and my dependencies are injected <strong>but</strong> when I try to use them I get <code>MissingMethodExceptions</code> for the methods <code>CreateIfNotExists</code> and <code>CreateQuery</code>. While my Web API app can query Azure Table Service my Core app can't use the same methods to do so.</p>  <p>After some research it seems that the ASP.NET Core implementation of the Azure Storage library has removed some synchronous methods and at runtime it uses this version rather than the .NET Framework compatible version my library references.</p>  <ol> <li>Is there any way to remove Azure Storage from the ASP.NET Core 2 app? Is it preinstalled  as I suspect?</li> <li>I guess the easiest way to fix it is to use methods that are present in the Framework and Core implementations  is this how you'd fix it?</li> </ol>,azure-storage
54797229,TFSMigrator error: non interactive login is not yet supported in this tool <p>When I run TFSMigrator (16.132.28529.3) using the /tenantDomainName parameter  it get the following error:</p>  <pre><code>[Error  @15:55:31.963] Non interactive login is not yet supported in this tool </code></pre>,azure-devops
36164142,"Why can't I edit or delete a blob on Azure? <p>I've been given a website hosted by Azure.  The data for the site is stored in blobs instead of tables.  Our client wants us to edit one of those blobs.  I downloaded the blob through Visual Studio  edited it in a text editor (I've tried Notepad  Notepad++  and Wordpad)  and then uploaded it through Visual Studio.  The upload seems to work  but when I view the website  the data hasn't changed.  I'm guessing that either the data isn't being uploaded correctly or that there is a cache that is restoring the original data.  Any suggestions on what's going on?</p>  <p>Here's something else I tried that may point to the problem.  I tried deleting the blob entirely and it reappeared after I viewed the website.</p>  <p>So here's the blob originally.  Note that the modified time is 7:23:15 PM. <a href=\https://i.stack.imgur.com/yLTSL.jpg\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/yLTSL.jpg\"" alt=\""enter image description here\""></a></p>  <p>I select the blob and then click the red X.  I get a confirmation message and choose yes.</p>  <p><a href=\""https://i.stack.imgur.com/F40qI.jpg\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/F40qI.jpg\"" alt=\""enter image description here\""></a></p>  <p>I choose yes and the blob seems to be gone.</p>  <p><a href=\""https://i.stack.imgur.com/MHoZk.jpg\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/MHoZk.jpg\"" alt=\""enter image description here\""></a></p>  <p>I then go to the website and navigate to the page that uses the blob data.  The blob has reappeared!  Note the time is now 7:53:01 PM which is about the time I opened the website.</p>  <p><a href=\""https://i.stack.imgur.com/cwn2V.jpg\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/cwn2V.jpg\"" alt=\""enter image description here\""></a></p>  <p>What is going on here and how can I edit a blob without my changes being overwritten?</p>""",azure-storage
50573988,"Handle a POST request in Azure Function to upload a file to blob storage <p>I'm trying to upload a file via simple Azure function HTTPTrigger in JS and it gives me the following error:</p>  <pre><code>[Error] Exception while executing function: Functions.HttpTriggerJS1. Microsoft.Azure.WebJobs.Host: Microsoft Azure WebJobs SDK '[Hidden Credential]' connection string is missing or empty. The Microsoft Azure Storage account connection string can be set in the following ways: 1. Set the connection string named '[Hidden Credential]' in the connectionStrings section of the .config file in the following format &lt;add name=\[Hidden Credential]\"" connectionString=\""DefaultEndpointsProtocol=http|https;AccountName=NAME;AccountKey=KEY\"" /&gt;  or 2. Set the environment variable named '[Hidden Credential]'  or 3. Set corresponding property of JobHostConfiguration. </code></pre>  <p>I'm not sure where to find and edit the .config file or add an environment variable. The connection string is already added to the <code>function.json</code> file as seen below.</p>  <p>Also  I don't know whether just <code>context.bindings.outputBlob = req.body; </code> is enough to create a blob in the storage container with <code>content-type': 'application/octet-stream'</code>.</p>  <p>index.js:</p>  <pre><code>module.exports = function (context  req) {   context.log('JavaScript HTTP trigger function processed a request.');   context.bindings.outputBlob = req.body;   context.res = {   // status: 200  /* Defaults to 200 */   body: \""Uploaded \""    };   context.done();  }; </code></pre>  <p>function.json</p>  <pre><code>{   \""bindings\"": [     {       \""authLevel\"": \""function\""        \""type\"": \""httpTrigger\""        \""direction\"": \""in\""        \""name\"": \""req\""        \""route\"": \""FileUploadNode/{filename}\""        \""methods\"": [         \""post\""       ]     }      {       \""type\"": \""http\""        \""direction\"": \""out\""        \""name\"": \""res\""     }      {       \""type\"": \""blob\""        \""name\"": \""outputBlob\""        \""path\"": \""CONTAINER-NAME/{filename}\""        \""connection\"": \""SOME CONNECTION STRING\""        \""direction\"": \""out\""     }   ]    \""disabled\"": false } </code></pre>""",azure-functions
13350284,"Can't recreate Virtual Machine after usage was exceeded (now paid for) <p>I was using the free evaluation of Windows Azure Virtual Machines to see if my company could switch from our local cloud service providers to a Windows Azure. Today I've exceeded the usage limit (forgot to stop/delete one spurious VM created for testing only). The main VM was disconnected and its disk stored in storage account (which didn't exceeded the limit  as this is  after all  a test and usage is very low). Since I need the disk  and most importantly  the data inside it as it has performance information and even some production data that should never have ended up on that test VM  but... anyway  I'm not being able to:</p>  <p>1) Reuse the old DNS. Even the VM being removed  when I try to create a new one and select the old DNS it tells me the old DNS is already in use (xpihomo.cloudapp.net)</p>  <p>2) I can't create a virtual machine  it keeps getting me errors like this: \The server encountered an internal error. Please retry the request. The long running operation tracking ID was: 9439ecfa765c4d6d94bd9238a6e579a1.\""</p>  <hr>  <p>UPDATE 2: I've deleted the Cloud Services  now I can reuse the DNS  but I still can't recreate the VM. It now gives this error: A lease conflict occurred with the blob <a href=\""https://portalvhds4bqgghbw63gp9.blob.core.windows.net/vhds/lucasoft-eval-eval-vm-2012-10-25.vhd\"" rel=\""nofollow\"">https://portalvhds4bqgghbw63gp9.blob.core.windows.net/vhds/lucasoft-eval-eval-vm-2012-10-25.vhd</a>. The long running operation tracking ID was: 97c64baeebce4c2d8e4a3c9661ef0130.</p>  <hr>  <p>I'm also very disappointed that I only have a forum to ask for guidance and support. And can't imagine how I would proceed if this issue involved sensitive information? Post it on a forum for everyone to see?</p>  <p>And even worse: the forum software insists on using pt-br as its locale (I'm from Brazil) and in the pt-br forums there is no Virtual Machine Preview dedicated forum! I've posted this same message there but I'm not hoping to get any answers. </p>  <p>Does anyone know what may be going on that is preventing the VM creation? </p>  <p>And  as an extra question  does anyone know if Amazon services suffer from the same (lack of) support issues?</p>  <p><strong>UPDATE</strong>: I've found an answer for (1):</p>  <p><a href=\""http://social.msdn.microsoft.com/Forums/pl-PL/WAVirtualMachinesforWindows/thread/ba1c873d-d86f-48aa-8ab2-98a058b7fdcd\"" rel=\""nofollow\"">http://social.msdn.microsoft.com/Forums/pl-PL/WAVirtualMachinesforWindows/thread/ba1c873d-d86f-48aa-8ab2-98a058b7fdcd</a></p>  <p>When the VM instance is deleted the Cloud Service used to run it is not deleted automatically  and it keeps a hold on the DNS. If you want to reuse the same DNS you'll have to delete the cloud service entry... But would it delete the data from my VM? I don't think so  as it is stored in a separate VHD  but I just can't take the risk right now of deleting it...</p>""",azure-virtual-machine
55449147,How to handle dbContext in azure functions? <p>I am writing an Azure function V2 in C# (ASP.NET core). I want to write REST API which performs database operations using EF. How to manage the dbContext so that it will work on local machine and cloud as well.</p>,azure-functions
56411544,"Difference between ILogger  ILoggerFactory and ILogger<> with MS logging on Azure Functions 2 <p><strong>Update</strong></p>  <p>What is the difference between ILoggerFactory and ILogger&lt;> with MS logging on Azure Functions 2  which supports Application Insights?</p>  <p>Code below:</p>  <pre class=\lang-cs prettyprint-override\""><code>    public class Functions     {         //other code         private ILogger _log;          public Functions(ILoggerFactory loggerFactory  ILogger&lt;Functions&gt; log)         {             _log = loggerFactory.CreateLogger&lt;Functions&gt;();             _log = log;         }          [FunctionName(\""Token\"")]         public async Task&lt;IActionResult&gt; Function1(             [HttpTrigger()]...)         {                _log.LogInformation(\""Function1 invoked\"");         }     } </code></pre>  <p><strong>Update 2</strong></p>  <p>ILogger: If ILogger is used as constructor parameter  the error below occurs.  It works if it is used as function parameter.</p>  <p>What is the service lifetime for ILogger instance?</p>  <p>Is there a plan to support it on CTOR?</p>  <pre><code>[04/06/2019 10:06:12] Executed 'SampleFunction' (Failed  Id=3912a5b7-10fa-41e1-9 0f8-fba9d2cda49b) [04/06/2019 10:06:12] Microsoft.Extensions.DependencyInjection.Abstractions: Una ble to resolve service for type 'Microsoft.Extensions.Logging.ILogger' while att empting to activate 'Microsoft.Azure.Functions.Samples.DependencyInjectionBasic. SampleFunction'. [04/06/2019 10:06:12] An unhandled host error has occurred. [04/06/2019 10:06:12] Microsoft.Extensions.DependencyInjection.Abstractions: Una ble to resolve service for type 'Microsoft.Extensions.Logging.ILogger' while att empting to activate 'Microsoft.Azure.Functions.Samples.DependencyInjectionBasic. SampleFunction'. </code></pre>""",azure-functions
35862654,"Creating VM's from image and adding to an existing Availability Set <p>How can I add an existing VM that I either created in the portal or imported from vmdepot to an existing availability set? It doesn't seem to be possible from the portal  does it work in Powershell? Does it work at all with the Resource Manager deployment model?</p>  <p><a href=\https://i.stack.imgur.com/Qhkog.jpg\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/Qhkog.jpg\"" alt=\""enter image description here\""></a></p>""",azure-virtual-machine
48493741,"Does Azure AppService platform support Azure AD v2.0 endpoint <p>Is it possible to use Azure AD v2.0 endpoint to authenticate in the Azure AppService platform? Just want to make sure it's possible before doing any investments in MSAL.</p>  <p><a href=\https://i.stack.imgur.com/xuBkO.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/xuBkO.png\"" alt=\""enter image description here\""></a></p>""",azure-functions
53866342,"Azure App Service - Running Solr on Jetty - LockObtainFailedException after Azure maintenance <p>I'm running a single (not scaled) solr instance on a Azure App Service. The App Service runs Java 8 and a Jetty 9.3 container.</p>  <p>Everything works really well  but when Azure decides to swap to another VM sometimes the JVM doesn't seem to shutdown gracefully and we encounter issues.</p>  <p>One of the reasons for Azure to decide to swap to another VM is infrastructure maintenance. For example Windows Updates are installed and your app is moved to another machine.</p>  <p>To prevent downtime Azure spins up the new app and when it's ready it will swap over to the new app. Seems fine  but this does not seem to work well with solr's locking mechanism.</p>  <p>We are using the default native <code>lockType</code>  which should be fine since we're only running a single instance. Solr should remove the <code>write.lock</code> file during shutdown  but this does not seem to happen all of the time.</p>  <p>The Azure Diagnostics tools clearly show this event happening: <a href=\https://i.stack.imgur.com/ChQOo.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/ChQOo.png\"" alt=\""enter image description here\""></a></p>  <p>And the memory usage shows both apps: <a href=\""https://i.stack.imgur.com/9ercH.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/9ercH.png\"" alt=\""enter image description here\""></a></p>  <p>During the start of the second instance solr tries to lock the index  but this is not possible because the first one is still using it (it also has the <code>write.lock</code> file). Sometimes the first one doesn't remove the <code>write.lock</code> file and this is were the problems start. The second solr instance will never work correctly without manual intervention (manually deleting the <code>write.lock</code> file).</p>  <p>The solr logs:</p>  <pre><code>Caused by: org.apache.solr.common.SolrException: Index dir 'D:\\home\\site\\wwwroot\\server\\solr\\****\\data\\index/' of core '*****' is already locked. The most likely cause is another Solr server (or another solr core in this server) also configured to use this directory; other possible causes may be specific to lockType: native </code></pre>  <p>and</p>  <pre><code>org.apache.lucene.store.LockObtainFailedException </code></pre>  <p>What can be done about this? I was thinking of changing the <code>lockType</code> to a memory-based lock  but I'm not sure if that would work because both instances are alive at the same time during a short period of time.</p>""",azure-web-app-service
47299898,"Azure IoT Hub - How to use Table Storage in IoT Hub? <p><del>First of all  sorry for my english skill.</del></p>  <p>I'm a high school student from South Korea who's doing project with Azure IoT Hub.</p>  <p>I am working on a project where a raspberry pi device is sending values to an Azure IoT Hub. I would like to save this data in Azure Table Storage as this data will be used by some other services (Azure WebApp for example).</p>  <p>So I tried to save raspberry pi values in Azure Table Storage. But when I add endpoints of IoT Hub  I just can use only blob storage container</p>  <p><img src=\https://i.stack.imgur.com/9a47H.png\"" alt=\""when i pick container\""></p>  <p><img src=\""https://i.stack.imgur.com/vE1Ez.png\"" alt=\""this is my storage created before  no any other setting  just default\""></p>  <p><img src=\""https://i.stack.imgur.com/1AMaB.png\"" alt=\""when i choose  default is blob and i can&#39;t change endpoints to table storage.\""></p>  <p>of course i still don't understand about iot hub please don't look so bad.</p>  <hr>  <p>In a nutshell</p>  <ol> <li>I want to send raspberry pi values to Azure Table Storage and not Blob Storage however only option available to me is Blob Storage when I am setting endpoints for Azure IoT Hub.</li> <li>How to send values to Table Storage via Azure IoT Hub.</li> </ol>  <p>by any chance  my logic for Azure is completely wrong?</p>""",azure-storage
26560722,"Drupal module Azure Blob broken images <p>I just started building a Drupal site with Azure.  I installed the <a href=\https://www.drupal.org/project/azure_blob\"" rel=\""nofollow\"">Azure Blob module</a> and everything works correctly (local environment) including displaying and uploading images to the storage blob.  However  after deploying the site and database to a staging server  all the images are broken.  I made sure the images are present since I've uploaded them while working locally.  I'm unable to locate what the actual issue is.</p>  <p>The module hasn't been updated for a while and I spent some time digging through the code for the module  but without avail.  I was wondering if anyone has run into similar issues and could perhaps point me to the right direction.  Thanks in advance.</p>""",azure-storage
29481201,"Cannot RDP into Azure VM - User/Group Issue <p>Frustrated with myself as I seem to have locked myself out of my Azure VM via RDP or FTP. When I try to login to the server via RDP I get an error message \The credentials are correct  but the host cannot log you on for another reason. \""</p>  <p>I don't know how I caused this but I believe it has to do with users or groups somehow. I was struggling with setting up a user to be allowed FTP access to a specific folder  created a new group for the user and then set permission to the folder. Got him all setup but managed to lock myself out in the process.</p>  <p>Any idea of what to try before I call Azure support and pay their fee? (if they can even help) </p>  <p>Thanks  been a long day...</p>""",azure-virtual-machine
40516053,"Connect to MongoDB Atlas cluster from an Azure App Service <p>I have a web app on Azure that connect to a MongoDB cluster hosted on Atlas (cloud.mongodb.com).</p>  <p>I'd like to use Atlas so I don't have to care about MongoDb configurations. The issue is that I get a timeout connecting my cluster. I have to set the app service ip in my mongo cluster whitelist  but If I try to download the page <a href=\http://www.whatsmyip.org/\"" rel=\""nofollow noreferrer\"">http://www.whatsmyip.org/</a> I get every time a different IP.</p>  <p>On the azure panel I've tried everything  set a VNET integration  set an ASE  a gateway. I really don't know how to expose the public IP.</p>  <p>However I have a VM that can query the mongo cluster  it has a Network interface with a public ip and a nsg (firewall).</p>""",azure-web-app-service
45134500,Azure App Service: Create hybrid connection endpoint API <p>Is it possible to create an App Service Hybrid Connection Endpoint via an API  either .NET or REST? It seems that it is only possible through the portal.<br/> I know there is an option to do this with the old BizTalk service hybrid connections  but I need this for the new (v2) App Service Hybrid connections.</p>,azure-web-app-service
41859172,"multiple field validation using F# (inside an azure function) <p>I have an azure function based on the http post template.  I expanded the json from 1 prop to 3.  </p>  <pre><code>let versionJ = json.[\version\""] let customerIdJ = json.[\""customerId\""] let stationIdJ = json.[\""stationId\""] match isNull versionJ with </code></pre>  <p>What is the best way to check for null across all three?  Use a tulple?</p>  <pre><code>match isNull versionJ  isNull customerIdJ  isNull stationIdJ with </code></pre>""",azure-functions
43865887,"Network Security Group for Filezilla(client) connection <p>I am new here.</p>  <p>Few days ago  attended MS azure events  and today registered with Azure (free account).<br> VM Environment: VM = CentOS 7  apache+php+mysql+vsftpd+phpMyAdmin<br><br> everything is up and running  able to visit the \info.php\"" via its public IP address.<br> SeLinux = disabled  Firewalld disabled.<br><br> my problem is not able to connect this server via Filezilla (PC client).  from Windows command prompt (FTP/put) is working  able to upload files. But via Filezilla<br><br></p>  <pre><code>Status: Connecting to 5x.1xx.1xx.7x:21... Status: Connection established  waiting for welcome message... Status: Insecure server  it does not support FTP over TLS. Status: Logged in Status: Retrieving directory listing... Command:    PWD Response:   257 \""/home/ftpuser\"" Command:    TYPE I Response:   200 Switching to Binary mode. Command:    PORT 192 168 1 183 234 99 Response:   200 PORT command successful. Consider using PASV. Command:    LIST Error:  Connection timed out after 20 seconds of inactivity Error:  Failed to retrieve directory listing Status: Disconnected from server Status: Connecting to 5x.1xx.1xx.7x:21... Status: Connection established  waiting for welcome message... Status: Insecure server  it does not support FTP over TLS. Status: Logged in Status: Retrieving directory listing... Command:    PWD Response:   257 \""/home/ftpuser\"" Command:    TYPE I Response:   200 Switching to Binary mode. Command:    PORT 192 168 1 183 234 137 Response:   200 PORT command successful. Consider using PASV. Command:    LIST Error:  Connection timed out after 20 seconds of inactivity Error:  Failed to retrieve directory listing </code></pre>  <p>I believe that is because of the Network Security group settings for inbound and outbound rules  need open some port  but not sure  because I tried open 1024-65535 all allow  still not working.</p>""",azure-virtual-machine
53870489,"Application Insights end-to-end multi component logging in Azure Functions <p>End-to-end logging between multiple components using Application Insights (AI) is based on a <a href=\https://github.com/dotnet/corefx/blob/master/src/System.Diagnostics.DiagnosticSource/src/HierarchicalRequestId.md\"" rel=\""nofollow noreferrer\"">hierarchical <code>Request-Id</code></a> header. So each component is responsible to honer a possible incoming <code>Request-Id</code>. To get the full end-to-end hierarchical flow correct in Application Insights the <code>Request-Id</code> header needs to be used as the AI <code>Operation.Id</code> and <code>Operation.ParentId</code> (as described <a href=\""https://docs.microsoft.com/en-us/azure/application-insights/application-insights-correlation\"" rel=\""nofollow noreferrer\"">here</a>).</p>  <p>But when making a request with a <code>Request-Id</code> header to a Azure Function using a <code>HttpTrigger</code> binding for example (<code>Microsoft.NET.Sdk.Functions 1.0.24</code>) with integrated Application Insights configured (as described <a href=\""https://blogs.msdn.microsoft.com/appserviceteam/2017/04/06/azure-functions-application-insights/\"" rel=\""nofollow noreferrer\"">here</a>) a completely new <code>Operation.Id</code> is created and used - causing the whole flow in AI to be lost. <strong>Any ideas on how to get around this?</strong></p>  <p>Setting up a separate custom <code>TelemetryClient</code> might be an option. But seems to require a lot of configuration to get the full <code>ExceptionTrackingTelemetryModule</code> and <code>DependencyTrackingTelemetryModule</code> right - especially when using Functions v2 and Core (ref to <a href=\""https://github.com/Huachao/azure-content/blob/master/articles/application-insights/app-insights-configuration-with-applicationinsights-config.md\"" rel=\""nofollow noreferrer\"">AI config</a>). Anyone go that successfully working?</p>""",azure-functions
49591628,"Could not load file or assembly 'Microsoft.WindowsAzure.Storage' Azure Functions <p>I am currently working with a Azure Function created in visual studio.  It is a timer function that calls some common code to write to a queue.  </p>  <p>Running the code locally does not cause any issues. Runs just fine but when publish it I get the following error: </p>  <blockquote>   <p>Could not load file or assembly 'Microsoft.WindowsAzure.Storage    Version=9.1.0.0  Culture=neutral  PublicKeyToken=31bf3856ad364e35' or   one of its dependencies. The system cannot find the file   specified.||System.IO.FileNotFoundException: Could not load file or   assembly 'Microsoft.WindowsAzure.Storage  Version=9.1.0.0    Culture=neutral  PublicKeyToken=31bf3856ad364e35' or one of its   dependencies. The system cannot find the file specified. File name:   'Microsoft.WindowsAzure.Storage  Version=9.1.0.0  Culture=neutral    PublicKeyToken=31bf3856ad364e35'    at   Esperanto.Core.Function.JobGetterLogic.SendJobsToQue()    at   JobGetter.TimedJob.Run(TimerInfo myTimer  TraceWriter log)</p> </blockquote>  <p>Here is my webjob code:</p>  <pre><code>public static class TimedJob {     [FunctionName(\TimedJob\"")]     public static void Run([TimerTrigger(\""0 */1 * * * *\"")]TimerInfo myTimer  TraceWriter log)     {         log.Info($\""C# Timer trigger function executed at: {DateTime.Now}\"");         try         {             var brain = new CoreLogic.Function.JobGetterLogic();             var result = brain.SendJobsToQue();         }         catch (Exception e)         {             log.Info(e.Message + \""||\"" + e.ToString());         }      } } </code></pre>""",azure-functions
50625930,Sending docker commands to Azure App Service for Containers <p>I need to map a file path in a third-party docker container (datalust/seq) to a file path in the hosting Web App.  More specifically  the /data folder in the container needs to be mapped to the /home/data folder in the Web App.</p>  <p>With a normal docker deployment  I can just use </p>  <pre><code>docker run -v /home/data:/data  </code></pre>  <p>but how do I pass this to the docker container running in the Web App?  Afaik  the only thing that can be passed are App Settings  which are basically environment variables in the container.</p>  <p>I need this because the /home folder on the host (web app) is the only folder that can be persisted to Azure Storage  by using the WEBSITES_ENABLE_APP_SERVICE_STORAGE app setting.  This way  I want to persist the /data folder in the container.</p>,azure-web-app-service
50381871,"Terraform Script for SQL Server 2014 on Windows Server 2012 R2 Datacenter VM on Azure <p>I'm trying to build a SQL Server 2014 on Windows Server 2012 R2 Datacenter VM on Azure using Terraform. </p>  <p><strong>This is how my module looks like</strong></p>  <pre><code>module \ms-sql-vm\"" {   source                                 = \"".../terraform_module/windows_vm\""   vm_name                                = \""ex-sql-vm\""   name_space                             = \""${module.randomename}\""   arm_location                           = \""centralus\""   vm_resource_group_name                 = \""${module....}\""   availability_set_id                    = \""${module....}\""   vm_network_interface_ids               = [\""${module....}\""]   vm_size                                = \""Standard_D2s_v3\""   vm_os_disk_name                        = \""example-os-disk-${randomname}\""   vm_os_caching                          = \""ReadWrite\""   vm_os_publisher                        = \""MicrosoftSQLServer\""   vm_os_offer                            = \""SQL2014SP2-WS2012R2\""   vm_os_sku                              = \""Enterprise\""   vm_os_version                          = \""12.10.0\""   vm_os_disk_size_gb                     = \""127\""   vm_data_disk_name                      = \""${module.....}\""   vm_data_disk_id                        = \""${module.....}\""   vm_managed_disk_type                   = \""Standard_LRS\""   vm_data_disk_size_gb                   = \""${module.....}\""   vm_data_caching                        = \""ReadWrite\""   vm_data_lun                            = 1   vm_admin_name                          = \""exampleusername\""   vm_admin_password                      = \""Example12345!!\""   boot_diagnostics_primary_blob_endpoint = \""${module......}\""   vm_delete_os_disk_on_termination       = true   vm_delete_data_disk_on_termination     = true } </code></pre>  <p>And I'm using this - <a href=\""https://www.terraform.io/docs/providers/azurerm/r/virtual_machine.html\"" rel=\""nofollow noreferrer\"">https://www.terraform.io/docs/providers/azurerm/r/virtual_machine.html</a> as my base module to build.</p>  <p>This above script is spinning up a Virtual Machine 2012 for me  but not the SQL Server. If you look at this image  after my script completes execution  I cannot fine the SQL Server Configuration Option in the image uploaded below. <a href=\""https://i.stack.imgur.com/TxXQi.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/TxXQi.png\"" alt=\""terraform sql server 2014 on windows 2012 vm\""></a></p>  <p>If I'm spinning up the Same SQL Server 2014 SP2 Enterprise on Windows Server 2012 R2 from Azure portal  I can see the SQL Server Config Option.</p>  <p><a href=\""https://i.stack.imgur.com/walMd.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/walMd.png\"" alt=\""SQL Server 2014 from Azure Portal\""></a></p>  <p>And along with my VM  I'm finding this extension on my resource group dashboard as shown in the image below for VM spinned-up using Portal  but that Extension is not available if I'm doing this with Terraform. I tried to find the extension  but not able to find that extension. <a href=\""https://i.stack.imgur.com/IJ5nk.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/IJ5nk.png\"" alt=\""Resource group - SQL Extension\""></a></p>  <p>The resource Type and name of this extension are </p>  <p>Name: SqlIaasExtension RESOURCE TYPE: Microsoft.Compute/virtualMachines/extensions</p>  <p>If I try to find that SqlIaasExtension with this command - </p>  <pre><code>az vm extension image list-names --publisher Microsoft.Compute/virtualMachines/extensions --query\""[?starts_with(name  'SqlIaasExtension')]\"" </code></pre>  <p>I get \""The request URL is not valid.\""</p>  <p>If I try with this command below  I get an empty array []:</p>  <pre><code>az vm extension image list-names --publisher Microsoft.Compute --query \""[?starts_with(name  'SqlIaasExtension')]\"" </code></pre>  <p>Is there any way to spin up this SQL Server 2014 on Windows Server 2012 R2 Datacenter VM on Azure with Terraform?</p>  <p>Did anybody tried it earlier?</p>  <p>Thanks for the help</p>""",azure-virtual-machine
42963499,Azure resource Locks - how they work <p>from new Azure Portal  I selected a Virtual machine and then I am able to create Multilple resource locks of type - Delete.</p>  <p>How does these Multiple resource locks of same type works/helps   when all of these lock does the same thing ?</p>,azure-virtual-machine
51194285,"How to setup Azure web service for Dynamics 365 <p>Good morning everyone </p>  <p>My apologies if this post is too similar to this post:</p>  <p><a href=\https://stackoverflow.com/questions/48158280/dynamics-365-and-azure-integration\"">Dynamics 365 and Azure integration</a></p>  <p>but I am struggling to understand exactly what is needed in order to setup a web service on an Azure server that is consumable by a Dynamics 365 plugin. Based on my research it appears that it goes as follows but I would like to see if any knows of a better guide.</p>  <p>1.) Construct the web service as normal on the Azure Windows Server.</p>  <p>2.) Register a proper DNS Domain name (friendly-name) and route it to the Azure server.</p>  <p>3.) Secure that Azure server/URL with a certificate.</p>  <p>4.) Call the web service from my C# Dynamics 365 plugin.</p>  <p>Is that everything or might I be missing something critical? Thank you!</p>""",azure-web-app-service
51913029,Azure Spring Boot ZipException <p>I've got a spring boot rest service with embedded tomcat deployed on an Azure App Service and I am experiencing intermittent outages  every few weeks.</p>  <p>Every time there is an outage the logs contain the following entries:</p>  <blockquote>   <p>Message:  java.util.zip.ZipException: ZIP_Read: error reading zip file ZIP_Read: error reading zip file<br>   Exception type:   java.util.zip.ZipException<br>   Failed method: java.util.zip.ZipFile.access$1400</p> </blockquote>  <p>With the following call stack.</p>  <pre><code>java.lang.IllegalStateException:    at org.apache.catalina.webresources.JarWarResourceSet.getArchiveEntries (JarWarResourceSet.java133)    at org.apache.catalina.webresources.AbstractArchiveResourceSet.getResource (AbstractArchiveResourceSet.java256)    at org.apache.catalina.webresources.StandardRoot.getResourceInternal (StandardRoot.java281)    at org.apache.catalina.webresources.CachedResource.validateResource (CachedResource.java97)    at org.apache.catalina.webresources.Cache.getResource (Cache.java69)    at org.apache.catalina.webresources.StandardRoot.getResource (StandardRoot.java216)    at org.apache.catalina.webresources.StandardRoot.getResource (StandardRoot.java206)    at org.apache.catalina.mapper.Mapper.internalMapWrapper (Mapper.java1027)    at org.apache.catalina.mapper.Mapper.internalMap (Mapper.java842)    at org.apache.catalina.mapper.Mapper.map (Mapper.java698)    at org.apache.catalina.connector.CoyoteAdapter.postParseRequest (CoyoteAdapter.java679)    at org.apache.catalina.connector.CoyoteAdapter.service (CoyoteAdapter.java336)    at org.apache.coyote.http11.Http11Processor.service (Http11Processor.java803)    at org.apache.coyote.AbstractProcessorLight.process (AbstractProcessorLight.java66)    at org.apache.coyote.AbstractProtocol$ConnectionHandler.process (AbstractProtocol.java868)    at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun (NioEndpoint.java1459)    at org.apache.tomcat.util.net.SocketProcessorBase.run (SocketProcessorBase.java49)    at java.util.concurrent.ThreadPoolExecutor.runWorker (ThreadPoolExecutor.java1149)    at java.util.concurrent.ThreadPoolExecutor$Worker.run (ThreadPoolExecutor.java624)    at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run (TaskThread.java61)    at java.lang.Thread.run (Thread.java748) Inner exception java.util.zip.ZipException handled at org.apache.catalina.webresources.JarWarResourceSet.getArchiveEntries:    at java.util.zip.ZipFile.access$1400 (ZipFile.java60)    at java.util.zip.ZipFile$ZipFileInputStream.read (ZipFile.java734)    at java.io.FilterInputStream.read (FilterInputStream.java133)    at java.io.PushbackInputStream.read (PushbackInputStream.java186)    at java.util.zip.ZipInputStream.readFully (ZipInputStream.java403)    at java.util.zip.ZipInputStream.readLOC (ZipInputStream.java278)    at java.util.zip.ZipInputStream.getNextEntry (ZipInputStream.java122)    at java.util.jar.JarInputStream.&lt;init&gt; (JarInputStream.java83)    at java.util.jar.JarInputStream.&lt;init&gt; (JarInputStream.java62)    at org.apache.catalina.webresources.TomcatJarInputStream.&lt;init&gt; (TomcatJarInputStream.java37)    at org.apache.catalina.webresources.JarWarResourceSet.getArchiveEntries (JarWarResourceSet.java108)    at org.apache.catalina.webresources.AbstractArchiveResourceSet.getResource (AbstractArchiveResourceSet.java256)    at org.apache.catalina.webresources.StandardRoot.getResourceInternal (StandardRoot.java281)    at org.apache.catalina.webresources.CachedResource.validateResource (CachedResource.java97)    at org.apache.catalina.webresources.Cache.getResource (Cache.java69)    at org.apache.catalina.webresources.StandardRoot.getResource (StandardRoot.java216)    at org.apache.catalina.webresources.StandardRoot.getResource (StandardRoot.java206)    at org.apache.catalina.mapper.Mapper.internalMapWrapper (Mapper.java1027)    at org.apache.catalina.mapper.Mapper.internalMap (Mapper.java842)    at org.apache.catalina.mapper.Mapper.map (Mapper.java698)    at org.apache.catalina.connector.CoyoteAdapter.postParseRequest (CoyoteAdapter.java679)    at org.apache.catalina.connector.CoyoteAdapter.service (CoyoteAdapter.java336)    at org.apache.coyote.http11.Http11Processor.service (Http11Processor.java803)    at org.apache.coyote.AbstractProcessorLight.process (AbstractProcessorLight.java66)    at org.apache.coyote.AbstractProtocol$ConnectionHandler.process (AbstractProtocol.java868)    at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun (NioEndpoint.java1459)    at org.apache.tomcat.util.net.SocketProcessorBase.run (SocketProcessorBase.java49)    at java.util.concurrent.ThreadPoolExecutor.runWorker (ThreadPoolExecutor.java1149)    at java.util.concurrent.ThreadPoolExecutor$Worker.run (ThreadPoolExecutor.java624)    at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run (TaskThread.java61)    at java.lang.Thread.run (Thread.java748) </code></pre>  <p>As soon as this occurs  all calls to the rest service returns a 500 and the log gets another entry like above. This continues until I manually reboot the app service.</p>  <p>I'm struggling to figure out what is the issue. Googling the exception only returns results for issues with opening zip files. The app does not do any zipping/unzipping in itself and the call stack seems to indicate that it's tomcat things(that could be caused by something I've done on Azure  in SpringBoot  the JVM or something else entirely).</p>  <p>CPU or memory usage appear to be fine preceding the outages so that doesn't seem to be a factor.  This issue is not preceded by any deployments or platform changes. </p>  <p>I'm stumped regarding what to do next  if anyone can point me in the right direction to investigate  it'll be much appreciated.</p>,azure-web-app-service
48653350,"What goes in the ssh_keys > key_data argument in a Terraform template <p>I have a template to deploy a Linux VM in Azure and am trying to use SSH keys for authentication.  When using the \ssh_keys\"" argument  what goes in the \""key_data\"" sub argument?  I am sure it is something to do with my public key  I am just not sure what exactly.</p>""",azure-virtual-machine
46963219,"Azure function goes idle when running in Consumption Plan with ServiceBus Queue trigger <p>I have also asked this question in the <a href=\https://social.msdn.microsoft.com/Forums/azure/en-US/af787179-3fba-4ec0-86d5-bd820f0c7e07/function-goes-idle-when-running-in-consumption-plan-with-servicebus-queue-trigger?forum=AzureFunctions\"" rel=\""nofollow noreferrer\"">MSDN Azure forums</a>  but have not received any guidance as to why my function goes idle.</p>  <p>I have an Azure function running on a Consumption plan that goes idle (i.e. does not respond to new messages on the ServiceBus trigger queue) despite following the instructions outlined in this <a href=\""https://github.com/Azure/Azure-Functions/issues/370\"" rel=\""nofollow noreferrer\"">GitHub issue</a>: </p>  <p>The configuration for the function is the following json:</p>  <pre><code>{   \""ConnectionStrings\"": {     \""MyConnectionString\"": \""Server=tcp:project.database.windows.net 1433;Database=myDB;User ID=user@project;Password=password;Encrypt=True;Connection Timeout=30;\""   }    \""Values\"": {     \""serviceBusConnection\"": \""Endpoint=sb://project.servicebus.windows.net/;SharedAccessKeyName=SharedAccessKeyName;SharedAccessKey=KEY_HERE\""    } } </code></pre>  <p>And the function signature is:</p>  <pre><code>public static void ProcessQueue([ServiceBusTrigger(\""queueName\""  AccessRights.Listen  Connection = \""serviceBusConnection\"")] ...) </code></pre>  <p>Based on the discussion in the GitHub issue  I believed that having either a <code>serviceBusConnection</code> entry OR an <code>AzureWebJobServiceBus</code> entry should be enough to ensure that the central listener triggers the function when a new message is added to the <code>ServiceBusQueue</code>  but that is proving to not be the case. </p>  <p>Can anyone clarify the difference between how those two settings are used  or notice anything else with the settings I provided that might be causing the function to not properly be triggered after a period of inactivity?</p>""",azure-functions
54532465,How to publish nuget packages from AppVeyor CI to Azure DevOps artifacts <p>I tried looking into it but couldn't find a documentation page at all. We have an AppVeyor CI build that we produce nuget packages from (here we run our own powershell script)  and we want to publish those to a private Azure DevOps artifacts. </p>  <p>I can't seem to get authentication to work.</p>,azure-devops
56273014,"Logging with Azure functions ~2.0 <p>I am trying to integrate <code>Microsoft.Logging.Extension</code> with Azure Functions ~2.</p>  <p>Logs below <strong>LogLevel=Error</strong> are not displayed in the Azure Log Stream or Kudu. The logs do appear in the console when running locally.</p>  <p>I create the factory as follows:</p>  <pre><code>LoggerFactory factory = new LoggerFactory(); factory     .AddAzureWebAppDiagnostics()     .AddConsole(); </code></pre>  <p>Then I try to use the loggers as follows:</p>  <pre><code>factory.CreateLogger&lt;TestClass&gt;().LogInformation(\This is a test information message.\""); </code></pre>  <p>My problem is: The logs won't show on Kudu/Azure Log Stream unless the level is <strong>Error</strong></p>  <p>My <code>host.json</code> file looks like this:</p>  <pre><code>{   \""version\"": \""2.0\""    \""singleton\"": {     \""listenerLockPeriod\"": \""00:00:15\""   }    \""logging\"": {     \""console\"": {       \""isEnabled\"": \""true\""     }      \""fileLoggingMode\"": \""debugOnly\""      \""logLevel\"": {       \""default\"": \""Information\""     }   } } </code></pre>  <p>What am I missing?</p>""",azure-functions
49486577,"Create PDF from existing pdf with azure storage <p>I made a bot application with the Microsoft Botbuilder. Now I want to create a pdf-file from the user input. The file should be stored in my azure storage. I have a \pdf-template\"" which should be copied and modified (this file is in the azure storage already). It has some textboxes which should be filled with the user input. I already wrote the code for that with iTextSharp.  But I need a filestream for this code. Does anybody know how to get the filestream from the file in my azure storage? Or is there maybe another way to finish my task?</p>  <p>Edit:  Here is the code where I need the filestream</p>  <pre><code>string fileNameExisting = Path.Combine(Directory.GetCurrentDirectory()  \""Some.pdf\"");      string fileNameNew = @\""Path/Some2.pdf\"";      var inv = new Invention      {         Inventor = new Inventor { Firstname = \""TEST!\""  Lastname= \""TEST!\"" }          Date = DateTime.Now          Title = \""TEST\""          Slogan = \""TEST!\""          Description = \""TEST!\""          Advantages = \""TEST!s\""          TaskPosition = \""TEST!\""          TaskSolution = \""TEST!\""      };      using (var existingFileStream = new FileStream(fileNameExisting  FileMode.Open))      using (var newFileStream = new FileStream(fileNameNew  FileMode.Create))      {         // Open existing PDF         var pdfReader = new PdfReader(existingFileStream);          // PdfStamper  which will create         var stamper = new PdfStamper(pdfReader  newFileStream);          var form = stamper.AcroFields;         var fieldKeys = form.Fields.Keys;          foreach (string fieldKey in fieldKeys)         {            var props = fieldKey.Split('.');            string t = GetProp(props  inv);            form.SetField(fieldKey  t);         }         stamper.Close();         pdfReader.Close();      }   }   public static string GetProp(string[] classes  object oldObj)   {      var obj = oldObj.GetType().GetProperty(classes[0]).GetValue(oldObj  null);      if(classes.Length&gt;1)      {         classes = classes.Skip(1).ToArray();         return GetProp(classes  obj);      }      Console.WriteLine(obj.ToString());         return obj.ToString();   } </code></pre>""",azure-storage
43674850,Azure Disk Space VM wise <p>We have a scenario wherein we are trying to fetch the attached disk VM wise and the respective the total space assigned to these disks. Is there any command or script to get the detail?</p>  <p>I have used the command <code>Get-AzureDisk</code> to get the output but it does not display all the VMs that I have in my list. Not sure why  any solution?</p>,azure-virtual-machine
39395081,"Access SQL database from Azure Function in NodeJS <p>I'm trying to create an Azure Function which is triggered by a http request and then selects data from a SQL database  it then returns the data.</p>  <p>I've tried to set up a basic example that simply connects to a database by following the example here: <a href=\https://msdn.microsoft.com/library/mt715784.aspx\"" rel=\""nofollow\"">https://msdn.microsoft.com/library/mt715784.aspx</a> It isn't Azure Function specific but i thought that it should run:</p>  <pre><code>var Connection = require('tedious').Connection;   var config = {       userName: 'userName'        password: 'password'        server: 'databaseServer.database.windows.net'        options: {encrypt: true  database: 'AdventureWorks'}   };    module.exports = function(context  req  saasSql) {      var connection = new Connection(config);       connection.on('connect'  function(err) {           if(err) {             context.log(err);         } else {             context.log(\""Connected\"");                context.res = {                 body: 'Connected'             };             context.done();         }     });   }; </code></pre>  <p>However when this runs (triggered in the admin console).  I get a log message to say that the function started and then nothing else in the logs.  The Output window at the bottom gives a Status: 502 Bad Gateway and this message: <em>Authentication is enabled for the function app. Disable authentication before running the function.</em></p>  <p>I guess that this is because I'm not calling context.done() as authentication is turned off for this function.  I can't seem to work out how to get any error info etc out of the connection attempt  I've tried binding to the error event as well but nothing gets fired.</p>  <p><strong>UPDATE</strong></p>  <p>The error message was a bug in the Azure Functions code and was displaying the incorrect error.  However  the above code still does not run (and no error is thrown).  It run's fine when I create a local node server and run that way so it seems like an issue with running in the Azure Functions framework. Is there any way to connect to a SQL DB from an Azure Function?</p>""",azure-functions
43315006,"Socket get net::ERR_CONNECTION_TIMED_OUT when deploy nodejs webapp on iisnode <p>I am new to nodeJs.Forgive me for asking some silly question.</p>  <p>I am trying to deploy a real-time chatroom webapp on Azure server with iisnode. The webapp works well on localhost  but when I upload it to run on the server  the socket cannot connect from client to server. I am using nodejs+ express + jade.</p>  <pre><code>server.js var express = require(\express\"")  http = require('http'); var app = express(); var server = http.createServer(app); var port  = process.env.PORT || 3700; app.set('views'  __dirname + '/tpl'); app.set('view engine'  \""jade\"");  app.engine('jade'  require('jade').__express);  var deployPath = process.env.deployPath || \""\"";  app.get(deployPath+ \""/\""  function(req  res){     res.render(\""page\"" {deployPath: deployPath}); });  app.use(deployPath  express.static(__dirname + '/public'));   var io = require('socket.io')(server); server.listen(port  'http://visafe-paltform.cloudapp.net'); io.sockets.on('connection'  function (socket) {     console(\""connected\"");     socket.emit('message'  { message: 'welcome to the chat' });     socket.on('send'  function (data) {         io.sockets.emit('message'  data);     }); });  console.log(\""Listening on port \"" + port);   Client.js   window.onload = function() {      var messages = [];     var address = window.location.protocol + '//' + window.location.host;      console.log(address);     var details = {           resource: (window.location.pathname.split('/').slice(0  -1).join('/') + '/socket.io').substring(1)       };       console.log(details);      //var socket = io.connect(address  details);     var socket = io.connect('http://visafe-paltform.cloudapp.net:3700');     //var socket = io.connect();     var field = document.getElementById(\""field\"");     var sendButton = document.getElementById(\""send\"");     var content = document.getElementById(\""content\"");      socket.on('message'  function (data) {         if(data.message) {             messages.push(data.message);             var html = '';             for(var i=0; i&lt;messages.length; i++) {                 html += messages[i] + '&lt;br /&gt;';             }             content.innerHTML = html;         } else {             console.log(\""There is a problem:\""  data);         }     });      sendButton.onclick = function() {         var text = field.value;         console.log(\""click:\""  field.value);         socket.emit('send'  { message: text });     };  } </code></pre>  <p>when i try to request the url  it gives me error:</p>  <pre><code>socket.io.js:4948 GET http://visafe-paltform.cloudapp.net:3700/socket.io/?EIO=3&amp;transport=polling&amp;t=LjM71Yc net::ERR_CONNECTION_TIMED_OUT </code></pre>  <p>Can anyone help me? Thanks in advance.</p>""",azure-virtual-machine
42615615,Is there any way to get the FTP deployment hostname programatically? <p>I'm in the process of getting a deployment that targets Azure App Service automated and I'm using FTP deployment.</p>  <p>Unfortunately  the hostnames for FTP deployment seem different from app to app and I'd like my scripts to be able to infer the correct one themselves.</p>  <p>Is there anything in the azure CLI that can get me the FTP hostname value?  I'm using 2.0 (the shiny new one) if that helps at all.</p>,azure-web-app-service
55558395,"Unable to run jsreportlocal on Azure WebApp Linux (.Net core 2.1 MVC) <p>I have existing .Netcore 2.1 MVC deployed on Azure WebApp Linux. I need to create reports pdf so I thought to use jsreport local.</p>  <pre><code>var rs = new LocalReporting().UseBinary(RuntimeInformation.IsOSPlatform(OSPlatform.Windows) ? JsReportBinary.GetBinary() : jsreport.Binary.Linux.JsReportBinary.GetBinary()).Configure((cfg) =&gt;     {          cfg.HttpPort = 1000;          cfg.AllowedLocalFilesAccess().BaseUrlAsWorkingDirectory();          return cfg;     }).AsUtility().Create(); var report = await rs.RenderAsync(new RenderRequest     {           Template = new Template          {               Recipe = Recipe.ChromePdf                Engine = Engine.None                Content = contentToPrint           }     }); </code></pre>  <p>On windows this code works fine. Once deployed on Web App (Linux) I get the error:</p>  <p>Failed Error rendering report: A critical error occurred while trying to execute the render command: Failed to launch chrome!/tmp/jsreport/compile/jsreport-2.4.0-Bk_dhUp8V/chrome/chrome: error while loading shared libraries: libX11.so.6: cannot open shared object file: No such file or directoryTROUBLESHOOTING: <a href=\https://github.com/GoogleChrome/puppeteer/blob/master/docs/troubleshooting.md\"" rel=\""nofollow noreferrer\"">https://github.com/GoogleChrome/puppeteer/blob/master/docs/troubleshooting.md</a> (1). caused by error (1) -> meta = {\""remoteStack\"":\""Error: Failed to launch chrome!\\n/tmp/jsreport/compile/jsreport-2.4.0-Bk_dhUp8V/chrome/chrome: error while loading shared libraries: libX11.so.6: cannot open shared object file: No such file or directory\\n\\n\\nTROUBLESHOOTING: <a href=\""https://github.com/GoogleChrome/puppeteer/blob/master/docs/troubleshooting.md\"" rel=\""nofollow noreferrer\"">https://github.com/GoogleChrome/puppeteer/blob/master/docs/troubleshooting.md</a>\\n\\n    at onClose (jsreportRuntime.js:400867:14)\\n    at Interface.helper.addEventListener (jsreportRuntime.js:400856:50)\\n    at emitNone (events.js:111:20)\\n    at Interface.emit (events.js:208:7)\\n    at Interface.close (readline.js:370:8)\\n    at Socket.onend (readline.js:149:10)\\n    at emitNone (events.js:111:20)\\n    at Socket.emit (events.js:208:7)\\n    at endReadableNT (_stream_readable.js:1064:12)\\n    at _combinedTickCallback (internal/process/next_tick.js:138:11)\\n    at process._tickCallback (internal/process/next_tick.js:180:9)\""}  stack = Error:     at responseToBuffer ([eval]:72595:29)    at concat ([eval]:72648:40)    at ConcatStream. ([eval]:17182:43)    at emitNone (events.js:111:20)    at ConcatStream.emit (events.js:208:7)    at finishMaybe ([eval]:97353:14)    at afterWrite ([eval]:97215:3)    at _combinedTickCallback (internal/process/next_tick.js:144:20)    at process._tickCallback (internal/process/next_tick.js:180:9)</p>""",azure-web-app-service
50075569,"Parsing form data in azure web app <p>I have a small testing a nodejs web app on azure that uses an azure cosmos db to insert and retrieve data. The web app is based on express framework  mongoose (for database interaction)  pug for templates and body-parser for parsing the data send by a web form. </p>  <p>The problem I have encountered is that I cannot access the data send by the web form  based on which I want to insert a new document in the azure cosmos db. Basically when I submit the web form the app should access the form data (with the help of <em>body-parser</em> module)  create a new document in the database and refresh the view (which will contain the info from the newly created document).</p>  <p>Below is the code of this small app.</p>  <pre><code>const express = require('express'); const http = require('http'); const mongoose= require('mongoose'); const bodyParser = require('body-parser');   const app = express(); var port = process.env.PORT || 5050; //normalizePort(process.env.PORT || '5050'); app.set('port'  port); app.set('views'  'views'); app.set('view engine'  'pug');  mongoose.connect(`mongodb://[user].documents.azure.com:10255/testdb?ssl=true`  {     auth: {       user: `[username]`        password: `[password]`     }   })   .then(() =&gt; console.log('connection successful'))   .catch((err) =&gt; console.error(err));  let citySchema = new mongoose.Schema ({     id: {type: String  required: true}      name: {type: String  required: true}      country: {type: String  required: true} });  const Cities = mongoose.model('Cities'  citySchema);  let getData = function(request  response) {     Cities.find({}  function(err  data) {         if (err) { return \There was an error\"";}         console.log(JSON.stringify(data));         response.render('index'  {             panelTitle: \""Azure CosmosDB Test\""                panelBody:\""Testing how to access Azure ComsosDB\""              cities: data         });     }); };  let urlencoded = bodyParser.urlencoded({extended: false});  app.get('/'  function(request  response) {     getData(request  response); });  app.get('/error'  function(request  response) {     response.render('error'); })  app.post('/'  urlencoded  function(request  response){     console.log(request.body);     let newCity = new Cities({id: request.body.id  name: request.body.name          country: request.body.country});     console.log(newCity);     newCity.save(function(err  savedCity){         console.log(JSON.stringify(savedCity));     });      response.redirect('back'); });  app.use(express.static(__dirname + '/public'));  const server = http.createServer(app); server.listen(port); </code></pre>  <p>On localhost the code work just fine  it insert the new document in the database and then in the refreshed view the new city appears on the list (generated based on the pug file).</p>  <hr>  <p>However on Azure nothing happened. The view is refreshed but the new document is not created and of course the view does not contain the info send by the web form. It is not a problem with the database connection because the app is able to extract the information for generating the list of the cities. Furthermore if in the <em>post</em> route  when I am creating a new city and try to save it I use direct values like this: </p>  <pre><code>let newCity = new Cities({id: 'MUN\""  name: \""Munich\""          country: \""Germany\""}); </code></pre>  <p>the document is created and saved in the azure cosmos db and the view contains the new data. </p>  <p>It seems to me that the <strong>req.body</strong> is empty and form data is not parsed although I am using the <em>body-parser</em> module in this respect. In the browser on developer tools - network tab - is showing the form data send to the server and i have a status code of 302. </p>  <p>If you have any idea why this is not working on azure please let me know.</p>  <p>Thanks!</p>""",azure-web-app-service
46811062,How to revert an azure disk back to its former snapshot? <p>I have a VM in azure  and via the portal have selected its Disk  and created a snapshot of it. How do I now revert back to that snapshot for the Disk (via portal or CLI)? </p>  <p>I'm not looking to create new disks or VMs from the snapshot  just revert back. </p>,azure-virtual-machine
46667074,"how to get cpu usage of azure vm throught powershell <p>can we see the metrics of the CPU usage and other details of the VM through power shell. i am trying to write a power shell script to get all the details of the azure virtual machine it show some error can any one have idea about how to write a script to get the details.  </p>  <hr>  <p>i am able to get the vm details Get-AzureRmVM -ResourceGroupName \RG\"" -Name \""VM\"" -Status but i am not getting cpu usage for that i tried some table contents \""WADPerformanceCountersTable\"" rule:- \""\\Processor(_Total)\\% Processor Time\"" </p>""",azure-virtual-machine
54745278,"WebApp Auth Azure AD Settings is stuck <p>I mistakenly deleted the Azure AD application linked to my WebApp. Then I wanted to link it to a new one but the Azure AD Settings page keeps loading and looks stuck.</p>  <p>I tried to turn the authentication Off and then On again to see if it would restore the Azure AD to \Not Configured\""  but it doesn't work. </p>  <p>Here is a picture of my Auth Config: <img src=\""https://i.imgur.com/X0dxdDT.png\"" alt=\""Auth config\""></p>  <p>Here is a picture of my Azure AD Config (nothing is clickable): <img src=\""https://i.imgur.com/So9RpnQ.png?2\"" alt=\""Azure AD config\""></p>  <p>For now the only solution I have is to either disable the Auth completely or make a new WebApp. Is this a known bug?</p>""",azure-web-app-service
22974713,"TFS \always\"" keep asking me for check-out using visual studio online <p>For enterprise library <code>.edmx</code> file. When I added new table or modified table it keep asking me for check-out which is already checked-out.</p>  <p>I am using VS Express 2012   Visual Stuido online (TFS). EL 5.0 </p>  <p>Anybody had same issue?</p>""",azure-devops
19230290,"Create Shared Access Token with Microsoft.WindowsAzure.Storage returns 403 <p>I have a fairly simple method that uses the NEW Storage API to create a SAS and copy a blob from one container to another. </p>  <p>I am trying to use this to Copy blob BETWEEN STORAGE ACCOUNTS. So I have TWo Storage accounts  with the exact same Containers  and I am trying to copy a blob from the Storage Account's Container to another Storage Account's Container. </p>  <p>I don't know if the SDK is built for that  but it seems like it would be a common scenario. </p>  <p>Some additional information:</p>  <ol> <li>I create the token on the Destination Container.  Does that token need to be created on both the source and destination? Does it take time to register the token? Do I need to create it for each request  or only once per token \lifetime\""? </li> </ol>  <p>I should mention a 403 is an Unauthorized Result http error code.</p>  <pre><code>  private static string CreateSharedAccessToken(CloudBlobClient blobClient  string containerName)     {         var container = blobClient.GetContainerReference(containerName);         var blobPermissions = new BlobContainerPermissions();          // The shared access policy provides read/write access to the container for 10 hours:          blobPermissions.SharedAccessPolicies.Add(\""SolutionPolicy\""  new SharedAccessBlobPolicy()         {             // To ensure SAS is valid immediately we don’t set start time              // so we can avoid failures caused by small clock differences:              SharedAccessExpiryTime = DateTime.UtcNow.AddHours(1)              Permissions = SharedAccessBlobPermissions.Write |                           SharedAccessBlobPermissions.Read         });           blobPermissions.PublicAccess = BlobContainerPublicAccessType.Blob;          container.SetPermissions(blobPermissions);          return container.GetSharedAccessSignature(new SharedAccessBlobPolicy()  \""SolutionPolicy\"");      } </code></pre>  <p>Down the line I use this token to call a copy operation  which returns a 403:</p>  <pre><code>  var uri = new Uri(srcBlob.Uri.AbsoluteUri + blobToken);             destBlob.StartCopyFromBlob(uri); </code></pre>  <p>My version of Azure.Storage is 2.1.0.2. </p>  <p>Here is the full copy method in case that helps:</p>  <pre><code>    private static void CopyBlobs(         CloudBlobContainer srcContainer  string blobToken          CloudBlobContainer destContainer)     {         var srcBlobList             = srcContainer.ListBlobs(string.Empty  true  BlobListingDetails.All); // set to none in prod (4perf)          //// get the SAS token to use for all blobs          //string token = srcContainer.GetSharedAccessSignature(         //    new SharedAccessBlobPolicy()  \""SolutionPolicy\"");          bool pendingCopy = true;          foreach (var src in srcBlobList)         {             var srcBlob = src as ICloudBlob;              // Determine BlobType:              ICloudBlob destBlob;             if (srcBlob.Properties.BlobType == BlobType.BlockBlob)             {                 destBlob = destContainer.GetBlockBlobReference(srcBlob.Name);             }             else             {                 destBlob = destContainer.GetPageBlobReference(srcBlob.Name);             }              // Determine Copy State:              if (destBlob.CopyState != null)             {                 switch (destBlob.CopyState.Status)                 {                     case CopyStatus.Failed:                         log.Info(destBlob.CopyState);                         break;                      case CopyStatus.Aborted:                         log.Info(destBlob.CopyState);                         pendingCopy = true;                         destBlob.StartCopyFromBlob(destBlob.CopyState.Source);                         return;                      case CopyStatus.Pending:                         log.Info(destBlob.CopyState);                         pendingCopy = true;                         break;                 }             }               // copy using only Policy ID:             var uri = new Uri(srcBlob.Uri.AbsoluteUri + blobToken);             destBlob.StartCopyFromBlob(uri);               //// copy using src blob as SAS             //var source = new Uri(srcBlob.Uri.AbsoluteUri + token);             //destBlob.StartCopyFromBlob(source);          }     } </code></pre>  <p>And finally the account and client (vetted) code:</p>  <pre><code>       var credentials = new StorageCredentials(\""BAR\""  \""FOO\"");         var account = new CloudStorageAccount(credentials  true);         var blobClient = account.CreateCloudBlobClient();         var sasToken = CreateSharedAccessToken(blobClient  \""content\""); </code></pre>  <p>When I use a REST client this seems to work... any ideas? </p>""",azure-storage
41379382,How to chage a VM's os Disk <p>I have created a VM (Standard DS11 v2) on Azure about 2 - 3 weeks ago. It attached a premium disk which has extra price. (I did not know that when I created the VM.)</p>  <p>Now I want to change this disk to a standard disk. As I see  it is not possible to downgrade a premium disk to standard. </p>  <p>What I am trying to do is:</p>  <ol> <li>Attach a standard disk to my VM.</li> <li>Copy premium disk to standard disk.</li> <li>Make standard disk OS disk.</li> <li>Detach premium disk.</li> <li>Delete premium disk. </li> </ol>  <p>How can I do that?</p>  <p>Also I am open to different solutions to my problem.</p>  <p>My OS is <code>Centos 7.2</code>.</p>,azure-storage
36452067,Unable to telnet to SQL mirroring port on public IP on Azure ARM VM <p>I am trying to mirror a on premise SQL database to Azure ARM VMs running SQL server. One for the mirror and one for the witness. I have setup the mirroring end points on the servers. However  I am getting an error to the effect that the mirror server can not be reached.</p>  <p>Reading through the net pages  I tested the port using telnet. I am able to telnet to the mirroring port on my local server from the Azure VM but unable to telnet from the local server to the VMs.</p>  <p>I am able to telnet on the mirroring port between the VMs using the Private IP Address but unable to do so using the Public IP address.</p>  <p>I have added the port to the Security group being used by these VMs to allow inbound connections as well as outbound connections.</p>  <p>I have tested that the server is listening on ip 0.0.0.0 and my mirroring port.</p>  <p>Any help would be very much appreciated.</p>,azure-virtual-machine
48696515,"VSTS Download Build Artifacts (Preview) Build Variable <p>I am attempting to download a build artifact using <strong>Download Build Artifacts (Preview).</strong> </p>  <p>For the most part this Task is working and I am able to select which Project  Build definition and Build (e.g. <strong>20180208.1</strong>) in the Edit Build Definition.  </p>  <p>I would like to specify the Build as a variable however I can't seem to get it working. </p>  <p>I have created a variable BuildId with the value <strong><em>20180208.1</em></strong> Then trying to reference it within the task as $(BuildId). When I run it the build fails and the error logs show the following</p>  <blockquote>   <p>2018-02-08T22:53:31.3627241Z ##[error]Build with id 20180208 not found</p> </blockquote>  <p>Note that the error is missing the <strong><em>.1</em></strong> from the end of the value. <a href=\https://i.stack.imgur.com/4xYve.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/4xYve.png\"" alt=\""BuildId\""></a></p>  <p>Any and all help is very much appreciated :-D<br> Thanks</p>""",azure-devops
44676186,"Azure cloud storage account with custom endpoint suffix <p>Imagine  we have 2 Azure storage accounts  one of them is regular  other one - Government (or Germany  Chine etc.). Here is how we create CloudBlobClient:</p>  <pre><code>    private const string ConnectionStringTemplate = \DefaultEndpointsProtocol={0};AccountName={1};AccountKey={2};\"";      public static CloudBlobClient Create(string protocol  string accountName  string accountKey)     {         var connectionString = string.Format(CultureInfo.InvariantCulture  ConnectionStringTemplate  protocol  accountName  accountKey);         var account = CloudStorageAccount.Parse(connectionString);          return account.CreateCloudBlobClient();     } </code></pre>  <p>This code works fine for regular account  but for Government one doesn't. We should specify EndpointSuffix (core.usgovcloudapi.net instead of core.windows.net which is default)  and connection string should be like this:</p>  <pre><code>\""DefaultEndpointsProtocol={0};AccountName={1};AccountKey={2};EndpointSuffix={3}\""; </code></pre>  <p>So  the question is  how can I know which account is if have only AccountName and AccountKey? Is there some API method to check account type or endpoint suffix for them?</p>""",azure-storage
13539443,"Azure get SQL DB servers REST request returned \HTTP error 500 : Internal Server Error\"" <p>I tried using \""enumerating servers\"" Get Servers option in REST API.</p>  <p>I am getting a response \""HTTP error 500 : Internal Server Error\"" .</p>  <p><a href=\""https://management.database.windows.net:8443/\"" rel=\""nofollow\"">https://management.database.windows.net:8443/</a>&lt;'SunscriptionID'>/servers</p>  <p>x-ms-version=1.0.</p>  <p>Please help me !</p>""",azure-storage
29527941,TFS as a local repository for Visual Studio Online <p>We just started test-running VSO for source control/Scrum management on a new project. We currently use TFS running in-house for other projects. I love the VSO scrum tools  but  with today's VSO outage  we are questioning whether VSO is practical for us as a source control.<br> After researching this afternoon  I don't see a solution to have a local backup of VSO. My current thought is to use a local git repo that pushes to VSO. The problem with that is switching technologies is not an easy sell  especially when we already have the local TFS to maintain.</p>  <p>We have thought of using VSO to manage scrum tasks and keep source control in-house  but I really don't like having the two separated (can't link commits and I think that everything should be in one place if possible). </p>  <p>Yes  for you purists out there  we do have a big whiteboard with index cards and stickies for our sprint tasks  but we're still looking at the cloud as another option ;)</p>  <p>To condense my rambling into a real question:  <strong>Is there a way to use in-house TFS as a local repo that pushes to VSO  or to at least have it mirror VSO?</strong></p>,azure-devops
40849771,Azure Webapp to azure Marklogic on VM using .net XCC library : An address incompatible with the requested protocol was used [::ffff:10.10.1.4]:9501 <p>We have a webapp hosted on azure Appservice plan talking to Marklogic server hosted on Azure VM. With webapp and VM talking over point to site VPN and are on the same VNET</p>  <p>When we call Marklogic server hosted at xcc://admin:admin@10.10.1.4:9501 using .net XCC library. We are getting an error : </p>  <blockquote>   <p>An address incompatible with the requested protocol was used   [::ffff:10.10.1.4]:9501</p>      <p>stacktrace Message:    at   Marklogic.Xcc.Impl.SessionImpl.SubmitRequest(Request request)    at   IET.TV.Common.MarkLogicHelper.MarkLogicHelper.Invoke(String moduleUri    String inputSearchDetails)    at   IET.TV.Common.MarkLogicHelper.MarkLogicHelper.InvokeToSingleString(String   moduleUri  String separator  String inputSearchDetails)</p> </blockquote>  <p>Is there is a way to control how the address format is generated using .net XCC library. Tried disabling IPV6 option on the VM still didnt work is there any other options to get it working</p>  <p>Marklogic library version used is MarkXCC.Net-8.0-6 and MVC 4 running on .net 4.6.</p>,azure-web-app-service
55701330,Task in CD pipeline to edit or transform some files before every deployment <p>I am trying to setup CI/CD pipeline with Azure DevOps. My requirement is to setup task in release stage to edit or transform few files (XML and other text files according to the customer) before every deployment.</p>  <p>e.g. to edit <code>pom.xml</code> file to edit artifact id before every deployment.</p>  <p>How and where I can setup this task?</p>,azure-devops
47617619,"Run R.NET in and Azure Function <p>I am trying to integrate R into an Azure Function.</p>  <p>Instead of just calling the R exe - I want to be able to try the R.NET library to make it easier to pass and collect data between .NET and R. For example  respond to an event.</p>  <p>It runs fine locally  but once deployed as an Azure function  I get various errors.  The latest \: This engine is not running. You may have forgotten to call Initialize\""</p>  <p>For anyone else wanting to try this  I had to force the Azure function to run as 64bit  and also install the R extension library to the function. at RDotNet.REngine.CheckEngineIsRunning()</p>  <p>Has anyone had any success?  Is anyone with R.NET experience wanting to help getting to work as an Azure function environment?</p>""",azure-functions
45016111,"Azure architecture design for a load-balanced environment <p>I'm new to Azure  and a little confused about cloud services. </p>  <p>I'm making a Testing Environment that consist of multiple instances (of the same VM) where each instance has a REST API server (Consisting of 2 API functions: <em>GetResults  SendFileForTesting</em>) and a load-balancer that distributes the requests upon the VMs. In each VM there is also a worker that processes the received files and saves the results in a shared DB.<br> The goal is  for the file processing to be distributed on the available VMs and the results to be saved in a shared place (So that the \GetResults\"" request would send all of the results to the client)<br> This is how it looks:</p>  <pre><code>[LoadBalancer]      | [Multiple VM nodes] - (API: GetResult  SendFileForTesting)      | [Shared Result DB] </code></pre>  <p>The <strong>question</strong> is  what is the best way to deploy this on azure?<br> Right now  I'm trying to create a load-balancer that has 3 clones of the same VM with the same REST API server and another VM that holds the shared DB.<br> Is there a better way to do this?</p>  <p>Thanks</p>""",azure-virtual-machine
56570231,"How to call an Azure Function App API with Easy-Auth Enables using Active Directory from a C# Client <p>I have an Azure Function App with Azure Active Directory configured but when I call if from my client I keep getting an Unauthorized response.</p>  <p>I have tried a couple different scenarios but nothing worked.  Below is a snippet of the last bit of code that I tried.</p>  <pre><code>                ///                 var @params2 = new NameValueCollection                 {                     {\grant_type\""  \""client_credentials\""}                      {\""client_id\""  $\""{ClientId}\""}                      {\""client_secret\""  $\""{ClientSecret}\""}                      {\""username\""  userId}                      {\""resource\""  \""https://management.azure.com/\""}                 };                 var queryString2 = HttpUtility.ParseQueryString(string.Empty);                 queryString2.Add(@params2);                 var content = new FormUrlEncodedContent(new Dictionary&lt;string  string&gt;                     {                         {\""grant_type\""  \""client_credentials\""}                          {\""client_id\""  ClientId}                          {\""client_secret\""  ClientSecret}                          {\""username\""  userId}                     });                 var authorityUri2 = $\""{string.Format(CultureInfo.InvariantCulture  AadInstance  Tenant).TrimEnd('/')}/oauth2/token\"";                 //var authorityUri2 = $\""https://login.microsoftonline.com/{Tenant}/v2.0/.well-known/openid-configuration\"";                 var authUri2 = String.Format(\""{0}?{1}\""  authorityUri2  queryString2);                 var client2 = new HttpClient();                 var message = client2.PostAsync(authorityUri2  content).Result;                 //var message = client2.GetAsync(authorityUri2).Result;                 var response = message.Content.ReadAsStringAsync().Result;                 dynamic values=null;                 try                 {                     values = JsonConvert.DeserializeObject&lt;Dictionary&lt;string  string&gt;&gt;(response);                 }                 catch                 {                     values = response;                 }                  var AuthToken2 = values[\""access_token\""];                 client2.DefaultRequestHeaders.Authorization = new AuthenticationHeaderValue(\""Bearer\""  AuthToken2);                 HttpResponseMessage response2 = await client2.GetAsync(AppBaseAddress.TrimEnd('/') + \""/api/AADIntegration\"");  if (response.IsSuccessStatusCode)                 {                     // Read the response and data-bind to the GridView to display To Do items.                     string s = await response.Content.ReadAsStringAsync();                     log.LogInformation($\""Success while getting / api / AADIntegration : {s}\"");                      return (ActionResult)new OkObjectResult(s);                 }                 else                 {                     string failureDescription = await response.Content.ReadAsStringAsync();                     log.LogInformation($\""An error occurred while getting / api / AADIntegration : {response.ReasonPhrase}\\n {failureDescription}\"");                     return (ActionResult)new OkObjectResult(failureDescription);                 }  </code></pre>  <p>Data should returned from the Function App.</p>""",azure-web-app-service
42618305,"Azure Functions - Could not load file or assembly ''Microsoft.WindowsAzure.Storage' <p>I have an azure function that is throwing following error even after i have the dependencies specified in project.json file.</p>  <p>\Could not load file or assembly 'Microsoft.WindowsAzure.Storage  Version=8.1.1.0  Culture=neutral  PublicKeyToken=31bf3856ad364e35' or one of its dependencies. The system cannot find the file specified.\""</p>  <pre><code>{   \""frameworks\"": {     \""net46\"": {       \""dependencies\"": {         \""WindowsAzure.Storage\"": \""8.1.1\""       }     }   } } </code></pre>  <p>I have tried to restart the app service  creating another FunctionApp to rule out any issue with host not loading the updated assemblies  still i cannot get it to work.</p>  <p>Nuget restore also shows that this assembly is being restored but still it keeps giving this error. What else can be wrong and how to go about debugging this issue?</p>""",azure-functions
47399962,Azure VM remote faily/sites down <p>this morning I tried to access my VM.I am unable to remote in and all sites are not loading. I ran a Network Watcher to confirm that these ports are passing firewall rules which they are. Any ideas what is going on?</p>,azure-virtual-machine
40997397,Invoking an Azure Function from an Azure LogicApp <p>An Azure Function can be invoked from a LogicApp using the default LogicApp connectors or a HTTP POST method.</p>  <p>We are using the default connector provided by LogicApp. The FunctionApp resides in the same region. This was working without any problem. Now  all of a sudden  every call to the function throws the following error.</p>  <blockquote>   <p>The 'code' query parameter provided in the HTTP request did not match the expected value.</p> </blockquote>  <p>When using the LA connectors  we do not even have to provide the 'code' parameter value  as it is handled by LogicApps internally.</p>  <p>Is this a known bug and is there a workaround? Or am I missing something here?</p>,azure-functions
33812986,"Can't delete azure storage queue message after it has been updated (Message not found) <p>Used two different libraries for node.js  <code>azure-storage</code> and <code>fast-azure-storage</code>  to the same result.</p>  <p>Here's what I do:</p>  <ol> <li>Create a message with default settings - ok.</li> <li>Get message from a queue - ok.</li> <li>Update message to reset <code>visibility timeout</code> - ok.</li> <li>Delete message after processing - Error: MessageNotFound.</li> </ol>  <p>If I skip updating  everything goes smooth.</p>  <p>So what I'm doing wrong?</p>  <p>P.S. Tried to analyse the http traffic  it seems to fully comply with the <a href=\https://msdn.microsoft.com/en-us/library/azure/hh452234.aspx\"" rel=\""nofollow\"">docs</a>. Like this is an Azure internal problem? Maybe someone has any experience updating messages using other language libraries? Too inconvenient to <code>curl</code> that service due to calculation of the auth header.</p>""",azure-storage
56227164,What is the 'PipelinesSDK' user and why has it been added to all of my code Repos? <p>We recently realized that a user 'PipelinesSDK' has elevated permissions (check in  contribute  label  manage branch  etc.) to all of our Repos.  It appears to be an Microsoft OOTB account  and is a member of the 'Security Service Group'  Other accounts that are members of the 'Security Service Group' include:  Agent Pool Service (n)  Hosted - Agent Service  Hosted VS2017 - Agent Service  Agent Service  etc.</p>  <p>I cannot find a reference to this account (PipelinesSDK) on the Microsoft forums.</p>,azure-devops
44211412,"How to specify build configuration for aspnet core project on Azure WebApp <p>For ASP.NET projects  I could setup a application setting with key SCM_BUILD_ARGS and value -p:Configuration=\Debug\"" to change de build configuration.  That doesn't seem to work for aspnet core 1.1 projects.  How to specify the build configuration in such case?</p>""",azure-web-app-service
52032407,"Create VM in Azure with powershell with no public IP <p>I'm creating VM on Azure from an Image using powershell.  </p>  <p>This is the script I'm using .</p>  <pre><code>$UserName = \username\"" $Password = ConvertTo-SecureString \""password@123\"" -AsPlainText -Force $psCred = New-Object System.Management.Automation.PSCredential($UserName  $Password)     New-AzureRmVm `     -ResourceGroupName \""RSG\"" `     -Name \""VMName\"" `     -ImageName \""ImageName\"" `     -Location \""West US\"" `     -VirtualNetworkName \""VNName\"" `     -SubnetName \""default\"" `     -Credential $psCred     -PublicIpAddressName \""None\"" `     -OpenPorts 3389 </code></pre>  <p>But  when I got into the Azure portal and see  some Public Ip is getting assigned by default. I have also tried without giving <code>PublicIpAddressName</code> property assuming   it wont assign any IP  but still it is assigning.  </p>  <p>I want the Public IP to be none.Can anyone help me achieve this.Thanks!</p>""",azure-virtual-machine
54876840,"Create FTP Server From Azure VM <p>I create FTP Server from my Azure Virtual Machine and try the private IP address <a href=\ftp://10.0.0.5\"" rel=\""nofollow noreferrer\"">ftp://10.0.0.5</a> and it works then when I try the public IP address it says that \""Entering Passive Mode\"" </p>  <p><a href=\""https://i.stack.imgur.com/2Uj3t.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/2Uj3t.png\"" alt=\""FTP Folder Error\""></a></p>""",azure-virtual-machine
46493196,"Need I clone an Azure storage account for staging slot? <p>I have an Azure Web Application <code>myapp</code> that uses (via <code>myappConnectionString</code>) a Table Storage Account <code>mytables</code>. </p>  <p>I created two development slots for <code>myapp</code>: <code>myapp-dev</code> and <code>myapp-staging</code>.  I've set the <code>myappConnectionString</code> as \Slot setting\""...</p>  <p>Now  what is the option for <code>mytables</code>?  Should I create two new storage accounts  or there is a possibility to create the \""dev slots\"" for the <code>mytables</code>  <code>mytables-dev</code> and <code>mytables-staging</code>  then use it in the <code>myappConnectionString</code>?</p>""",azure-web-app-service
57492562,How to show column each stage in azure devops <p>I need query data in azure devops for get every changed date in every stage in devops (like new to--> in progress --> to closed status) including change date for each stage </p>  <p>There are column show in devops query but only last stage</p>  <p>For example stage new in query is in 14 august  change to in progress is 15  august  how to get it using query for all task in devops..</p>,azure-devops
17722317,"Encountered a runtime exception when running code <p>I am trying to interact my web app with azure api. I got this php exception error. Can anyone tell me what is it?</p>  <p>RuntimeException: The provided config value '[http | https]' does not belong to the valid values subset:</p>  <p>This is my code (account key has been deleted):</p>  <pre><code>$conn_string=\DefaultEndpointsProtocol=[http | https];AccountName=storage;AccountKey=...\"";   $blobRestProxy = ServicesBuilder::getInstance()-&gt;createBlobService($conn_string); </code></pre>""",azure-storage
56774104,"How to write to serial log in boot diagnostics in azure from VM? <p>I tried writing to COM2 port (which was the only available port in mode) like this:</p>  <pre><code>#define diagnose_general(c a  ...)(printf(\%s - \""c\""\\n\""  #a  a(__VA_ARGS__))) #define diagnose(a  ...)diagnose_general(\""%lx\"" a __VA_ARGS__)  #include &lt;stdio.h&gt; #include &lt;Windows.h&gt;   main() {FILE *fserial; diagnose_general(\""%p\"" fserial=fopen  \""COM2\""  \""w\"");  diagnose(fprintf fserial \""\\n\\nthread %lx:\\n\""  GetCurrentThreadId()); diagnose_general(\""%zx\"" fwrite \""test\"" sizeof \""test\"" 1 fserial); diagnose(fflush fserial); diagnose(fclose fserial);} </code></pre>  <p>It succeseeds but nothing new is shown in the boot diagnostics Serial log window in the portal. Any ideas?</p>""",azure-virtual-machine
56384991,"Azure Function v2 references a project with a higher version of Newtonsoft.Json than Microsoft.NET.Sdk.Functions <p>I am writing a v2 Azure Durable Function. When passing a C# object to a helper activity Function  I get a runtime error in my custom <code>JsonConverter</code>used in serializing the type being passed. The custom <code>JsonConverter</code> is in a library that must reference Newtonsoft.Json 12.x  while Microsoft.NET.Sdk.Functions is locked into 11.0.2.</p>  <blockquote>   <p>jObject  error CS1705: Assembly 'ContractLibrary' with identity 'ContractLibrary  Version=1.0.0.0  Culture=neutral  PublicKeyToken=null' uses 'Newtonsoft.Json  Version=12.0.0.0  Culture=neutral  PublicKeyToken=30ad4fe6b2a6aeed' which has a higher version than referenced assembly 'Newtonsoft.Json' with identity 'Newtonsoft.Json  Version=11.0.0.0  Culture=neutral  PublicKeyToken=30ad4fe6b2a6aeed'    </p> </blockquote>  <p>I believe this <a href=\https://github.com/Azure/azure-functions-host/issues/4049\"" rel=\""nofollow noreferrer\"">GitHub Issue</a> is relevant. <a href=\""https://github.com/Azure/azure-functions-host/issues/4049#issuecomment-470706577\"" rel=\""nofollow noreferrer\"">This comment</a> on that Issue seems to indicate that adding Newtonsoft.Json 12.x as a direct dependency of your Function project may help. This helped in another Function project  but now I have hit this wall again. Is there anything I can do to mitigate this?</p>""",azure-functions
35834117,Git error fatal: Authentication failed <p>I am trying to use git to push my repository to a visual studio team services project  but I get the error:</p>  <pre><code>fatal: Authentication failed for (url of team project </code></pre>  <p>I am using the cmds:</p>  <pre><code>git remote add origin      https://XXXXXXX.visualstudio.com/DefaultCollection/_git/project  git push -u origin -–all </code></pre>  <p>Any idea of the fix for this?</p>  <p>Thanks!</p>,azure-devops
41985925,"How to add a reference to an Azure Function C# project? <p>With the help of the latest Azure SDK  I got the Azure Function tools For Visual Studio So that I can debug my Azure Function on premises - cool.</p>  <p>My azure function needs to use the code of a Business object dll</p>  <p>From the .csx script I can make a reference to the .dll with such a directive at the start</p>  <pre><code>#r  \ServiceBusQueue.Shared.dll\"" </code></pre>  <p>There is no \""Add reference...\"" in an Azure function project. I can only add a Build dependency so that the business object dll is built first.</p>  <p>But when the dll code is updated there is no copying of the dll output to the bin of my azure function directory. Publish on the web is ok This is required in order for the latest business object code to be used in local debug session.</p>  <p>Because there is no tab for Prebuild events in an Azure function project  the solution I have found is to write a <code>Prebuild event</code> in the Function App project </p>  <p><strong>.funproj file</strong></p>  <pre><code>&lt;Target Name=\""BeforeBuild\""&gt;     &lt;Message Text=\""Copying dlls into Azure Function ...\"" /&gt;     &lt;Exec Command=\""Call CopyDlls.cmd $(Configuration)\"" /&gt; &lt;/Target&gt; </code></pre>  <p><strong>Batch file :</strong></p>  <pre><code>rem %1 is the configuration  debug or release echo %1 mkdir .\\ServiceBusQueueTriggerCSharp\\bin copy ..\\ServiceBusQueue.Shared\\bin\\%1\\*.* .\\ServiceBusQueueTriggerCSharp\\bin rem DOS subtlety : test than return code is equal or greater than 1 rem : make the compilation to fail if errorlevel 1 exit /b 1 </code></pre>  <p>That way the dll is copied in the bin directory of the Azure Function project.</p>  <p>Is there a more integrated/cleaner way to do such a thing ?</p>""",azure-functions
45889228,Azure App Service WebSocket Authentication <p>I have an Azure App Service running AspNet Core with Web API &amp; WebSockets middleware enabled. Everything works fine when App service authentication is turned OFF. </p>  <p>When Azure AD authentication is turned ON for the App Service  the Web APIs are working fine but WebSocket connections are failing. I am using ADAL.js in the fronted to authenticate the users and set the bearer token in Authorization header for the API calls.</p>  <p>But I am not sure how to set the bearer token while setting up the WebSocket connection. Does anybody know how to achieve this?</p>,azure-web-app-service
50848781,Azure Storage: Table query filter works on Emulator but no on Azure <p>i'm trying to run a query on an Azure Storage table with this filter </p>  <pre><code>(PartitionKey eq '6') and (ReservedOn ne datetime'0001-01-01T00:00:00.0000000Z') </code></pre>  <p>However  it works on my local emulator but not on Azure. would like to know what might be wrong with this query.</p>  <p>Thank you</p>,azure-storage
53901280,"Azure Virtual Machine DELETE API returning HTTP 204 instead of 404 <p>I am using the following API: <strong><a href=\https://docs.microsoft.com/en-us/rest/api/compute/virtualmachines/delete\"" rel=\""nofollow noreferrer\"">https://docs.microsoft.com/en-us/rest/api/compute/virtualmachines/delete</a></strong></p>  <p>When <strong>trying to delete a VM which does not exist</strong>  I am given this response:</p>  <p><strong>Response Code: 204</strong></p>  <p>Headers- cache-control: no-cache expires: -1 pragma: no-cache x-ms-correlation-request-id: 0bda7be7-6f2a-4202-9565-04d16c210606 x-ms-ratelimit-remaining-subscription-deletes: 14996 x-ms-request-id: 0bda7be7-6f2a-4202-9565-04d16c210606 x-ms-routing-request-id: WESTINDIA:20181223T044056Z:0bda7be7-6f2a-4202-9565-04d16c210606</p>  <p>Body: null</p>  <p><strong>Shouldn't ideally a HTTP 404 be returned?</strong></p>""",azure-virtual-machine
54310000,"Microsoft.IdentityModel.Clients.ActiveDirectory is working fine in the system while i uploading plugin on CRM  its showing an error <p>I am using <code>Microsoft.IdentityModel.Clients.ActiveDirectory</code>. It's working as required in the Console application. While I am uploading it on CRM by converting it to plugin  it's throwing this error. I have ILmerge all dll but <code>Microsoft.IdentityModel.Clients.ActiveDirectory.platform.dll</code> is not merging with it and throwing duplication dll error. Please suggest the solution.</p>  <p><a href=\https://i.stack.imgur.com/Ixbxi.jpg\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/Ixbxi.jpg\"" alt=\""Error\""></a></p>""",azure-devops
45021356,Programmatically creating a user in an Azure Virtual Machine from a webapp in the same resource group <p>I have an MVC Web App running in Azure inside of a resource group where I am also running a Virtual Machine to host an FTP service.  When I create user accounts in the web app  I'd like the application to simultaneously create a user account in the Virtual Machine such that the new user can log in to the FTP server.  As far as I can tell  the VM isn't part of a domain and we're not using Active Directory for these users.  The VM runs Windows Server 2016 Datacenter.  I've found approaches for doing this with Active Directory  and for Linux VMs  but those won't get the job done here.  Can anyone point me in the right direction here?  Any input would be appreciated.</p>,azure-virtual-machine
56194611,"PHP/Drupal Web Application crashes on Azure Web Apps <p>We have hosted application on azure web apps and its continuously crashing due to some issue (might be configuration) - Below is description. We detected Application crashes during this timeframe.</p>  <p><strong>Description:</strong> We detected crashes in your application .</p>  <p><strong>Next Steps:</strong> Please check the event logs table below to see if there are any uncaught exceptions might be causing this. Also  you can check out useful Links section to explore some of the other options that can help diagnose crashes in your application.</p>  <p><strong>Exception Code:</strong> 142 crashes due to (0xE0434352 - CLR Exception)</p>  <p><a href=\https://i.stack.imgur.com/D94lx.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/D94lx.png\"" alt=\""\""></a></p>""",azure-web-app-service
55640718,Subdomain Azure WebApp <p>This is more of a general question about. I have a website running as an Azure App Service. I configured a custom domain so that you are able to call it by <strong>my-site-name.com</strong>. As the request of customers kept growing and each customer has specific demands  I was wondering if it is possible to have a subdomain for each customer. For example  <strong>client1.my-site-name.com</strong> and <strong>client2.my-site-name.com</strong>. Is it possible to do all of this within a single App Service or do I need to set up an Azure App Service for each subdomain? The reason behind my question is  that it would be quite expensive to have an App Service for each indivudal customer.</p>,azure-web-app-service
50703818,"Cannot open Azure VM open port <p>I have a development computer game server which is running on a Azure VM. At the moment i'm unable to see a service running via the port(22) on the VM. I have added an inbound rule on the Networking settings for the VM on Azure as seen in the image</p>  <p><strong><em>Azure Portal</em></strong><br> <a href=\https://i.stack.imgur.com/cUWZP.png\"" rel=\""nofollow noreferrer\"">Azure Portal</a></p>  <p>I have also added an inbound rule in the firewall on the VM itself as seen below for those ports. ( There is another rule for TCP that has the same configuration)</p>  <p><strong><em>Firewall Settings</em></strong><br> <a href=\""https://i.stack.imgur.com/tfevb.png\"" rel=\""nofollow noreferrer\"">Firewall</a></p>  <p>As seen in the image below  the program is listening to one of the ports  but using <a href=\""http://canyouseeme.org/\"" rel=\""nofollow noreferrer\"">http://canyouseeme.org/</a> (as seen on the left side of the screenshot below) the port doesn't seem to be open.The right side show the Application(server) listening to the port(22).</p>  <p><strong><em>Program</em></strong><br> <a href=\""https://i.stack.imgur.com/euh7J.png\"" rel=\""nofollow noreferrer\"">Program</a></p>  <p>Is there something that i'm not configuring correctly? Any suggestions would be greatly appreciated. </p>""",azure-virtual-machine
53123355,"How do you increase # of self-hosted parallel jobs on Azure DevOps Services using an associated VS Enterprise subscription? <p>I have a Visual Studio (formally MSDN) <strong><em>Enterprise</em></strong> License.</p>  <p>My newly created Azure DevOps Service does not reflect this when looking at the self-hosted pipeline configuration under <strong>Project Settings > Pipelines > Retention and parallel jobs</strong>.</p>  <p><a href=\https://i.stack.imgur.com/FkbHw.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/FkbHw.png\"" alt=\""Appropriate section of parallel jobs configuration\""></a></p>  <p>According the the (i) info button:</p>  <blockquote>   <p>Visual Studio Enterprise subscribers get one self-hosted parallel job   as a subscriber benefit.</p> </blockquote>  <p>Anyone know how I can get my Enterprise Subscription to show through to Azure DevOps Services (formally VSTS)? It was pretty simple to do with TFS  but am drawing blanks on ADOS.</p>  <p>My user account for both my Enterprise account and ADOS are one and the same - I was rather hoping it would just show through - apparently that's not the case.</p>  <p>The best I found was <a href=\""https://docs.microsoft.com/en-us/azure/devops/pipelines/licensing/concurrent-pipelines-tfs?view=tfs-2018#use-your-visual-studio-enterprise-subscription-benefit\"" rel=\""nofollow noreferrer\"">this</a> page - but it's only for TFS and explicitly warns that:</p>  <blockquote>   <p>The requested page is not available for Azure DevOps Services. You have been redirected to the newest product version this page is available for.</p> </blockquote>  <p>My initial attempt at asking MS through their online chat \""Concierge Service\"" was met with apathy and a suggestion I ask elsewhere...</p>""",azure-devops
35921299,How to break a lease on Blob Storage in Azure with PowerShell? <p>How do I break a lease on an item in Blob Storage utilizing PowerShell?</p>  <p>I'm receiving the following when trying to upload something over the current image:</p>  <pre><code>Add-AzureRmVhd : The remote server returned an error: (412) There is currently a lease on the blob and no lease ID was specified in the request.. At line:1 char:1 + Add-AzureRmVhd -Destination $osDiskUri -LocalFilePath $localFileName  ... + ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~     + CategoryInfo          : CloseError: (:) [Add-AzureRmVhd]  StorageException     + FullyQualifiedErrorId : Microsoft.Azure.Commands.Compute.StorageServices.AddAzureVhdCommand </code></pre>,azure-storage
33673676,"Nuget DisableSourceControlIntegration not working <p>I'm trying to follow the no-commit strategy in keeping assemblies out of TFS while using NuGet.  I'd like the projects to auto-restore dependencies and not add pending changes to TFS. </p>  <p>I've read a few ways to do this; one being using .tfignore  which will be a pain with the number of projects we have.  We could cloak the folder in TFS  but we would need to add the packages folder for every project in order to cloak it.  The last way  is to configure NuGet via NuGet.config using disableSourceControlIntegration which will keep the NugetClient from adding the packages to the project or solution.  </p>  <p>**This is the configuration XML I'm using:</p>  <pre><code>&lt;solution&gt; &lt;add key=\disableSourceControlIntegration\"" value=\""true\"" /&gt; &lt;/solution&gt; </code></pre>  <p>If I place it in my {SolutionDir}.nuget folder it works for that solution.  I'm trying to place it in my %AppData%\\nuget folder so that it is applied to all solutions but package restore is still causing TFS to add my packages folder contents.</p>  <p>I'm using Visual Studio 2013  NuGet 2.8.6 and TFS from VSOnline.**</p>""",azure-devops
55984904,"Azure DevOps Multiple Organizations or Multiple Projects <p>In trying to organize our Azure Devops we are trying to decide if we should use multiple projects  organizations  or not. The challenge is that we're housing multiple client projects each with its own solution. The options are to make multiple orgs (one for each client) or multiple projects under our own org. It seems per this <a href=\https://docs.microsoft.com/en-us/azure/devops/organizations/projects/about-projects?view=azure-devops\"" rel=\""nofollow noreferrer\"">https://docs.microsoft.com/en-us/azure/devops/organizations/projects/about-projects?view=azure-devops</a> post MSFT recommends the least number of projects possible. We have about the same 10ppl jumping between the projects but there are cases where only a subset would have access  though that's less of a concern than proper use/organization of the repos in a multi-customer setting.</p>""",azure-devops
42509939,Joomla on Azure Web App - performance issues <p>I'm trying to get Joomla running on Azure Web Apps but the performance is terrible. 3-5 second response time no matter what operation I'm doing.</p>  <p>Tried the Bitnami VM and it runs much much smoother  so the problem is obviously in the web app. Have tried both Cleardb and the internal mysql preview db and both give the same laggy result. It doesn't matter what sized machines I run on  they all lag.</p>  <p>The only thing I haven't tried is upgrading the Cleardb database from the free tier to the paid ones  simply because my subscription doesn't allow it. Since I see the same performance issue with the internal mysql db this should not matter.</p>  <p>My guess is that this is an issue with PHP and IIS. Anyone with similar experience  and possibly a solution?</p>,azure-web-app-service
57081360,Azure Functions Multi Instantiation <p>I've implemented an Azure Function with several triggers. Daily trigger creates an item in a queue  queue trigger takes that item and fetches data from a database and generates a report in a blob store  blob store trigger writes an email with the report as an attachment. </p>  <p>Now I have several database which should have the same chain. </p>  <p>My idea was to introduce a dispatcher queue where a generic item (e.g. With properties indicating the start and stop time of the report data and the DB name) is enqueued  and multi instances of my function parametrized with the DB name handle the respective item. </p>  <p>Anyone with a better approach?</p>,azure-functions
36243319,"Cap Resource Usage with Azure DataMovementLibrary Utility <p>I wrote a little utility to run a nightly backup from one of my servers to an Azure blob storage using the Data Movement Library (0.2.0): <a href=\https://azure.microsoft.com/en-us/blog/announcing-azure-storage-data-movement-library-0-2-0/\"" rel=\""nofollow\"">https://azure.microsoft.com/en-us/blog/announcing-azure-storage-data-movement-library-0-2-0/</a></p>  <p>Nice library.  Anyway  I'm wondering if there's a way I can cap the resource usage of this?  I've got a few gig of data to transfer nightly but would rather have a \""low spread\"" resource usage than \""let's try to cram it all at once\"" scenario.</p>  <p>I suspect this is more of a generic process resource question than anything specific to this library  though I've never really had to worry about such elsewhere and would appreciate pointers.</p>  <p>My top priority is bandwidth: I'd like to keep a reasonable amount of open buffer on the network and limit the CPU usage to a reasonable amount.  RAM seems to take care of itself for the most part  but if I can easily cap that also  I'd go for it.</p>  <p>I currently fire this console app utility through the Windows Task Scheduler on a 2012R2 server.  The only lead I have is to possibly set up a launcher that creates a low priority Process to start the utility  but I'm unsure how that ties in with specific resources.</p>  <p>What else can I do to gain some control over the resources this would use?</p>""",azure-storage
22773510,"Image upload not working on Azure Storage <p>I have just deployed my c# web application to windows azure. Image upload works fine on my local machine however now the website has been deployed the image upload doesn't work with azure storage. I just recieve an error saying <code>Error. An error occurred while processing your request.</code> When trying to upload an image.</p>  <p>Any help would be grateful.</p>  <p><strong>Image Upload Controller</strong></p>  <pre><code>public ActionResult Create(UserprofileImage userprofileimage  HttpPostedFileBase file)         {             if (ModelState.IsValid)             {                 if (file != null)                 {                     var manager = new UserManager&lt;ApplicationUser&gt;(new UserStore&lt;ApplicationUser&gt;(new ApplicationDbContext()));                     var currentUser = manager.FindById(User.Identity.GetUserId());                     file.SaveAs(HttpContext.Server.MapPath(\~/Images/\"")                                                           + file.FileName);                     userprofileimage.userImagePath = file.FileName;                     userprofileimage.UserId = currentUser.Id;                     userprofileimage.current = 1;                     db.UserprofileImages.Add(userprofileimage);                     db.SaveChanges();                     var userimage = db.UserprofileImages.Where(u =&gt; u.UserId == currentUser.Id &amp;&amp; u.Id != userprofileimage.Id).ToList();                     foreach(var item in userimage)                     {                         item.Id = 0;                         db.SaveChanges();                     }                      return RedirectToAction(\""Index\""  \""Profile\"");                 }               }              return View(userprofileimage);         } </code></pre>  <p>** Image Upload HTML **</p>  <pre><code>@using (Html.BeginForm(\""Create\""  \""UserprofileImage\""  null  FormMethod.Post                                new { enctype = \""multipart/form-data\"" })) {     @Html.AntiForgeryToken()      &lt;div class=\""form-horizontal\""&gt;          &lt;hr /&gt;         @Html.ValidationSummary(true)          &lt;div class=\""form-group\""&gt;             &lt;div class=\""control-label col-md-2\""&gt;                 Profile Image             &lt;/div&gt;              &lt;div class=\""col-md-10\""&gt;                 &lt;input id=\""userImagePath\"" title=\""Upload a profile picture\""                        type=\""file\"" name=\""file\"" /&gt;             &lt;/div&gt;         &lt;/div&gt;          &lt;div class=\""form-group\""&gt;             &lt;div class=\""col-md-offset-2 col-md-10\""&gt;                 &lt;input type=\""submit\"" value=\""Create\"" class=\""btn btn-default\"" /&gt;             &lt;/div&gt;         &lt;/div&gt;     &lt;/div&gt; } </code></pre>""",azure-storage
55678562,How do you import a DevOps build? <p>I want to take a build from one #DevOps project and put it on another project.  I see how to export the build to JSON  but don't see a way to import it.</p>  <p>I have seen another SO question on how to do this for releases  but that didn't seem to help.</p>,azure-devops
32852566,Routing between two Azure VMs in same region when using external IP <p>I've got two Azure Virtual Machines which both reside in the US-East-2 region. For billing reasons I cannot put them into a virtual network (each VM is on a different subscription) but I can connect from VM1 to VM2 using VM1's Public IP.</p>  <p>Will Azure route the traffic internally or will I get billed for regular internet traffic?</p>,azure-virtual-machine
50523091,"How to deliver large payloads (ie. more than 150 KB) to other functions? <p>While reading the data from function   the result for that is more than 130KB so for that I'm getting an exception of \The UTF-32 size of the JSON-serialized payload must not exceed 60 KB. The current payload size is 130 KB.\"" What to do because I want to deliver that larger amount to data to other function?</p>  <p><a href=\""https://i.stack.imgur.com/GyoTS.png\"" rel=\""nofollow noreferrer\"">enter image description here</a></p>""",azure-functions
8617151,".Net Class Library Unit Test Setup Step for All Tests called only once <p>I have a class library and associated test library. The class library needs to have the Windows Azure Storage emulator started at the beginning of the run regardless of how many classes or tests are executed. I see the base test class but that is called for every class. I need something more akin to a global class that is only called once at the beginning. </p>  <p>This question is in relation to this Azure Storage Emulator setup for testing: <a href=\https://stackoverflow.com/questions/7547567/how-to-start-azure-storage-emulator-from-within-a-program\"">How to start Azure Storage Emulator from within a program</a></p>  <p>I'm using Visual Studio 2010 Professional. The class library is .Net Framework 4.</p>""",azure-storage
50241701,Is it possible to integrate html report with VSTS build summary? <p>How do I integrate a html test results report generated by karma-htmlfile-reporter with VSTS build summary section? Any inputs will help</p>,azure-devops
54370813,Durable Functions: Error getting value from 'UsePollingFileWatcher' <p>This error just started ocurring out of nowhere. I have a durable function in Azure that has been running for about 6 weeks with no problem and last week started failing.</p>  <pre><code>Error getting value from 'UsePollingFileWatcher' on 'Microsoft.Extensions.FileProviders.PhysicalFileProvider'. </code></pre>  <p>I tried it locally and got the same error. There have been absolutely no code changes between what was working and what isn't working now. I'm really stumped.</p>  <pre><code>Newtonsoft.Json.JsonSerializationException HResult=0x80131500 Message=Error getting value from 'UsePollingFileWatcher' on 'Microsoft.Extensions.FileProviders.PhysicalFileProvider'. Source=Newtonsoft.Json StackTrace: at Newtonsoft.Json.Serialization.ExpressionValueProvider.GetValue(Object target) at Newtonsoft.Json.Serialization.JsonSerializerInternalWriter.CalculatePropertyValues(JsonWriter writer  Object value  JsonContainerContract contract  JsonProperty member  JsonProperty property  JsonContract&amp; memberContract  Object&amp; memberValue) at Newtonsoft.Json.Serialization.JsonSerializerInternalWriter.SerializeObject(JsonWriter writer  Object value  JsonObjectContract contract  JsonProperty member  JsonContainerContract collectionContract  JsonProperty containerProperty) at Newtonsoft.Json.Serialization.JsonSerializerInternalWriter.SerializeValue(JsonWriter writer  Object value  JsonContract valueContract  JsonProperty member  JsonContainerContract containerContract  JsonProperty containerProperty) at Newtonsoft.Json.Serialization.JsonSerializerInternalWriter.SerializeObject(JsonWriter writer  Object value  JsonObjectContract contract  JsonProperty member  JsonContainerContract collectionContract  JsonProperty containerProperty) at Newtonsoft.Json.Serialization.JsonSerializerInternalWriter.SerializeValue(JsonWriter writer  Object value  JsonContract valueContract  JsonProperty member  JsonContainerContract containerContract  JsonProperty containerProperty) at Newtonsoft.Json.Serialization.JsonSerializerInternalWriter.SerializeObject(JsonWriter writer  Object value  JsonObjectContract contract  JsonProperty member  JsonContainerContract collectionContract  JsonProperty containerProperty) at Newtonsoft.Json.Serialization.JsonSerializerInternalWriter.SerializeValue(JsonWriter writer  Object value  JsonContract valueContract  JsonProperty member  JsonContainerContract containerContract  JsonProperty containerProperty) at Newtonsoft.Json.Serialization.JsonSerializerInternalWriter.SerializeList(JsonWriter writer  IEnumerable values  JsonArrayContract contract  JsonProperty member  JsonContainerContract collectionContract  JsonProperty containerProperty) at Newtonsoft.Json.Serialization.JsonSerializerInternalWriter.SerializeValue(JsonWriter writer  Object value  JsonContract valueContract  JsonProperty member  JsonContainerContract containerContract  JsonProperty containerProperty) at Newtonsoft.Json.Serialization.JsonSerializerInternalWriter.SerializeObject(JsonWriter writer  Object value  JsonObjectContract contract  JsonProperty member  JsonContainerContract collectionContract  JsonProperty containerProperty) at Newtonsoft.Json.Serialization.JsonSerializerInternalWriter.SerializeValue(JsonWriter writer  Object value  JsonContract valueContract  JsonProperty member  JsonContainerContract containerContract  JsonProperty containerProperty) at Newtonsoft.Json.Serialization.JsonSerializerInternalWriter.SerializeList(JsonWriter writer  IEnumerable values  JsonArrayContract contract  JsonProperty member  JsonContainerContract collectionContract  JsonProperty containerProperty) at Newtonsoft.Json.Serialization.JsonSerializerInternalWriter.SerializeValue(JsonWriter writer  Object value  JsonContract valueContract  JsonProperty member  JsonContainerContract containerContract  JsonProperty containerProperty) at Newtonsoft.Json.Serialization.JsonSerializerInternalWriter.Serialize(JsonWriter jsonWriter  Object value  Type objectType) at Newtonsoft.Json.JsonSerializer.SerializeInternal(JsonWriter jsonWriter  Object value  Type objectType) at DurableTask.Core.Serializing.JsonDataConverter.Serialize(Object value  Boolean formatted) at DurableTask.Core.Serializing.JsonDataConverter.Serialize(Object value) at DurableTask.Core.TaskOrchestrationContext.&lt;ScheduleTaskInternal&gt;d__15.MoveNext() at System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw() at System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess(Task task) at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task) at DurableTask.Core.TaskOrchestrationContext.&lt;ScheduleTaskToWorker&gt;d__14`1.MoveNext() at System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw() at System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess(Task task) at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task) at DurableTask.Core.TaskOrchestrationContext.&lt;ScheduleTask&gt;d__13`1.MoveNext() at System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw() at System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess(Task task) at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task) at Microsoft.Azure.WebJobs.DurableOrchestrationContext.&lt;CallDurableTaskFunctionAsync&gt;d__52`1.MoveNext() at System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw() at System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess(Task task) at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task) at System.Runtime.CompilerServices.TaskAwaiter.GetResult() at DGS.Interfaces.IAM.Functions.IdentityAccessManager.&lt;OrchestrateUpdateDirectory&gt;d__12.MoveNext() in C:\...\IAM.UpdateDirectory.cs:line 141  Inner Exception 1: InvalidOperationException: Cannot modify UsePollingFileWatcher once file watcher has been initialized. </code></pre>,azure-functions
17783415,"Azure Virtual Machine is stuck in Running (Provisioning) mode <p>We created an image from a virtual machine that was running perfectly fine on azure(from last 1 year). This machine has lots of configuration. We executed sysprep utility and created image. We followed all steps mentioned in below article.</p>  <p><a href=\http://www.windowsazure.com/en-us/manage/windows/how-to-guides/capture-an-image/\"" rel=\""nofollow\"">http://www.windowsazure.com/en-us/manage/windows/how-to-guides/capture-an-image/</a></p>  <p>Now we are trying to create VM using that image and received provisioning timeout issue 2 times. No further information is received along with time out issue. We started one more time  but still it’s showing in provisioning mode. </p>  <p>vhd of actual machine is still available in storage.  We tried to create machine from the disk option. In this case machine created successfully and status shown as running  but RDP didn't worked. Following information was also missing on that machine:</p>  <p>1)     Host Name</p>  <p>2)     RDP CERTIFICATE THUMBPRINT</p>  <p>We need assistance to get back the original machine. Please suggest as it’s critical to production.</p>""",azure-virtual-machine
14478462,What does CloudQueue.EndAddMessage(IAsyncResult) actually do? <p>Let's say I call</p>  <pre><code>AsyncCallback callback = new AsyncCallback(QueueMessageAdded); queue.BeginAddMessage(new CloudQueueMessage(message)  callback  null); </code></pre>  <p>where <code>QueueMessageAdded</code> is</p>  <pre><code>private static void QueueMessageAdded(IAsyncResult result) {     queue.EndAddMessage(result); } </code></pre>  <p>What does <strong>EndAddMessage</strong> do?</p>  <p>Including waiting for all callbacks to have been called  it is as slow as calling the synchronous version like this:</p>  <pre><code>Parallel.ForEach(messages  message =&gt; queue.AddMessage(message)); </code></pre>,azure-storage
57127316,"How to return multiple json objects from azure function c#? <p>I already checked the duplicate question and tried same code but doesn't work.</p>  <p>I have two json serialized objects and want to return those two outputs .</p>  <pre><code>#r \Newtonsoft.Json\""  using System.Net; using Microsoft.AspNetCore.Mvc; using Microsoft.Extensions.Primitives; using Newtonsoft.Json; using System.Text;  public static async Task&lt;HttpResponseMessage&gt; Run(HttpRequest req  ILogger log) {     log.LogInformation(\""C# HTTP trigger function processed a request.\"");      string requestBody = await new StreamReader(req.Body).ReadToEndAsync();     dynamic data = JsonConvert.DeserializeObject(requestBody);      var httpResult = data.a;     var sqlData = data.b;      var matchedList = new List&lt;dynamic&gt;();          var unmatchedList = new List&lt;dynamic&gt;();               foreach (var itemHttp in httpResult)             {                 foreach (var itemSql in sqlData)                 {                     if (itemHttp.name == itemSql.tablename)                     {                         matchedList.Add(itemHttp);                     }                     else{                          unmatchedList.Add(itemHttp.name);                     }                 }             }      var jsonToReturn1 = JsonConvert.SerializeObject(matchedList);      var jsonToReturn2 = JsonConvert.SerializeObject(unmatchedList);        return new HttpResponseMessage(HttpStatusCode.OK) {         Content = new StringContent( new { a= new{jsonToReturn1}  b= new {jsonToReturn2}}  Encoding.UTF8  \""application/json\"")     };   } </code></pre>  <p>input used for function -</p>  <pre><code>{   \""a\"": [     {       \""id\"": \""1\""        \""name\"": \""aaa\""     }      {       \""id\"": \""2\""        \""name\"": \""bbb\""     }      {       \""id\"": \""3\""        \""name\"": \""ccc\""     }      {       \""id\"": \""4\""        \""name\"": \""ddd\""     }   ]    \""b\"": [     {       \""id\"": \""111\""        \""tablename\"": \""aaa\""     }      {       \""id\"": \""222\""        \""tablename\"": \""bbb\""     }   ] } </code></pre>""",azure-functions
54697246,"How to send message to Azure IOT hub and display it on Client application using Azure function in portal <p>Am working on Azure resources like Azure Service Bus  Azure Functions  IOT Hub. Here am trying to send queue messages from Azure Service Bus to IOT Hub using Azure functions and then display that messages in my local device (Cloud-To-Device). Am able to read my messages in Azure function using Service Bus Queue Trigger and tried to send them to IOT Hub as output of function. Once  when I run the Azure function \Its can sending the messages to IOT Hub as output\"" but it unable to send them to client device. Can you please suggest me to \""How to solve this situation\""</p>""",azure-functions
29828583,"Error between Azure Web App and Azure Storage in production <p>I have an app in Azure Web Apps (ASP.NET MVC 4) and want to upload files to Azure Storage. The Web.config is configured with the Storage Emulator:</p>  <pre><code>&lt;appSettings&gt;   ...   &lt;add key=\StorageConnectionString\"" value=\""UseDevelopmentStorage=true\"" /&gt;   &lt;add key=\""CloudStorageContainerReference\"" value=\""dnc-demo\"" /&gt; &lt;/appSettings&gt; </code></pre>  <p>And the connection string is configured in the Web.Release.config  :</p>  <pre><code>&lt;connectionStrings&gt;     &lt;add name=\""StorageConnection\"" connectionString=\""DefaultEndpointsProtocol=https;AccountName=XXXX;AccountKey=XXX\"" xdt:Transform=\""SetAttributes\"" xdt:Locator=\""Match(name)\""/&gt; &lt;/connectionStrings&gt; </code></pre>  <p>The problem is that when I upload the file(in production) the following error occurs:</p>  <pre><code>[SocketException: An attempt was made to access a socket in a way forbidden by its access permissions 127.0.0.1:10000] </code></pre>  <p>How can I fix it??</p>  <p>Thanks!!</p>""",azure-storage
46803037,Azure Redis Cache Host Machine <p>I am currently playing with redis cache and need help to figure out whether to host it on a Linux machine or a Windows machine. I believe redis team does not officially support Windows. Thus the safer option goes to Linux.</p>  <p>But i prefer to use windows if there is a reliable implementation since i feel more comfortable with it. </p>  <p>Microsoft developed their own implementation of redis on 64bit windows server and claiming its production ready. What i need to know here is what they are using to host their Azure Redis Cache service. Do they trust their own implementation on windows or they went for the safer option.</p>  <p><strong>Note</strong>: consuming azure redis cache as a service on the cloud is not an option.</p>,azure-virtual-machine
35953354,"How do you authencate to Azure App Services locally? <p>There are alot of tutorials on how to configure the Authentication properties of a given Azure App Service instance:</p>  <p><a href=\https://azure.microsoft.com/en-us/documentation/articles/app-service-api-authentication/\"" rel=\""noreferrer\"">Api Apps</a></p>  <p><a href=\""https://azure.microsoft.com/en-us/blog/announcing-app-service-authentication-authorization/\"" rel=\""noreferrer\"">Expanding App Service Authentication/Authorization</a></p>  <p>There are guides for configuring the Azure Server-Side properties for:</p>  <p><a href=\""https://azure.microsoft.com/en-us/documentation/articles/app-service-mobile-how-to-configure-active-directory-authentication/\"" rel=\""noreferrer\"">AAD</a></p>  <p><a href=\""https://azure.microsoft.com/en-us/documentation/articles/app-service-mobile-how-to-configure-facebook-authentication/\"" rel=\""noreferrer\"">FaceBook</a></p>  <p><a href=\""https://azure.microsoft.com/en-us/documentation/articles/app-service-mobile-how-to-configure-twitter-authentication/\"" rel=\""noreferrer\"">Twitter</a></p>  <p><a href=\""https://azure.microsoft.com/en-us/documentation/articles/app-service-mobile-how-to-configure-google-authentication/\"" rel=\""noreferrer\"">Google</a></p>  <p><a href=\""https://azure.microsoft.com/en-us/documentation/articles/app-service-mobile-how-to-configure-microsoft-authentication/\"" rel=\""noreferrer\"">Microsoft Account</a></p>  <p>I believe these all are setting properties on the server-side gateways that sit in front of our Azure App Service components.  This approach is nice  because you can initiate a login flow simply by directing your user's browser to ~/.auth/login/XYZ.</p>  <p>However  I can't figure out how I'm supposed to Authenticate against any of these at DEVELOPMENT time  running MVC apps and API Apps locally on my PC via localhost.  I don't have a gateway running locally.  There isn't an endpoint listening to localhost/.auth/login/XYZ.</p>  <p>So  what's the story?  How do you authenticate there?  Specifically  how do you develop in such a way that whatever you're going to need to do locally can be Published to your Web and Api Apps and have the auth experience work within the eco-system of the App Service in Azure?</p>""",azure-web-app-service
53190909,"Random Selenium E2e Tests Fail because of timeouts on Azure DevOps but work locally and with remote Selenium (BrowserStack Automate) <p>I've got a suite of Selenium tests that work perfectly in my local environment and using Browserstack Automate  but fail on Azure DevOps.  </p>  <p>There are no configuration or setting changes when running on Azure Devops.</p>  <p>We've followed all the documentation here: <a href=\https://docs.microsoft.com/en-us/azure/devops/pipelines/test/continuous-test-selenium?view=vsts\"" rel=\""noreferrer\"">https://docs.microsoft.com/en-us/azure/devops/pipelines/test/continuous-test-selenium?view=vsts</a></p>  <p>Random tests fail  never the same ones.  </p>  <p>The tests always fail because of timeouts.  I wait for the pages to load for 5 minutes so it's not a case of the timeouts being too low. </p>  <p>There are no firewalls in place  the application is public.</p>  <p>Authentication always succeeds so the tests are able to load the application.</p>  <p>Not sure what to try next.</p>  <p>Below is a copy of the Azure DevOps log.  4 tests passed but all the other's failed.  Usually  only 4-5 tests fail.</p>  <p>This tests works perfectly using BrowserStack Automate (remote selenium) and locally.</p>  <pre><code>2018-11-17T05:40:28.6300135Z  Failed   StripeAdmin_WhenOnTab_DefaultSortIsByIdDescending 2018-11-17T05:40:28.6300461Z Error Message: 2018-11-17T05:40:28.6304198Z  Test method CS.Portal.E2e.Tests.Admin.StripeAdmin.StripeAdminTests.StripeAdmin_WhenOnTab_DefaultSortIsByIdDescending threw exception:  2018-11-17T05:40:28.6305677Z OpenQA.Selenium.WebDriverTimeoutException: Timed out after 300 seconds 2018-11-17T05:40:28.6307041Z Stack Trace: 2018-11-17T05:40:28.6307166Z     at OpenQA.Selenium.Support.UI.DefaultWait`1.ThrowTimeoutException(String exceptionMessage  Exception lastException) 2018-11-17T05:40:28.6307999Z    at OpenQA.Selenium.Support.UI.DefaultWait`1.Until[TResult](Func`2 condition) 2018-11-17T05:40:28.6308188Z    at CS.Portal.E2e.Tests.Utility.WebDriverUtilities.WaitForElement(IWebDriver driver  By by  Boolean mustBeDisplayed) in D:\\a\\1\\s\\CS.Portal.E2e.Tests\\Utility\\WebDriverUtilities.cs:line 26 2018-11-17T05:40:28.6319651Z    at CS.Portal.E2e.Tests.Admin.StripeAdmin.StripeAdminTests.StripeAdmin_WhenOnTab_DefaultSortIsByIdDescending() in D:\\a\\1\\s\\CS.Portal.E2e.Tests\\Admin\\StripeAdmin\\StripeAdminTests.cs:line 51 2018-11-17T05:40:28.6319982Z  2018-11-17T05:40:34.4671568Z Results File: D:\\a\\1\\s\\TestResults\\VssAdministrator_factoryvm-az416_2018-11-17_03_08_24.trx 2018-11-17T05:40:34.4692222Z  2018-11-17T05:40:34.4695222Z Attachments: 2018-11-17T05:40:34.4697610Z   D:\\a\\1\\s\\TestResults\\672f4d28-5082-42e9-a7e7-f5645aadcfd8\\VssAdministrator_factoryvm-az416 2018-11-17 03_02_43.coverage 2018-11-17T05:40:34.4697943Z  2018-11-17T05:40:34.4698278Z Total tests: 34. Passed: 4. Failed: 30. Skipped: 0. </code></pre>""",azure-devops
48163740,How to generate EF entities from DB in Azure Functions? <p>I'm trying to use EF with Azure Functions in Visual Studio using C#. I have installed EF through NuGet. <br/> However when I tried to add an ADO.NET Entity Data Model to the project  I couldn't find it under New Item -> Visual C# Items -> Data like with web and console projects. <br/> How does one do this? Is it supported?</p>,azure-functions
44677338,"ASP.NET Core Azure App Service httpContext.Request.Headers[\Host\""] Value <p>Faced strange behaviour today. We are hosting asp.net core 1.1 web app with Azure App Services and using subdomains that route to a specific controller or area.  So in my SubdomainConstraint: IRouteConstraint I use </p>  <pre><code>HttpContext.Request.Headers[\""Host\""] </code></pre>  <p>to get host name. That previously returned smth like that</p>  <pre><code>mywebsite.com or subdomain.mywebsite.com  </code></pre>  <p>Starting today (or a maybe yesterday) it started to return my App Service name instead of host name. On localhost everything works fine. Enumerating through </p>  <pre><code>Context.Request.Headers </code></pre>  <p>in one of my Views gives me on localhost:</p>  <pre><code>Accept :  text/html application/xhtml+xml application/xml;q=0.9 image/webp */*;q=0.8 Accept-Encoding : gzip  deflate  sdch  br Accept-Language : ru-RU ru;q=0.8 en-US;q=0.6 en;q=0.4 ca;q=0.2 Cookie : .AspNetCore.Antiforgery.... Host : localhost:37202 User-Agent : Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36  (KHTML  like Gecko) Chrome/58.0.3029.110 Safari/537.36 Upgrade-Insecure-Requests : 1 </code></pre>  <p>in Azure App Service:</p>  <pre><code>Connection : Keep-Alive Accept : text/html application/xhtml+xml application/xml;q=0.9 image/webp */*;q=0.8 Accept-Encoding : gzip  deflate  sdch Accept-Language : ru-RU ru;q=0.8 en-US;q=0.6 en;q=0.4 ca;q=0.2 Cookie : AspNetCore.Antiforgery.... Host : mydeploymentname:80 Max-Forwards : 10 User-Agent : Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML  like Gecko) Chrome/58.0.3029.110 Safari/537.36 Upgrade-Insecure-Requests : 1 X-LiveUpgrade : 1 X-WAWS-Unencoded-URL : / X-Original-URL : / X-ARR-LOG-ID : 9c76e796-84a8-4335-919c-9ca4rb745f4fefdfde DISGUISED-HOST : mywebsite.com X-SITE-DEPLOYMENT-ID : mydeploymentname WAS-DEFAULT-HOSTNAME : mydeploymentname.azurewebsites.net X-Forwarded-For : IP:56548 MS-ASPNETCORE-TOKEN : a97b93ba-6106-4301-87b2-8af9a929d7dc X-Original-For : 127.0.0.1:55602 X-Original-Proto : http </code></pre>  <p>I can get what I need from </p>  <pre><code>Headers[\""DISGUISED-HOST\""] </code></pre>  <p>But having problems with redirects to a login page  it redirects to the wrong URL with my deployment name.</p>  <p>Wondering if I could mess something up anywhere. But we've made last deployment like a few days ago and it worked fine after that.</p>""",azure-web-app-service
32619221,Difference between new and classic storage accounts in Azure <p>Azure has <code>Storage accounts</code> and <code>Storage accounts (classic)</code> in the Azure Portal.</p>  <p>What are the differences between them? Is there any reason to migrate from a classic storage account to a new storage account?</p>,azure-storage
33648864,"VSO Build vNext - Nuget Package Build Step - Use build number to version package <p>I have my build number format specified as :</p>  <pre><code>$(BuildDefinitionName)_$(Year:yyyy).$(Month).$(DayOfMonth)$(Rev:.r) </code></pre>  <p>This creates build Numbers in the format of \BuildDefinitionName_2015.11.11.1\""</p>  <p>Where revision seems to be the number of times the build has run for that day.</p>  <p>I would like to be able to use this value in further build steps.</p>  <p>For example I am creating a nuget package with the nuget packager step and am using the option \""Use build number to version the package\""</p>  <p>This creates me packages similar to this \""PackageName.2015.11.11.1.nupkg\""</p>  <p>I then want to use the nuget publisher build step to publish this  but the problem is that over time you get more than one package in the package folder and the nuget publisher step uses a pattern for matching packages to publish.</p>  <p>ie </p>  <ul> <li>\""PackageName.2015.11.11.1.nupkg\""</li> <li>\""PackageName.2015.11.11.2.nupkg\""</li> <li>\""PackageName.2015.11.11.3.nupkg\""</li> </ul>  <p>Without being explicit about the file to publish  the publisher step will publish all these files.</p>  <p>I don't want this  I just want it to publish the file which matches the current build number.</p>  <p>So I would like to be able to set the build number parts in the pattern.</p>  <p>ie <code>PackageName.$(Year:yyyy).$(Month).$(DayOfMonth)$(Rev:.r).nupkg</code></p>  <p>But it appears that these variables do not get substituted in the search path and come through as a literal match.</p>  <p>It seems strange that in the nuget package step it gives you the option to create packages by build number  but then does not allow you to match this in the nuget publish build step.</p>""",azure-devops
41354909,"Download Bulk Images from Azure Blob C# - Request Time out Issue <p>We are storing our files into Azure blob  we are giving option to our user to download multiple files in a zip format  ( can be 500-1000 files) from our website. We have placed a code but its taking longer time to execute and as we are having our website hosted on Azure Web app its getting 500 request time out. Can some one help us to show how we can improve and make it more faster? </p>  <p>Please find a code that we did. </p>  <pre><code>string[] pods;                             string fileName = \\"";                             try                             {                                 System.IO.Directory.CreateDirectory(path);                                 foreach (var item in objData)                                 {                                     pods = item.POD.Split(new string[] { \"" \"" }  StringSplitOptions.None);                                     foreach (var itemPOD in pods)                                     {                                         string[] data = itemPOD.Split(new string[] { \""/\"" }  StringSplitOptions.None);                                         fileName = System.IO.Path.Combine(path  DateTime.Now.ToString(\""dd_MM_yyyy\"") + \""_\"" + data[data.Length - 1]);                                         try                                         {                                             var stream = new WebClient().OpenRead(itemPOD);                                             using (System.Drawing.Image img = System.Drawing.Image.FromStream(stream))                                             {                                                 img.Save(fileName  System.Drawing.Imaging.ImageFormat.Jpeg);                                                 GC.Collect();                                             }                                         }                                         catch (Exception)                                         {                                          }                                     }                                 }                                 FileDownloads objFileDownload = new FileDownloads();                                 var filesCol = objFileDownload.GetFile(path);                                 using (var memoryStream = new MemoryStream())                                 {                                     using (var ziparchive = new ZipArchive(memoryStream  ZipArchiveMode.Create  true))                                     {                                         for (int i = 0; i &lt; filesCol.Count; i++)                                         {                                             ziparchive.CreateEntryFromFile(filesCol[i].FilePath  filesCol[i].FileName);                                         }                                     }                                     return File(memoryStream.ToArray()  \""application/zip\""  \""Attachments.zip\"");                                 }                             }                             catch (Exception)                             {                              } </code></pre>""",azure-web-app-service
45060748,"Binding to Custom Queue Trigger fields in Azure Functions <p>I've been struggling to define table/blob output bindings based on data in a queue trigger.  I realize I could accomplish this with imperative binding in code  but I think this should also be possible via the bindings in functions.json.  I thought I'd solved this  but am now getting a strange runtime error which I cannot find any information on via searching.</p>  <p>Here's the functions.json definition I am using:</p>  <pre><code>{   \bindings\"": [     {       \""name\"": \""myQueueItem\""        \""type\"": \""queueTrigger\""        \""direction\"": \""in\""        \""queueName\"": \""w2pdfqueue\""        \""connection\"": \""xxxxxxxx\""     }      {       \""type\"": \""table\""        \""name\"": \""FW2Table\""        \""tableName\"": \""FW2\""        \""take\"": 1        \""connection\"": \""xxxxxxxxx\""        \""direction\"": \""in\""        \""partitionKey\"": \""{PartitionKey}\""        \""rowKey\"": \""{RowKey}\""     }      {       \""type\"": \""blob\""        \""name\"": \""outputBlob\""        \""path\"": \""{ClientID}/{ResourceID}\""        \""connection\"": \""xxxxxxxxxx\""        \""direction\"": \""inout\""     }   ]    \""disabled\"": false } </code></pre>  <p>And here is the Run statement I have:</p>  <pre><code>public static void Run(W2QueueItem myQueueItem  TraceWriter log  W2Row FW2Table  CloudBlockBlob outputBlob) </code></pre>  <p>Finally  the custom queue message I am trying to use for binding:</p>  <pre><code>public class W2QueueItem  {     public string PartitionKey { get; set; }     public string RowKey { get; set; }     public string ClientID { get; set; }     public string ResourceID { get; set; } } </code></pre>  <p>All of the above compiles successfully  however at runtime I am getting the following error message.  I'm not sure how to proceed -- other examples online of binding to custom queue messages do not seem to encounter this type of error.  Any suggestions would be welcome!</p>  <pre><code>ost: Binding parameters to complex objects (such as 'W2QueueItem') uses Json.NET serialization.  1. Bind the parameter type as 'string' instead of 'W2QueueItem' to get the raw values and avoid JSON deserialization  or 2. Change the queue payload to be valid json. The JSON parser failed: Unexpected character encountered while parsing value: s. Path ''  line 0  position 0. . </code></pre>  <p>The contents of the message queue when the error occurs are:</p>  <pre><code>{   \""PartitionKey\"": \""d6a2e537-a0a0-4949-a6fd-2e56723cdaf0\""    \""RowKey\"": \""1|053e3136-048d-417b-94c0-6339d3b9c835\""    \""ClientID\"": \""ef1de151-9855-54d7-4598-6ee416dc5a51\""    \""ResourceID\"": \""a33efdd2-45ae-47ee-bc56-55b431468962\""    \""$AzureWebJobsParentId\"": \""e1337646-5f0f-44e4-86fe-e6a46589a739\"" } </code></pre>""",azure-functions
39262448,"Building Windows 10 Mobile app using Visual Studio Team Services <p>I'm trying to build Windows 10 Mobile app (UWP) using Visual Studio Team Services (was Visual Studio Online) build system  however it fails with error:</p>  <blockquote>   <p>Could not find SDK \WindowsMobile  Version=10.0.14393.0\"".</p> </blockquote>  <p>How can I solve this? Does it need any special setting? I think it's related to the \""Windows Mobile Extension for the UWP\"" that is referenced in the solution.</p>""",azure-devops
47305164,"Azure app service: Cannot find the certificate in X509Store(StoreName.My  StoreLocation.CurrentUser) <p>I have written a program that needs a certificate for signing and some other things.</p>  <p>I have uploaded my pfx file as private certificate in SSL certificates of my app service.</p>  <p><a href=\https://i.stack.imgur.com/4qHsq.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/4qHsq.png\"" alt=\""enter image description here\""></a></p>  <p>Then I've tried to see installed certificates on my app service as it has been described <a href=\""https://blogs.msdn.microsoft.com/karansingh/2017/03/15/azure-app-services-how-to-determine-if-the-client-certificate-is-loaded/\"" rel=\""nofollow noreferrer\"">in here</a> by using power shell.</p>  <p><a href=\""https://i.stack.imgur.com/QuYgn.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/QuYgn.png\"" alt=\""enter image description here\""></a></p>  <p>But my current user doesn't have any certificates.</p>  <p>I've also checked my local machine  but it wasn't there either.  <a href=\""https://i.stack.imgur.com/kj5w6.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/kj5w6.png\"" alt=\""enter image description here\""></a></p>  <p>I cannot also find it using my c# code:</p>  <pre><code> X509Store certStore = new X509Store(StoreName.My  StoreLocation.CurrentUser);         certStore.Open(OpenFlags.ReadOnly);         X509Certificate2Collection certCollection = certStore.Certificates.Find(X509FindType.FindByThumbprint  ThumbPrint  false);         if (certCollection.Count == 0)             throw new Exception(\""Certificate not found\""); </code></pre>""",azure-web-app-service
56024285,How to set default branch policies for future branches in Azure Devops <p>I want to lock release branches from merging anything. Adding a default branch policy is fine as well. I can do it for any existing branch but not future branches. Is there a way to set default branch policies?</p>,azure-devops
49440908,How do I add a C# Azure Function App an Azure Resource Group Project for deployment <p>How do I add a C# Azure Function App that I have created in my Visual Studio 2017 solution to an Azure Resource Group Project and have it deploy to Azure. The ultimate goal here is I have a WebApp that is a website but I want to use an Azure Function App as a backend. This would require two separate projects but I want them to publish at the same time which lead me to Azure Resource Group projects. I was able to successfully deploy the Resource Group when it was only the WebApp but once I added the Function App it fails to build. I feel like this whole process should be a lot simpler.</p>,azure-functions
20889686,"Migrate local Git repo to Visual Studio Online from IDE <p>I created a new Team Project on Visual Studio Online that I have connected to in Visual Studio 2013. Using the IDE  I cloned a local Git repo (that was pulled down from GitHub) into the Local Git Repositories section. </p>  <p>When I went through the documentation on Visual Studio's <a href=\http://www.visualstudio.com/en-us/get-started/share-your-code-in-GIT-vs\"" rel=\""nofollow noreferrer\"">website</a>  it showed an option to \""Publish to {Team Project}.\""</p>  <p><img src=\""https://i.stack.imgur.com/YkW2G.png\"" alt=\""enter image description here\""></p>  <p>Mine doesn't show this:</p>  <p><img src=\""https://i.stack.imgur.com/pWCKc.png\"" alt=\""enter image description here\""></p>  <p>And it looks like this has been a <a href=\""https://stackoverflow.com/questions/14711796/publish-local-git-repository-to-team-foundation-service\"">problem</a> in the past (others have needed to change the .git/config file). Has this been fixed yet so I can use the IDE completely? Or am I missing something? </p>""",azure-devops
48894871,"Terraform - Provision VM Extensions with Parameters <p>I'm trying to provision two <code>Azure</code> Virtual Machine <code>Extensions</code>  that have parameters associated to them:</p>  <ol> <li>Microsoft Antimalware</li> <li>Site24x7 Agent for Windows Server Monitoring</li> </ol>  <p>I could not find much documentation  but I tried to extract the data from the azure portal under <code>Automation script</code> to see how it was setup in JSON template.</p>  <pre><code>resource \azurerm_virtual_machine_extension\"" \""test1\"" { name                 = \""IaaSAntimalware\"" location             = \""${azurerm_resource_group.test.location}\"" resource_group_name  = \""${azurerm_resource_group.test.name}\"" virtual_machine_name = \""${azurerm_virtual_machine.testapp.name}\"" publisher            = \""Microsoft.Azure.Security\"" type                 = \""IaaSAntimalware\"" type_handler_version = \""1.5.5.1\"" auto_upgrade_minor_version = \""true\""  settings = &lt;&lt;SETTINGS     {         \""AntimalwareEnabled\"": true          \""RealtimeProtectionEnabled\"": \""true\""          \""ScheduledScanSettings\"": {             \""isEnabled\"": \""true\""              \""day\"": \""1\""              \""time\"": \""120\""              \""scanType\"": \""Quick\""             }          \""Exclusions\"": {             \""Extensions\"": \""\""              \""Paths\"": \""\""              \""Processes\"": \""\""             }     } SETTINGS  tags {     environment = \""${var.tag_env}\"" } } </code></pre>  <p><a href=\""https://i.stack.imgur.com/9Plng.png\"" rel=\""nofollow noreferrer\"">Azure Portal Configuration for Antimalware Extension</a></p>  <blockquote>   <p>azurerm_virtual_machine_extension.test1: 1 error(s) occurred:`</p>      <p>azurerm_virtual_machine_extension.test1: compute.VirtualMachineExtensionsClient#CreateOrUpdate: Failure sending request: StatusCode=400 -- Original Error: autorest/azure: Service returned an error. Status=400 Code=\""InvalidParameter\"" Message=\""The value of parameter typeHandlerVersion is invalid.\""</p> </blockquote>  <p>Does anyone know the proper syntax?</p>""",azure-virtual-machine
57553375,"Images uploaded to Azure blob storage unavailable when browsing by direct URL <p>I have uploaded a number of images to a Blob container on an Azure storage account of type StorageV2 (general purpose v2).</p>  <p>These were uploaded programmatically. Here's the code I used:</p>  <pre><code>public Task CopyFile(string fileName  string targetPath) {     var blobRef = Container.GetBlockBlobReference(targetPath);      blobRef.Properties.ContentType = GetContentType(fileName);      return blobRef.UploadFromFileAsync(fileName); }  public string GetContentType(string fileName) {     var provider = new FileExtensionContentTypeProvider();      if (!provider.TryGetContentType(fileName  out var contentType))     {         contentType = \application/octet-stream\"";     }      return contentType; } </code></pre>  <p><code>Container</code> is an initialized <code>CloudBlobContainer</code> instance.</p>  <p>When I use the Storage Explorer I can see the uploaded files. If I view the properties of any file it lists a Uri property. However  if I copy the value (a URL) and paste into a browser I see the following error page:</p>  <pre><code>&lt;Error&gt;     &lt;Code&gt;ResourceNotFound&lt;/Code&gt;     &lt;Message&gt;         The specified resource does not exist. RequestId:12485818-601e-0017-6f69-56c3df000000 Time:2019-08-19T08:35:13.2123849Z     &lt;/Message&gt; &lt;/Error&gt; </code></pre>  <p>But if I double-click the file in Storage Explorer it downloads the image correctly. The URL it uses is the same as the one I copied earlier as far as I could tell  except for some additional querystrings that look like this: <code>?sv=2018-03-28&amp;ss=bqtf&amp;srt=sco&amp;sp=rwdlacup&amp;se=2019-08-19T16:49:38Z&amp;sig=%2FJs7VnGKsjplalKXCcl0XosgUkPWJccg0qdvCSZlDSs%3D&amp;_=1566204636804</code></p>  <p>I assume this must mean my blobs are not publically available  but I can't find any setting that will make my images available publically at their known URI. Can anyone point me in the right direction here? Thank you.</p>""",azure-storage
57386955,Retrieve Application Insights association with app service through powershell <p>I need to get the list of azure application insights associated withe azure resources through powershell. Can anyone help with the query?</p>,azure-web-app-service
56051095,Global exception handler for Azure Functions <p>Is it possible to have a global exception handler for Azure Functions .Net C# project?</p>  <p>We'd like to have a centralized place to log exceptions to Rollbar.</p>,azure-functions
53171428,"upload file to azure blob/file storage with python <p>I want to upload a blob file from a device</p>  <p>Normally I use the command:</p>  <pre><code>import iothub_client client.upload_blob_async( filename  content  len(content)  callback_blobUpload  blobContext ) </code></pre>  <p>...as mentioned in azure documentation  example.</p>  <p>the file is stored in azure as follows: location: storageContainer/deviceId/blobFilePathName</p>  <p>I want to upload the file with the following destination result:</p>  <ol> <li>location: storageContainer/subcontainer1/subContainer2/deviceId/blobFilePathName</li> <li>location: storageContainer/subcontainer1/subContainer2/blobFilePathName</li> </ol>  <p>Is this possible with the MS python library \azure-iothub-device-client\"" ?</p>""",azure-storage
28675770,"Why doesn't Azure Table Storage support DateTimeOffset? <p>Before anyone closes this as a duplicate  I am aware that Azure Table Storage doesn't support the <code>DateTimeOffset</code> type natively (<a href=\https://msdn.microsoft.com/en-us/library/azure/dd179338.aspx\"" rel=\""nofollow\"">MSDN states as much</a>; trying to read and write entities having <code>DateTimeOffset</code> properties doesn't throw an exception  but doesn't maintain the correct timestamps either).</p>  <p>My question is why <em>isn't</em> this data type supported  particularly as it already existed when Azure was created. What's even more confusing is that the .NET API for Azure Table Storage seems to offer support for the data type: entities get converted into a dictionary of <code>EntityProperty</code> values  and the <code>EntityProperty</code> class has both a <code>DateTimeOffsetValue</code> property and a constructor that takes a value of that type. Seems odd that they would add this support in the API if the Azure side of things doesn't support the type anyway.</p>""",azure-storage
24369164,Azure Virtual Machine vs dedicated server <p>I need to provide a desktop application up to 10 users. This application is a ERP  basically database mining and reporting. I will use Windows Server to offer support to concurrent users via Remote Desktop Connection.</p>  <p>Do somebody have experience comparing the performance between Azure Virtual Machine and a dedicated server?</p>  <p>At the present  I use Azure  but changing the settings to a powerful machine does not seem to affect to the time to generate reports  specially when the application needs to read the database or load the dlls for first . </p>,azure-virtual-machine
43157308,"Building/deploying azure webjob with website copies source files instead of binaries/executable <p>I've added a webjobs sdk project to my existing website.  The website runs as an azure app service.  I've always done building and deployment by queueing up a new build in visual studio online and deploying from there to my azure website.  Recently I created this webjob project in the same solution  that based on this webjobs-list.json generated and put in the website project should cause the webjob to also be deployed with the website during deployment (or so the documentation says).  What is happening though is that when it deploys  and I take a look at what is in app_data\\jobs\\continuous  is not the binaries and executable that I expect  it's the actual source code/project files that have been copied into there.  Obviously that isn't going to run  and it shouldn't have thrown source code out there on my website anyway.  </p>  <p>I also had to change my release definition in visual studio online to just look for [my website project name].zip  instead of just *.zip  because otherwise I'd get an error from the release indicating: Error: More than one package matched with specified pattern. Please restrain the search patern.</p>  <p>...this appeared to be because the build process not only creates a zip file for my website  it also creates one for the webjobs project.  From what I understand and have read  I am supposed to change my release to just look for the website zip file and ignore the other zip file  and just let that get deployed and it should all work fine  but again  what is copied into my jobs folder on the website isn't the binaries or executable for the webjob  it's the actual source files.  </p>  <p>How can I get this to deploy just the binaries and executable with the site instead of the source files?  </p>  <p>The only other thing I could find to do is remove the webjobs-list.json file from the web project so they are no longer linked together  which causes the build to no longer populate app_data\\jobs\\continuous with my web job project source files when deployed  and to create an additional task in my release definition to grab and deploy the other zip file that is created during the build (for the webjob project  and it contains the debug files with those binaries for whatever reason).  However everything I read tells me that this is not supposed to have to be done  it should just work without me having to do this.</p>  <p>EDIT:</p>  <p>My web project is an MVC 5 project that I created with VS 2013.  The web jobs project uses the 2.0.0.0 version of the webjobs sdk.</p>  <p>The build and release definitions  I followed the steps in this article to create:</p>  <p><a href=\https://www.visualstudio.com/en-us/docs/build/apps/cd/deploy-webdeploy-webapps\"" rel=\""nofollow noreferrer\"">https://www.visualstudio.com/en-us/docs/build/apps/cd/deploy-webdeploy-webapps</a></p>  <p>The only additional thing I did after following this article  is in my release definition  I changed the Package or Folder field to look for [my mvc web project name].zip  instead of *.zip  otherwise I'd get the error message noted above.</p>""",azure-devops
53410687,How to sign-in with azure in node js application <p>Please help me to login with authentication using azure active directory.</p>,azure-devops
47536304,"How to generate a low disk alert for an Azure virtual machine <p>i have an virtual machine (which am using as build server) which disk gets piled up frequently and am working on fixing that  mean while am looking for options to setup an alert to be fired when my disk space gets high.</p>  <p>i checked the available metrics under monitoring but could only find \disk write bytes\"" and \""disk read bytes\"" which are not helpful for me.</p>  <p>i will need help on setting a disk space alert to be sent to my email.</p>  <p>Any help on this is really appreciated.</p>""",azure-virtual-machine
51704048,"How to use #load in scriptcs for an Azure function <p>I downloaded the code of an Azure Function created in the portal. Now I'm tryng to load a class in the main file (run.csx) using in the first line:</p>  <pre><code>#load \..\\shared\\data.csx\"" </code></pre>  <p>but i get the error: </p>  <pre><code> \""run.csx(1 7): error CS1504: Source file '..\\shared\\data.csx' could not be opened -- Could not find file.\"" </code></pre>  <p>I added in the host.json:</p>  <pre><code>\""watchDirectories\"": [ \""Shared\"" ] </code></pre>  <p>I tried with uppercase  lowcase  put the class in the same folder of the run.csx but it doesn't work. I miss something?</p>""",azure-functions
4084499,Best way to Architect Azure Worker Role to Process Data from ~10 Queues <p>I have one worker role that throws data into around 10 queues that need to be processed. There is a lot of data - probably around 10-100 messages a second that gets queued up in various queues. </p>  <p>The queues hold different data and process them separately. There is a single queue in particular that is very active. </p>  <p>The way I have it setup now  I a separate worker role that spawns 10 different threads  each thread executes a method that has a while(true){get message from queue and process it}. Whenever data in the queue gets backed up we simply launch more of these processes to help speed up the processing of the data from the queue. Also  since one queue is more active  I actually launch a number of threads pointing at the same method to process data from that queue. </p>  <p>However  I am seeing high CPU utilization of the deployment. Almost at or near 100% constantly. </p>  <p>I am wondering if this is because of thread starvation? Or because accessing the queue is RESTful and the threads end up blocking each other via doing the connection and slowing things down? Or  is it because I use:</p>  <pre><code>while(true) {    var message = get message from queue;    if(message != null)    {        //process message    } } </code></pre>  <p>And that gets executed too fast? </p>  <p>Every processing of the message also saves it to the Azure Table Storage or the DB - so it might be the process of saving this data that is eating up the CPU. </p>  <p>In effect  it's been really hard to debug the high CPU load. So  my question is: are there general architecture changes that I can make that will help alleviate + prevent any possible issue that there might be? (e.g. instead of using while(true) using a different type of polling - although I'd imagine it's the same in the end for that example). </p>  <p>Maybe simply spawning new threads using new Thread() is not the best way to go. </p>,azure-storage
17956277,best technique for saving CSV logs in Azure Blob <p>I'm logging a registration entry to a CSV file (as it's needed for later to include all registrations throughout the month)  by appending the entry to the last line of that file  like:</p>  <pre><code>using (StreamWriter w = new StreamWriter(currentPath  true)) {     w.WriteLine(fileRow); } </code></pre>  <p>but in Windows Azure  I can't access physical files  so I need to use Blob Storage. </p>  <p><strong>How do I perform the same operation on a Blob block?</strong></p>  <p>I tried:</p>  <pre><code>CloudBlobContainer blobContainer = blobStorage.GetContainerReference(containerName); cloudBlob = blobContainer.GetBlobReferenceFromServer(blobNameLogs);  MemoryStream oldText = new MemoryStream(); cloudBlob.DownloadToStream(oldText);  // record to save string fileRow = row.ToFileRow();  // append MemoryStream newText = new MemoryStream(); using (StreamWriter w = new StreamWriter(newText  System.Text.Encoding.Default)) {     w.WriteLine(oldText);     w.WriteLine(fileRow);      // set blob data     cloudBlob.UploadFromStream(newText); } </code></pre>  <p>But I keep getting <code>0 bytes</code> on the file after this operation ... what am I missing? Is there an easier operation for simply append text to an existing file?</p>,azure-storage
51857714,"Azure Function Sengrid - Attachment only working locally <p>I'm trying to add a file to a mail sent by an azure function.</p>  <p>Here my function : </p>  <pre><code>#r \Newtonsoft.Json\"" #r \""SendGrid\"" #r \""System.Web\""  using System.Web; using SendGrid.Helpers.Mail; using System.Net; using Microsoft.AspNetCore.Mvc; using Microsoft.Extensions.Primitives; using Newtonsoft.Json; using Microsoft.AspNetCore.Http; using System.IO; using Microsoft.Azure.WebJobs.Host; using System;  public static IActionResult Run(HttpRequest req  TraceWriter log  out SendGridMessage message) {     log.Info(\""C# HTTP trigger function processed a request.\"");      string requestBody = new StreamReader(req.Body).ReadToEnd();     EmailContent data = JsonConvert.DeserializeObject&lt;EmailContent&gt;(requestBody);      if (data == null)     {         throw new ArgumentNullException(\""Data could not be null\"");     }      message = new SendGridMessage();      message.AddTo(data.Email);     message.SetFrom(new EmailAddress(\""no-reply@netflio.com\""));     message.AddContent(\""text/html\""  HttpUtility.HtmlDecode(data.Body));     message.AddAttachment(data.AttachmentName  Convert.ToBase64String(data.Attachment));     message.SetSubject(data.Subject);      return (ActionResult)new OkObjectResult(\""OK\""); }  public class EmailContent {      public string Email { get; set; }     public string Subject { get; set; }     public string Body { get; set; }     public byte[] Attachment { get; set; }     public string AttachmentName { get; set; }  } </code></pre>  <p>My function works very well in my local machine but not on my azure function.</p>  <p>The file is missing...</p>""",azure-functions
54832090,"AppServices won't allow \:\"" in setting name but needed for linux env var <p>I have published my linux container to App Services for Containers.</p>  <p>The way my container works is that it reads settings like API keys and connections strings from environment variables inside the running container.</p>  <p>I found a stack overflow post that says to set the env vars I need to use the \""App Settings\"" in Azure.  The problem is all the env vars have a colon in them  like:</p>  <pre><code>database:connectionString=myConnectionString </code></pre>  <p>App Services will not allow me to set a key that has a colon in it  however this is a perfectly valid syntax for a linux environment variable.</p>  <p>I really don't want to inject passwords during the build process into the actual image as that could cause a lot of issues.</p>  <p>How can I set an env var in App Services for containers that has a <code>:</code> in the key?</p>""",azure-web-app-service
51592162,"VSTS : Unable to upload to HockeyApp <p>As I'm trying to upload an iPad application (XCode project) to HockeyApp with VSTS's build pipeline  it fails and returns following error message.</p>  <p><a href=\https://i.stack.imgur.com/626Rw.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/626Rw.png\"" alt=\""enter image description here\""></a></p>  <pre><code>2018-07-30T10:37:57.0420460Z ##[error]Error: Failed to upload the package. HTTP status code: 422. Responce: {\""status\"":\""error\"" \""message\"":\""Version could not be created from build. Please make sure that your .ipa file has the correct format.\""} </code></pre>  <p>All other tasks in the pipeline such as applying certificate / provision profile / XCode build succeeds but it fails in the last Hockeyapp task.</p>  <p>Any idea what may be going wrong?</p>""",azure-devops
51325508,How to set azure-web-app-service application settings for node.js app via deployment <p>Is it possible to set azure app service application settings (especially env variables) via deployment? We are using local git repositories to deploy our NodeJS application to different azure appservices. There are several environment variables required to run the application. I'd like to know if there is a way to insert those automatically while deploying the application so I do not have to set them manually for each application. If its possible how does azure handles changes in the environment settings if I changed a variable afterwords? For example if I have sensitive data that I have to enter after deployment directly into the env variable?</p>  <p>Here's an example. Variables: Name=InitialValue</p>  <pre><code>VAR_1=Test1234 VAR_2=Hello World USERNAME= PASSWORD= </code></pre>  <p>USERNAME AND PASSWORD need to be empty an filled afterwords directly via azure portal. Now I redeploy. What happens to my USERNAME and PASSWORD entries? What happens if I change the value of VAR_1? In this case I'd like to have the environment variable changed.</p>,azure-web-app-service
49183571,"Sudden drop in SQL Azure query performance after moving web app to Azure <p>What could explain this big drop in performance in an Azure SQL DB after moving the app from an hosted VPS to an Azure App service?</p>  <p><a href=\https://i.stack.imgur.com/3FXuB.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/3FXuB.png\"" alt=\""enter image description here\""></a></p>  <p>Here's a typical chart from Query Store's High Variation chart over the past two weeks. The red arrow indicates when I moved the production app from another hosting provider to an Azure App. Prior to moving the app  I experienced zero timeouts. Now  using the same Azure SQL DB  timeouts are triggering frequently for longish queries (but by no means too arduous).</p>  <p>The only other change I made was change the user principle in the connection string. This user only has SELECT  INSERT  UPDATE  DELETE and EXECUTE permissions.</p>  <p>My theories are:  - something to do with networking between the app and the db. Resiliency? But I have a SQL exec plan specified  - something wrong with the user I set up?  - bad plan regression (I have now enabled auto FORCE PLAN tuning)  - a problem caused by Hangfire running on two servers simultaneously (now mitigated by moving HF tables to a new DB)  - something is triggering some kind of throttling that I cannot figure out.</p>  <p>Here is a chart of timeouts from Log Analytics:</p>  <p><a href=\""https://i.stack.imgur.com/6kyW6.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/6kyW6.png\"" alt=\""enter image description here\""></a></p>  <p>All help appreciated. Note: this site has had almost identical traffic over the past 30 days.</p>  <p>In fact  take a look at this from the SQL DB metrics over the past week:</p>  <p><a href=\""https://i.stack.imgur.com/OOmO1.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/OOmO1.png\"" alt=\""enter image description here\""></a></p>  <p>And here is some Wait info - last 6 hours:</p>  <p>Blue = PARALLELISM Orange = BUFFERIO</p>  <p><a href=\""https://i.stack.imgur.com/IhEFi.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/IhEFi.png\"" alt=\""enter image description here\""></a></p>""",azure-web-app-service
32524540,"How to open ports on azure virtual machine? <p>I set a new port by Add EndPoints option but it does not open that specific port on azure virtual machine.... i checked using following link  can any one tell me how to resolve this issue?</p>  <p><a href=\http://postimg.org/image/wb5rid6ib/\"" rel=\""nofollow\"">http://postimg.org/image/wb5rid6ib/</a></p>  <p>TCPSockets endpoint is not open on my virtual machine</p>""",azure-virtual-machine
54836050,"Azure file storage putRange operation fails with 416: InvalidHeaderValue (Content-Length) <p>I'm using the Azure SDK to perform basic operations on an Azure files storage. In order to support larger file uploads I support chunked uploads  so I'm calling:</p>  <p><code>$storage-&gt;createFileFromContent(...)</code> on the first chunk and</p>  <p><code>$storage-&gt;putFileRange(...)</code> on all the following.</p>  <p>The first request works fine and the file is filled with inside the first range specified. The second and following requests however fail with the error:</p>  <pre><code>Code: 416 Value: The range specified is invalid for the current size of the resource. </code></pre>  <p>Here are my specified headers for the first request:</p>  <pre><code>{   [\x-ms-range\""]=&gt;\""bytes=0-2999999\""   [\""content-length\""]=&gt;3000000   [\""x-ms-write\""]=&gt;\""Update\"" } </code></pre>  <p>Actual size of the stream: <strong>3000000</strong></p>  <p>And for the second request:</p>  <pre><code>{   [\""x-ms-range\""]=&gt;\""bytes=3000000-5999999\""   [\""content-length\""]=&gt;3000000   [\""x-ms-write\""]=&gt;\""Update\"" } </code></pre>  <p>Actual size of the stream: <strong>3000000</strong></p>  <p>Can someone please tell me what is wrong?? I also tried to adjust the Range to something like 300000-6000000  but then I get this error:</p>  <p>\""Code: 400 Value: The value for one of the HTTP headers is not in the correct format. >> Content-Length\""</p>  <p><strong>Could this be caused by a wrong configuration of the storage in Azure?</strong></p>""",azure-storage
46852886,Import Azure Function from portal into Visual Studio <p>I really like working with Azure functions in the portal but am starting to need some more tooling that I'm used to for committing to my git repo  easily adding assemblies  and just plain working in a more familiar environment.</p>  <p>Is it possible to create your Azure function app and possibly the functions themselves in the portal and then move over to Visual Studio and import that function app as a project? Or am I approaching this wrong? I understand we can create straight from Visual Studio and then publish up to Azure and maybe that is the way we should be doing it in the first place.</p>,azure-functions
50158670,"querying complex type in Azure Table <p>I am new to NoSql concepts. Coming from a mind set of \ModelFirst\"" i usually design my models first. I have a model as follows.</p>  <pre><code>public class Book {     public string Name { get; set; }     [EntityPropertyConverter(typeof(Category))]     public List&lt;Category&gt; Categories { get; set; } } public class Category {     public string Name { get; set; } } </code></pre>  <p>Student class is a complex type and </p>  <pre><code>[EntityPropertyConverter] </code></pre>  <p>attribute helps serialize Categories before writing to Azure Table and deserialize when reading back.</p>  <p>A book can belong to more than one categories. My question is if someone has to search a book by one of n number of categories  how can we do that.   </p>  <p>Azure Table supports quires like below</p>  <pre><code>TableQuery.GenerateFilterCondition(\""Categories\""  QueryComparisons.Equal  JsonConvert.SerializeObject(???)) </code></pre>  <p>But with this i cannot get the required result. </p>  <p>please do comment if my overall approach is incorrect. </p>""",azure-storage
43426879,How to find on which resource group my webapp is running using node js? <ul> <li>I have a node.js microservice running on azure webapp.  <ul> <li>I have two different resource group in azure <code>dev</code> and <code>prod</code></li> <li>I have two different config file in that microservice let say <code>devConfig</code> and <code>prodConfig</code> both have a different configuration for the respective environment.</li> </ul></li> </ul>  <p>I want to find on which resource group my webapp is running  so that if its dev I fetch the details from <code>devConfig</code> and same for <code>prodConfig</code>.</p>,azure-web-app-service
46975623,"Being a Global Administrator in Azure portal I am unable to configure Continuous Delivery Preview <p>Logged into Azure portal--> App Services-->Selected the Project-->Continuous Delivery Preview I see error message \You do not have enough permissions on this App Service to setup Continuous Delivery. Learn More: <a href=\""https://go.microsoft.com/fwlink/?linkid=843472\"" rel=\""nofollow noreferrer\"">https://go.microsoft.com/fwlink/?linkid=843472</a>\"" and Configure button is disabled. I am the Global Administrator and why I don't had the permissions to configure  where I can assign those access. Error message</p>  <blockquote>   <p>Failed to set Azure permission 'RoleAssignmentId: 9****a' for the   service principal '2****3' on subscription id '****': error code:   Forbidden  innner error code: AuthorizationFailed  inner error message   The client 'my mail Id' with object id '***** does not have   authorization to perform action   'Microsoft.Authorization/roleAssignments/write' over scope   '/subscriptions/*****'. For troubleshooting refer to link</p> </blockquote>""",azure-web-app-service
49130977,"Does a call to \Deploy web service(via API key) \"" re run trained Azure ML model again <p>I wanted to know how exactly the following works in backend</p>  <p><strong>Scenario :</strong> </p>  <blockquote>   <p>-> We get data from Edgex foundry in UTC format and we it store it in Azure Document DB in (CST/CDT timezone) format</p>      <p>-> We trained ML model on data(with Date in CST/CDT timezone) and Deploy web service.</p> </blockquote>  <p><strong>So I have few basic doubts below</strong></p>  <blockquote>   <ol>   <li><p>When web job hits our predictive webservice   will the trained ML model be run again?</p></li>   <li><p>Do we need to convert the UTC timezone for new incoming test data( which we want to predict) into CST/CDT timezone  as TimeStamp does   matter for our prediction?</p></li>   <li><p>What happens in backend when predictive webservice API is called?</p></li>   </ol> </blockquote>""",azure-web-app-service
54111932,"How to exclude one branch in Azure DevOps build pipeline <p>In Azure DevOps its possible to define <a href=\https://docs.microsoft.com/en-us/azure/devops/pipelines/build/triggers?view=vsts&amp;tabs=yaml\"" rel=\""nofollow noreferrer\"">build pipelines</a> which by default is executed when a code is pushed to a branch.</p>  <p>I want the pipeline to run for all branches except one. The configuration</p>  <pre><code>trigger:   branches:     include:     - branchToInclude     exclude:     - branchToExclude </code></pre>  <p>works when I push to branchToInclude.</p>  <p>But if I take away the include part the pipeline is not executed when I push to branchToInclude.</p>  <pre><code>trigger:   branches:     exclude:     - branchToExclude </code></pre>  <p>A * instead of branchToInclude is not accepted when I try to save the file. Is there a way to configure a pipeline to execute for all branches except one?</p>""",azure-devops
42652292,query geospatial with azure function <p>I could not find any document on how to use docuementdb geospatial query using azure function using nodejs:</p>  <pre><code>SELECT *  FROM Areas a  WHERE ST_WITHIN({'type': 'Point'  'coordinates':[31.9  -4.8]}  a.location) </code></pre>,azure-functions
50719134,How to stop continuous and remove schedule from schedules web jobs in VSTS <p>In VSTS Release  how do I stop all continuous webjobs and remove schedule from triggered webjobs for specific deployment slot?</p>  <h1>scenario:</h1>  <p>I have a asp.net core web application with bunch of webjobs. Some of them are scheduled  some are continuous.</p>  <p>In VSTS Release I deploy the webjobs together with web app to App Service using Web Deploy.</p>  <p>However  in staging environment I don't want to run the webjobs  since they would interfere with production (the share the same database  etc).</p>  <p>I guess I would have to write some powershell to stop the webjobs. It comes down to these steps:</p>  <ol> <li>How do I run PowerShell in VSTS that is connected to my Azure Subscription</li> <li>How do I list all webjobs for my webapp and deployment slot</li> <li>How do I stop continuous webjob</li> <li>How do I set trigger to manual and remove schedule from scheduled webjobs</li> </ol>,azure-devops
53267657,"Python script job not running on Azure Batch - ODBC error <p>I am trying to run a Python job using a VM on Azure Batch. It's a simple script to add a line to my Azure SQL Database. I downloaded the ODBC connection string straight from my Azure portal yet I get this error. The strange thing is I can run the script perfectly fine on my own machine. I've configured the VM to install the version of Python that I need and then execute my script - I'm at a complete loss. Any ideas?</p>  <pre><code>cnxn = pyodbc.connect('Driver={ODBC Driver 13 for SQL Server};Server=tcp:svr-something.database.windows.net fakeport232;Database=db-something-prod;Uid=something@svr-something;Pwd{fake_passwd};Encrypt=yes;TrustServerCertificate=no;Connection Timeout=30;') </code></pre>  <p>Traceback (most recent call last):</p>  <blockquote>   <p>File \D:\\batch\\tasks\\apppackages\\batch_python_test1.02018-11-12-14-          30\\batch_python_test\\python_test.py\""  line 12  in            r'Driver={ODBC Driver 13 for SQL Server};Server=tcp:svr-          mydatabase.database.windows.net '         pyodbc.InterfaceError: ('IM002'  '[IM002] [Microsoft][ODBC Driver Manager]          Data          source name not found and no default driver specified (0) (SQLDriverConnect)')</p> </blockquote>""",azure-virtual-machine
35903095,"Websocket exhausted on Azure App Service Standard S1 plan? <p>We've updated from Basic to Standard for our two instance App Service apps  and I'm getting this warning:</p>  <p><a href=\https://i.stack.imgur.com/dblAp.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/dblAp.png\"" alt=\""Websocket exhasted on Standard Azure plan\""></a></p>  <p>Based on this the Standard plan should have unlimited websocket?</p>  <p><a href=\""https://azure.microsoft.com/en-us/documentation/articles/azure-subscription-service-limits/#app-service-limits\"" rel=\""nofollow noreferrer\"">https://azure.microsoft.com/en-us/documentation/articles/azure-subscription-service-limits/#app-service-limits</a></p>  <p>What is the meaning of this?</p>""",azure-web-app-service
51088281,Prevent post build event in VSTS <p>For development purposes my team has a post build event defined to pack and publish nuget packages locally. This step is not necessary during the build in VSTS because we have a step defined for that during the building to pack and ship the nuget packages to a different server  whithout symbols. Right now this step is executed in any build we run. How to prevent that only in the build server?</p>,azure-devops
55836115,"Will HTTP/2 in Azure App Service auto fallback to HTTP/1.1 for legacy browsers <p>I want to turn on HTTP/2 for my web app hosted by Azure App Service. However  1% of my users are using browsers that doesn't support HTTP/2. </p>  <p><strong>Does Azure App Service automatically fallback to HTTP/1.1 for these browsers even if I've turned HTTP/2 on?</strong></p>  <p>In other words </p>  <p><strong>When turn on HTTP/2 in Azure app service instance  will the server accept HTTP/1.1 request from browsers?</strong></p>  <p>I checked the Azure App Service announcement <a href=\https://azure.microsoft.com/en-us/blog/announcing-http-2-support-in-azure-app-service/\"" rel=\""nofollow noreferrer\"">here</a>  but it doesn't say if auto-fallback is support or not.</p>""",azure-web-app-service
44764974,installing postgres in azure ubuntu virtual machine using powershell <p>I am able to create ubuntu virtual machines using powershell script in azure.  But i would like to know how to install postgresql database into newly created ubuntu virtual machine of azure  and also other softwares if needed.</p>  <p>I need a help in doing so in powershell. any guidelines or suggestions on it.</p>,azure-virtual-machine
56275791,"Can you run a webjob on two separate app services concurrently (bypass singleton lock)? <p>I am setting up an Azure WebJob (Timer Triggered) on two separate app services. But because of the singleton lock  only one of them can actually preform their function  while the other one stops. Is there a way to let the \same\"" WebJob run on both concurrently? The applications are two environments of the same web page (demo and production)  so it would be nice if I didnt have to create a new WebJob project for each app service  but rather reuse the one I have.</p>""",azure-web-app-service
25580065,tfs android not checking in <p>Using TFS in eclipse. And while checking in whole project this error occurs. I can check in seperate files.</p>  <blockquote>   <p>The local item 'D:\LUDev\Stalker\AndroidApp\gen\com\stalker\androidappa\BuildConfig.java' no longer exists. (The local item 'D:\LUDev\Stalker\AndroidApp\gen\com\stalker\androidappa\BuildConfig.java' no longer exists.)</p> </blockquote>  <p>I don't have <code>D:\LUDev\Stalker\AndroidApp\gen\com\stalker\androidappa...</code> this directory in my local as well as server directory.</p>,azure-devops
54764551,"Azure service bus functions. Receive messages in batch <p>I would like to receive messages from a Azure ServiceBus Topic in batch mode.</p>  <p>Reading <a href=\https://docs.microsoft.com/en-us/azure/azure-functions/functions-best-practices\"" rel=\""nofollow noreferrer\"">https://docs.microsoft.com/en-us/azure/azure-functions/functions-best-practices</a> it states:</p>  <blockquote>   <p>For C# functions you can change the type to a strongly-typed array. For example  instead of EventData sensorEvent the method signature could be EventData[] sensorEvent. </p> </blockquote>  <p>I have a method:</p>  <pre><code>public static void Run([ServiceBusTrigger(\""mytopic name\""  \""MySubscription\""  AccessRights.Listen  Connection = TopicService.ConnectionStringName)] string messages  TraceWriter logger) </code></pre>  <p>This method is working  but it takes 1 message at the time.</p>  <p>According to the Microsoft Documentation  I just could change this to:</p>  <pre><code>public static void Run([ServiceBusTrigger(\""mytopic name\""  \""MySubscription\""  AccessRights.Listen  Connection = TopicService.ConnectionStringName)] string[] messages  TraceWriter logger) </code></pre>  <p>And add the following to the host.json file (<a href=\""https://docs.microsoft.com/en-us/azure/azure-functions/functions-host-json\"" rel=\""nofollow noreferrer\"">https://docs.microsoft.com/en-us/azure/azure-functions/functions-host-json</a>):</p>  <pre><code>{     \""aggregator\"": {         \""batchSize\"": 10          \""flushTimeout\"": \""00:00:30\""     } } </code></pre>  <p>But running the function  I get an exception:</p>  <blockquote>   <p>mscorlib: Exception while executing function: MyFunction.    Microsoft.Azure.WebJobs.Host: Exception binding parameter 'messages'. System.Runtime.Serialization: There was an error deserializing the object of type System.String[]. The input source is not correctly formatted. System.Runtime.Serialization: The input source is not correctly formatted.</p> </blockquote>  <p>Note: the topic and the subscription have the setting \""Enable batched operations\"" enabled.</p>  <p>What am I missing here?</p>""",azure-functions
24182700,Azure MS Access database - best location? <p>My company is considering migrating our systems to Azure. We have an asp .net web application running with Access Database. My boss doesn't want to use SQL azure just yet - he may want it one day but for now we will stick with ms Access. Where would be the best place to put our Access Database?</p>  <p>I have been doing some tests and it seems to work just fine when it's located in the Azure website directory inside App_Data folder. However  I am not sure if this is a safe approach. </p>  <p>The other option I have read about is putting in on a virtual machine. </p>  <p>I am not sure which approach to take. The point is to keep using MS Access with an Azure website</p>  <p>Thanks</p>,azure-virtual-machine
51002269,Can I have an Azure website and webjobs in the same deployment slot with common app setting names but with different values? <p>Like many basic configuraitons I've got an Azure website and several associated webjobs sharing a deployment slot.  I would like to define an application setting  e.g. <code>MySetting</code> that both the web app and webjobs can refer to  but I want to have <em>different</em> values for that setting - one value specific for the web app and one for the webjobs.  AND  while I do understand that I can put MySetting in the web app's Application Settings blade and then override that setting in the webjobs by creating a MySetting entry in the webjob's <code>app.config</code>  I do <em>not</em> want to store secrets in application files.</p>  <p>What options do I have?</p>,azure-web-app-service
53200501,Set/Change Default Organization in Azure DevOps <p>I had an existing organization on Azure DevOps (say  <code>org1</code>) to host my main projects and I recently added another organization (say  <code>org2</code>) to host projects I work on for a non-profit where I volunteer.</p>  <p>After creating <code>org2</code>  whenever I log into Azure DevOps or access <code>https://dev.azure.com</code>  it redirects me to <code>https://dev.azure.com/org2</code> instead of <code>https://dev.azure.com/org1</code> as it did before I created the new organization.  Unfortunately  I access <code>org1</code> much more frequently so this is a silly inconvenience.</p>  <p>How can I set or change the default organization so that my default page is <code>https://dev.azure.com/org1</code> again?</p>,azure-devops
51134020,Is it possible to publish azure functions as precompiled dll's in the azure portal <p>I am developing Azure functions locally on VS and wish to publish them to azure portal later on. I want my function code to be non editable and non visible in the portal.</p>  <p>Is it possible to pre-compile these function to dll's while publishing? I am thinking this also saves the cold time as the function will be pre-compiled. Or do I need at least one function there in which I can add reference to the dll of other functions.</p>,azure-functions
54353834,Azure Function App and Microsoft.TeamFoundationServer.Client Nuget Packages Conflicts in Dependency <p>Although my title mentions a specific case  perhaps this is an issue in general. I am trying to develop an Azure Function App which will use <code>Microsoft.TeamFoundationServer.Client</code>.</p>  <p>Now  TeamFoundation Client needs <code>Newtonsoft.Json (&gt;= 10.0.3)</code>  while Azure Function App SDK needs <code>Newtonsoft.Json (= 9.0.1)</code>; Note the <strong>> and >=</strong>;</p>  <p>Clearly both the conditions cannot be satisfied. One option is to choose a downgraded version of TeamFoundationServer client so the requirements for NewtonSoft.Json is met. Not sure if this is the only feasible solution here. It looks odd for a package to require specific version rather than minimum version.</p>  <p>In any case  how can the dependency conflict on Newtonsoft.json for Azure Function App and Microsoft.TeamFoundationServer.Client be resolved? </p>,azure-functions
39064729,How to debug app services azure <p>I created app service running on nodejs in azure  how to debug nodejs on azure by atom editor?</p>  <p>I saw a lot of tutorial that explain how to debug with visual studio but I prefer atom.</p>  <p>Thanks  Michael.</p>,azure-web-app-service
49015909,"Azure App Service Migration Assistant keeps crashing <p>I am trying to use the Azure App Service Migration Assistant to migrate a web app to Azure.  I am not a developer so not sure what type of web app it is but it does connect to a SQL database.  The web app is running on IIS on a Windows 2012 R2 server and the database is running on a separate Windows 2012 R2 server on SQL 2014.  I installed the Azure App Service Migration Assistant on the web server but each time I try to run it  it generates a pop-up that says \Web Deploy is needed for migrating your site content and database to azure\"".  When I click Yes to install it  it generates the error in the image below:</p>  <p><a href=\""https://i.stack.imgur.com/8Oneg.jpg\"" rel=\""nofollow noreferrer\"">Web_Deploy_Install_Error</a></p>""",azure-web-app-service
41656298,"Azure Load Balancing of Cloud Service not working <p>I have a web app deployed to a Cloud Service on two instances  size A1v2 standard.  My understanding is that once I have multiple instances deployed that service the same public endpoint  load balancing should automatically be handled by Azure (since it's a Cloud Service).</p>  <p>I RDP into each instance.  Here is the first instance: <a href=\https://i.stack.imgur.com/q2N00.jpg\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/q2N00.jpg\"" alt=\""enter image description here\""></a></p>  <p>As you can see  it's using 100% of CPU.</p>  <p>Here is the second instance: <a href=\""https://i.stack.imgur.com/wq8VE.jpg\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/wq8VE.jpg\"" alt=\""enter image description here\""></a></p>  <p>Just sitting there!  Not doing a bloody thing!</p>  <p>The worst part is that this also kills autoscaling.  The average CPU usage is 50% so Azure doesn't provision any more instances.  Possibly a good thing since they'd just be sitting there doing nothing anyway (facepalm).</p>""",azure-virtual-machine
52916407,Create Classic VM from VHD in Azure <p>I have a server in Classic ASM which I want to move to another subscription.</p>  <p>I tried using the move feature on the portal but it throws error that target subscription is not empty.</p>  <p>Are there any way that I can recreate the classic VM from its VHDs and also migrate its IP address to the new Subscription. I don't want the Generalise the VM.</p>  <p>Thanks.</p>,azure-virtual-machine
33300685,"VSO continuous integration and custom DLL <p>I'm trying to set up CI with with visual studio online in an existing project  using git.</p>  <p>My project contains a custom DLL and I can not find a way to resolve this error :</p>  <blockquote>   <p>C:\\Program Files (x86)\\MSBuild\\14.0\\bin\\amd64\\Microsoft.Common.CurrentVersion.targets (1819): Could not resolve this reference. Could not locate the assembly \CaradbaAccess\"". Check to make sure the assembly exists on disk. If this reference is required by your code  you may get compilation errors.</p>      <p>Models\\Search\\DbSearchResultsTests.cs (4): The type or namespace name   'CaradbaAccess' could not be found (are you missing a using directive   or an assembly reference?)</p> </blockquote>  <p>Actually this file is contained (and also referenced) in the project and in the git repo. Obviously this build on my machine.</p>  <p>Where do I have to put this file to make VSO build working? </p>  <p>Note : This seems to be a duplicate of <a href=\""https://stackoverflow.com/questions/31951990/visual-studio-online-build-fails-local-works\"">this</a> but it is not. The question in the link is about a nuget package  my problem is about a custom DLL.</p>""",azure-devops
38123887,"Can I implement async \fire and forget\"" HTTP triggers in azure functions <p>I have an azure functions app that has a long running operation. I would like to trigger it via HTTP (for simplicity) with some input and no output. I don't want to keep the HTTP connection open for the whole time that the job is running.</p>  <p>What are my options for building a functions app where the runtime accepts some data and then immediately returns control to the caller before invoking my run.csx file?</p>""",azure-functions
36443957,"Azure VM: too frequent DNS lookup [TTL 60] <p>I have a VM setup on Azure (classic VM running CentOS).  I am developing my mobile app that connect with RESTful API's hosted on Azure VM.  My mobile app performance was slow and on investigation  I found DNS lookup to the FQDN of my Azure VM is too long (about 5-5.5 seconds per lookup) and very frequent.  Attached is the output of \dig\"" tool on my Mac.</p>  <p><a href=\""http://i.stack.imgur.com/rtxRi.jpg\"" rel=\""nofollow\"">Dig tool output</a></p>  <p>Is there a way I can control TTL for the Azure VM's?  Would it help if I buy a static IP and map it to my Azure VM's FQDN?  Also  is there a way to reduce the DNS lookup time?</p>  <p>Thanks  Giri</p>""",azure-virtual-machine
53252741,"edgelet_utils... Get https://warlibregistry.azurecr.io/v2/iot-edge-engine-simulator/manifests/0.0.1-amd64: unauthorized: authentication required <p>I get a quite strange error message after executing Install-SecurityDaemon. I deployed the IoT Edge module image to Azure Registry using Visual Studio Code. Then  I try to execute the IoT Edge solution in the simulator. Everything is ok.</p>  <p>I executed Install-SecurityDaemon. Everything went ok. But when I exec \iotedge list\"" command  I saw that only two main modules arrived but there is no module developed by me <code>PS C:\\WINDOWS\\system32&gt; iotedge list NAME             STATUS           DESCRIPTION               CONFIG edgeHub          failed           Failed (137) an hour ago  mcr.microsoft.com/azureiotedge-hub:1.0 edgeAgent        running          Up 1 second               mcr.microsoft.com/azureiotedge-agent:1.0</code> </p>  <p>I'd seen the log and found only one error message:</p>  <p><code>11.11.2018 22:52:37 warn: edgelet_docker::runtime -- Attempt to pull image failed. 11.11.2018 22:52:42 info: edgelet_core::watchdog -- Checking edge runtime status 11.11.2018 22:52:42 info: edgelet_core::watchdog -- Edge runtime is running. 11.11.2018 22:52:43 warn: edgelet_docker::runtime -- Attempt to pull image failed. 11.11.2018 22:52:43 info: edgelet_http::logging -- [mgmt] - - - [2018-11-11 19:52:43.487711600 UTC] \""POST /modules?api-version=2018-06-28 HTTP/1.1\"" 500 Internal Server Error 141 \""-\"" \""-\"" pid(any) 11.11.2018 22:52:43 warn: edgelet_utils::logging -- Get https://warlibregistry.azurecr.io/v2/iot-edge-engine-simulator/manifests/0.0.1-amd64: unauthorized: authentication required 11.11.2018 22:52:55 info: edgelet_http::logging -- [mgmt] - - - [2018-11-11 19:52:55.502141500 UTC] \""POST /modules?api-version=2018-06-28 HTTP/1.1\"" 500 Internal Server Error 141 \""-\"" \""-\"" pid(any) 11.11.2018 22:52:55 warn: edgelet_utils::logging -- Get https://warlibregistry.azurecr.io/v2/iot-edge-engine-simulator/manifests/0.0.1-amd64: unauthorized: authentication required</code></p>  <p>Then I execute \""docker login\"" command to be sure  that docker properly authorized in Azure registry. Everything was ok. Then  I reinstall SecurityDaemon. I got the same error.</p>  <p>Executing command </p>  <p><code>PS C:\\WINDOWS\\system32&gt; docker pull warlibregistry.azurecr.io/iot-edge-engine-simulator:0.0.1-amd64 0.0.1-amd64: Pulling from iot-edge-engine-simulator Digest: sha256:4ba6ae6442ca974b2c52459b85c0861e9664f26990c6e87f20829954f4d67d09</code></p>  <p><code>Status: Image is up to date for warlibregistry.azurecr.io/iot-edge-engine-simulator:0.0.1-amd64</code></p>  <p>return no errors. But if try to get manifest <a href=\""https://warlibregistry.azurecr.io/v2/iot-edge-engine-simulator/manifests/0.0.1-amd64\"" rel=\""nofollow noreferrer\"">https://warlibregistry.azurecr.io/v2/iot-edge-engine-simulator/manifests/0.0.1-amd64</a> I really got the JSON with the error \""unauthorized: authentication required\"". </p>  <p>In the Azure Portal after adding my module engineSimulator I saw another one iot_edge_engine_simulator with type \""Module identity\"" which is not created by me. When I installed e.g. Microsoft module termoSensor - there is no such additional module.</p>  <p>So  I'm stuck  I don't know why the error occurs and what to do further. </p>  <p>Thank you for a help! </p>""",azure-devops
54928745,"Service Bus Topic to ADLS using Logic App <p>I'm new to Logic Apps and i have some basic questions. I created the below workflow (1 Trigger + 2 Actions) Where:</p>  <p>1) Reading for any new messages in Azure Service Bus Topic.</p>  <p>2) Then Load the data to Azure Data Lake respective Folders.</p>  <p><a href=\https://i.stack.imgur.com/iRww9.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/iRww9.png\"" alt=\""enter image description here\""></a></p>  <p>With regard to this i have some queries:</p>  <ul> <li><p>In ADLS i'm creating folder like [Subject Area]\\YYYY\\MM\\DD. So from a design perspective is there a way to skip the second step (ADLS Create Folder) or the workflow will ignore if the target folder exists.</p></li> <li><p>If i have 4 different Subject Areas then do i need to create 4<br> instances of Logic Apps.</p></li> <li><p>With respect to Function App and Azure Logic Apps which is more<br> economical. And how do i scale and Monitor my logic App execution.</p></li> </ul>""",azure-functions
38905676,"Recover an App Service from Azure <p>yesterday I deleted the wrong web app from my azure's account. I tried to follow steps here found on google but this assume's there was a backup made. <a href=\https://azure.microsoft.com/en-us/documentation/articles/web-sites-restore/\"" rel=\""nofollow\"">https://azure.microsoft.com/en-us/documentation/articles/web-sites-restore/</a> is there a way to recover a deleted web app without having a backup of it? </p>""",azure-web-app-service
53667088,"Cannot get site_credential.username in azurerm_app_service <p>I have got my app service:</p>  <pre><code>resource \azurerm_app_service\"" \""appservice\"" {    name = name\""    location = \""${var.location}\""    resource_group_name = \""${azurerm_resource_group.resourcegroup.name}\""    app_service_plan_id = \""${azurerm_app_service_plan.appserviceplan.id}\""     app_settings{         ...     }     site_config {     dotnet_framework_version = \""v4.0\""     scm_type                 = \""LocalGit\""   }  } </code></pre>  <p>And I try to add site_credential.username as a key_vault_secret</p>  <pre><code>resource \""azurerm_key_vault_secret\"" \""key_vault_secret_publish_profile_username\"" {   name = \""username\""    value = \""${azurerm_app_service.appservice.site_credential.username}\""   vault_uri = \""${azurerm_key_vault.keyvault.vault_uri}\"" } </code></pre>  <p>terraform plan is ok  when i try \""terraform apply\"" it returns following error:</p>  <p>1 error(s) occurred:</p>  <ul> <li>azurerm_key_vault_secret.key_vault_secret_publish_profile_username: Resource 'azurerm_app_service.appservice' does not have attribute 'site_credential.username' for variable 'azurerm_app_service.appservice.site_credential.username'</li> </ul>  <p>Terraform docs provides that scm_type must be set to \""LocalGit\"" => <a href=\""https://www.terraform.io/docs/providers/azurerm/r/app_service.html\"" rel=\""nofollow noreferrer\"">https://www.terraform.io/docs/providers/azurerm/r/app_service.html</a></p>""",azure-web-app-service
56428852,How to trigger C++ code with event grid in Azure? <p>I am trying to upload a blob in the Azure storage and it uploads successfully. Now the next step is to process the blob with C++ code. Since Azure function does not support C++ how can I process the blob?</p>,azure-functions
53083680,Move organization from VSTS to TFS <p>I have an organization (all my projects - Only work items  no code) on Team Services (free edition). I have now started collaborating with another team who has a licensed TFS. I need to move all my projects to TFS.</p>  <p>Is that possible? Please help.</p>,azure-devops
50117715,Azure Logic App FTP Connector not running for files modified before the current date <p>I am working on FTP Connector of the Azure Logic App and it is working fine if I upload a file with today's last modified date. But FTP connector is not triggered for files that are modified before the current date.  I have found in the trigger history that the trigger is <strong>skipped</strong> and <strong>Status code 202</strong> is being returned. Kindly suggest me a solution so as to trigger the FTP Connector whenever any file (even if is modified a year ago) is added on the FTP.</p>,azure-functions
51183800,"How to append data to a parquet file in Azure blob using Azure function <p>I am trying to append to a parquet file which is in Azure blob using Azure function c# script. </p>  <p>I have been able to append to a locally created parquet file using Parquet.net package. However  while I am trying to execute the code to append to a parquet file which is in Azure  I am getting errors. </p>  <p>Below code works for a local parquet file append.</p>  <pre><code>var ds = new DataSet(new DataField&lt;int&gt;(\id\"") new DataField&lt;string&gt;(\""city\"")); ds.Add(1  \""London\""); using (Stream fileStream = File.Open(file  FileMode.OpenOrCreate  FileAccess.ReadWrite)) {    ParquetWriter.Write(ds  fileStream CompressionMethod.None null null  true);    Console.Write(\""File writing completed successfully\\n\""); } </code></pre>  <p>However the code below does not work for an Azure parquet file append</p>  <pre><code>var ds = new DataSet(new DataField&lt;int&gt;(\""id\"") new DataField&lt;string&gt;(\""city\"")); ds.Add(1  \""London\""); Stream stream = new MemoryStream(); ParquetWriter.Write(ds  stream CompressionMethod.None null null  false); parquetBlob.AppendBlock(stream); //this line fails with error </code></pre>  <p>I get following error:</p>  <pre><code>2018-07-05T05:07:14.479 [Info] Parquet file writing started 2018-07-05T05:07:14.667 [Info] Parquet file writing : successfully written to memory stream 2018-07-05T05:07:14.686 [Info] Exception  while appending to parquet file: Microsoft.WindowsAzure.Storage.StorageException: The remote server returned an error: (400) Bad Request. ---&gt; System.Net.WebException: The remote server returned an error: (400) Bad Request.    at System.Net.HttpWebRequest.GetResponse()    at Microsoft.WindowsAzure.Storage.Core.Executor.Executor.ExecuteSync[T](RESTCommand`1 cmd  IRetryPolicy policy  OperationContext operationContext) in c:\\Program Files (x86)\\Jenkins\\workspace\\release_dotnet_master\\Lib\\ClassLibraryCommon\\Core\\Executor\\Executor.cs:line 677    --- End of inner exception stack trace ---    at Microsoft.WindowsAzure.Storage.Core.Executor.Executor.ExecuteSync[T](RESTCommand`1 cmd  IRetryPolicy policy  OperationContext operationContext) in c:\\Program Files (x86)\\Jenkins\\workspace\\release_dotnet_master\\Lib\\ClassLibraryCommon\\Core\\Executor\\Executor.cs:line 604    at Microsoft.WindowsAzure.Storage.Blob.CloudAppendBlob.AppendBlock(Stream blockData  String contentMD5  AccessCondition accessCondition  BlobRequestOptions options  OperationContext operationContext) in c:\\Program Files (x86)\\Jenkins\\workspace\\release_dotnet_master\\Lib\\ClassLibraryCommon\\Blob\\CloudAppendBlob.cs:line 2145    at Submission#0.writeParquet(String data  CloudAppendBlob parquetBlob  TraceWriter log) in D:\\home\\site\\wwwroot\\EventHubTriggerCSharp2\\run.csx:line 189    at Submission#0.WriteToBlob(String fileName  String data  TraceWriter log) in D:\\home\\site\\wwwroot\\EventHubTriggerCSharp2\\run.csx:line 158 Request Information RequestID:45299e54-001e-009d-7d1e-143e91000000 RequestDate:Thu  05 Jul 2018 05:07:13 GMT StatusMessage:The value for one of the HTTP headers is not in the correct format. ErrorCode:InvalidHeaderValue </code></pre>  <p>Any help will be highly appreciated.</p>""",azure-functions
56424667,"How to fetch \last login/accessed\"" time of Azure virtual machine <p>I want to get a list of Azure virtual machines that were not accessed / logged in for a week  so I can send an email to the users if these can be de-provisioned. </p>  <p>I used the below cmdlet to check the last accessed/login details  but it doesnot give me those details.</p>  <pre><code>$vm = get-azurermvm -ResourceGroupName \""ADL-RG\"" -Name \""W1905\"" -Status </code></pre>  <p>Can anyone help me with the correct approach?</p>""",azure-virtual-machine
49028052,"VSTS Test result update API is not working <p>Hi iam using VSTS test management APIS for upating test results.</p>  <p>First iam using {collection name}/{projectname}/_apis/test/runs/{result id}/results?api-version=2.0-preview</p>  <p>with JSON value</p>  <pre><code>[{\testResult\"":{\""id\"":100000} \""testCase\"":{\""id\"":417} \""priority\"":1 \""outcome\"":\""Failed\"" \""testPoint\"":{\""id\"":51} \""state\"":\""Completed \"" \""associatedWorkItems\"":[452]}] </code></pre>  <p>all works fine suddenly it will updated test result but work item bug is not linked with test result.</p>  <p>When i use 3.0-preview</p>  <pre><code>[{\""id\"":100000 \""outcome\"":\""Failed\"" \""state\"":\""Completed \"" \""associatedBugs\"":[199 200]}] </code></pre>  <p>Still not working</p>  <p>What iam using wrong.</p>""",azure-devops
57079549,"Deploying multiple function under same azure function app not working <p>Trying to deploy 3 functions of different types(CosmosDBTrigger/TimerTrigger/HttpTrigger) in the same azure function app service account  attached the folder structure for reference.</p>  <p>Functions are not working as expected but throwing error after successful deployment.</p>  <h1>Expection received:</h1>  <p>Function (CopyToQueue) Error: Microsoft.Azure.WebJobs.Host: Error indexing method 'CopyToQueue'. Microsoft.Azure.WebJobs.Host: Cannot bind parameter '<strong>inputCloudSyncJobModels</strong>' to type IEnumerable`1. Make sure the parameter Type is supported by the binding. If you're using binding extensions (e.g. Azure Storage  ServiceBus  Timers  etc.) make sure you've called the registration method for the extension(s) in your startup code (e.g. builder.AddAzureStorage()  builder.AddServiceBus()  builder.AddTimers()  etc.).</p>  <h1>One of the function declaratives as below:</h1>  <pre><code>       public static async Task Run([**TimerTrigger**(scheduleExpression: \%TimerConfig%\"")]TimerInfo myTimer              [CosmosDB(databaseName: \""%DatabaseName%\""              collectionName: \""%InputCollection%\""              SqlQuery =\""%JobsSelectQuery%\""              ConnectionStringSetting = \""CosmosDBConnectionString\"")]             IEnumerable&lt;object&gt; **inputCloudSyncJobModels**              [Queue(queueName: \""%JobsQueueName%\""  Connection = \""StorageConnectionString\"")] IAsyncCollector&lt;string&gt; outputCloudQueueModels              Microsoft.Extensions.Logging.ILogger log  ExecutionContext context) </code></pre>  <p>If I deploy same functions under different individual azure function app services they are working charm without any modifications. </p>  <p>Please suggest the way to make these functions as working ones when they are deployed under same azure function app service.</p>  <p><a href=\""https://i.stack.imgur.com/IGl1B.jpg\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/IGl1B.jpg\"" alt=\""FunctionList\""></a></p>""",azure-functions
49150471,"Nuget feed in VSTS \Including description is not supported while including all versions.\"" <p>I created a nuget feed in my VSTS and I follow the instructions to push a package but I'm getting this error consuming it from Visual Studio:</p>  <blockquote>   <p>\""[CGPE.LogClient3] Failed to retrieve metadata from source   '<a href=\""https://cgpe.pkgs.visualstudio.com/_packaging/30074c7b-4682-48db-9c97-9afd15e93471/nuget/v3/query2/?q=&amp;skip=0&amp;take=26\"" rel=\""nofollow noreferrer\"">https://cgpe.pkgs.visualstudio.com/_packaging/30074c7b-4682-48db-9c97-9afd15e93471/nuget/v3/query2/?q=&amp;skip=0&amp;take=26</a>⪯release=false⊃portedFramework=native Version=v0.0&amp;semVerLevel=2.0.0'.   Response status code does not indicate success: 500 (Internal Server   Error - Including description is not supported while including all   versions. (VSTS Activity ID: 1C80CF12-0FE0-4757-A230-1461A7C07A2F)).\""</p> </blockquote>  <p>Also  I get a \""No packages found\"" performing a nuget list.</p>  <blockquote>   <p>nuget list -Source   <a href=\""https://cgpe.pkgs.visualstudio.com/_packaging/CGPE.LogClient3/nuget/v3/index.json\"" rel=\""nofollow noreferrer\"">https://cgpe.pkgs.visualstudio.com/_packaging/CGPE.LogClient3/nuget/v3/index.json</a>   Please provide credentials for:   <a href=\""https://cgpe.pkgs.visualstudio.com/_packaging/CGPE.LogClient3/nuget/v3/index.json\"" rel=\""nofollow noreferrer\"">https://cgpe.pkgs.visualstudio.com/_packaging/CGPE.LogClient3/nuget/v3/index.json</a>   UserName: Vicente    Password: ****************************************************<br>   No packages found.</p> </blockquote>  <p>But the package is pushed</p>  <blockquote>   <p>nuget.exe push -Source   <a href=\""https://cgpe.pkgs.visualstudio.com/_packaging/CGPE.LogClient3/nuget/v3/index.json\"" rel=\""nofollow noreferrer\"">https://cgpe.pkgs.visualstudio.com/_packaging/CGPE.LogClient3/nuget/v3/index.json</a>   -ApiKey key \""VSTS-HelloWorld\\VSTS-HelloWorld 1.0.55.nupkg\"" Pushing VSTS-HelloWorld 1.0.55.nupkg to   '<a href=\""https://cgpe.pkgs.visualstudio.com/_packaging/30074c7b-4682-48db-9c97-9afd15e93471/nuget/v2/\"" rel=\""nofollow noreferrer\"">https://cgpe.pkgs.visualstudio.com/_packaging/30074c7b-4682-48db-9c97-9afd15e93471/nuget/v2/</a>'...</p>      <p>PUT   <a href=\""https://cgpe.pkgs.visualstudio.com/_packaging/30074c7b-4682-48db-9c97-9afd15e93471/nuget/v2/\"" rel=\""nofollow noreferrer\"">https://cgpe.pkgs.visualstudio.com/_packaging/30074c7b-4682-48db-9c97-9afd15e93471/nuget/v2/</a></p>      <p>Please provide credentials for:   <a href=\""https://cgpe.pkgs.visualstudio.com/_packaging/CGPE.LogClient3/nuget/v3/index.json\"" rel=\""nofollow noreferrer\"">https://cgpe.pkgs.visualstudio.com/_packaging/CGPE.LogClient3/nuget/v3/index.json</a></p>      <p>UserName: Vicente Password:</p>      <p>Conflict   <a href=\""https://cgpe.pkgs.visualstudio.com/_packaging/30074c7b-4682-48db-9c97-9afd15e93471/nuget/v2/\"" rel=\""nofollow noreferrer\"">https://cgpe.pkgs.visualstudio.com/_packaging/30074c7b-4682-48db-9c97-9afd15e93471/nuget/v2/</a>   14828ms</p>      <p>Response status code does not indicate success: 409 (Conflict - The   feed already contains 'VSTS-HelloWorld 1.0.55'. (VSTS Activity ID:   CD8E6A2A-2F0E-4F8C-8768-42EDCE269083)).</p> </blockquote>  <p>I can't find any information about this problem.</p>  <p>Thanks a lot.</p>""",azure-devops
56601988,"How to find builds with a specific trigger <p>I'm trying to test the triggers I've setup for my new builds.  Is there a way to query \the system\"" and find all builds that use a specific trigger?</p>  <pre><code>select build_name where trigger like '/BRANCH/QA/%' </code></pre>  <p>..and no i don't expect/need/care that it be sql interface... but you get the point</p>""",azure-devops
53053957,App service certificate is not renewed despite of selecting rekey <p>I did a rekey on my app service certificate  however the expiration time of my certificate has not changed. </p>,azure-web-app-service
54765117,Tracking scripts and Azure CDN <p>I'm using Google Analytics on my static website that I'm hosting on azure blob storage (static website)  and using Azure CDN to secure it. (otherwise I don't really need a CDN  my page isn't particularly high traffic.)</p>  <p>I've noticed  though  that my filters in GA don't seem to work anymore. I assume it has to do with the IP address of the CDN provider somehow? I'm not very well versed in how CDN's work  but I thought it would work since it's a client side script  after all.</p>  <p>Is there anything I can do about this?</p>,azure-storage
55956777,Azure Application Gateway App Service using Active Directory redirecting to signin-oidc <p>I have put my app behind azure application gateway. I can access my app using the application gateway through this url: <code>https://myapps.westus.cloudapp.azure.com/myapp</code></p>  <p>My app requires azure ad so I and I am prompted to login (with azure AD)  after I login I am redirected to: <code>https://myapp.azurewebsites.net/signin-oidc</code></p>  <p>But I want my app url to be masked by the gateway name: <code>https://myapps.westus.cloudapp.azure.com/myapp</code></p>  <p>How do I configure my app to be masked by the url  after I sign in through azure AD. I am using a path based rule for my backend pool as /myapp</p>,azure-web-app-service
55052795,"How to add local VS project to existing non-empty Azure DevOps Repo <p>I have a local Visual Studio 2017 project which I want to add to an existing non-empty repo in Azure DevOps. Is that possible?</p>  <p>DevOps has two branches - master and a secondary branch. I would like to add local VS project to master branch. Local VS project is has same structure and code base of master branch.</p>  <p>I tried several approaches and one of them is the below series of commands:</p>  <p><strong>Approach 1</strong></p>  <ol> <li>go into local vs project solution folder</li> <li>run \git init\""</li> <li>git remote add origin </li> <li>git add .</li> </ol>  <p><em>Error:</em> After I run git add command (#4)  i get error that say db.lock permission denied and unable to open index file db.lock</p>  <p><strong>Approach 2</strong></p>  <p>I tried adding VS project by clicking on  the \""add to source control\"" option in the bottom right of visual studio and then selected the correct non-empty azure repo. Once i clicked publish  i saw below output:</p>  <p><em>Error:</em> Updates were rejected because the remote contains work that you do not have locally. This is usually caused by another repository pushing to the same ref. You may want to first integrate the remote changes (e.g.  'git pull ...') before pushing again. See the 'Note about fast-forwards' in 'git push --help' for details.</p>  <p>Any pointers or references?</p>""",azure-devops
10748926,"Will my source code be lost once Team Foundation Service Preview comes out of preview? <p>Does anyone know if I put some source code on \Team Foundation Service Preview\"" (tfspreview.com: tfs on the cloud)  will all source code be lost once the program is outside of the preview stage?</p>  <p>Im intent on purchasing once its live  just seeing if its feasible to start using now.</p>""",azure-devops
57391559,Alert me How to send data to Sales Force objects from function app? <p>I know <code>we have connector into Logic app to insert data into Sales Force</code> but is there any <code>sample code present in c#</code></p>  <p>using which we can able to insert data into sales force object using azure function?</p>  <p>I have <code>json array as output</code> and its <code>hard to use for-each and compose</code> in term of nested logic into logic app.</p>  <p>so i want to use c# code using function app.</p>,azure-functions
54246102,"Azure Pipelines: Passing a variable as a parameter to a template <p>I am currently evaluating Azure Pipelines with a small POC and I think I have hit a limitation but wanted to know if anyone had a workaround.</p>  <p>Here is the key parts for what I am trying to do.</p>  <p><strong>azure-pipelines.yml</strong></p>  <pre><code>variables:   - name: FavouriteSportsTeam     value: \Houston Rockets\"" jobs:   - template: Build1.yml     parameters:       SportsTeam: $(FavouriteSportsTeam)   - template: Build2.yml     parameters:       SportsTeam: $(FavouriteSportsTeam) </code></pre>  <p><strong>Build1.yml</strong></p>  <pre><code>parameters:   SportsTeam: \""A Default Team\"" jobs:   - job: SportsTeamPrinter     steps:       - script: \""echo ${{ parameters.SportsTeam }}\"" </code></pre>  <p>Now when I attempt to run this  the variable passed from the azure-pipelines.yml file isn't expanded  and it's left as \""$(FavouriteSportsTeam)\""</p>  <p>Is it possible to pass an expanded variable as a parameter to another file?</p>""",azure-devops
40916248,Microsoft azure site recovery <p>I am performing azure site recovery from vmware to azure through a site to site virtual private network. My on premise network bandwidth is 50mbps. </p>  <p>what will be the bandwidth in azure network?? is there any document or tool for this??</p>,azure-virtual-machine
18823024,Change script timeout on windows azure Website <p>How is it possible to change the script timeout on a windows azure website?</p>,azure-storage
50871501,"Azure App Services Enforce HTTPS for only for one/specific custom domain/s <p>I have an Azure App service and it has multiple custom domains mapped. When I enforce HTTPS from SSL Configuration it applied all custom domains. </p>  <p><a href=\https://i.stack.imgur.com/xNMJN.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/xNMJN.png\"" alt=\""enter image description here\""></a></p>  <p>Is there any way to enforce HTTPS only for one/specific custom domain/s?</p>""",azure-web-app-service
56019840,Is there any way to connect with Azure VM from visual studio solution? I want to access Azure VM serial Console using C# code <p>I am trying to access Azure VM's Serial console to execute some powershell script. How can I do it using C# code?</p>,azure-virtual-machine
50854624,"How to configure storage for MsSql Export Purpose in Azure <p>I want to Export <code>Mssql</code> file from azure to local system <a href=\https://docs.microsoft.com/en-us/azure/sql-database/sql-database-export\"" rel=\""nofollow noreferrer\"">according to this link</a><br> But when I go to Export and click on the storage configuration:<br><br> <a href=\""https://i.stack.imgur.com/BLHli.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/BLHli.png\"" alt=\""enter image description here\""></a> <br>and then it opens configuration form but nothing happen there  and storage option is also closed  <br><br> <a href=\""https://i.stack.imgur.com/6zLQj.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/6zLQj.png\"" alt=\""enter image description here\""></a> <br><br> Any solution for it ? </p>""",azure-storage
47774208,"Open custom inbound firewall ports e.g. 8077 by any way using java in azure <p>I am launching one windows instance in Azure(Microsoft) using Java and trying to open few inbound ports like 445  8077 for my work. I have also tried using Security groups port opening but it is only opening the inbound ports at security group level  not at the system level. Provide me some solution so that I can open either before launch itself or after launch is also fine. I have done the same thing in AWS as asked in below URL:<br> <a href=\https://stackoverflow.com/questions/47653202/open-some-custom-inbound-ports-e-g-8077-by-using-80-or-3389\"">Open some custom inbound ports e.g. 8077 by using 80 or 3389</a></p>""",azure-virtual-machine
57399079,"Azure DevOps Pull Request from Dev to Master is fetching old code <p>I am having this scenario when merging code using <strong><em>Git</em></strong> in <strong><em>Azure DevOps</em></strong>:</p>  <p><strong>On 7/30:</strong> A pull request was created to merge code from <strong><em>Dev branch</em></strong> to <strong><em>Master</em></strong> choosing  the Squash and Merge option. So  only one single commit was done without preserving all history.</p>  <p><strong>From 7/31 to 8/6:</strong> All <strong><em>feature branches</em></strong> are already merge into the <strong><em>Dev branch</em></strong> with the Merge commit option preserving all commit history.</p>  <p><strong>Now  on 8/7:</strong> I am trying to <strong><em>merge Dev branch</em></strong> to <strong><em>master</em></strong> one more time (doing this at the end of each Sprint). However  while creating the pull request something I noticed and took my attention is that on the pull request  I am getting older changes before 7/30.</p>  <p><a href=\https://i.stack.imgur.com/SE6hL.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/SE6hL.png\"" alt=\""enter image description here\""></a></p>  <p>Should not the pull request be showing/ displaying all changes done from 7/31 to 8/6?</p>  <p><a href=\""https://i.stack.imgur.com/vhegD.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/vhegD.png\"" alt=\""enter image description here\""></a></p>""",azure-devops
51486311,Cannot Install TFS agent on Window Server 2012 R2  unclear error <p>Agent Version: 2.122.1 Windows -Windows server 2012 R2  TFS version -2017  getting this error when trying to install TFS agent on windows  exits when i run run.cmd from TFS agent folder. the installer exits with these errors. There seems to be no clear documentation of troubleshooting such errors. the power shell version on the machine is 4.0.</p>  <pre><code>Agent is built for Windows - win7-x64. [2018-07-23 17:27:42Z INFO AgentProcess] RuntimeInformation: Microsoft  Windows 6.3.9600 . [2018-07-23 17:27:42Z INFO AgentProcess] Version: 2.122.1 [2018-07-23 17:27:42Z INFO AgentProcess] Commit:  fc6746af2429c6ffa73c0793d732e6853f9fb375 [2018-07-23 17:27:42Z INFO AgentProcess] Culture: en-US [2018-07-23 17:27:42Z INFO AgentProcess] UI Culture: en-US [2018-07-23 17:27:42Z INFO HostContext] Well known directory 'Bin': 'C:\Users\SChalla\Downloads\CATTSPool\bin' [2018-07-23 17:27:42Z INFO HostContext] Well known directory 'Root': 'C:\Users\SChalla\Downloads\CATTSPool' [2018-07-23 17:27:42Z INFO AgentProcess] Validating directory permissions for: 'C:\Users\SChalla\Downloads\CATTSPool' [2018-07-23 17:27:42Z INFO PowerShellExeUtil] Generation: '1' [2018-07-23 17:27:42Z INFO PowerShellExeUtil] Key name 'HKEY_LOCAL_MACHINE\SOFTWARE\Microsoft\PowerShell\1'  value name 'Install': '1' [2018-07-23 17:27:42Z INFO PowerShellExeUtil] Key name 'HKEY_LOCAL_MACHINE\SOFTWARE\Microsoft\PowerShell\1\PowerShellEngine'  value name 'PowerShellVersion': '2.0' [2018-07-23 17:27:42Z INFO PowerShellExeUtil] Unsupported version. Skipping. [2018-07-23 17:27:42Z INFO PowerShellExeUtil] Generation: '3' [2018-07-23 17:27:42Z INFO PowerShellExeUtil] Key name 'HKEY_LOCAL_MACHINE\SOFTWARE\Microsoft\PowerShell\3'  value name 'Install': '1' [2018-07-23 17:27:42Z INFO PowerShellExeUtil] Key name 'HKEY_LOCAL_MACHINE\SOFTWARE\Microsoft\PowerShell\3\PowerShellEngine'  value name 'PowerShellVersion': '4.0' [2018-07-23 17:27:42Z INFO PowerShellExeUtil] Key name 'HKEY_LOCAL_MACHINE\SOFTWARE\Microsoft\PowerShell\3\PowerShellEngine'  value name 'ApplicationBase': 'C:\Windows\System32\WindowsPowerShell\v1.0' [2018-07-23 17:27:42Z INFO NetFrameworkUtil] Key name 'HKEY_LOCAL_MACHINE\SOFTWARE\Microsoft\.NETFramework'  value name 'InstallRoot': 'C:\Windows\Microsoft.NET\Framework64\' [2018-07-23 17:27:42Z INFO NetFrameworkUtil] Key name 'SOFTWARE\Microsoft\NET Framework Setup\NDP' contains sub keys: [2018-07-23 17:27:42Z INFO NetFrameworkUtil]  'CDF' [2018-07-23 17:27:42Z INFO NetFrameworkUtil]  'v3.0' [2018-07-23 17:27:42Z INFO NetFrameworkUtil]  'v4' [2018-07-23 17:27:42Z INFO NetFrameworkUtil]  'v4.0' [2018-07-23 17:27:42Z INFO NetFrameworkUtil] Key name 'HKEY_LOCAL_MACHINE\SOFTWARE\Microsoft\NET Framework Setup\NDP\v3.0'  value name 'Version' is null. [2018-07-23 17:27:42Z INFO NetFrameworkUtil] Key name 'HKEY_LOCAL_MACHINE\SOFTWARE\Microsoft\NET Framework Setup\NDP\v3.0'  value name '' is null. [2018-07-23 17:27:42Z INFO NetFrameworkUtil] Key name 'SOFTWARE\Microsoft\NET Framework Setup\NDP\v3.0' contains sub keys: [2018-07-23 17:27:42Z INFO NetFrameworkUtil]  'Setup' [2018-07-23 17:27:42Z INFO NetFrameworkUtil] Key name 'HKEY_LOCAL_MACHINE\SOFTWARE\Microsoft\NET Framework Setup\NDP\v3.0\Setup'  value name 'Version' is null. [2018-07-23 17:27:42Z INFO NetFrameworkUtil] Key name 'HKEY_LOCAL_MACHINE\SOFTWARE\Microsoft\NET Framework Setup\NDP\v4'  value name 'Version' is null. [2018-07-23 17:27:42Z INFO NetFrameworkUtil] Key name 'HKEY_LOCAL_MACHINE\SOFTWARE\Microsoft\NET Framework Setup\NDP\v4'  value name '' is null. [2018-07-23 17:27:42Z INFO NetFrameworkUtil] Key name 'SOFTWARE\Microsoft\NET Framework Setup\NDP\v4' contains sub keys: [2018-07-23 17:27:42Z INFO NetFrameworkUtil]  'Client' [2018-07-23 17:27:42Z INFO NetFrameworkUtil]  'Full' [2018-07-23 17:27:42Z INFO NetFrameworkUtil] Key name 'HKEY_LOCAL_MACHINE\SOFTWARE\Microsoft\NET Framework Setup\NDP\v4\Client'  value name 'Version': '4.7.03062' [2018-07-23 17:27:42Z INFO NetFrameworkUtil] Key name 'HKEY_LOCAL_MACHINE\SOFTWARE\Microsoft\NET Framework Setup\NDP\v4\Client'  value name 'Install': '1' [2018-07-23 17:27:42Z INFO NetFrameworkUtil] Key name 'HKEY_LOCAL_MACHINE\SOFTWARE\Microsoft\NET Framework Setup\NDP\v4\Client'  value name 'InstallPath': 'C:\Windows\Microsoft.NET\Framework64\v4.0.30319\' [2018-07-23 17:27:42Z INFO NetFrameworkUtil] Key name 'HKEY_LOCAL_MACHINE\SOFTWARE\Microsoft\NET Framework Setup\NDP\v4\Client'  value name 'Release': '461814' [2018-07-23 17:27:42Z INFO NetFrameworkUtil] Type is System.Int32 [2018-07-23 17:27:42Z INFO NetFrameworkUtil] Interpreted version: 4.6.2 [2018-07-23 17:27:42Z INFO NetFrameworkUtil] Key name 'HKEY_LOCAL_MACHINE\SOFTWARE\Microsoft\NET Framework Setup\NDP\v4\Full'  value name 'Version': '4.7.03062' [2018-07-23 17:27:42Z INFO NetFrameworkUtil] Key name 'HKEY_LOCAL_MACHINE\SOFTWARE\Microsoft\NET Framework Setup\NDP\v4\Full'  value name 'Install': '1' [2018-07-23 17:27:42Z INFO NetFrameworkUtil] Key name 'HKEY_LOCAL_MACHINE\SOFTWARE\Microsoft\NET Framework Setup\NDP\v4\Full'  value name 'InstallPath': 'C:\Windows\Microsoft.NET\Framework64\v4.0.30319\' [2018-07-23 17:27:42Z INFO NetFrameworkUtil] Key name 'HKEY_LOCAL_MACHINE\SOFTWARE\Microsoft\NET Framework Setup\NDP\v4\Full'  value name 'Release': '461814' [2018-07-23 17:27:42Z INFO NetFrameworkUtil] Type is System.Int32 [2018-07-23 17:27:42Z INFO NetFrameworkUtil] Interpreted version: 4.6.2 [2018-07-23 17:27:42Z INFO NetFrameworkUtil] Key name 'HKEY_LOCAL_MACHINE\SOFTWARE\Microsoft\NET Framework Setup\NDP\v4.0'  value name 'Version' is null. [2018-07-23 17:27:42Z INFO NetFrameworkUtil] Key name 'HKEY_LOCAL_MACHINE\SOFTWARE\Microsoft\NET Framework Setup\NDP\v4.0'  value name '': 'deprecated' [2018-07-23 17:27:42Z INFO NetFrameworkUtil] Found 2 versions: [2018-07-23 17:27:42Z INFO NetFrameworkUtil]  4.6.2 [2018-07-23 17:27:42Z INFO NetFrameworkUtil]  4.6.2 [2018-07-23 17:27:42Z INFO NetFrameworkUtil] Testing for min NET Framework version: '4.5' [2018-07-23 17:27:42Z INFO CommandLineParser] Parse [2018-07-23 17:27:42Z INFO CommandLineParser] Parsing 1 args [2018-07-23 17:27:42Z INFO CommandLineParser] parsing argument [2018-07-23 17:27:42Z INFO CommandLineParser] HasArgs: False [2018-07-23 17:27:42Z INFO CommandLineParser] Adding Command: run [2018-07-23 17:27:42Z INFO AgentProcess] Arguments parsed [2018-07-23 17:27:43Z INFO VstsAgentWebProxy] No proxy setting found. [2018-07-23 17:27:43Z INFO Agent] ExecuteCommand [2018-07-23 17:27:43Z INFO ConfigurationStore] currentAssemblyLocation: C:\Users\SChalla\Downloads\CATTSPool\bin\Agent.Listener.dll [2018-07-23 17:27:43Z INFO HostContext] Well known directory 'Bin': 'C:\Users\SChalla\Downloads\CATTSPool\bin' [2018-07-23 17:27:43Z INFO ConfigurationStore] binPath: C:\Users\SChalla\Downloads\CATTSPool\bin [2018-07-23 17:27:43Z INFO HostContext] Well known directory 'Bin': 'C:\Users\SChalla\Downloads\CATTSPool\bin' [2018-07-23 17:27:43Z INFO HostContext] Well known directory 'Root': 'C:\Users\SChalla\Downloads\CATTSPool' [2018-07-23 17:27:43Z INFO ConfigurationStore] RootFolder: C:\Users\SChalla\Downloads\CATTSPool [2018-07-23 17:27:43Z INFO ConfigurationStore] ConfigFilePath: C:\Users\SChalla\Downloads\CATTSPool\.agent [2018-07-23 17:27:43Z INFO ConfigurationStore] CredFilePath: C:\Users\SChalla\Downloads\CATTSPool\.credentials [2018-07-23 17:27:43Z INFO ConfigurationStore] ServiceConfigFilePath: C:\Users\SChalla\Downloads\CATTSPool\.service [2018-07-23 17:27:43Z INFO ConfigurationStore] AutoLogonSettingsFilePath: C:\Users\SChalla\Downloads\CATTSPool\.autologon [2018-07-23 17:27:43Z INFO CommandSettings] Flag 'help': 'False' [2018-07-23 17:27:43Z INFO CommandSettings] Flag 'version': 'False' [2018-07-23 17:27:43Z INFO CommandSettings] Flag 'commit': 'False' [2018-07-23 17:27:43Z INFO CommandSettings] Command 'configure': 'False' [2018-07-23 17:27:43Z INFO CommandSettings] Command 'remove': 'False' [2018-07-23 17:27:43Z INFO CommandSettings] Command 'localRun': 'False' [2018-07-23 17:27:43Z INFO ConfigurationManager] LoadSettings [2018-07-23 17:27:43Z INFO ConfigurationStore] IsConfigured() [2018-07-23 17:27:43Z INFO ConfigurationStore] IsConfigured: False [2018-07-23 17:27:43Z INFO ConfigurationManager] Is configured: False [2018-07-23 17:27:43Z ERR  Terminal] WRITE ERROR: An error occurred: Not configured [2018-07-23 17:27:44Z ERR  AgentProcess] System.InvalidOperationException: Not configured    at Microsoft.VisualStudio.Services.Agent.Listener.Configuration.ConfigurationManager.LoadSettings()    at Microsoft.VisualStudio.Services.Agent.Listener.Agent.&lt;ExecuteCommand&gt;d__5.MoveNext() --- End of stack trace from previous location where exception was thrown ---    at System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw()    at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task)    at Microsoft.VisualStudio.Services.Agent.Listener.Program.&lt;MainAsync&gt;d__1.MoveNext() </code></pre>  <p>Any suggestions would be helpful</p>,azure-devops
47739904,"Using In-Proc COM DLL with Azure Function <p>Is it possible to use an In-Proc COM DLL with Azure Functions?  </p>  <p>I am migrating my web service to Azure Functions.  One of the components has a dependency on a legacy 32-bit COM DLL.  This would normally require the DLL to be regsvr32-ed on the system where it will be used.  As that seems not possible with Azure Functions is it possible to use such legacy implementations?  </p>  <p>Or would it be necessary to revert to a classic cloud service to support this?  (My preference would be use the Consumption service plan and benefit from \serverless\"" architecture.)</p>  <p>Steps:</p>  <ol> <li>Create new Azure Function App </li> <li>Add new Azure Function (http trigger)</li> <li>Add reference to 32-bit COM component</li> <li>Call simple test method on COM component</li> <li>Run locally - works fine</li> <li>Publish Azure Function</li> <li>Open function http path - Azure Function fails</li> </ol>  <p>Error log reports exception:</p>  <p>Could not load file or assembly 'Interop.MyCOMLib  Version=1.0.0.0  Culture=neutral  PublicKeyToken=null' or one of its dependencies. The system cannot find the file specified.</p>  <blockquote>   <p>Exception while executing function: Legacy   Microsoft.Azure.WebJobs.Host.FunctionInvocationException : Exception   while executing function: Legacy ---> System.IO.FileNotFoundException   : Could not load file or assembly 'Interop.MyCOMLib  Version=1.0.0.0    Culture=neutral  PublicKeyToken=null' or one of its dependencies. The   system cannot find the file specified.    at async   Functions.Legacy.Run(HttpRequestMessage req TraceWriter log)    at   System.Runtime.CompilerServices.AsyncTaskMethodBuilder 1.Start[TStateMachine](TStateMachine&amp;   stateMachine)    at Functions.Legacy.Run(HttpRequestMessage   req TraceWriter log)    at lambda_method(Closure  Legacy  Object[] )<br>   at   Microsoft.Azure.WebJobs.Host.Executors.TaskMethodInvoker 2.InvokeAsync(TReflected   instance Object[] arguments)    at async   Microsoft.Azure.WebJobs.Host.Executors.FunctionInvoker 2.InvokeAsync[TReflected TReturnValue](Object   instance Object[] arguments)    at async   Microsoft.Azure.WebJobs.Host.Executors.FunctionExecutor.InvokeAsync(IFunctionInvoker   invoker ParameterHelper parameterHelper CancellationTokenSource   timeoutTokenSource CancellationTokenSource   functionCancellationTokenSource Boolean throwOnTimeout TimeSpan   timerInterval IFunctionInstance instance)    at async   Microsoft.Azure.WebJobs.Host.Executors.FunctionExecutor.ExecuteWithWatchersAsync(IFunctionInstance   instance ParameterHelper parameterHelper TraceWriter   traceWriter CancellationTokenSource functionCancellationTokenSource)<br>   at async   Microsoft.Azure.WebJobs.Host.Executors.FunctionExecutor.ExecuteWithLoggingAsync(??)   at async   Microsoft.Azure.WebJobs.Host.Executors.FunctionExecutor.ExecuteWithLoggingAsync(??)   End of inner exception</p> </blockquote>  <p>Also  if I go to the solution's Dependencies | COM then select the Interop.Lib and select to Embed Interop Types then with this change  after publish  on calling the publushed function:</p>  <p>\""Retrieving the COM class factory for component with CLSID {D84F92D7-FFFF-4C16-B939-EC98E3A6EBC0} failed due to the following error: 80040154 Class not registered (Exception from HRESULT: 0x80040154 (REGDB_E_CLASSNOTREG)).\""</p>  <p>Thus  the challenge is how to register the COM classes with Azure Functions?</p>""",azure-functions
45340248,"Azure Functions - route template with file <p>I have created an Azure Function that receives an HTTP request and returns an HTTP request.  The function:</p>  <ol> <li>Accepts an HTTP request</li> <li>Creates a URI to a location in blob storage with a shared access signature that expires in n minutes/hours</li> <li>Returns a 302 status code with the location header set to the URI that will expire in n minutes/hours</li> </ol>  <p>I was able to get this to work when I placed the path to the blob in a query parameter  but it fails when that variable is in the route template.</p>  <p>I tried to make the route template: storage/{containerName:alpha}/{path:alpha} but it always returns a 404.  Below is an example cURL of how the request is constructed.</p>  <pre><code>GET /api/storage/example-container-name/example.jpg?code=SSBhbSBhIHRlYXBvdCwgZG8geW91IHRoaW5rIEkgd291bGQgcHV0IGEgcGFzc3dvcmQgaGVyZT8= HTTP/1.1 Host: hostdoesnotexist.azurewebsites.net     Cache-Control: no-cache </code></pre>  <p>**Note:The host is not real  path and code are not real.*</p>  <p>I did find this question that was related to the Azure Functions Proxy doing the same thing  but this question is not applicable to the Functions.</p>  <p><a href=\https://stackoverflow.com/questions/42449624/azure-functions-proxy-route-to-storage-account\"">Azure Functions Proxy - route to storage account</a></p>  <p>Using this <a href=\""https://docs.microsoft.com/en-us/azure/azure-functions/functions-bindings-http-webhook#url\"" rel=\""nofollow noreferrer\"">Azure Functions HTTP and webhook bindings</a> example  and scrolling to the <strong>Customizing the HTTP endpoint</strong> section  I created another function with the following code:</p>  <p>Function.json - id changed from int? to alpha</p>  <pre><code>{   \""bindings\"": [     {       \""name\"": \""req\""        \""type\"": \""httpTrigger\""        \""direction\"": \""in\""        \""methods\"": [         \""get\""       ]        \""route\"": \""products/{category:alpha}/{id:alpha}\""        \""authLevel\"": \""function\""     }      {       \""name\"": \""$return\""        \""type\"": \""http\""        \""direction\"": \""out\""     }   ]    \""disabled\"": false } </code></pre>  <p>run.csx</p>  <pre><code>public static async Task&lt;HttpResponseMessage&gt; Run(HttpRequestMessage req                                                       string category                                                       string id                                                      TraceWriter log) {     if (id == null)         return  req.CreateResponse(HttpStatusCode.OK  $\""All {category} items were requested.\"");     else         return  req.CreateResponse(HttpStatusCode.OK  $\""{category} item with id = {id} has been requested.\""); } </code></pre>  <p>So if the route is products/test/abcd then it responds with:</p>  <p>200 - \""test item with id = abc has been requested.\""  </p>  <p>But  if you change this to products/test/abcd.jpg then it responds with:</p>  <p>404 - The resource you are looking for has been removed  had its name changed  or is temporarily unavailable.</p>  <p>This is the same behavior I am seeing with the other function I created.</p>  <p>Does anyone know if this is a bug like the proxies example  or should my route look different?  Again  I have this working using query parameters  but it fails when I move the variables into the route template.</p>  <p>Edited - Added files based on feedback function.json</p>  <pre><code>{   \""bindings\"": [     {       \""name\"": \""req\""        \""type\"": \""httpTrigger\""        \""direction\"": \""in\""        \""methods\"": [         \""get\""       ]        \""route\"": \""products/{category:alpha}\""        \""authLevel\"": \""function\""     }      {       \""name\"": \""$return\""        \""type\"": \""http\""        \""direction\"": \""out\""     }   ]    \""disabled\"": false } </code></pre>  <p>run.csx</p>  <pre><code>using System.Net;  public static async Task&lt;HttpResponseMessage&gt; Run(HttpRequestMessage req                                                       string category                                                       TraceWriter log) {     string id = req.GetQueryNameValuePairs()         .FirstOrDefault(q =&gt; string.Compare(q.Key  \""id\""  true) == 0)         .Value;       if (id == null)         return  req.CreateResponse(HttpStatusCode.OK  $\""All {category} items were requested.\"");     else         return  req.CreateResponse(HttpStatusCode.OK  $\""{category} item with id = {id} has been requested.\""); } </code></pre>  <p>proxies.json</p>  <pre><code>{     \""$schema\"": \""http://json.schemastore.org/proxies\""      \""proxies\"": {         \""GetJustArtinAroundStorageLinkProxy\"": {             \""matchCondition\"": {                 \""route\"": \""/products/{category:alpha}/{id}\""                  \""methods\"": [                     \""GET\""                 ]             }              \""backendUri\"": \""https://&lt;company-name&gt;.azurewebsites.net/api/products/{category:alpha}?id={id}\""         }     } } </code></pre>""",azure-functions
53227811,"HttpRequestMessage properties in Azure function <p>When my web request is run  some properties that are in the <code>Properties</code> property of <code>HttpRequestMessage</code> are from the <code>System.Web</code> namespace  although the application I am developing is .NET Core 2 Azure function.</p>  <p>I would like to use one object from the collection  <code>MS_HttpContext</code> which is of type  <code>System.Web.HttpContextWrapper</code>. Is it possible to use this object and somehow cast to it? This object seems to be from standard .NET framework. </p>  <pre><code>[FunctionName(\Track\"")] public static async Task&lt;HttpResponseMessage&gt; Run([HttpTrigger(AuthorizationLevel.Anonymous  \""get\""  Route = \""track\"")]HttpRequestMessage req  TraceWriter log  ExecutionContext context) {     // HttpContextWrapper is from System.Web  so this does not work     var ctx = (HttpContextWrapper)req.Properties[\""MS_HttpContext\""]  } </code></pre>  <p>EDIT: my question is slightly different than my previos question (<a href=\""https://stackoverflow.com/questions/53211824/get-remote-ip-address-in-azure-function\"">Get remote IP address in Azure function</a>)  because it asks how can classes from <code>System.Web</code> namespace be accessed from a .NET Core application. Although I admit the desired result is the same in both questions  to get the remote IP address.</p>""",azure-functions
52256425,"Unable to install a specific site extension in Azure Web App <p>I want to install a site extension to my Web App. Site Extension - Azure Web Apps Disk Usage. However  the problem is that I cannot find the extension in the list of extensions that are shown to me. I have checked the list of extension in the Azure portal as well is the scm site  but there are only a limited set of extensions are shown to me. <a href=\https://i.stack.imgur.com/rDrhL.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/rDrhL.png\"" alt=\""enter image description here\""></a></p>  <p>What am I missing here?  Is there some setting that I am missing?</p>""",azure-web-app-service
44642622,"getting file path in asp.net class library project on Azure WebApp <p>I am having a class library in which I am access a file from the application path using the below code. It wont work on azure as it cannot find the application path. How to make it work azure as it works fine on my local machine.</p>  <pre><code> private string GetProjectPath()         {             string SolutionName = \MyApi.sln\"";             //Get name of the target project which we want to test              var projectName = typeof(TerminationMatchInquiry).GetTypeInfo().Assembly.GetName().Name;              //Get currently executing test project path             var applicationBasePath = new Uri((typeof(TerminationMatchInquiry).GetTypeInfo().Assembly.CodeBase)).LocalPath;             //Find the folder which contains the solution file. We then use this information to find the              //target project which we want to test             DirectoryInfo directoryInfo = new DirectoryInfo(applicationBasePath);             do             {                 var solutionFileInfo = new FileInfo(Path.Combine(directoryInfo.FullName  SolutionName));                 if (solutionFileInfo.Exists)                 {                     return Path.GetFullPath(Path.Combine(directoryInfo.FullName  projectName));                 }                 directoryInfo = directoryInfo.Parent;             }             while (directoryInfo.Parent != null);              throw new Exception($\""Solution root could not be located using application root {applicationBasePath}\"");         } </code></pre>""",azure-web-app-service
47454047,"Azure blob storage to JSON in azure function using SDK <p>I am trying to create a timer trigger azure function that takes data from blob  aggregates it  and puts the aggregates in a cosmosDB. I previously tried using the bindings in azure functions to use blob as input  which I was informed was incorrect (see this thread: <a href=\https://stackoverflow.com/questions/47437077/azure-functions-python-no-value-for-named-parameter\"">Azure functions python no value for named parameter</a>). </p>  <p>I am now using the SDK and am running into the following problem: </p>  <pre><code>import sys  os.path sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__)  'myenv/Lib/site-packages'))) import json import pandas as pd from azure.storage.blob import BlockBlobService   data = BlockBlobService(account_name='accountname'  account_key='accountkey') container_name = ('container') generator = data.list_blobs(container_name)  for blob in generator: print(\""{}\"".format(blob.name)) json = json.loads(data.get_blob_to_text('container'  open(blob.name)))   df = pd.io.json.json_normalize(json) print(df) </code></pre>  <p>This results in an error:</p>  <pre><code>IOError: [Errno 2] No such file or directory: 'test.json' </code></pre>  <p>I realize this might be an absolute path issue  but im not sure how that works with azure storage. Any ideas on how to circumvent this?</p>  <hr>  <p>Made it \""work\"" by doing the following:</p>  <pre><code>for blob in generator: loader = data.get_blob_to_text('kvaedevdystreamanablob' blob.name if_modified_since=delta) json = json.loads(loader.content) </code></pre>  <p>This works for ONE json file  i.e I only had one in storage  but when more are added I get this error:</p>  <pre><code>ValueError: Expecting object: line 1 column 21907 (char 21906) </code></pre>  <p>This happens even if i add <code>if_modified_since</code> as to only take in one blob. Will update if I figure something out. Help always welcome.</p>  <hr>  <p>Another update: My data is coming in through stream analytics  and then down to the blob. I have selected that the data should come in as arrays  this is why the error is occurring. When the stream is terminated  the blob doesnt immediately append <code>]</code> to the EOF line in json  thus the json file isnt valid. Will try now with using line-by-line in stream analytics instead of array.</p>""",azure-functions
54432786,Alert me Hosted WCF website in azure app service <p>when I hosted wcf website in auzre app service I get an exception as following:</p>  <p>An unsecured or incorrectly secured fault was received from the other party. See the inner FaultException for the fault code and detail..</p>,azure-web-app-service
54187616,"How to clear credential cache by CredentialProvider.VSS.exe <p>I made a NuGet feed at <a href=\https://azure.microsoft.com/en-us/services/devops/artifacts/\"" rel=\""nofollow noreferrer\"">Azure Artifacts</a>. I installed <code>NuGet.exe</code> and <code>CredentialProvider.VSS.exe</code> into my project. I can list/get/push NuGet packages. At this time  no problem at all. But I want to clear my credential cache that created by <code>CredentialProvider.VSS.exe</code>. How can I do that?</p>""",azure-devops
48859064,Azure VM Extension List <p>Looking to see if there's a easy way to retrieve all 'attached' extensions to a Virtual Machine whether it's Windows / Linux using PowerShell?</p>  <p>From my research  the 'Get-AzureRmVMExtension' extension requires that you provide a name parameter and doesn't allow the ability to list all associated.</p>,azure-virtual-machine
46157549,"Azure load balancer: NAT redirect RDP to VM  and load balance HTTP to availability set? <p>It looks like you can't NAT as well as load balance unless it's to the same destination. Once I created the NAT rule (so I can RDP to the load balancer over a custom port  and then that's redirected to my management VM)  I cannot create the backend pool to use for HTTP load balancing. I go to backend pools and click create and it already fills in \associated with \"" and I cannot change that to my web VMs availability set.</p>  <p>I've also tried creating the backend pool first  for which I select the web VM availability set  but then when I create a NAT rule I cannot point to the management VM  only to the availability set/specific VM in that set.</p>  <p>What am I missing? Is there a solution besides recreating the management VM and putting it in the web VM availability set?</p>""",azure-virtual-machine
18489958,"I got exception when connecting to TFS sources in Visual studio 2012 <p>I cannot get sources dialog in my visual studio 2012.  I got null reference exception: Any ideas what causes this? </p>  <p><img src=\https://i.stack.imgur.com/SL0qU.png\"" alt=\""enter image description here\""></p>  <pre><code>System.NullReferenceException: Object reference not set to an instance of an object.    at Microsoft.VisualStudio.TeamFoundation.VersionControl.PendingChanges.PendingChangesModelVS.Initialize(IServiceProvider serviceProvider  VersionControlServer versionControlServer  Workspace workspace)    at Microsoft.TeamFoundation.VersionControl.Controls.PendingChanges.PendingChangesPage.InitializeModel(PageInitializeEventArgs e)    at Microsoft.TeamFoundation.Controls.WPF.TeamExplorer.TeamExplorerPageBase.Initialize(Object sender  PageInitializeEventArgs e)    at Microsoft.VisualStudio.TeamFoundation.VersionControl.PendingChanges.PendingChangesPageVS.Initialize(Object sender  PageInitializeEventArgs e)    at Microsoft.TeamFoundation.Controls.WPF.TeamExplorer.Framework.TeamExplorerPageHost.Initialize(TeamExplorerPageContext context) </code></pre>  <p>VS pro with latest updates.</p>""",azure-devops
23729809,BlockBlobRoot folder in Azure Storage locally <p>I found a folder named BlockBlobRoot in my local folder: <code>C:\Users\&lt;user name&gt;\AppData\Local\WAStorageEmulator\</code>   its size increased quickly.</p>  <p>My question is:</p>  <ol> <li>What and where data come from in this folder?</li> <li>Can I keep its size not increase so much or maintain in a certain size?</li> <li>Can this folder be moved to somewhere other place?</li> </ol>,azure-storage
42386299,"Azure Function on Time Trigger not firing <p>I have an Azure Function setup on a Consumption plan which contains 6 individual Timer Triggered functions.</p>  <ul> <li>3 of them fire every hour at 5 past the hour (0 5 * * * *)</li> <li>1 of them fires every night at midnight (0 0 0 * * *)</li> <li>1 of them fires on a Monday at 8am (0 0 8 * * Mon)</li> <li>And the final one is supposed to fire at 1am every morning (0 0 1 * * *) but isn't</li> </ul>  <p>They are all copies of the same application  but do different things depending upon the command line arguments. They're triggered by a Run.ps1 Powershell script which contains the appropriate command line args.</p>  <p>Yesterday at 09:40 I tried running the problem function manually and it ran  so I changed the schedule to (0 0 11 * * *) and it ran at 11am as expected.  So I changed the schedule back to (0 0 1 * * *) but at 1am this morning it didn't run :(</p>  <p><a href=\https://i.stack.imgur.com/HN7jr.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/HN7jr.png\"" alt=\""enter image description here\""></a></p>  <p>I'm going to try changing the schedule so that it runs at 2am in case there's something causing an issue at 1am  but other than than what else can I try?</p>""",azure-functions
56538118,"Getting Azure Function App log output to Log Analytics <p>We are using and Azure Functions in a larger chain of events. All other parts of this chain have their logs available in log analytics so that we can easily trace any given request through the entire system. However  I can't find a way to get the Function App logs to the same place. I'm guessing it should be possible since it looks like this in our workspace:</p>  <p><a href=\https://i.stack.imgur.com/2olVR.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/2olVR.png\"" alt=\""logs workspace\""></a></p>  <p>The <a href=\""https://docs.microsoft.com/en-us/azure/azure-functions/functions-monitoring\"" rel=\""nofollow noreferrer\"">documentation</a> for monitoring function apps only mention Application Insights.</p>""",azure-functions
39907323,I need to remote desktop into 100s of VMs created in Azure <p>I will be creating 100s of Virtual Machines in the Azure  which I will use them for execution of my UI test case. Challenge here is I Need to have a active desktop for running the Tests. Currently at on promise I download Microsoft Remote desktop manager and make connections to 20-30 machines from each RDP session and hence able to keep desktop active for 100s of VMs.</p>  <p>In Azure I have observed that it downloads 1 rdp file for each VM. So my question now is what is the best way to remote desktop into 100s of VMs running in azure ?. Are there any other ways to keep desktop active and logged in without using the RDP manager  ?</p>,azure-virtual-machine
42104848,"Visual Studio Team Services Basic Build and Deploy <p>I am trying to get a very basic build and release process going using Visual Studio Team Services.</p>  <p>I have created a bare bones Build that uses all default steps and settings for \Visual Studio\"".</p>  <p>Looks as though my problem is that no files are being copied in the \""Copy Files To\"" step. it's Contents field = **\\bin\\$(BuildConfiguration)** (by default)</p>  <p>My project isn't being built to a bin directory though so no files are found to copy.</p>  <p>How do I get my web application project via Team Services to package only required files to a location so team services can find and copy only those required to deploy?</p>""",azure-devops
47710629,"cannot \enable debugger\"" in server explorer for azure vm  visual studio 2017 <p>What can be the reason I cannot enable debugger for some of my VM's in server explorer? </p>  <p>I try to follow this guide: </p>  <p><a href=\""https://docs.microsoft.com/en-us/azure/vs-azure-tools-debug-cloud-services-virtual-machines\"" rel=\""nofollow noreferrer\"">https://docs.microsoft.com/en-us/azure/vs-azure-tools-debug-cloud-services-virtual-machines</a></p>  <p>When I right click on the VM in Visual Studio Server Explorer I do not get the same options as in the tutorial: </p>  <p><a href=\""https://i.stack.imgur.com/ahPT8.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/ahPT8.png\"" alt=\""enter image description here\""></a></p>  <p>This is the menu I expected to see (from the tutorial):</p>  <p><a href=\""https://i.stack.imgur.com/wtTsr.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/wtTsr.png\"" alt=\""enter image description here\""></a></p>""",azure-virtual-machine
52823025,"Azure: Container did not start within expected time (WebApp) <p>I'm getting the following error when trying to deploy a webapp:</p>  <p><strong>ERROR - Container XXX_0 for site XXX did not start within expected time limit. Elapsed time = 1800.4463925 sec</strong></p>  <p>I'm trying to deploy a node app. Using automatic deployment with a .deployment file. The .deployment file looks as follows:</p>  <pre><code># 1. KuduSync if [[ \$IN_PLACE_DEPLOYMENT\"" -ne \""1\"" ]]; then   \""$KUDU_SYNC_CMD\"" -v 50 -f \""$DEPLOYMENT_SOURCE\"" -t \""$DEPLOYMENT_TARGET\"" -n \""$NEXT_MANIFEST_PATH\"" -p \""$PREVIOUS_MANIFEST_PATH\"" -i \"".git;.hg; .deployment;deploy.sh\""   exitWithMessageOnError \""Kudu Sync failed\"" fi  # 2. Select node version selectNodeVersion  # 3. Install npm packages for root directory if [ -e \""$DEPLOYMENT_TARGET/package.json\"" ]; then   cd \""$DEPLOYMENT_TARGET\""   # echo \""Running $NPM_CMD install --production for root directory\""   # eval $NPM_CMD install --production   echo \""Running $NPM_CMD install --production for root directory\""   eval $NPM_CMD install   exitWithMessageOnError \""npm failed\""   ##################   echo Building App...   eval $NPM_CMD run build   ##################   echo Starting App...   # eval $NPM_CMD run start   # cd - &gt; /dev/null fi  ##################################################################################### echo \""Finished successfully.\"" </code></pre>  <p>The package.json file has the following script:</p>  <pre><code>  \""scripts\"": {     \""dev\"": \""node server.js\""      \""build\"": \""next build\""      \""start\"": \""echo 'work!!' &amp;&amp; NODE_ENV=production &amp;&amp; node server.js\""   } </code></pre>  <p>And server.js is as follows:</p>  <pre><code>const {   createServer } = require('http') const next = require('next') const app = next({   dev: process.env.NODE_ENV !== 'production' }) const routes = require('./routes') const handler = routes.getRequestHandler(app) console.log(\""HEYYYY\""); // Without express app.prepare()   .then(() =&gt; {     console.log(\""Ready on Localhost:80!!!\"");     createServer(handler)       .listen(80  (err) =&gt; {         if (err) throw err;         console.log(\""Ready on Localhost:80\"");       });   }) </code></pre>  <p>What I've gathered from research is that:</p>  <ol> <li>There is not enough time for the app to start </li> <li>The port isn't open/ doesn't respond to a <a href=\""https://blogs.msdn.microsoft.com/waws/2017/09/08/things-you-should-know-web-apps-and-linux/#NoPing\"" rel=\""nofollow noreferrer\"">ping at start up</a></li> </ol>  <p>To solve (1) I  set WEBSITES_CONTAINER_START_TIME_LIMIT to 1800 (which is the max)</p>  <p>To solve (2) I set WEBSITES_PORT (in app setting) with a value of \""80\"" to expose that port. (As per documentation)</p>  <p>Any others things I should try ?</p>  <p>PS the default docker log file outputs the following:</p>  <pre><code>2018-10-15T14:32:59.946431939Z &gt; XXX@1.0.0 start /home/site/wwwroot 2018-10-15T14:32:59.946455839Z &gt; echo 'work!!' &amp;&amp; NODE_ENV=production &amp;&amp; node server.js 2018-10-15T14:32:59.946462839Z  2018-10-15T14:33:00.249554126Z work!! 2018-10-15T14:34:41.634101502Z HEYYYY 2018-10-15T14:35:38.838555689Z  DONE  Compiled successfully in 48099ms14:35:38 2018-10-15T14:35:38.838868291Z  2018-10-15T14:35:39.406086808Z Ready on Localhost:80!!! 2018-10-15T14:35:39.460029162Z Ready on Localhost:80 </code></pre>""",azure-web-app-service
41537011,"Azure Web Function: Create binding from http request to inputBlob path <h2>Desired Scenario</h2>  <p>From an Arduino:</p>  <ul> <li>take a photo and upload image as a blob in Azure storage container (works fine)</li> <li>call a Web Function using HTTP with blob name and other info (works fine) From the Web function</li> <li>read the HTTP request (works fine)</li> <li>read the blob using the information from the HTTP request (does not work)</li> <li>process the blob (not implemented yet)</li> <li>respond result to Arduino</li> </ul>  <h2>Problem</h2>  <p>I can't figure out how to make the binding from the path to the HTTP parameters.</p>  <h2>Web Function Config</h2>  <pre><code>{   \bindings\"": [     {       \""authLevel\"": \""function\""        \""name\"": \""request\""        \""type\"": \""httpTrigger\""        \""direction\"": \""in\""        \""methods\"": [         \""post\""       ]     }      {       \""name\"": \""$return\""        \""type\"": \""http\""        \""direction\"": \""out\""     }   ]    \""disabled\"": false } </code></pre>  <p>Error:</p>  <pre><code>Function ($HttpTriggerCSharp1) Error: Microsoft.Azure.WebJobs.Host: Error indexing method 'Functions.HttpTriggerCSharp1'. Microsoft.Azure.WebJobs.Host: No binding parameter exists for 'blobName'. </code></pre>  <p>ORIGINAL  NON-WORKING code (working code below):</p>  <pre><code>using System.Net;  public static async Task&lt;HttpResponseMessage&gt; Run(     HttpRequestMessage request       string blobName            // DOES NOT WORK but my best guess so far     string inputBlob       TraceWriter log) {  // parse query parameter    string msgType = request.GetQueryNameValuePairs()     .FirstOrDefault(q =&gt; string.Compare(q.Key  \""msgType\""  true) == 0)     .Value;  // Get request body dynamic data = await request.Content.ReadAsAsync&lt;object&gt;();  // Set name to query string or body data   msgType = msgType ?? data?.msgType;  string deviceId = data.deviceId; string blobName = data.BlobName; // DOES NOT COMPILE  log.Info(\""blobName=\"" + blobName); // DOES NOT WORK log.Info(\""msgType=\"" + msgType);  log.Info(\""data=\"" + data);   return msgType == null     ? request.CreateResponse(HttpStatusCode.BadRequest  \""HTTP parameter must contain msgType=&lt;type&gt; on the query string or in the request body\"")     : request.CreateResponse(HttpStatusCode.OK  \""Hello \"" + deviceId + \"" inputBlob:\"");// + inputBlob );  } </code></pre>  <p>HTTP request looks like this: </p>  <pre><code>  https://xxxxxxprocessimagea.azurewebsites.net/api/HttpTriggerCSharp1?code=CjsO/EzhtUBMgRosqxxxxxxxxxxxxxxxxxxxxxxx0tBBqaiXNewn5A==&amp;msgType=New image    \""deviceId\"": \""ArduinoD1_001\""     \""msgType\"": \""New image\""     \""MessageId\"": \""12345\""     \""UTC\"": \""2017-01-08T10:45:09\""     \""FullBlobName\"": \""/xxxxxxcontainer/ArduinoD1_001/test.jpg\""     \""BlobName\"": \""test.jpg\""     \""BlobSize\"": 9567     \""WiFiconnects\"": 1     \""ESPmemory\"": 7824     \""Counter\"": 1 </code></pre>  <p>(I know  msgType appears both in URL and in headers. I've tried different combinations - no effect).</p>  <p>If what I'm trying to do is impossible  alternative suggestions are also welcome. I just need a way through.</p>  <p>This code works thanks to Tom Sun's hint. The trick was to remove the binding to the storage blob in the JSON and instead just call the blob directly from the code.</p>  <pre><code>    #r \""Microsoft.WindowsAzure.Storage\""     using Microsoft.WindowsAzure.Storage; // Namespace for CloudStorageAccount     using Microsoft.WindowsAzure.Storage.Blob; // Namespace for Blob storage types     using Microsoft.WindowsAzure.Storage.Queue;     using Microsoft.Azure.WebJobs;     using Microsoft.Azure.WebJobs.Host;     using System.Net;     using System.IO;      public static async Task&lt;HttpResponseMessage&gt; Run(HttpRequestMessage request  string inputBlob  TraceWriter log)     {         string msgType = request.GetQueryNameValuePairs()             .FirstOrDefault(q =&gt; string.Compare(q.Key  \""msgType\""  true) == 0)             .Value;          dynamic data = await request.Content.ReadAsAsync&lt;object&gt;();         msgType = msgType ?? data?.msgType;          string deviceId = data.deviceId;         string blobName = data.BlobName;          string connectionString = AmbientConnectionStringProvider.Instance.GetConnectionString(ConnectionStringNames.Storage);         CloudStorageAccount storageAccount = CloudStorageAccount.Parse(connectionString);         CloudBlobClient blobClient = storageAccount.CreateCloudBlobClient();         CloudBlobContainer container = blobClient.GetContainerReference(\""nnriothubcontainer/\"" + deviceId);         CloudBlockBlob blob = container.GetBlockBlobReference(blobName);          MemoryStream imageData = new MemoryStream();         await blob.DownloadToStreamAsync(imageData);          return msgType == null             ? request.CreateResponse(HttpStatusCode.BadRequest  \""HTTP parameter must contain msgType=&lt;type&gt; on the query string or in the request body\"")             : request.CreateResponse(HttpStatusCode.OK  \""Hello \"" + deviceId + \"" inputBlob size:\"" + imageData.Length);// + inputBlob );     } </code></pre>""",azure-functions
56459862,Nuxt webapp deployment through azure pipelines <p>i'm already thankfull for anyone reading this. I've stumbled across some problems trying to deploy a Nuxt application in a correct way. For testing purposes i've created a clean installed Nuxt application so i'm sure nothing is wrong with my codebase. What my ultimate goal is is to push all my nuxt code to github which than gets picked up from a azure deployment pipeline and generates the needed build files and drops them to the webapp service and runs the needed start command. There's no documentation to be find about Azure which is really annoying for me. I'm not used to deploying stuff through a pipeline but need this to be working for this project.</p>  <p>Has anyone experience with Nuxt and deployments through Github -> Azure pipeline -> Build -> Web app running immediatly</p>  <p>What's i've tried already is pushing all the source code to a repository which get's picked up by azure pipeline. The only thing the pipeline does is paste the code in the wwwroot folder. Which is obviously not enough to make the application run automated.</p>  <p>What i expect is some insight from someone who is experienced with nuxt and azure deployments through github/bitbucket (doesn't really make a difference)</p>,azure-devops
55054767,Azure Java Web App with Application Insights showing 404 every 5 minutes <p>I have a Java Web App running in Azure Web App with Application Insights enabled and the javaagent configured in Application Settings.</p>  <p>In the insights  I see a 404 request to the web server (GET /) every 5 minutes  for which I do not have a handler (intentionally). The insights show no other dependencies involved and there is no Apache/Azure logs for the IP address of the culprit  but it seems it would be coming from the web app itself?</p>  <p>Is there a health check that is created automatically and how does one configure/disable it but keep the other insights like dependencies?</p>  <p>Java 8</p>  <p>Tomcat 8.5 (latest)</p>  <p>Spring Boot application</p>  <p>EDIT: I do not have the Spring Boot Actuator configured  for what its worth</p>,azure-web-app-service
45693707,"Azure add vm agent to Virtual machine created from special VHD <p>I have a VM from a special VHD file. This VM was not created through code (in which case it would already have the vm agent installed). </p>  <p>This special VHD has Windows 7  but obviously not the vm agent inside it. How can I automatically install the VM agent to this vm(I know you can manually do it by downloading the MSI file from <a href=\https://go.microsoft.com/fwlink/?LinkID=394789&amp;clcid=0x409\"" rel=\""nofollow noreferrer\"">https://go.microsoft.com/fwlink/?LinkID=394789&amp;clcid=0x409</a>  and installing the agent  but I'm looking for a programmatic solution  perhaps powershell)?</p>""",azure-virtual-machine
27230095,"TFS 2013 & VSO Problems with Build & Continuous Integration <p>I'm going to start with a little background regarding a recurrent problem we've been having with TFS.</p>  <p>A short while ago we upgraded our in-house server to utilise TFS 2013. Some of our projects were embedded with build definitions and continuous delivery prior to the upgrade and worked perfectly. However  after finalising the upgrade our build definitions failed due to what the system assumed were missing files (mainly for <code>AspNetCompileMerge.targets</code>)  but after investigating the issue we couldn't find the root cause.</p>  <p>To cut a long story short  we tried a number of ways to fix the problem  the only one which worked was by commenting out the below code within the affected application <code>CSPROJ</code> file.</p>  <pre><code>&lt;PropertyGroup&gt;   &lt;VisualStudioVersion Condition=\'$(VisualStudioVersion)' == ''\""&gt;12.0&lt;/VisualStudioVersion&gt;   &lt;VSToolsPath Condition=\""'$(VSToolsPath)' ==    ''\""&gt;$(MSBuildExtensionsPath32)\\Microsoft\\VisualStudio\\v$(VisualStudioVersion)&lt;/VSToolsPath&gt; &lt;/PropertyGroup&gt; </code></pre>  <p>However  problem number 2 cropped up a few days later when we merged some of the projects onto VSO without the build definitions. The cause of the issue was due to me commenting out the above lines of code. After un-commenting the above code in the <code>CSPROJ</code> file and checking in the project everything started working again... <strong>Until today!</strong></p>  <p>This morning I reimplemented the Build Defintions into the affected projects and tried publishing to VSO which is when I started getting the same error mentioned in paragraph 2. As I had already come across this issue before the fix was to comment the code out again.</p>  <p>The above information now leads me to the following questions</p>  <ul> <li>Did something change in TFS 2013 for Build Definitions to not work correctly when the above code is implemented?</li> <li>Why is it that the above code needs to be removed when utilising Build Definitions in TFS 2013?</li> <li>Is the above code important when Build Definitions are enabled or disabled? </li> </ul>  <p>Obviously it isn't a be all and end all if we can check in without the code  however I would like to understand why it breaks on check in.</p>  <p>I initially assumed this was a misconfiguration on our server  however this bug is also evident in the online version as well so this theory went out of the window. The affected applications were originally built in VS 2012 on the MVC 5 platform if this helps.</p>""",azure-devops
53404951,SSH Service Connection - Cannot parse privateKey: Unsupported key format <p>I'm trying to setup a release pipeline to copy files over to a linux server via ssh. However when I try to run the release I get the following error during the copy task:</p>  <pre><code>Failed to connect to remote machine. Verify the SSH service connection details. Error: Cannot parse privateKey: Unsupported key format. </code></pre>  <p>I've tried generating the key multiple times with <code>ssh-keygen -t rsa</code> and uploaded or copied the contents of the private key directly into the Private Key text area in the service connection. All to no avail.</p>  <p>It seems like I'm missing something simple as I can't find much mention of others having issue with this.</p>,azure-devops
51929888,"Azure Function Triggered by IoT Hub event - the messaging entity could not be found <p>When developing Azure Function thru Class Library approach (local development) I came across issue when using Even Hub compatible endpoint of IoTHub for triggering my function. This is set thru IoTHubTrigger attribute:</p>  <pre><code> [FunctionName(\IoTHubMessageProcessor\"")]  public static void Run([IoTHubTrigger(\""messages/events\""   Connection= \""IoTHubReceiveEventsConnectionEndpoint\"")]EventData message  ILogger log) </code></pre>  <p>When using provided connection string and messages/events endpoint I received error stating that \""messaging entity could not be found\"". </p>  <p><a href=\""https://i.stack.imgur.com/w4kFr.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/w4kFr.png\"" alt=\""enter image description here\""></a></p>""",azure-functions
44786141,How do I define retry count and internal for Azure function? <p>I have a blob triggered azure function. If there an exception thrown in the function  I would like to define the retry policy (count and interval).<br> Is there a way I can do that ?</p>,azure-functions
45359686,"Accessing Azure Storage through Unity <p>I am working on a project where I need to create a online HighScore Leaderboard(best score achieved) for every level in the game. Example: LevelName: A2  Score: 10.33  User: \SomePlayer\"".</p>  <p>So  since I have 130$/month due to my MSDN subscription  I have been researching about table storages and managed to setup one and I think it fills my needs.</p>  <p>My next step was to get an Azure function running to communicate with this table.</p>  <p>My question is  is it possible to access a Azure Function through Unity? Or am I overthinking this? Is there any simpler method?</p>""",azure-storage
39703955,"Path to file in VSTS <p>I'm looking to run a batch file programmatically in C#  as part of a test (being run in MS TEST)  which I have working on my local machine. The batch file I want to run is in the repository in a support folder that also contains source code. In VSTS the tests are run like this :</p>  <blockquote>   <p>\C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\Common7\\IDE\\CommonExtensions\\Microsoft\\TestWindow\\vstest.console.exe\"" \""C:\\International\\InternationalAppAutomation\\International.IntegrationTests.UI\\International.IntegrationTests.UI\\bin\\Debug\\International.IntegrationTests.UI.dll\"" \""C:\\International\\InternationalAppAutomation\\International.IntegrationTests.UI\\International.IntegrationTests.UI\\obj\\Debug\\International.IntegrationTests.UI.dll\""  /TestCaseFilter:\""TestCategory=Explore\"" /Settings:\""C:\\International\\InternationalAppAutomation\\International.IntegrationTests.UI\\International.IntegrationTests.UI\\QA.testsettings\"" /logger:trx /TestAdapterPath:\""C:\\International\\InternationalAppAutomation\""</p> </blockquote>  <p>and since I am using relative paths to run the batch file it fails because VSTS runs from a different location than my local machine does. What is the recommended solution to this problem?</p>  <p>Note - I cannot put this batch file in the test output folder because it is very large and we don't want to copy it for each new test run.</p>""",azure-devops
13989482,"Load balancing a Windows 2012 VM with internal clients <p>I have a setup of two VM (win 2012) setup into one cloud service. Each VM runs a simple TCP Service that accepts connections and keeps them connected for as long as the client wishes.</p>  <p>The problem is that I can't connect to the endpoint twice from the same client (different TcpClient objects of course).</p>  <p>This is possible when not running load balanced.</p>  <p>There is also an issue when the server tries to connect to itself (due to some lazy coding). First time  it's ok. Second connection it failes with a \server did not respond\"" message.</p>  <p>My question is simply: Is it possible to connect from the same host more than once? </p>""",azure-virtual-machine
52149595,Proper management of application settings when using VSTS and Azure <p>There are two different ways how to manage the application settings if you use VSTS and Azure. Please keep in mind this is only an example of tools used for continuous deployment.</p>  <p>You can override JSON files(Web config in older systems) in the CD pipeline in VSTS or you can override the settings in Azure ‘Application Setting’ section. I’m just thinking what setting should be managed where?  My idea is to manage settings which depend on 3rd party modules like databases (connection strings)  external services (e.g. Application Insights) in the Azure Application Settings section. This can give you the flexibility to change some setting very quickly if some changes appear in the 3rd party system.</p>  <p>The stuff which depends only on the app I would manage in the VSTS. What about feature toggles? Let’s say you have a stock Market and you are building a module which manages selling/buying new cryptocurrency called Blah. After all the tests you decide to make a release of the feature and take of the flag which is responsible to enable/disable the new feature. Where would you take off the flag- in App Settings in Azure or in the CD pipeline in the VSTS?</p>  <p>Maybe there are more other types of settings which I didn’t mention  and which are problematic to manage? The main reason I am asking this question is the settings management becomes problematic when the application growths  it is very easy to cause a mess in the config files. Please tell me what is the proper way of management of the app settings in the Web Application?</p>,azure-devops
43651853,"Azure Pre-compiled Function failed with unexpected error: Could not load file or assembly 'Common.Logging  Version=3.0.0.0...' <p>I have the following NuGet dependencies in my project (Azure Pre-compiled Function):</p>  <pre><code>&lt;package id=\Common.Logging\"" version=\""3.3.1\"" targetFramework=\""net461\""/&gt; &lt;package id=\""Common.Logging.Core\"" version=\""3.3.1\"" targetFramework=\""net461\""/&gt; </code></pre>  <p>When the function code is executed (using the VS tooling)  I receive the following error :</p>  <blockquote>   <p>Loader failed with unexpected error: Could not load file or assembly   'Common.Logging  Version=3.0.0.0  Culture=neutral    PublicKeyToken=af08829b84f0328e' or one of its dependencies. The   system cannot find the file specified.</p> </blockquote>  <p>The <code>Common.Logging.dll</code> file exists inside the <code>bin</code> folder. What can be the root cause ?</p>  <p>Thanks for your help! Regards</p>""",azure-functions
6898007,Azure Queue Storage vs WCF Services <p>Could anyone please whether it's a good idea to expose messages via Azure Queue storage or via WCF Services?</p>  <p>if we expose messages via Azure it will be resful service and it's more reliable. Any thoughts?</p>  <p>Regards</p>,azure-storage
16070533,"How to use the blob storage service from ios? <p>In my application I need to use the Windows Azure services to store the data for that I am using this:<a href=\http://www.windowsazure.com/en-us/develop/mobile/tutorials/get-started-with-data-ios/\"" rel=\""noreferrer\"">http://www.windowsazure.com/en-us/develop/mobile/tutorials/get-started-with-data-ios/</a> sdk for Windows azure integration  from my app. Now I need to upload the images to Azure and for that I was using the same sdk...But later I found that the right place in Windows Azure to upload the larger images is to Blob Storage Client.</p>  <p>In .Net they have the different library and I found this link <a href=\""http://www.windowsazure.com/en-us/develop/net/how-to-guides/blob-storage/\"" rel=\""noreferrer\"">http://www.windowsazure.com/en-us/develop/net/how-to-guides/blob-storage/</a> for uploading the images to blob storage.</p>  <p>But how can I do that with Objective C?</p>  <p>After some research I found this link <a href=\""http://www.deviantpoint.com/post/2012/02/18/Using-Azure-Storage-Services-from-an-iPhone-App-Part-1-Table-and-Blob-setup-Azure-iOS-toolkit-and-Model-Classes.aspx\"" rel=\""noreferrer\"">http://www.deviantpoint.com/post/2012/02/18/Using-Azure-Storage-Services-from-an-iPhone-App-Part-1-Table-and-Blob-setup-Azure-iOS-toolkit-and-Model-Classes.aspx</a> but its not clear about How to upload an image and getting the image url in response?</p>""",azure-storage
55828590,Azure api for fetching Virtual Machine not returning object of VHD(Virtual Hard Disk) <p>I am trying to call the azure api for fetching the details of a particular VM. I am getting all other details in the response but it is not returning the VHD object. Can anyone please tell me why is this happening and how can this be fixed?</p>  <pre><code>https://management.azure.com/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.Compute/virtualMachines/{vmName}?api-version=2018-06-01 </code></pre>  <p>I am trying to call the api like this but it is not returning VHD object.I am getting everything else in api response but VHD object is not being returned.</p>,azure-virtual-machine
39060096,"NPM install not working unless node_modules folder is first deleted? <p>I have a visual studio team services build definition with a first step of \npm install\"". This definition deploys to an azure web app.</p>  <p>NPM completes without error  however when visiting the web app  the error \""Cannot find module 'express'\"" is thrown. When running \""npm install\"" manually from the \""wwwroot\"" folder  where the web app files and package.json are located the command completes successfully again  but the error persists.</p>  <p><em>However</em>  when i delete the \""node_modules\"" from within the \""wwwroot\"" folder  and run \""npm install\"" again  the error is gone and the web app functions as intended!</p>  <p>How can I fix my build definition so that these manual steps are not required on every deployment?</p>  <p>The relevant excerpt from my package.json is below:</p>  <pre><code> \""dependencies\"": {     \""express\"": \""^4.13.4\""      \""pug\"": \""^2.0.0-alpha7\""      \""bluebird\"": \""^3.4.1\""  }  </code></pre>  <p>The npm log is available below:</p>  <pre><code>    2016-08-21T01:19:28.9476070Z ##[debug]check path : C:\\LR\\MMS\\Services\\Mms\\TaskAgentProvisioner\\Tools\\agents\\1.104.1\\tasks\\Npm\\0.2.15\\task.json 2016-08-21T01:19:28.9476070Z ##[debug]set resource file to: C:\\LR\\MMS\\Services\\Mms\\TaskAgentProvisioner\\Tools\\agents\\1.104.1\\tasks\\Npm\\0.2.15\\task.json 2016-08-21T01:19:28.9486073Z ##[debug]system.culture=en-US 2016-08-21T01:19:28.9646119Z ##[debug]check path : C:\\Program Files\\nodejs\\npm.cmd 2016-08-21T01:19:28.9656074Z ##[debug]npm=C:\\Program Files\\nodejs\\npm.cmd 2016-08-21T01:19:28.9666075Z ##[debug]cwd=C:\\a\\1\\s 2016-08-21T01:19:28.9686074Z ##[debug]path exists: C:\\a\\1\\s 2016-08-21T01:19:28.9696068Z ##[debug]command=install 2016-08-21T01:19:28.9696068Z ##[debug]C:\\Program Files\\nodejs\\npm.cmd arg: install 2016-08-21T01:19:28.9706071Z ##[debug]arguments=null 2016-08-21T01:19:28.9706071Z ##[debug]exec tool: C:\\Program Files\\nodejs\\npm.cmd 2016-08-21T01:19:28.9716073Z ##[debug]Arguments: 2016-08-21T01:19:28.9716073Z ##[debug]   install 2016-08-21T01:19:28.9726071Z [command]C:\\Program Files\\nodejs\\npm.cmd install 2016-08-21T01:19:43.5330503Z smart-iot@1.0.0 C:\\a\\1\\s 2016-08-21T01:19:43.5330503Z +-- azure-iot-device-amqp@1.0.10 2016-08-21T01:19:43.5340519Z | +-- azure-iot-amqp-base@1.0.10 2016-08-21T01:19:43.5340519Z | | +-- amqp10@3.2.2 2016-08-21T01:19:43.5340519Z | | | +-- node-amqp-encoder@0.0.2  2016-08-21T01:19:43.5350499Z | | | +-- node-int64@0.4.0  2016-08-21T01:19:43.5350499Z | | | `-- stately.js@1.3.0  2016-08-21T01:19:43.5360508Z | | `-- amqp10-transport-ws@0.0.3 2016-08-21T01:19:43.5360508Z | |   `-- nodejs-websocket@1.6.0  2016-08-21T01:19:43.5370502Z | `-- azure-iot-device@1.0.10 2016-08-21T01:19:43.5370502Z |   `-- azure-storage@1.1.0 2016-08-21T01:19:43.5370502Z |     `-- readable-stream@2.0.6 2016-08-21T01:19:43.5380497Z |       +-- process-nextick-args@1.0.7  2016-08-21T01:19:43.5380497Z |       `-- util-deprecate@1.0.2  2016-08-21T01:19:43.5390498Z +-- express@4.14.0 2016-08-21T01:19:43.5390498Z | +-- accepts@1.3.3 2016-08-21T01:19:43.5390498Z | | `-- mime-types@2.1.11 2016-08-21T01:19:43.5400508Z | |   `-- mime-db@1.23.0  2016-08-21T01:19:43.5400508Z | +-- array-flatten@1.1.1  2016-08-21T01:19:43.5420690Z | +-- content-disposition@0.5.1  2016-08-21T01:19:43.5420690Z | +-- cookie-signature@1.0.6  2016-08-21T01:19:43.5430497Z | +-- debug@2.2.0  2016-08-21T01:19:43.5430497Z | | `-- ms@0.7.1  2016-08-21T01:19:43.5440674Z | +-- depd@1.1.0  2016-08-21T01:19:43.5440674Z | +-- escape-html@1.0.3  2016-08-21T01:19:43.5450502Z | +-- etag@1.7.0  2016-08-21T01:19:43.5450502Z | +-- finalhandler@0.5.0 2016-08-21T01:19:43.5460530Z | | `-- unpipe@1.0.0  2016-08-21T01:19:43.5460530Z | +-- fresh@0.3.0  2016-08-21T01:19:43.5470497Z | +-- merge-descriptors@1.0.1  2016-08-21T01:19:43.5470497Z | +-- methods@1.1.2  2016-08-21T01:19:43.5480496Z | +-- on-finished@2.3.0  2016-08-21T01:19:43.5480496Z | | `-- ee-first@1.1.1  2016-08-21T01:19:43.5490499Z | +-- parseurl@1.3.1  2016-08-21T01:19:43.5490499Z | +-- path-to-regexp@0.1.7  2016-08-21T01:19:43.5500513Z | +-- proxy-addr@1.1.2 2016-08-21T01:19:43.5500513Z | | `-- forwarded@0.1.0  2016-08-21T01:19:43.5500513Z | +-- send@0.14.1 2016-08-21T01:19:43.5510491Z | | +-- destroy@1.0.4  2016-08-21T01:19:43.5510491Z | | `-- mime@1.3.4  2016-08-21T01:19:43.5520499Z | +-- type-is@1.6.13 2016-08-21T01:19:43.5520499Z | | `-- media-typer@0.3.0  2016-08-21T01:19:43.5520499Z | `-- utils-merge@1.0.0  2016-08-21T01:19:43.5530492Z `-- pug@2.0.0-beta4 2016-08-21T01:19:43.5530492Z   +-- pug-code-gen@0.0.7  2016-08-21T01:19:43.5540495Z   | +-- doctypes@1.1.0  2016-08-21T01:19:43.5540495Z   | +-- js-stringify@1.0.2  2016-08-21T01:19:43.5540495Z   | +-- pug-attrs@2.0.1  2016-08-21T01:19:43.5550503Z   | `-- void-elements@2.0.1  2016-08-21T01:19:43.5550503Z   +-- pug-filters@1.2.3 2016-08-21T01:19:43.5550503Z   | +-- clean-css@3.4.19 2016-08-21T01:19:43.5560494Z   | | `-- source-map@0.4.4  2016-08-21T01:19:43.5560494Z   | |   `-- amdefine@1.0.0  2016-08-21T01:19:43.5570499Z   | +-- jstransformer@1.0.0 2016-08-21T01:19:43.5570499Z   | | +-- is-promise@2.1.0  2016-08-21T01:19:43.5570499Z   | | `-- promise@7.1.1  2016-08-21T01:19:43.5580491Z   | +-- pug-walk@0.0.3  2016-08-21T01:19:43.5580491Z   | +-- resolve@1.1.7  2016-08-21T01:19:43.5590498Z   | `-- uglify-js@2.7.0 2016-08-21T01:19:43.5590498Z   |   +-- source-map@0.5.6  2016-08-21T01:19:43.5590498Z   |   +-- uglify-to-browserify@1.0.2  2016-08-21T01:19:43.5600495Z   |   `-- yargs@3.10.0  2016-08-21T01:19:43.5600495Z   |     +-- camelcase@1.2.1  2016-08-21T01:19:43.5600495Z   |     +-- cliui@2.1.0  2016-08-21T01:19:43.5610497Z   |     | +-- center-align@0.1.3  2016-08-21T01:19:43.5610497Z   |     | | +-- align-text@0.1.4  2016-08-21T01:19:43.5620497Z   |     | | | +-- kind-of@3.0.4  2016-08-21T01:19:43.5620497Z   |     | | | | `-- is-buffer@1.1.4  2016-08-21T01:19:43.5620497Z   |     | | | +-- longest@1.0.1  2016-08-21T01:19:43.5630568Z   |     | | | `-- repeat-string@1.5.4  2016-08-21T01:19:43.5630568Z   |     | | `-- lazy-cache@1.0.4  2016-08-21T01:19:43.5640500Z   |     | +-- right-align@0.1.3  2016-08-21T01:19:43.5640500Z   |     | `-- wordwrap@0.0.2  2016-08-21T01:19:43.5640500Z   |     +-- decamelize@1.2.0  2016-08-21T01:19:43.5650495Z   |     `-- window-size@0.1.0  2016-08-21T01:19:43.5650495Z   +-- pug-lexer@2.0.2 2016-08-21T01:19:43.5660502Z   | +-- character-parser@2.2.0  2016-08-21T01:19:43.5660502Z   | | `-- is-regex@1.0.3  2016-08-21T01:19:43.5660502Z   | `-- is-expression@2.1.0 2016-08-21T01:19:43.5670500Z   |   `-- object-assign@4.1.0  2016-08-21T01:19:43.5670500Z   +-- pug-parser@2.0.1 2016-08-21T01:19:43.5670500Z   | `-- token-stream@0.0.1  2016-08-21T01:19:43.5680491Z   `-- pug-strip-comments@0.0.1  2016-08-21T01:19:43.5680491Z     `-- pug-error@0.0.0  2016-08-21T01:19:43.5820489Z ##[debug]rc:0 2016-08-21T01:19:43.5820489Z ##[debug]success:true 2016-08-21T01:19:43.5830501Z ##[debug]task result: Succeeded 2016-08-21T01:19:43.6100505Z Finishing task: Npm </code></pre>  <p>As an example  the \""express\"" module folder is missing its \""index.js\""  \""LICENCE\"" and \""package.json\"" files for an unknown reason.</p>""",azure-devops
56882273,"Persisting Batch Task Output to Storage Account <p>I was using <a href=\https://docs.microsoft.com/en-us/azure/batch/batch-task-output-files\"" rel=\""nofollow noreferrer\"">Batch service API to persist task data to Azure Storage</a> but I updated the code to use Azure AD Authentication instead of using Storage and Batch account credentials. And the Batch service API does not work anymore as it requires <em>Account Key credentials</em> to generate the <a href=\""https://docs.microsoft.com/en-us/azure/batch/batch-task-output-files#get-a-shared-access-signature-for-the-container\"" rel=\""nofollow noreferrer\"">shared access signature for the container</a> where I wish to store the output.</p>  <p>The only other way of persisting batch task output I found was to use the <a href=\""https://docs.microsoft.com/en-us/azure/batch/batch-task-output-file-conventions\"" rel=\""nofollow noreferrer\"">Batch File Conventions library for .NET</a> but that requires me to make modifications to the task code  which is not an option.</p>  <p>Is there any way I can save the task output to Azure Storage without using a SAS Uri?</p>  <p>Additional information:</p>  <ol> <li>The Storage Account is linked to the Batch Account.</li> <li>The Service Principal has Storage Blob Data Owner (this is temporary  I plan on using Storage Blob Data Contributor)</li> </ol>""",azure-storage
45709036,"Azure blob upload rename if blob name exist <p>In Azure blob upload  a file is overwritten if you upload a new file with the same file name (in the same container).</p>  <p>I would like to rename the new file before saving it  to avoid overwriting any files - Is this possible?</p>  <p>Scenario:</p>  <ol> <li>Upload file \Image.jpg\"" to container \""mycontainer\""</li> <li>Upload file \""Image.jpg\"" to container \""mycontainer\"" (with different content)</li> <li>Rename second \""Image.png\"" to \""Image_{guid}.jpg\"" before saving it to \""mycontainer\"".</li> </ol>""",azure-storage
39535806,Visual Studio 2013 project - Downloading package 'NuGet.Build' failed <p>I have a project under source control (TFS) and it physical location is:</p>  <pre><code>C:\repositry\devRep\application\DevEnv\Test\Project1 </code></pre>  <p>I have moved solution file <code>(.sln)</code> and its project to one level up using TFS <code>(Source Control Explorer Move option)</code></p>  <pre><code>C:\repositry\devRep\application\DevEnv\Project1 </code></pre>  <p>However  I did not move <code>.nuget folder</code> one level up and it is still at original location</p>  <pre><code>C:\repositry\devRep\application\DevEnv\Test\Project1 </code></pre>  <p><strong>Problem:</strong></p>  <p>If i build i get the following error</p>  <blockquote>   <p>This project references NuGet package(s) that are missing on this   computer. Enable NuGet Package Restore to download them.</p> </blockquote>  <p>Also  If i try to open <code>package.config under .NuGet folder</code> of my solution  i get this error </p>  <blockquote>   <p>Downloading package 'NuGet.Build' failed.</p> </blockquote>  <p>I am sure it is becuase i did not move it up along with solution and projects BUT i am not sure how do i move it up?</p>  <p>? Same approach as i did for projects ? just delete this folder and VS will auto create it?</p>  <p>Any suggestion?</p>,azure-devops
46153008,"Azure Functions with node.js  Azure Service Bus and Apps Insight - Error on setup of AppsInsights <p>When I use azure module (to query Service Bus) and Application Insights module  I get the following error upon initialization of AppsInsight:</p>  <p><code>System.Exception : Error: Zone already loaded. at new Error (native) at Error.AppInsightsAsyncCorrelatedErrorWrapper</code></p>  <p>The code to replicate it is very simple:</p>  <pre><code>var azure = require('azure'); var serviceBusService = azure.createServiceBusService(&lt;Service Bus Endpoint&gt;);  const appInsights = require(\applicationinsights\""); appInsights.setup(&lt;Apps Insight key&gt;).start(); </code></pre>  <p>The error is thrown on the last line and I assume is a result of dependencies overlapping between azure and applicationinsights module.</p>  <p>Any suggestions how to overcome this are appreciated! </p>""",azure-functions
56121313,"Azure Function Username and Password <p>I noticed  after creating a publish profile for an Azure Function  that the profile includes a username and password  neither of which I supplied.  I don't even know what the password is.  The username is merely the name of the Function App  prefixed with a dollar sign.  Where did these come from?  Are they something I need to know more about?</p>  <p>I'm partly curious  but partly wondering if this has anything to do with a separate issue where my Function App runs locally just fine  but doesn't run once published to Azure.</p>  <p><a href=\https://i.stack.imgur.com/KNISD.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/KNISD.png\"" alt=\""enter image description here\""></a></p>""",azure-functions
38006649,"Configuring notification tag for Azure Function <p>I'm using an Azure function to pick up messages from an event hub and send out notifications via the Azure notification hub. Works great! Now I wanted to see whether I could add tags to those messages in order to allow user targeting via those tags. </p>  <p>The output for the notification hub has a \tag expression\"" parameter which you can configure. But this seems to be a static text. I need to dynamically set these tags based on the message received from the event hub instead. I'm not sure whether you can somehow put dynamic content in there? </p>  <p>I also found that the constructor of the GcmNotification object that I'm using has an overload which allows a tag string to be used. But when I try that I get a warning on compile time stating this is deprecated and when the function fires it shows an error because the Tag property should be empty. </p>  <p>So I'm not clear on a) whether this is at all possible and b) how to do it when it is. Any ideas? </p>  <p><strong>Update</strong>: as suggested I tried creating a POCO object to map to my input string. The string is as follows: </p>  <p><code>[{\""deviceid\"":\""repsaj-neptune-win10pi\"" \""readingtype\"":\""temperature1\"" \""reading\"":22.031614503139451 \""threshold\"":23.0 \""time\"":\""2016-06-22T09:38:54.1900000Z\""}]</code></p>  <p>The POCO object:</p>  <pre><code>public class RuleMessage {     public string deviceid;     public string readingtype;     public object reading;     public double threshold;     public DateTime time; } </code></pre>  <p>For the function I now tried both <code>RuleMessage[]</code> and <code>List&lt;RuleMessage&gt;</code> as parameter types  but the function complains it cannot convert the input: </p>  <blockquote>   <p>2016-06-24T18:25:16.830 Exception while executing function: Functions.submerged-function-ruleout. Microsoft.Azure.WebJobs.Host: Exception binding parameter 'inputMessage'. Microsoft.Azure.WebJobs.Host: Binding parameters to complex objects (such as 'RuleMessage') uses Json.NET serialization.    1. Bind the parameter type as 'string' instead of 'RuleMessage' to get the raw values and avoid JSON deserialization  or   2. Change the queue payload to be valid json. The JSON parser failed: Cannot deserialize the current JSON array (e.g. [1 2 3]) into type 'Submission#0+RuleMessage' because the type requires a JSON object (e.g. {\""name\"":\""value\""}) to deserialize correctly.   To fix this error either change the JSON to a JSON object (e.g. {\""name\"":\""value\""}) or change the deserialized type to an array or a type that implements a collection interface (e.g. ICollection  IList) like List that can be deserialized from a JSON array. JsonArrayAttribute can also be added to the type to force it to deserialize from a JSON array.</p> </blockquote>  <p>Function code:</p>  <pre><code>using System; using Newtonsoft.Json; using Newtonsoft.Json.Linq; using Microsoft.Azure.NotificationHubs;  public static void Run(List&lt;RuleMessage&gt; inputEventMessage  string inputBlob  out Notification notification  out string outputBlob  TraceWriter log) {     if (inputEventMessage == null || inputEventMessage.Count != 1)     {         log.Info($\""The inputEventMessage array was null or didn't contain exactly one item.\"");          notification = null;         outputBlob = inputBlob;          return;     }      log.Info($\""C# Event Hub trigger function processed a message: {inputEventMessage[0]}\"");       if (String.IsNullOrEmpty(inputBlob))         inputBlob = DateTime.MinValue.ToString();      DateTime lastEvent = DateTime.Parse(inputBlob);     TimeSpan duration = DateTime.Now - lastEvent;      if (duration.TotalMinutes &gt;= 0) {         notification = GetGcmMessage(inputMessage.First());          log.Info($\""Sending notification message: {notification.Body}\"");         outputBlob = DateTime.Now.ToString();     }      else {         log.Info($\""Not sending notification message because of timer ({(int)duration.TotalMinutes} minutes ago).\"");          notification = null;         outputBlob = inputBlob;     } }  private static Notification GetGcmMessage(RuleMessage input) {     string message;      if (input.readingtype == \""leakage\"")         message = String.Format(\""[FUNCTION GCM] Leakage detected! Sensor {0} has detected a possible leak.\""  input.reading);     else         message = String.Format(\""[FUNCTION GCM] Sensor {0} is reading {1:0.0}  threshold is {2:0.0}.\""  input.readingtype  input.reading  input.threshold);      message = \""{\\\""data\\\"":{\\\""message\\\"":\\\""\""+message+\""\\\""}}\"";      return new GcmNotification(message); }  public class RuleMessage {     public string deviceid;     public string readingtype;     public object reading;     public double threshold;     public DateTime time; } </code></pre>  <p><strong>Update 28-6-2016</strong>: I've not managed to get it working by switching ASA output to line seperated to that it doesn't generate a JSON array any more. This is a temp. fix because the Function binding now fails as soon as there is more than one line in the output (which can happen). </p>  <p>Anyways  I now proceeded to set the tagExpression  as per instruction I changed it to: </p>  <pre><code>{   \""type\"": \""notificationHub\""    \""name\"": \""notification\""    \""hubName\"": \""repsaj-neptune-notifications\""    \""connection\"": \""repsaj-neptune-notifications_NOTIFICATIONHUB\""    \""direction\"": \""out\""    \""tagExpression\"": \""deviceId:{deviceid}\"" } </code></pre>  <p>Where <code>{deviceid}</code> equals the deviceid property on my RuleMessage POCO. Unfortunately this doesn't work  when I call the function it outputs: </p>  <blockquote>   <p>Exception while executing function: Functions.submerged-function-ruleout. Microsoft.Azure.WebJobs.Host: Exception binding parameter 'notification'. Microsoft.Azure.WebJobs.Host: No value for named parameter 'deviceid'.</p> </blockquote>  <p>Which is not true  I know for sure the property has been set as I've logged it to the ouput window. I also tried something like {inputEventMessage.deviceid}  but that doesn't work either (as I didn't get how the runtime would map {deviceid} to the correct input object when there's more than one. </p>""",azure-functions
47578888,How to store image in Blob service with Azure function? <p>Let say I have very simple application to store image something like this</p>  <pre><code>const express = require('express') const bodyParser = require('body-parser') const multipart = require('parse-multipart') const fs = require('fs') const app = express()  app.post('/images'  bodyParser.raw({ type: 'multipart/form-data' })  (req  res) =&gt; {   const parts = multipart.Parse(req.body  multipart.getBoundary(req.headers['content-type']));   fs.writeFileSync(`./images/${parts[0].filename}`  parts[0].data)   res.status(200).send() }) </code></pre>  <p>Now I would like do same with Azure function to store image in Blob service. I have something like this</p>  <pre><code>const multipart = require('parse-multipart')  module.exports = function (context  req) {   const parts = multipart.Parse(req.body  multipart.getBoundary(req.headers['content-type']))   context.bindings.blob = parts[0].data   context.res = {     status: 200   }   context.done() } </code></pre>  <p>blob binding is configured function.json. The image is stored and I can download it from portal  but the content is not correct. </p>  <p>What I am missing here?</p>,azure-functions
41571095,Azure App Service with native Tomcat - how to modify tomcat-users.xml? <p>I have an App Service running native  non-marketplace Tomcat.  I want to be able to restart specific webapps  instead of restarting the whole Tomcat/app service.</p>  <p>GUI Tomcat Manager is not available  so I figure I could do it via command line.  To get access to it  I need to modify tomcat-users.xml  but it's in the system folders  and is not editable.   </p>  <p>How can I specify my tomcat users?  There is already a way to use web.config in wwwroot folder to override JVM options and to change other Tomcat settings  so maybe there is a way to specify tomcat users as well?</p>,azure-web-app-service
56734450,"Connect to web server on Azure VM from Azure Automation runbook <p>I have a VM running on Azure running a web server  only internal connections are allowed and I'm using a private IP. Can connect to it from my local machine as intended. </p>  <p>Now I'm trying to connect to that web server from an Azure Automation Powershell runbook. But the server only returns a \Unable to connect\"" error message. </p>  <p>Everything is in the same resource group and I do not want to run the runbook on the VM itself  it should run as a serverless script. How do I connect/refer to the private IP? Do I need to setup some specific network rules as well for the VM in order to allow connections from Azure Automation?</p>""",azure-virtual-machine
51278772,"Visual Studio Publish profile settings for Single Page App on Azure <p>I want to publish my single page app to Azure. I have created the App Service  App Service Plan and downloaded the publish profile settings on my local. Now I can use FTP to publish it to Azure. But I am wondering if there is a way I can configure this in the my Visual Studio similar to what we do when publishing a .Net application (MVC or Web API) as shown below in the snapshot.</p>  <p><a href=\https://i.stack.imgur.com/AQd9h.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/AQd9h.png\"" alt=\""enter image description here\""></a></p>  <p>My single page application is not part of the solution. This is how the structure of my projects look like.</p>  <p><a href=\""https://i.stack.imgur.com/x6EGo.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/x6EGo.png\"" alt=\""enter image description here\""></a></p>  <p>It has one .Net Core Web API project and one Single Page App created in Vue.js. I can publish the Web API project from the Visual Studio but not the SPA. Any help with this please?</p>""",azure-web-app-service
52453148,"Azure ARM API to find Available VM size/sku for a given subscription and region <p>How to get the list of VM size/sku available for a given subscription and region using ARM api?</p>  <p>I found online one ARM API - <a href=\https://docs.microsoft.com/en-us/rest/api/compute/virtualmachinesizes/list\"" rel=\""nofollow noreferrer\"">https://docs.microsoft.com/en-us/rest/api/compute/virtualmachinesizes/list</a></p>  <p>But it is not giving correct data as per requirement.</p>  <p>You can check the attached image. This api return list of both VM sizes (1) available ones (with black color in image) (2) not available ones (grayed out in image) and no field to distinguish them.</p>  <p>where as I need a list the only available VMs Or at least some flag in record which shows whether sku size is enabled or not.</p>  <p><a href=\""https://i.stack.imgur.com/on15c.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/on15c.png\"" alt=\""enter image description here\""></a></p>""",azure-virtual-machine
46141697,Azure Function to blob storage  specify filename and metadata <p>This question is fairly straightforward. I haven't figured if it's possible to specify the filename programmatically and adding metadata to the output blob object as described in a binding in an Azure Function built on NodeJS. Is it possible and how would one do this?</p>,azure-functions
49033224,Azure functions testing and deployment from Jenkins <p>I am looking for some information on Azure functions. I have developed few functions in NodeJS and would like to use Jenkins to do some testing on it and then deploy it to Azure. Are there any references/docs for this?</p>  <p>Specifically  I would like to know if there are any examples of testing done on Azure functions using Jenkins.</p>,azure-functions
56283613,Azure Webapp (using Nodejs) logging to Blob storage <p>I'm using Azure Webapp (Windows) to host a nodejs app. Inside my app  I'm using bunyan as my logger library. </p>  <p>I have configured App logging to Azure Storage Blog through the web portal. I selected the storage accounts  blob container  etc. </p>  <p>If I go to Log Stream  I do see the logs from my app in the portal. However  those logs are not being stored in the selected Blob container. There's a folder (inside the container) that was created by the app service and it does log things like when a new version of my app is deployed using a CSV file but that's all. </p>  <p>I've read my posts indicating that Nodejs is not supported for this environment (logging to blob storage). Is this true? Am I missing something?</p>,azure-web-app-service
50654360,"How to access environment variables in custom script extension script on Azure <p>I have created a RHEL Linux VM and installed Oracle JDK in it.</p>  <p>Post creation of VM  I am executing script using Custom Script extension in VM. Below is my script.</p>  <p><strong>Myscript.sh</strong></p>  <pre><code>echo \$$ $JAVA_HOME $$\"" &gt;&gt; output.log echo `env` &gt;&gt; output.log </code></pre>  <p><strong>output.log</strong></p>  <pre><code>$$ $$ PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin PWD=/var/lib/waagent/custom-script/download/1 LANG=en_US.UTF-8 SHLVL=4 _=/usr/bin/env </code></pre>  <p>When I ran the above script  I don't see JAVA_HOME is set. But I see JAVA_HOME value when I logged into the machine.</p>  <p><strong>Update:-</strong></p>  <p>During installation of Oracle JDK  I set JAVA_HOME in /etc/profile.</p>  <p><strong>script1.sh</strong></p>  <pre><code>javaHomeValue=$(cat /etc/profile | grep JAVA_HOME | awk -F= '{print $2}') </code></pre>  <p>echo \"" -- $javaHomeValue -- \"" >> output.log</p>  <p><strong>output.log</strong></p>  <pre><code>-- /usr/java/jdk1.8.0_172-amd64 -- </code></pre>  <p>I am able to get JAVA_HOME using the above script1.sh</p>  <p>Is there any reason  Why JAVA_HOME is not set in environment variables during execution of Custom script?</p>""",azure-virtual-machine
17661248,Azure VM pricing - Is it better to have 80 single core machines or 10 8-core machines? <p>I am limited by a piece of software that utilizes a single core per instance of the program run. It will run off an SQL server work queue and deposit results to the server. So the more instances I have running the faster the overall project is done. I have played with Azure VMs a bit and can speed up the process in two ways.</p>  <p>1) I can run the app on a single core VM  clone that VM and run it on as many as I feel necessary to speed up the job sufficiently.</p>  <p>OR</p>  <p>2) I can run the app 8 times on an 8-core VM  ...again clone that VM and run it on as many as I feel necessary to speed up the job sufficiently.</p>  <p>I have noticed in testing that the speed-up is roughly the same for adding 8 single core VMs and 1 8-core VM. Assuming this is true  would it better better price-wise to have single core machines? </p>  <p>The pricing is a bit of a mystery  whether it is real cpu usage time  or what. It is a bit easier using the 1 8-core approach as spinning up machines and taking them down takes time  but I guess that could be automated.</p>  <p>It does seem from some pricing pages that the multiple single core VM approach would cost less?</p>  <p>Side question: so could I do like some power shell scripts to just keep adding VMs of a certain image and running the app  and then start shutting them down once I get close to finishing? After generating the VMs would there be some way to kick off the app without having to remote in to each one and running it?</p>,azure-virtual-machine
53832647,"Azure DevOps Build Pipeline - Unable to deploy .NET Core app <p>I'm trying to create a CI/CT pipeline for my project. All the steps got completed successfully including <code>Publish Build Artifacts</code> but unfortunately I get an error during azure webapp deployment</p>  <p>Build Pipeline <a href=\https://i.stack.imgur.com/dlVv3.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/dlVv3.png\"" alt=\""enter image description here\""></a></p>  <h1>Azure publish Step</h1>  <p><a href=\""https://i.stack.imgur.com/TRwnn.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/TRwnn.png\"" alt=\""enter image description here\""></a></p>  <h1>Publish Artifact: Drop</h1>  <p><a href=\""https://i.stack.imgur.com/6YuDK.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/6YuDK.png\"" alt=\""enter image description here\""></a></p>  <h1>Azure App Service Deploy: XXXX Server</h1>  <p><a href=\""https://i.stack.imgur.com/tUll2.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/tUll2.png\"" alt=\""enter image description here\""></a></p>  <p>I get following error in this step</p>  <blockquote>   <p>Error: No package found with specified pattern: D:\\a\\1\\a\\Drop\\xxx.xx.UI.API.zip</p> </blockquote>  <p>Any idea what I am doing wrong?</p>""",azure-devops
42245682,"Why use Service Bus when deploying EPiServer CMS to Azure? <p>My task is to deploy an EpiServer 7 CMS site that has been running on-prem VM to Azure web app  two instances.</p>  <p>In the guide I found at link is telling me to set up Service Bus. Does anyone know why I need the SB? <a href=\http://world.episerver.com/documentation/developer-guides/CMS/Deployment/deployment-scenarios/Deploying-to-Azure-webapps/\"" rel=\""nofollow noreferrer\"">http://world.episerver.com/documentation/developer-guides/CMS/Deployment/deployment-scenarios/Deploying-to-Azure-webapps/</a></p>  <p><strong>Additional comments:</strong></p>  <p>I have a problem in following scenario: I´m logging in to EPi on instance1 on my browser  and then I turn an image upside down. This does not affect instance 2 that I have open in another browser  even after reloading the page. Is this something that the Service Bus is there to handle? </p>  <p>I will create another question thread for this  but: Is there any other way except blob storage to store my images so that updates on instance1 will affect instance2?</p>""",azure-web-app-service
56298708,Unable to create add migrations with EntityFrameworkCore.Tools and AzureFunctions <p>I have been trying for hours to run migrations on Azure Functions with EntityFramework.Core. It throws an error:</p>  <pre><code>PM&gt; add-migration newmigration Error:   An assembly specified in the application dependencies manifest (Test.API.deps.json) was not found:     package: 'Test.API'  version: '1.0.0'     path: 'Test.API.dll' </code></pre>  <p>To try to solve the problem  I updated the .net core version to 2.2.300(currently the latest) from 2.2.104.Updated the Azure functions SDK and EntityFramework to the latest too. Tried with different sql servers but still no progress. Deleted the bin and obj folders - no luck. And even delete the packet manager cache...</p>  <hr>  <p>UPDATE: The problem is than in the folder <em>bin/debug/netcoreapp2.2</em> I have another folder <em>bin</em> where the <strong>Test.API.dll</strong> is but the <strong>manifest file</strong> is in folder  <em>bin/debug/netcoreapp2.2</em>.  If you cut and paste everything from the inner bin in <em>bin/debug/netcoreapp2.2</em>  everything works fine. Also if you go to the manifest file and explicitly add the whole path to <strong>Test.API.dll</strong>  it works. But it still needs manual work  any thoughts how to make it automatically recognize the right path to <strong>Test.API.dll</strong>?</p>,azure-functions
51169690,"How to run schema creation sql script in mssql with nodejs? <p>I have my code deployed in Azure Function App and using NodeJS I am trying to execute a sql script on SQL Server database. To work this out I have used NPM package <a href=\https://www.npmjs.com/package/sqlcmd-runner\"" rel=\""nofollow noreferrer\"">sqlcmd-runner</a>.</p>  <p>Here is the code I am using:</p>  <pre><code>module.exports.dumpScriptinDatabase = (dbConfig  context) =&gt; {     return new Promise((resolve  reject) =&gt; {     sqlcmd({         server: dbConfig.server          database: dbConfig.options.database          username: dbConfig.userName          password: dbConfig.password          encryptedConnection: true          inputFiles: [`${__dirname}\\\\db.sql`]     })     .catch((error) =&gt; {         reject('Error dumping script!!')     })     .done(() =&gt; {         resolve('Dumping script completed.')     }); }); </code></pre>  <p>I am getting all the database details in <code>dbConfig</code> variable. Also <code>db.sql</code> creates the tables  views etc. in the schema.</p>  <p>The issue I am facing is this module never returns me error in case of failure and it also does not executes successfully. The server returns 502 error code on execution.</p>  <p>One thing I am able to debug is that the npm package code uses sqlcmd to execute the script.</p>  <p>Can someone help me on this?</p>""",azure-functions
52524972,Why is my Azure Function App Timestamp an hour less <p>I have an Azure Function App that runs every five minutes. The document has a Timestamp field using</p>  <pre><code>DateTime.Now </code></pre>  <p>I live in the UK which is currently british summer time 26-09-18 which is 1 hour ahead of GMT. My Azure data centre is UK South. The timestamp is one hour wrong. E.G. 20:01 is stored in the documnt as 19:01. How can I correct this?</p>,azure-functions
55849625,"None of the constructors found with 'Autofac.Core.Activators.Reflection.DefaultConstructorFinder <p>I am working on <code>Azure functions</code> with <code>Autofac</code> container. I have implemented generic repository pattern in project to interact with backend.</p>  <p>I am not sure what I am doing wrong may be there is a problem while registering the Generic types.</p>  <p>If I remove generic repository part from my project it works fine.</p>  <p>I have visited all the links on stack overflow but didn't find any suitable solution.</p>  <p>I am facing the below error while running the function.</p>  <blockquote>   <p>Executed 'sort' (Failed  Id=2cebaac1-a63e-4cf8-b82f-68e2ebeeb32d)   [4/25/2019 12:28:18 PM] System.Private.CoreLib: Exception while   executing function: sort. Microsoft.Azure.WebJobs.Host: Exception   binding parameter '_chargeOptionsServcie'. Autofac: An error occurred   during the activation of a particular registration. See the inner   exception for details. Registration: Activator = ChargeOptionsService   (ReflectionActivator)  Services =   [Awemedia.Chargestation.Business.Interfaces.IChargeOptionsServcie]    Lifetime = Autofac.Core.Lifetime.CurrentScopeLifetime  Sharing = None    Ownership = OwnedByLifetimeScope ---> None of the constructors found   with 'Autofac.Core.Activators.Reflection.DefaultConstructorFinder' on   type 'Awemedia.Chargestation.Business.Services.ChargeOptionsService'   can be invoked with the available services and parameters:</p> </blockquote>  <p>here is my function code:</p>  <pre><code>[DependencyInjectionConfig(typeof(DIConfig))]     public class Function1     {         [FunctionName(\Function1\"")]         public HttpResponseMessage Get(             [HttpTrigger(AuthorizationLevel.Anonymous  \""get\""  Route = null)] HttpRequestMessage req  [Inject]IChargeOptionsServcie _chargeOptionsServcie  [Inject]IErrorHandler _errorHandler)         {             return req.CreateResponse(HttpStatusCode.OK  _chargeOptionsServcie.GetAll());         }     } </code></pre>  <p>Here is my service code:</p>  <pre><code>public class ChargeOptionsService : IChargeOptionsServcie     {          private readonly IBaseService&lt;ChargeOptions&gt; _baseService;         private readonly IMapper _mapper;          public ChargeOptionsService(IBaseService&lt;ChargeOptions&gt; baseService  IMapper mapper)         {             _baseService = baseService;             _mapper = mapper;         }           public IEnumerable&lt;ChargeOptionsResponse&gt; GetAll()         {             return _baseService.GetAll().Select(t =&gt; _mapper.Map&lt;ChargeOptions  ChargeOptionsResponse&gt;(t));         }      } </code></pre>  <p>here is my <code>DIConfig.cs</code> code where i am registering my dependencies:</p>  <pre><code>public class DIConfig     {         public DIConfig(string functionName)         {             DependencyInjection.Initialize(builder =&gt;             {                  builder.RegisterGeneric(typeof(BaseRepository&lt;&gt;)).As(typeof(IBaseRepository&lt;&gt;));                 builder.RegisterGeneric(typeof(BaseService&lt;&gt;)).As(typeof(IBaseService&lt;&gt;));                  builder.RegisterType&lt;ErrorHandler&gt;().As&lt;IErrorHandler&gt;();                 builder.RegisterType&lt;ChargeOptionsService&gt;().As&lt;IChargeOptionsServcie&gt;();                 builder.RegisterType&lt;EventsService&gt;().As&lt;IEventsService&gt;();             }  functionName);         }     } </code></pre>  <p>My base service class:</p>  <pre><code>public class BaseService&lt;T&gt; : IBaseService&lt;T&gt;     {         private readonly IBaseRepository&lt;T&gt; _repository;          public BaseService(IBaseRepository&lt;T&gt; repository)         {             _repository = repository;         }          public IEnumerable&lt;T&gt; GetAll()         {             return _repository.GetAll();         }          public T GetById(int id)         {             return _repository.GetById(id);         }          public IEnumerable&lt;T&gt; Where(Expression&lt;Func&lt;T  bool&gt;&gt; exp)         {             return _repository.Where(exp);         }          public T AddOrUpdate(T entry  int Id)         {             var targetRecord = _repository.GetById(Id);             var exists = targetRecord != null;              if (exists)             {                 _repository.Update(entry);             }             _repository.Insert(entry);             return entry;         }         public T AddOrUpdate(T entry  Guid guid)         {             var targetRecord = _repository.GetById(guid);             var exists = targetRecord != null;              if (exists)             {                 _repository.Update(entry);             }             _repository.Insert(entry);             return entry;         }         public void Remove(int id)         {             var label = _repository.GetById(id);             _repository.Delete(label);         }          public bool InsertBulk(IEnumerable&lt;T&gt; entities)         {             return _repository.InsertBulk(entities);         }          public T GetById(Guid guid)         {             return _repository.GetById(guid);         }     } </code></pre>  <p>Here is my base repository :</p>  <pre><code>public class BaseRepository&lt;T&gt; : IBaseRepository&lt;T&gt; where T : class     {          private readonly Context _context;          private readonly DbSet&lt;T&gt; _entities;          private readonly IErrorHandler _errorHandler;          public BaseRepository(AwemediaContext context  IErrorHandler errorHandler)         {             _context = context;             _entities = context.Set&lt;T&gt;();             _errorHandler = errorHandler;         }         public IEnumerable&lt;T&gt; GetAll()         {             return _entities.ToList();         }         public T GetById(int id)         {             return _entities.Find(id);         }          public IEnumerable&lt;T&gt; Where(Expression&lt;Func&lt;T  bool&gt;&gt; exp)         {             return _entities.Where(exp);         }         public T Insert(T entity)         {             if (entity == null) throw new ArgumentNullException(string.Format(_errorHandler.GetMessage(ErrorMessagesEnum.EntityNull)  \""\""  \""Input data is null\""));             _entities.AddAsync(entity);             _context.SaveChanges();             return entity;         }         public void Update(T entity)         {             if (entity == null) throw new ArgumentNullException(string.Format(_errorHandler.GetMessage(ErrorMessagesEnum.EntityNull)  \""\""  \""Input data is null\""));              var oldEntity = _context.Find&lt;T&gt;(entity);             _context.Entry(oldEntity).CurrentValues.SetValues(entity);             _context.SaveChanges();         }         public void Delete(T entity)         {             if (entity == null) throw new ArgumentNullException(string.Format(_errorHandler.GetMessage(ErrorMessagesEnum.EntityNull)  \""\""  \""Input data is null\""));              _entities.Remove(entity);             _context.SaveChanges();         }         public bool InsertBulk(IEnumerable&lt;T&gt; entities)         {             bool result = false;             if (entities.Count() &gt; 0)             {                 _entities.AddRange(entities);                 _context.SaveChanges();                 result = true;             }             return result;         }         public T GetById(Guid guid)         {             return _entities.Find(guid);         }      } </code></pre>  <p>Please help me.I am breaking my head for last three days.</p>  <p><a href=\""https://i.stack.imgur.com/hcixE.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/hcixE.png\"" alt=\""enter image description here\""></a></p>""",azure-functions
50946175,"How do I map an Azure File Share as a volume in a Docker Compose file? <p>I have so far only found examples on how to create a volume on the host machine  e.g:</p>  <pre><code>version: \3.3\"" services:   mysql:     image: mysql     volumes:        - db-data:/var/lib/mysql/data volumes:   db-data: </code></pre>  <p>So this defines a volume named db-data that will physically be stored on the host machine running the container.</p>  <p>Is is possible to makes the db-data volume point to an Azure File Share in an Azure Storage account and how would I specify the needed parameters?</p>""",azure-storage
16215432,"Exception when trying to connect to SQL Azure Database <p>I am completely new to Windows Azure.</p>  <p>I currently have a local db for my .NET application. I have created an azure account along with a relevant SQL Azure Database.</p>  <p>I am working on adding the C# code in order to pass the data from the local application to the cloud. In order to test this functionality I have added a random user who I want to insert into the Azure DB. </p>  <p>I have used the following tutorial: <a href=\http://www.windowsazure.com/en-us/develop/net/how-to-guides/sql-database/\"" rel=\""nofollow\"">http://www.windowsazure.com/en-us/develop/net/how-to-guides/sql-database/</a></p>  <p>I are trying to connect to the Azure SQL Database using a connection string in app.config:</p>  <pre><code>&lt;?xml version=\""1.0\"" encoding=\""utf-8\""?&gt; &lt;configuration&gt;   &lt;connectionStrings&gt;     &lt;add name=\""STAREntities\""        connectionString =\""Server=tcp:fkr95b1any.database.windows.net 1433;Database=StarSoftwareDb;User ID=starSoft1@fkr95b1any;Password=xxxxxx;Trusted_Connection=False;Encrypt=True;\"" /&gt;   &lt;/connectionStrings&gt; &lt;/configuration&gt; </code></pre>  <p>This method is being used for registration  this code establishes the connection to the azure database  however it is currently failing on 'conn.Open();'. </p>  <pre><code>SqlConnectionStringBuilder csBuilder;  csBuilder = new SqlConnectionStringBuilder(ConfigurationManager.ConnectionStrings[\""STAREntities\""].ConnectionString);  SqlConnection conn = new SqlConnection(csBuilder.ToString()); conn.Open(); </code></pre>  <p>On clicking the register button which triggers this code  the program hangs for a long period before throwing the following error:</p>  <p>A network-related or instance-specific error occurred while establishing a connection to SQL Server. The server was not found or was not accessible. Verify that the instance name is correct and that SQL Server is configured to allow remote connections. (provider: TCP Provider  error: 0 - A connection attempt failed because the connected party did not properly respond after a period of time or established connection failed because connected host has failed to respond.)</p>  <p>Any help or advice here would be greatly appreciated.</p>  <p>UPDATE</p>  <p>I have changed my connection string to the one @Leonardo suggested below. I have also enable 'TCP/IP' and 'Named Pipes' in sql server configuration manager aswell as allowing opening port 1433.</p>  <p>The dashboard for the master DB is now showing successful connections on the table but I am still getting an exception on </p>  <pre><code>conn.Open() </code></pre>""",azure-storage
8386391,"Windows Azure Drive - Access Denied Exception <p>I am trying to write a test WCF service which writes image files into Azure Drive storage:</p>  <p>Below is the code I have written:</p>  <pre><code>            var storageAccount = CloudStorageAccount.Parse(RoleEnvironment.GetConfigurationSettingValue(\DataConnectionString\""));             blobStorage = storageAccount.CreateCloudBlobClient();              CloudBlobContainer container = blobStorage.GetContainerReference(\""mydrives\"");             container.CreateIfNotExist();              CloudPageBlob pageBlob = container.GetPageBlobReference(\""myvhd\"");             CloudDrive drive = new CloudDrive(pageBlob.Uri  storageAccount.Credentials);              try             {                 drive.Create(100);                 driveLetter = drive.Mount(0  DriveMountOptions.None);                 var fileExtension = Path.GetExtension(file.FileName);                 var fileName = string.Format(\""{0:10}_{1}{2}\""  DateTime.Now.Ticks  Guid.NewGuid()  fileExtension);                 File.WriteAllBytes(driveLetter + \""\\\\\"" + fileName  file.FileStream);             }             catch (CloudDriveException e)             {                 System.Diagnostics.Debug.WriteLine(e.Message);             } </code></pre>  <p>file.FileStream is the byte array that I am getting from Silverlight client.</p>  <p>This code works perfectly when I run it locally. I could even see the drive blobs and images uploaded using the storage emulator viewer.</p>  <p>But as soon as I publish it to the cloud and run it  I get the following exception:</p>  <pre><code>&lt;InnerException i:nil=\""true\""/&gt;&lt;Message&gt;Access to the path 'd:\\1634586886770888071_aa98357b-888d-4dde-a231-1ca5d5c73b49.jpeg' is denied.&lt;/Message&gt;&lt;StackTrace&gt;    at System.IO.__Error.WinIOError(Int32 errorCode  String maybeFullPath)&amp;#xD;        at System.IO.FileStream.Init(String path  FileMode mode  FileAccess access  Int32 rights  Boolean useRights  FileShare share  Int32 bufferSize  FileOptions options  SECURITY_ATTRIBUTES secAttrs  String msgPath  Boolean bFromProxy  Boolean useLongPath)&amp;#xD;        at System.IO.FileStream..ctor(String path  FileMode mode  FileAccess access  FileShare share  Int32 bufferSize  FileOptions options  String msgPath  Boolean bFromProxy)&amp;#xD;        at System.IO.FileStream..ctor(String path  FileMode mode  FileAccess access  FileShare share)&amp;#xD;        at System.IO.File.WriteAllBytes(String path  Byte[] bytes)&amp;#xD;        at ProcessService.FileService.UploadDCMToDrive(FileToTransfer file) in C:\\Users\\Vinod\\Desktop\\TestAzure_Vinod\\ProcessService\\FileService.svc.cs:line 68&amp;#xD;        at SyncInvokeUploadDCMToDrive(Object   Object[]   Object[] )&amp;#xD;        at System.ServiceModel.Dispatcher.SyncMethodInvoker.Invoke(Object instance  Object[] inputs  Object[]&amp;amp; outputs)&amp;#xD;        at System.ServiceModel.Dispatcher.DispatchOperationRuntime.InvokeBegin(MessageRpc&amp;amp; rpc)&amp;#xD;        at System.ServiceModel.Dispatcher.ImmutableDispatchRuntime.ProcessMessage5(MessageRpc&amp;amp; rpc)&amp;#xD;        at System.ServiceModel.Dispatcher.MessageRpc.Process(Boolean isOperationContextSet)&lt;/StackTrace&gt;&lt;Type&gt;System.UnauthorizedAccessException&lt;/Type&gt; </code></pre>  <p>I tried starting the application with elevated permissions (as per <a href=\""https://stackoverflow.com/questions/7568380/windows-azure-exception-access-to-the-path-xyz-exe-is-denied\"">this</a>) but I still get the same error. Can anyone shed some light on this please?</p>  <p><strong>UPDATE</strong>: I created a folder using the below code:</p>  <pre><code>DirectoryInfo di = new DirectoryInfo(driveLetter + \""\\\\images\""); if (!di.Exists)   di.Create(); </code></pre>  <p>Now I am getting this error:</p>  <pre><code>Could not find a part of the path 'd:\\images\\test.jpeg </code></pre>  <p>It's really weird :-(</p>""",azure-storage
25381649,Remote server not found error on blob download from Azure <p>I have an application that upload  download and delete files on Azure blob storage. It works fine but when I perform load testing <strong>sometimes</strong> I got following exception during file download.</p>  <blockquote>   <p>Microsoft.WindowsAzure.Storage.StorageException: The remote server returned an error: (404) Not Found. ---> System.Net.WebException: The remote server returned an error: (404) Not Found.</p> </blockquote>  <p>I am initializing these things once in constructor and then reuse it for all methods:</p>  <pre><code>cloudStorageAccount = CloudStorageAccount.Parse(_storage.ConnectionString); blobClient = cloudStorageAccount.CreateCloudBlobClient(); container = blobClient.GetContainerReference(_storage.Container);  var permission = container.GetPermissions(); permission.PublicAccess = BlobContainerPublicAccessType.Container; container.SetPermissions(permission); </code></pre>  <p>Here is my code for blob download:</p>  <pre><code>MemoryStream memoryStream = new MemoryStream();  var retryPolicy = TransientFactory.GetStorageRetryPolicy();         retryPolicy.ExecuteAction(() =&gt;             {                                     CloudBlockBlob blockBlob = container.GetBlockBlobReference(sourceUri);                                     if (blockBlob.Exists())                 {                     blockBlob.DownloadToStream(memoryStream);                     memoryStream.Position = 0;                                         }             });         return memoryStream; </code></pre>,azure-devops
47325208,Migrating to Durable Function <p>I have a non-durable pipeline of three Azure Http Trigger Functions. They pass along a custom json graph in a sequence.</p>  <p>I have started to migrate this to Durable Functions (using the sample as a basis) and it appears that I can just pass the json graph around as a string without using Task&lt;HttpResponseMessage> etc.</p>  <p>Is this the best way with Durable Functions. Could I still keep each function as a HttpTrigger in order to have the flexibility of calling the whole pipeline as Durable but each individual as an HttpTrigger? </p>,azure-functions
48228139,VSTS Release Variables Enter Value at Run Time <p>I'd like to be able to allow a user to enter the value of a variable (e.g. Password) at run time. I looked at the Pre-Deployment Approval setting and Manual Intervention task  but can't figure out how to achieve this.</p>  <p>Our Ops team doesn't want us to save the Production server password in the Release Definition  even if it's masked/encrypted.</p>  <p>Thanks  Angie</p>,azure-devops
55579778,"Copy latest files from S3 to Azure Blob (using Azure Factory V2) <p>I'm still new to Azure Data Factory and am trying to move files that are dumped in my S3 folder/bucket daily to Azure blob. I already created datasets (for source and sink) and linked services in Data Factory. </p>  <p>But since my S3 bucket receives new file every day  I'm wondering how to move <strong>the latest file that was dropped in the S3 (say at 5am EST) on a daily basis</strong>. I have looked through most of the answers online like <a href=\https://stackoverflow.com/questions/52989698/copy-data-from-azure-blob-storage-to-aws-s3\"">this</a>  <a href=\""https://stackoverflow.com/questions/52334901/azure-data-factory-copy-data-dynamically-get-last-blob\"">this</a>  <a href=\""https://stackoverflow.com/questions/53074516/incrementally-copy-s3-to-azure-blob\"">this</a> and <a href=\""https://stackoverflow.com/a/52340763/1330974\"">this</a>. But none of them explains how to figure out which is the latest file in S3 (maybe <strong>based on last modified date/time or by matching the file name pattern that goes like this 'my_report_YYYYMMDD.csv.gz'</strong>) and only copy that file to the destination blob.</p>  <p>Thank you in advance for your help/answer!</p>""",azure-storage
43192274,"Azure msdeploy Python App Service <p>I'm trying to deploy an Azure App Service running Flask on Python 3.4.  When I deploy from within Visual Studio (2015) via Web Deploy  everything works nicely.  But  when I attempt to deploy from my CI/CD server (TeamCity 10.0.3 on Windows Server 2012 R2) using an MSBuild step  the deployment succeeds without errors  but my app is apparently missing some crucial components and just throws HTTP errors on every request (my logging isn't able to capture the actual errors because the app is apparently totally hosed at this point).  I'm deploying numerous C# applications from this TeamCity instance using Web Deploy without fail.  My build has the following steps:</p>  <ol> <li><p>Command Line Runner - Copy publish profile (because msdeploy looks for it at ~/__profiles for some unknown reason and I can't find a flag or configuration setting to change): </p>  <p><code>mkdir __profiles  copy *.pubxml __profiles</code></p></li> <li><p>Command Line Runner - Create venv at top level folder: </p>  <p><code>c:\\python34\\python.exe -m venv env</code></p></li> <li><p>Command Line Runner - Install from requirements.txt: </p>  <p><code>env\\scripts\\pip install -r requirements.txt</code></p></li> <li><p>Powershell Runner - Stop Azure App Service</p></li> <li><p>MSBuild Runner - Deploy (Build file path points to the .pyproj file): </p>  <p><code>/p:DeployOnBuild=true  /p:PublishProfile=\My Publish Profile\"" /p:Configuration=Release /p:AllowUntrustedCertificate=True  /p:UserName=%WebDeployUserName% /p:Password=%WebDeployPassword%</code></p></li> <li><p>Powershell Runner - Start Azure App Service</p></li> </ol>  <p><a href=\""https://github.com/Microsoft/PTVS/issues/2364\"" rel=\""nofollow noreferrer\"">Related GitHub Issue</a></p>""",azure-web-app-service
43218748,"Azure VM: OS disk size <p>After creating a Windows Server Virtual Machine in Azure I noticed that the OS disk (C: drive) is only 30GB in size. </p>  <p>My impression was that all new VMs have 127GB OS disk size. (<a href=\https://docs.microsoft.com/en-us/azure/virtual-machines/windows/expand-os-disk\"" rel=\""nofollow noreferrer\"">Expand the OS drive of a Windows VM in Azure</a>)</p>  <p>Could someone clarify please?</p>  <p><strong>Edit</strong></p>  <p>Also  I was creating a VM using my MSDN subscription - could that be the cause of this?</p>  <p><strong>Edit 2</strong></p>  <p>I managed to increase the OS drive size by running the following (as described in linked article above). Then I had to resize the disk inside the OS.</p>  <pre><code>Login-AzureRmAccount Select-AzureRmSubscription -SubscriptionName 'my-subscription-name' $rgName = 'my-resource-group-name' $vmName = 'my-vm-name' $vm = Get-AzureRmVM -ResourceGroupName $rgName -Name $vmName Stop-AzureRmVM -ResourceGroupName $rgName -Name $vmName # Set the size to whatever is needed. $vm.StorageProfile.OSDisk.DiskSizeGB = 1023 Update-AzureRmVM -ResourceGroupName $rgName -VM $vm Start-AzureRmVM -ResourceGroupName $rgName -Name $vmName </code></pre>""",azure-virtual-machine
52148882,"Download multiple powershell files from Azure Storage container as a Zip <p>How to download all the PowerShell files from the Azure storage account container to a zip folder through power shell cmdlets?</p>  <p>As of now  the below cmdlet helps to download a specific blob by its name</p>  <pre><code>$blob = Get-AzureStorageBlobContent -Container hemac -Blob \CreateAndDeploy-Eventhubs.ps1\"" -Context $ctx -Destination $f -Force </code></pre>""",azure-web-app-service
28615256,Microsoft Azure - how to store backup data <p>I have a trivial and simple task - I want to store some my data (documents  photos etc) on Azure as backup. Which type of service should I select? Store as Blob? But I want to save a structure of data (folders  subfolders etc). Azure Backup? It stores only archive data  I don't want to archive it all in one. DocumentDB? I not need to have features like return json format etc... What is the best way to store many (thousands) files (big and small) to save folder structure without archivation to one file (so  I want to have a simple way to get only one file quickly)</p>  <p>I use Windows 7.</p>,azure-storage
27508035,"Cannot browse local Azure Storage Emulator in VS2013 - Azure SDK 2.4/2.5 <p>When using the Server Explorer in VS2013  I cannot browse the Blob Storage under Development.<br> I receive this error:   \Failed To Connect To Microsoft Azure storage emulator\""</p>  <p>I have started VS as Administrator.  </p>  <p>I was having this issue using Azure SDK 2.4 so I updated to 2.5 and I am getting the same result.  However  I can browse the emulator using Azure Storage Explorer 6.   </p>  <p>Any ideas?</p>""",azure-storage
18024200,"Azure DNS issues after destroying/recreating VM <p>Like many people  we have Azure VMs that we want to destroy when not in use so that we don't have to pay for their core usage.  All of the VMs in question are on the same domain and the DC/DNS server is never destroyed/recreated and has a static IP.  After successfully using a combination of Export/Remove/Import-AzureVM  however  all of the IP settings for the network adapter (DNS is my primary concern) are gone because a new network adapter is created each time I reconstruct the VM using Import-AzureVM.</p>  <p>I initially tried using NETSH to set my DNS entry at startup  but it depends on knowing the name of the adapter and the adapter name changes daily (since we're taking the machines down for the evening and recreating them in the morning).  My next not-so-brilliant idea was to include a VBScript that renamed the adapter to the same name on startup so that NETSH would always have the same adapter name to deal with.  However  it was at that point that I discovered that all of the old adapters still exist  but are simply hidden and not in use  rendering my plan moot.</p>  <p>Here are the test NETSH command and VBScript I was attempting to use  just for the sake of reference:</p>  <pre><code>'this script was modified from one i got from the Scripting Guys Const NETWORK_CONNECTIONS = &amp;H31&amp;  Set objShell = CreateObject(\Shell.Application\"") Set objFolder = objShell.Namespace(NETWORK_CONNECTIONS)  Set colItems = objFolder.Items For Each objItem in colItems   'only one adapter is ever returned by this query  but it didn't seem like a bad idea to leave the loop alone just in case               objItem.Name = \""testlan\""     wscript.echo objItem.Name Next </code></pre>  <p>NETSH</p>  <pre><code>netsh interface ip add dns name=\""testlan\"" 10.0.0.4  </code></pre>  <p>I know I can't be the only person trying to solve this issue  but I've been unable to find the solution through a significant amount of Googling and trial and error on my part.  Many thanks!</p>  <p>Ben</p>""",azure-virtual-machine
56618396,"azure database most significant differences in comparison to aurora mysql (aws manged databse) <p>i would like to know the main differences   aproaches needed to be taken as devops for using  azure manged database in comparison to AWS rds <a href=\https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/Aurora.AuroraMySQL.html\"" rel=\""nofollow noreferrer\"">https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/Aurora.AuroraMySQL.html</a>  i found this  <a href=\""https://medium.com/@lakshmanLD/comparison-of-mysql-across-aws-azure-and-gcp-19af2d208d9a\"" rel=\""nofollow noreferrer\"">https://medium.com/@lakshmanLD/comparison-of-mysql-across-aws-azure-and-gcp-19af2d208d9a</a> which point out some differences   the most significantly for my team is that Manual Backup (DB snapshots can be created anytime manually) is not supports in Azure   is there any other main / big differences ? some different dev-ops approaches that needed to be taken ?</p>""",azure-devops
52105313,"Git commands in a batch file ran through VSTS throwing an error <p>I have cloned remote GitHub repository into my Build Server. A build definition in VSTS generated a file as build artifact. I copy that file into local github repository in build server through a powershell script task in VSTS. I want to run Git commands to push this new build artifact file from local github repository to remote GitHub repository. I have stored batch file with Git commands on build server. When a build runs on VSTS  I try to invoke batch file residing in build server through a \Command Line Script\"" VSTS task.</p>  <p>Command Line Script:</p>  <pre><code>cd \""batch file path\"" GitCommands.bat </code></pre>  <p>Now I keep getting errors related to git commands in batch file. Below is an example. </p>  <p><strong>Note: I am trying to push a single file directly to github repository using git commands in batch file.</strong></p>  <pre><code>2018-08-30T20:17:07.9089221Z On branch master 2018-08-30T20:17:07.9090417Z Your branch is up to date with 'origin/master'. 2018-08-30T20:17:07.9166091Z  2018-08-30T20:17:07.9180427Z Untracked files: 2018-08-30T20:17:07.9205244Z   (use \""git add &lt;file&gt;...\"" to include in what will be committed) 2018-08-30T20:17:07.9224271Z  2018-08-30T20:17:07.9298112Z    filename.ipa 2018-08-30T20:17:07.9316134Z  2018-08-30T20:17:07.9457726Z nothing added to commit but untracked files present (use \""git add\"" to track) 2018-08-30T20:17:10.4572412Z fatal: Unable to write new index file 2018-08-30T20:17:10.4614209Z file added 2018-08-30T20:17:10.5106172Z On branch master 2018-08-30T20:17:10.5107096Z Your branch is up to date with 'origin/master'. 2018-08-30T20:17:10.5131465Z  2018-08-30T20:17:10.5145982Z Untracked files: 2018-08-30T20:17:10.5184825Z    filename.ipa 2018-08-30T20:17:10.5204032Z  2018-08-30T20:17:10.5280428Z nothing added to commit but untracked files present 2018-08-30T20:17:38.9087093Z Terminate batch job (Y/N)?  </code></pre>  <p>Batch file content:</p>  <pre><code>*cd to github loval repository  git status  git add .  echo file added  git commit -m \""Adding ipa file to the repository through VSTS automated build\""  git push origin master* </code></pre>""",azure-devops
20729380,Slow load balancing through Azure Cloud Service <p>In Azure  I have two Ubuntu VMs running the same python bottle services under one Cloud Service. The two VMs are set to be in the same Load-Balanced Set and are load-balanced in a Round-Robin fashion under that cloud service.</p>  <p>However  my problem is that each request takes 3~8 seconds to get to the underlying VM. (i.e. The load balancer is working  but it's very slow routing the requests.) I assume it's not normal  is it?</p>  <p>It seems that I can't even access the cloud service instance(load balancer) in Azure. Can anyone give me a hint where I might have set wrong and resulted in this? </p>  <p>Thanks!</p>,azure-virtual-machine
54729680,"What does the @ refer to in the value to a key `task` in a YAML document for Azure? <p>Many values for the key <code>task</code> in YAML documents for Azure  seem to contain <code>@number</code>. For example <a href=\https://docs.microsoft.com/en-us/azure/devops/pipelines/tasks/build/index-sources-publish-symbols?view=azure-devops\"" rel=\""nofollow noreferrer\"">this one</a> is called <code>PublishSymbols@2</code></p>  <p>What does the <code>@number</code> refer to?</p>""",azure-devops
15744913,Backup Microsoft Azure Virtual Machine <p>I currently have a Rackspace Cloud Server that I'd like to migrate to an Azure Virtual Machine. I recently got an MSDN subscription which gives me a certain level of hosting via Azure at no cost  where I'm currently paying for that level of service with Rackspace. </p>  <p>However  one of the nice things about Rackspace is that I can schedule nightly/weekly backups of the VM image. Is there any mechanism for doing this on Azure? I'm worried about protecting against corruption of the database (i.e. what if someone were to run an UPDATE statement and forget the WHERE clause). Is there a mechanism for this with Azure?</p>  <p>I know the VMs are stored as .VHD files in my local Azure storage  but the VM image is 127 gigs. Downloading that nightly even with FIOS internet isn't really going to fly as a solution.</p>,azure-virtual-machine
54663323,Django in Ubuntu 18.04 on Azure VM gunicorn Can't connect to ('0.0.0.0'  80) <p>I'm trying to deploy my Django application to Azure virtual machine with Ubuntu 18.04.</p>  <ol> <li>I have set up the VM and connect to it via SSH.</li> <li>Then run the update and upgrade command</li> <li>Setup Python and Virtualenvironment </li> <li>Upload my code and activate the environment</li> <li>Allow the port <code>8000</code> using <code>sudo ufw allow 8000</code> for testing</li> <li><p>After installing all the requirements  when I run the command:</p>  <pre><code>python manage.py runserver 0.0.0.0:8000 </code></pre></li> </ol>  <p>The application runs  but when I open the URL as: :8000/</p>  <p>It doesn't return anything not any errors in the console</p>  <blockquote>   <p><strong>Update:</strong>    It's just fixed by manually adding the port <code>8000</code> in azure portal under <code>Inbound port rules</code>.   But: when I try to run it via gunicorn as:</p> </blockquote>  <pre><code>gunicorn --pythonpath PROJECT PROJECT.wsgi:application --log-file - --bind 0.0.0.0:80 </code></pre>  <p>it returns another error as below:</p>  <blockquote>   <p>[30007] [ERROR] Can't connect to ('0.0.0.0'  80)</p> </blockquote>  <p>What can be wrong here?</p>,azure-virtual-machine
43453755,"Installation of Azure Functions to visual studio 2015 <p>I am new to Azure Functions. I am trying to install Azure functions 2.9.6 version. I am able to install it  but still cannot see it in visual studio templates. I have updated my visual studio to update 3. Earlier  I tried version 3 too  but its still not fixed. Where I am getting it wrong.This is the snapshot of my installed programs. <a href=\https://i.stack.imgur.com/7hDGN.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/7hDGN.png\"" alt=\""This is the snapshot of my installed programs.\""></a></p>  <p>Edited: I tried to convert the azure function code into cs code for running it  but failed with errors: <a href=\""https://i.stack.imgur.com/F83a6.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/F83a6.png\"" alt=\""enter image description here\""></a></p>""",azure-functions
53860194,"Azure DevOps resources repo: self <p>Can someone please explain or provide documentation for </p>  <pre><code>resources:   - repo: self </code></pre>  <p>in the azure-pipelines.yml files?  I cannot find any documentation for it.  </p>  <p>Here's the official Azure docs: <a href=\https://docs.microsoft.com/en-us/azure/devops/pipelines/yaml-schema\"" rel=\""nofollow noreferrer\"">https://docs.microsoft.com/en-us/azure/devops/pipelines/yaml-schema</a></p>""",azure-devops
49304238,"Request Access Token in Postman for Azure Function App protected by Azure AD B2C <p>I have an AspNetCore 2.0 MVC web API secured by an Azure Active Directory B2C tenant.  I have been able to use Postman to test the API end points by following this SO posting: <a href=\https://stackoverflow.com/questions/47275079/request-access-token-in-postman-for-azure-ad-b2c/47564076#comment85605907_47564076\"">Request Access Token in Postman for Azure AD B2C</a> (in particular  the Microsoft documented steps referenced in SpottedMahn's comments: <a href=\""https://docs.microsoft.com/en-us/aspnet/core/security/authentication/azure-ad-b2c-webapi#use-postman-to-get-a-token-and-test-the-api\"" rel=\""nofollow noreferrer\"">https://docs.microsoft.com/en-us/aspnet/core/security/authentication/azure-ad-b2c-webapi#use-postman-to-get-a-token-and-test-the-api</a> )</p>  <p>Now  I am working on a serverless version of the above - the app is pretty much identical expect that the endpoints have been implemented by Azure functions in an Azure Functions App</p>  <p>The Functions App has Authentication on  Log in with Azure Active Directory and the following settings:</p>  <p><a href=\""https://i.stack.imgur.com/16ZbS.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/16ZbS.png\"" alt=\""enter image description here\""></a></p>  <p>This is how i have set up the Application in the Azure B2C tenant:</p>  <p><a href=\""https://i.stack.imgur.com/aZ8yr.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/aZ8yr.png\"" alt=\""enter image description here\""></a></p>  <p>If I access the functions endpoint via a browser  I get successfully routed to the Azure AD B2C login page and can log in  then see the results from the API endpoint.  So I'm pretty confident all is good w.r.t. the Azure AD B2C &lt;-> Function App configuration.</p>  <p>However  I can't use the Request Access Token technique linked above to get a token and inspect the endpoint in Postman</p>  <p>If I take the token obtained after authentication (for example by using fiddler and observing the id_token being returned)  and in Postman I choose Bearer authentication and supply that id_token  then Postman successfully hits my endpoint.  However  if I follow the steps in the linked document above  I do get the \""login\"" popup and then do get a valid [looking] token  but when I click Use Token and run the request  I get </p>  <blockquote>   <p>You do not have permission to view this directory or page.</p> </blockquote>  <p>I'd really like to be able to request an access token from postman just like I can with my aspnetcore 2.0 app (really just for the consistency so I don't have to remember lots of different techniques). Is that possible for Azure Function Apps and if so  any clues what I'm doing wrong in the above?</p>""",azure-functions
39528437,Retroactively joining existing VMs to a VNet (Azure) <p>I have two classic VMs provisioned in Azure. They exist in different resource groups  and I now I want to join them to a VNet. How do I do that? I can't exactly find documentation related to this  and since my application is live  I want to minimize downtime (or entirely eradicate downtime preferably).</p>,azure-virtual-machine
54368380,"Old Azure WebJob logs <p>How to find old WebJob logs for Azure Web Service Application? I try to open <code>kudu</code> for selected Web application  and then go to  <code>data\\jobs\\triggered\\WebJobVistracksSync</code>  but only current day logs there:</p>  <p><a href=\https://i.stack.imgur.com/9lv7K.jpg\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/9lv7K.jpg\"" alt=\""enter image description here\""></a></p>  <p>but I want to look at old log files  approx 1 month ago. Is it possible?</p>""",azure-web-app-service
16056054,"How can i setup connected VMs on Windows Azure with 2 different regions <p>I gone through official announcement of <a href=\http://weblogs.asp.net/scottgu/archive/2013/04/16/windows-azure-general-availability-of-infrastructure-as-a-service-iaas.aspx\"" rel=\""nofollow\"">General availability of Virtual Machine on Windows Azure</a>. so i would like to move one of my client's production app on this. Requirement to set up this app on 2 different regions as below</p>  <p>Basically we have two demographics from Australia and Turkey from where people will be accessing the server  So we need two web servers one from Australia and another from Europe </p>  <p><strong>- 2 Web servers with Window server 2008 r2</strong> <br></p>  <p><strong>- Separate Database server with SQL server</strong> <br></p>  <p><strong>- One Load balancer</strong></p>  <p><strong>Queries</strong> <br></p>  <p><strong>1)</strong> What data centers are best suited for above regions? <br> <strong>2)</strong> we are not concerned about up-time instead we are concerned about performance at locale<br>    based so to run application on 1 VM is okay? <br> <strong>3)</strong> In which region database should be hosted so both web server can access smoothly     regardless of performance issue. what should be region of it? <br> <strong>4)</strong> Can we setup load balancing such a way for one url it would transfer request to     Australian server and for other transfer request to European server?<br> <strong>5)</strong> I have calculated price with </p>  <ul> <li>2 VM (small) for to host window server <br> </li> <li>1 vm (medium) to host sql server <br> </li> <li>35 GB bandwidth</li> <li>support for developer and it would cost me <strong>around $300</strong> </li> </ul>  <p>Do I need to consider other pricing apart from this?</p>""",azure-virtual-machine
45840623,"Custom IExceptionHandler <p>I'm trying to get a custom <code>IExceptionHandler</code> to work with my Azure Function (C# class library). The idea is to have my own exception handler for unexpected exceptions that will contain my own in-memory trace log; to clarify  I <strong>do</strong> want these sent to the client browser and displayed to the user.</p>  <p>Details follow.</p>  <p>With this simple custom exception handler:</p>  <pre><code>public sealed class CustomExceptionHandler : ExceptionHandler {   public override void Handle(ExceptionHandlerContext context)   {     context.Result = new ResponseMessageResult(         context.Request.CreateErrorResponse(HttpStatusCode.BadRequest              \custom message string\""));   } } </code></pre>  <p>I've tried to install it as such:</p>  <pre><code>[FunctionName(\""Function1\"")] public static HttpResponseMessage Run(     [HttpTrigger(AuthorizationLevel.Anonymous  \""get\""  Route = \""works\"")]     HttpRequestMessage req) {   req.GetConfiguration().Services.Replace(typeof(IExceptionHandler)        new CustomExceptionHandler());   throw new Exception(\""unexpected exception\""); } </code></pre>  <p>but when deployed  I just get the generic \""operation failed\"" error message (e.g.  XML-formatted from Chrome):</p>  <pre><code>&lt;ApiErrorModel xmlns:i=\""http://www.w3.org/2001/XMLSchema-instance\"" xmlns=\""http://schemas.datacontract.org/2004/07/Microsoft.Azure.WebJobs.Script.WebHost.Models\""&gt;   &lt;Arguments xmlns:d2p1=\""http://schemas.microsoft.com/2003/10/Serialization/Arrays\"" i:nil=\""true\""/&gt;   &lt;ErrorCode&gt;0&lt;/ErrorCode&gt;   &lt;ErrorDetails i:nil=\""true\""/&gt;   &lt;Id&gt;dec07825-cf4e-49cc-a80e-bef0dbd01ba0&lt;/Id&gt;   &lt;Message&gt;An error has occurred. For more information  please check the logs for error ID dec07825-cf4e-49cc-a80e-bef0dbd01ba0&lt;/Message&gt;   &lt;RequestId&gt;51df1fec-c1c2-4635-b82c-b00d179d2e50&lt;/RequestId&gt;   &lt;StatusCode&gt;InternalServerError&lt;/StatusCode&gt; &lt;/ApiErrorModel&gt; </code></pre>  <p>If I turn on <code>Diagnostic Logs -&gt; Detailed error messages</code> in the AF UI and try to ensure detailed error messages are always written:</p>  <pre><code>[FunctionName(\""Function1\"")] public static HttpResponseMessage Run(     [HttpTrigger(AuthorizationLevel.Anonymous  \""get\""  Route = \""works\"")]     HttpRequestMessage req) {   req.GetRequestContext().IncludeErrorDetail = true;   req.GetRequestContext().IsLocal = true;   req.GetConfiguration().Services.Replace(typeof(IExceptionHandler)        new CustomExceptionHandler());   throw new Exception(\""unexpected exception\""); } </code></pre>  <p>then I do get exception details  but still apparently handled by the builtin exception handler (XML-formatted from Chrome):</p>  <pre><code>&lt;ApiErrorModel xmlns:i=\""http://www.w3.org/2001/XMLSchema-instance\"" xmlns=\""http://schemas.datacontract.org/2004/07/Microsoft.Azure.WebJobs.Script.WebHost.Models\""&gt;   &lt;Arguments xmlns:d2p1=\""http://schemas.microsoft.com/2003/10/Serialization/Arrays\"" i:nil=\""true\""/&gt;   &lt;ErrorCode&gt;0&lt;/ErrorCode&gt;   &lt;ErrorDetails&gt;Microsoft.Azure.WebJobs.Host.FunctionInvocationException : Exception while executing function: Function1 ---&gt; System.Exception : unexpected exception at ...&lt;/ErrorDetails&gt;   &lt;Id&gt;5e752375-002b-4ab7-a348-20edad64a3fe&lt;/Id&gt;   &lt;Message&gt;Exception while executing function: Function1 -&gt; unexpected exception&lt;/Message&gt;   &lt;RequestId&gt;b6611456-f3f1-4591-97e4-920dae59b5ff&lt;/RequestId&gt;   &lt;StatusCode&gt;InternalServerError&lt;/StatusCode&gt; &lt;/ApiErrorModel&gt; </code></pre>  <p>so this is exposing the stack trace and exception message  but I don't have my in-memory trace log.</p>  <p>What I want to do is create the response message for unexpected exceptions myself. For example  this is what my custom error response looks like for an expected exception (JSON-formatted  from Postman):</p>  <pre><code>{   \""message\"": \""An error has occurred.\""    \""exceptionMessage\"": \""Could not find package `nito.bob`\""    \""exceptionType\"": \""Common.ExpectedException\""    \""stackTrace\"": \""   at ...\""    \""log\"": [     \""Received request for jsonVersion=4  packageId=`nito.bob`  packageVersion=``  targetFramework=``\""      \""Looking up latest package version for `nito.bob`\""      \""No non-prerelease package version found for `nito.bob`; looking up latest prerelease package version\""      \""No package version found for `nito.bob`\""      \""Returning 404: Could not find package `nito.bob`\""   ]    \""requestId\"": \""b2df08cb-1071-4e47-bd24-bf74152e4b2a\"" } </code></pre>  <p>This is just the basic <code>HttpError</code>-formatted exception (with details) that I augment with <code>log</code> and <code>requestId</code>. Since this is an expected exception  this is not being done in an <code>IExceptionHandler</code>; I'm just returning the <code>HttpResponseMessage</code>.</p>  <p>The fun part: my custom <code>IExceptionHandler</code> works <em>just fine</em> when hosting the AF locally. It just doesn't work <a href=\""https://stephenclearyrepro1.azurewebsites.net/api/works\"" rel=\""noreferrer\"">when deployed</a>. If I take <a href=\""https://github.com/StephenClearyExamples/FunctionsExecutionContextRepro\"" rel=\""noreferrer\"">the code</a> and run it locally  I get back the response I expect (JSON-formatted from Postman):</p>  <pre><code>{   \""Message\"": \""custom message string\"" } </code></pre>  <p>Alternative approaches that won't work for me:</p>  <ul> <li>Catching all <code>Exception</code>s and returning <code>HttpRequestMessage.CreateErrorResponse</code>. I'm already doing this for <em>expected</em> exceptions  and that works fine. This isn't a good solution for <em>unexpected</em> exceptions because I want the function execution to clearly be marked as \""failed\"". Returning an <code>HttpResponseMessage</code> (even with a 500 status code) is treated by the AF runtime as \""successful\""  and does not show as \""failed\"" in the dashboard or logs (or presumably by App Insights  though I haven't explicitly checked that).</li> </ul>""",azure-functions
18097161,"Calling RestAPI against storage emulator from ConsoleApp  Request not showing up in fiddler <p>As a sandbox application i wrote a console app which will call RestApi for storage services.The app is running as expected and i can see calls made by application in Fiddler.I wrote this sandbox so that i could specifically use Rest API calls.</p>  <p>The point i am stuck is how to see REST calls made by my application against storage emulator in Fiddler. <strong>I know</strong> if i am using storage client library (azure SDK) then could have used following</p>  <pre><code>UseDevelopmentStorage=true;DevelopmentStorageProxyUri=http://ipv4.fiddler </code></pre>  <p>I tried setting the Proxy on the <code>HttpWebRequest</code> but that is also not helping me.Following i the excerpt from my code.</p>  <pre><code>HttpWebRequest request = (HttpWebRequest)WebRequest.Create(URI); WebRequest.DefaultWebProxy = new WebProxy(\http://ipv4.fiddler\""); </code></pre>  <p>or </p>  <pre><code>HttpWebRequest request = (HttpWebRequest)WebRequest.Create(URI); request.Proxy = new WebProxy(\""http://ipv4.fiddler\""); </code></pre>  <p>or</p>  <pre><code>HttpWebRequest request = (HttpWebRequest)WebRequest.Create(URI); request.Proxy = new WebProxy(\""127.0.0.1\"" 8888); </code></pre>  <p>also tried setting up this in app.config like </p>  <pre><code> &lt;system.net&gt;     &lt;defaultProxy&gt;       &lt;proxy               proxyaddress=\""http://ipv4.fiddler\""               bypassonlocal=\""False\"" /&gt;     &lt;/defaultProxy&gt;   &lt;/system.net&gt; </code></pre>  <p>but none seems to be working for me. Again just to be clear about my question  app is running fine for me both for storage emulator and My subscription. Only issue is that i cant see call in Fiddler if executed against storage emulator.</p>  <p>Thanks.</p>""",azure-storage
55191206,How to change the URL of Web API service <p>An Azure App Service Web API using .NET Core was successfully deployed using the Visual Studio 2017 Publish function but now the URL needs to change.  How can I do that?</p>,azure-web-app-service
51617438,Getting public IP of instances in Azure VMSS? <p>I have a python program that gives me all the details regarding different VM instances of a Virtual Machine Scale Set(VMSS) in Azure  in JSON format. However  I want something (a parameter) to  identify which Public IP is for which instance.</p>  <p>The program just gives me a list of Public IP's of the all the instances now. So  let us assume that I want to get the Public IP of the 3rd instance specifically. </p>  <p>What should I do?</p>,azure-virtual-machine
24196134,"Web deployment times out in azure <p>Trying an azure web deployment for the first time and its throwing me the error below </p>  <p>(The website has been created on azure and accessible through browser - Web deploy tool seems to time out and having trouble connecting to azure.)</p>  <p><strong>Error 3   Web deployment task failed. (Could not complete the request to remote agent URL '<a href=\https://waws-prod-am2-009.publish.azurewebsites.windows.net/msdeploy.axd?site=mysitename\"" rel=\""nofollow\"">https://waws-prod-am2-009.publish.azurewebsites.windows.net/msdeploy.axd?site=mysitename</a>'.) Could not complete the request to remote agent URL '<a href=\""https://waws-prod-am2-009.publish.azurewebsites.windows.net/msdeploy.axd?site=mysitename\"" rel=\""nofollow\"">https://waws-prod-am2-009.publish.azurewebsites.windows.net/msdeploy.axd?site=mysitename</a>'. The operation has timed out     0   0   mysitename Appreciate any help on this.</strong></p>""",azure-web-app-service
52446199,"Routing in Azure Functions using python <p>I know that I can use query parameters in Azure functions to get the values</p>  <pre><code>\myfunction?p=one&amp;p2=two\"" </code></pre>  <p>I am referring to this question </p>  <blockquote>   <p><a href=\""https://stackoverflow.com/questions/39430279/how-can-i-do-routing-in-azure-functions\"">How can I do Routing in Azure Functions?</a></p> </blockquote>  <p>However it only addresses C# and node.js  I want to get the values following flask style</p>  <pre><code>/function/&lt;name&gt;/&lt;id&gt; </code></pre>  <p>which I can directly access  how do I do it in python in Azure functions</p>  <p>I also referred this doc  which only talks about node.js and C#</p>  <blockquote>   <p><a href=\""https://github.com/Azure/azure-functions-host/wiki/Http-Functions\"" rel=\""nofollow noreferrer\"">https://github.com/Azure/azure-functions-host/wiki/Http-Functions</a></p> </blockquote>""",azure-functions
41840552,"Parse Server Config Options In Azure <p>I've installed a parse.com server in Azure.  All is working well with the initial setup.</p>  <p>I now want to lock down the server with a few of the \Advanced Options\"" as annotated on the Parse Server Github page.</p>  <p>I understand that I do these in the App Settings in Azure a la the below:</p>  <p><a href=\""https://i.stack.imgur.com/e1wuS.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/e1wuS.png\"" alt=\""Azure App Settings Photo\""></a></p>  <p>Namely  sessionLength should be visible following a server restart?  However this is not the case as I still get 1 year sessions for newly logged in users.  Am I filling in the details incorrectly  is there an error with Azure &amp; Parse Server  or am I doing this completely wrong?</p>""",azure-web-app-service
51089282,"How to Measure Azure Function Cold Start Time <p>I've been doing research lately around Azure Function <a href=\https://blogs.msdn.microsoft.com/appserviceteam/2018/02/07/understanding-serverless-cold-start/\"" rel=\""nofollow noreferrer\"">cold start time</a> that can occur with a consumption-based plan. I understand the concepts  but how do I actually measure the cold start time of my Azure Functions? I can't seem to find any good documentation on this.</p>  <p>In the Azure Portal  I see there is a \""Monitor\"" tab for each of my functions  but the only statistic shown is \""Duration (MS)\"" and it is unclear if this includes the start up time.</p>  <p>In general  are there better ways to monitor this?</p>""",azure-functions
51970324,"Azure Functions \Could not load assembly\"" when running in live environment <p>My function app has a project reference: <code>MyFA.csproj</code> --> <code>MyLibrary.csproj</code>. When I build  <code>MyLibrary.dll</code> is in <code>bin</code> folder as expected. But when I test in the live environment I get <code>Could not load assembly MyLibrary</code> error. I went to Process Explorer in Kudu and searched for <code>MyLibrary</code> and found the dll sitting at </p>  <pre><code>w3wp.exe:5328 -&gt; C:\\DWASFiles\\Sites\\mawsFnPlaceholder51_v1\\Temporary ASP.NET Files\\root\\26c08606\\ff1fbe16\\assembly\\dl3\\05ad04a1\\e5a46c4a_273ad401\\MyLibrary.DLL </code></pre>  <p>but somehow it's not loading when I need it.</p>  <p>Any idea why this is?</p>""",azure-functions
41628683,Azure Networking ActiveFTP issue <p>We have recently moved our server onto Azure. It runs our point-of-sale system and uploads a few files via FTP to our webserver which then gets parsed and products are created.</p>  <p>The point of sale software developers have a bunch of batch files that run FTP.exe which unfortunately doesn't support passive file transfers(regardless of what you read - quote pasv &amp; literal pasv don't work). So we are stuck using active transfers  unfortunately this doesn't suit Azure very well.</p>  <p>The server is using ports 10090 - 10100 for active connections (I have created a rule in the NSG to allow 10090-10100 in) but unfortunately this isn't working at all.</p>  <p>I'm in the process of trying to convince the developers to rewrite using WinSCP so that we can just use passive transfers  but otherwise I've been searching for another solution  and so far nothing has worked.</p>  <p>I know it's not an issue in the OS as I've turned off Windows Firewall &amp; still no luck.</p>  <p>Any help or suggestions with this problem is greatly appreciated.!</p>,azure-virtual-machine
48947739,"Azure App Service - write to filesystem - ASP.NET web application <p>I have an ASP.NET web application  created in Visual Studio 2017.</p>  <p>In the application there is a form  where the users can upload files. When files are uploaded  I process them and I save them on the filesystem:</p>  <pre><code>var photo = Request.Files[\file\""]; photo.SaveAs(\""D:\\\\home\""); </code></pre>  <p>Everything works perfect locally  but it's not working when I deploy the App on Azure App Services.</p>  <p>I read that  on Azure  the path</p>  <pre><code>D:\\home </code></pre>  <p>should be writable.</p>  <p>But when I try the code I get this error:</p>  <pre><code>Access to the path 'd:\\home\\test_image.JPG' is denied. </code></pre>""",azure-web-app-service
52046122,"Unable to load a certificate in Azure Function <p>I am developping an Azure Function which needs to load a certificate from a secured Base 64 string. The certificate is protected by a key. The certificate and the password are stored in an Azure Key Vault.</p>  <p>When I try to load the certificate from the Function  I get errors in both v1 and v2 Functions.</p>  <p>Here is the code used to load the certificate :</p>  <pre><code>var certificate = new X509Certificate2(Convert.FromBase64String(certificateBase64)  certificatePassword) </code></pre>  <p>With this code for .Net I have a strange issue I can reproduce locally. The issue is linked to .Net 4.6.1. In .Net Core 2.0  it works fine locally (in Azure Function CLI)  but I got a strange issue regarding a file not found (<a href=\https://github.com/dotnet/corefx/issues/11042\"" rel=\""nofollow noreferrer\"">https://github.com/dotnet/corefx/issues/11042</a>) </p>  <p>As mentionned at the end the previous post  I tried to the <strong>X509KeyStorageFlags.EphemeralKeySet</strong> flag.</p>  <pre><code>var certificate = new X509Certificate2(Convert.FromBase64String(certificateBase64)  certificatePassword  X509KeyStorageFlags.EphemeralKeySet) </code></pre>  <p>The flag is not yet available for .Net Core 2 (<a href=\""https://github.com/dotnet/corefx/issues/24454\"" rel=\""nofollow noreferrer\"">https://github.com/dotnet/corefx/issues/24454</a>)  and not also in .Net 4.6.1  the framework used by Azure Functions.</p>  <p>Is there a way to force the Net Framework used by an Azure Function v1 ? Is there any <strong>simple</strong> workaround in .Net Core 2.0  wihtout storing the certificate as a file on the Function ?</p>""",azure-functions
14369093,Streaming Videos from Azure ( Blob or Media Services) <p>I have an MVC 4 website hosted in azure that needs  to upload a video and on a different page allow that uploaded video to be streamed back to a client player.</p>  <p>The first option allows the user to upload and encode the video (.mp4) The second option is I manually upload and encode the video and provide the url to the user.  </p>  <p>In either case  the video would be presented to the users on another page.</p>  <p>Im having a devil of a time trying to get this to work.  Any suggestions/working samples?</p>,azure-storage
22239345,Start Up Windows Server 2012 Virtual Machine in Windows Azure Automatically at 7AM <p>One of the virtual machines I have on Windows Azure only needs to be available 12 hours per day each weekday.  I am connecting to a database and running some analysis.  Considering they charge for compute hours  it would be nice if I wasn't charged for the time the VM is sitting idle.  I have found a method to auto shut down at a specific time  but I can't find a way to automatically start up the machine.</p>,azure-virtual-machine
53103896,"Azure Function - Publishing Failed - RequestTimeout <p>I have a basic Azure Function app. When I try to publish the app  I receive an error that says \error : The attempt to publish the ZIP file through https://... failed with HTTP status code RequestTimeout.\"".</p>  <p>This app is a .NET Standard app. I followed the instructions <a href=\""https://docs.microsoft.com/en-us/azure/azure-functions/functions-create-your-first-function-visual-studio#publish-the-project-to-azure\"" rel=\""nofollow noreferrer\"">here</a>. The difference is  my app has an Event Hub Trigger instead of the Http Trigger shown in the documentation. I don't understand why i'm getting a Timeout during deployment. I also don't know how to get past this.</p>  <p>What am I doing wrong?</p>  <p><strong>Update</strong></p>  <p>Here are the logs.</p>  <pre><code>1&gt;------ Build started: Project: MyProject.Functions  Configuration: Release Any CPU ------ 1&gt;MyProject.Functions -&gt; C:\\MyProject\\MyProject.Functions\\bin\\Release\\netcoreapp2.1\\bin\\MyProject.Functions.dll ========== Build: 1 succeeded  0 failed  0 up-to-date  0 skipped ==========   Publish Started   MyProject.Functions -&gt; C:\\MyProject\\MyProject.Functions\\bin\\Release\\netcoreapp2.1\\bin\\MyProject.Functions.dll   MyProject.Functions -&gt; C:\\MyProject\\MyProject.Functions\\obj\\Release\\netcoreapp2.1\\PubTmp\\Out\\   Publishing C:\\MyProject\\MyProject.Functions\\obj\\Release\\netcoreapp2.1\\PubTmp\\MyProject.Functions - 20181101105531356.zip to https://my-project.scm.azurewebsites.net/api/zipdeploy... C:\\Users\\me\\.nuget\\packages\\microsoft.net.sdk.functions\\1.0.23\\build\\netstandard1.0\\Microsoft.NET.Sdk.Functions.Publish.ZipDeploy.targets(42 5): error : The attempt to publish the ZIP file through https://my-project.scm.azurewebsites.net/api/zipdeploy failed with HTTP status code RequestTimeout. [C:\\MyProject\\MyProject.Functions\\MyProject.Functions.csproj] </code></pre>""",azure-functions
55260797,"Control Job Order in Azure DevOps Release Pipeline <p>I have a complicated release that spans multiple deployment groups and I am planning to use the 3rd party <a href=\https://github.com/jabbera/vsts-git-release-tag\"" rel=\""nofollow noreferrer\"">vsts-git-release-tag</a> extension to tag the release. Ideally  the entire release (all jobs) would succeed first before tagging the repository.</p>  <p>So I am trying to work out what the best way to accomplish that is. If this were a build pipeline rather than a deployment pipeline  it is clear I could just arrange them <a href=\""https://docs.microsoft.com/en-us/azure/devops/pipelines/process/multiple-phases?view=azure-devops&amp;tabs=yaml\"" rel=\""nofollow noreferrer\"">using <code>dependsOn</code></a>  as follows.</p>  <pre><code>jobs: - job: Deployment_Group_1   steps:   - script: echo hello from Deployment Group 1 - job: Deployment_Group_2   steps:   - script: echo hello from Deployment Group 2 - job: Tag_Repo   steps:   - script: echo this is where I would tag the Repo   dependsOn:   - Deployment_Group_1   - Deployment_Group_2 </code></pre>  <p>However  there doesn't seem to be equivalent functionality (at least currently) in release pipelines as specified <a href=\""https://docs.microsoft.com/en-us/azure/devops/pipelines/process/multiple-phases?view=azure-devops&amp;tabs=yaml\"" rel=\""nofollow noreferrer\"">in this document</a>.</p>  <blockquote>   <h2>Note</h2>      <p>Running multiple jobs in parallel is supported only in build pipelines at present. It is not yet supported in release pipelines.</p> </blockquote>  <p>Although it doesn't specifically mention the <code>dependsOn</code> feature  there doesn't seem to be a way to utilize it in release pipelines (correct me if I am wrong).</p>  <p>I realize I could probably create a separate stage containing a single job and task to create the Git tag  but that feels like a hack. <strong>Is there a better way to run a specific release job after all other release jobs have completed?</strong></p>""",azure-devops
50071264,"Automatically upload files in local directory to Azure Storage Explorer blob storage <p>I wrote Python code to upload files from a local directory to a blob container in Azure Storage Explorer  and am now trying to do this automatically (i.e. if there are files in the directory  they are automatically uploaded).  Is there any way I can do this? </p>  <pre><code>import os from azure.storage.blob import BlockBlobService from azure.storage.blob import ContentSettings   accountName = \accountName\"" ContainerSAS = \""SAS_Key\"" containerName = \""containerName\""  # Create reference to container using account name and SAS key try:     sas_service = BlockBlobService(account_name=accountName       sas_token=ContainerSAS) except Exception as e:     print(\""Error during SAS service creation. Details: {0}\"".format(e)) print(\""Created SAS service with account {0}\"".format(accountName))  # Upload files to container from path # directory_path = \""&lt; path to your directory &gt;\"" directory_path = \""F:/dat_files_test\"" for filename in os.listdir(directory_path):     print(filename)     blobName = filename     localFile = directory_path + \""/\"" + filename      try:         sas_service.create_blob_from_path(         containerName          blobName          localFile          content_settings=ContentSettings(content_type='DPS/dat')         )     except Exception as e:         print(\""Error during blob uploading. Details: {0}\"".format(e)) print(\""All files uploaded\"") </code></pre>""",azure-storage
56268770,"Specifying Dockefile Path in Azure Pipelines <p>We are trying to use Azure Pipelines to build Docker image for a Dot Net Core App. When setting up the pipeline if I check \default build context\"" will it automatically pick the Dockerfile from my root directory?</p>  <p>Dockerfile is currently in the root directory but I want to move the Dockerfile inside the api project. How do I setup the pipeline so the docker build command is executed from root directory but refer to Dockerfile inside the project?</p>  <p><a href=\""https://i.stack.imgur.com/xv57l.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/xv57l.png\"" alt=\""enter image description here\""></a></p>""",azure-devops
51852647,Is it possible to trigger an azure function on a random schedule? <p>I am creating an Azure function and would like it to run with a random delay between each run. I want the delay between each run to be randomly selected from the interval 10 - 20 minutes. For example  I want:</p>  <ul> <li>function run</li> <li>11 min delay</li> <li>function run</li> <li>17 min delay</li> <li>function run</li> <li>10 min delay</li> <li>function run</li> <li>20 min delay</li> <li>etc ...</li> </ul>  <p>Is this possible? Thanks.</p>,azure-functions
57485471,I'm having trouble triggering a build from a Git tag <p>I want to trigger a build when any of the following is true:</p>  <ul> <li>When there is a change to a particular branch (dev) <strong>and</strong> a subset of folders was modified (paths)</li> <li>When a git tag that matches a pattern (RC* or Release*) is set <strong>and</strong> a subset of folders was modified (paths)</li> </ul>  <p>When I add a <em>paths</em> statement to my yaml build template only my branch trigger fires. I am unable to trigger off of a tag. When I remove the <em>paths</em> statement both my branch and tag filters work.</p>  <p>What am I missing?</p>  <p>This triggers on branch = dev or tag is either RC* or Release*</p>  <pre><code>trigger:   branches:     include:       - dev   tags:     include:       - RC*       - Release* </code></pre>  <p>This triggers on branch = dev only.</p>  <pre><code>trigger:   branches:     include:       - dev   tags:     include:       - RC*       - Release*   paths:     include:       - /site/ </code></pre>,azure-devops
53206761,"Displaying Pdf from azure blob storage <p>I'm trying to get a pdf file displayed on my page. The pdf file is located as a blob on azure. I'm getting the link to the blob itself from the server  that way i can grab the file directly from the storage instead of passing it through the server.</p>  <p>I set up a shared access signature(SAS key) because the container is protected.</p>  <p>Since I'm using angular 5 I need to sanitize my url which i'm doing.</p>  <pre><code> this.http.get(baseUrl + 'api/download/fileuri?sheetId=' + this.sheetId  { responseType: 'text' }).subscribe(result =&gt; {         this.url = result.toString();                     this.sanitizedUrl = this.sanitizer.bypassSecurityTrustResourceUrl(this.url);         console.log(this.sanitizedUrl);     }  error =&gt; console.error(error)); </code></pre>  <p>I'm then putting it inside a object  yet i either get nothing but a white page or i get the following error.</p>  <pre><code>&lt;object [data]=\sanitizedUrl\"" type=\""application/pdf\"" style=\""width:100%; height:100vh\""&gt;&lt;/object&gt; </code></pre>  <p><a href=\""https://i.stack.imgur.com/a0yGd.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/a0yGd.png\"" alt=\""enter image description here\""></a></p>  <p>I set up the following in azure:</p>  <p><a href=\""https://i.stack.imgur.com/TH3zM.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/TH3zM.png\"" alt=\""enter image description here\""></a></p>  <p>The weirdest part is: I can grab that file but just inputting that link  it just starts downloading it. But the moment i try to access it from the object  it throws that error. So the link is correct and it works. It's just whenever i try to access it from within the page..</p>""",azure-storage
46344983,How many access policies can I create and add on the same one Azure container? <p>I didn't find the answer by search. I thought I should be able to create many stored access policies on one container (at least thousands). But by tests  my program can only add up to 5 policies on one container. </p>  <p>Then I tried Microsoft Azure Storage Explorer  it also has this restriction  can add only up to 5. But I cannot find any description about this. Is there any way to remove this restriction? Thanks.</p>,azure-storage
11419260,"Azure queue issue <blockquote>   <p><strong>Possible Duplicate:</strong><br>   <a href=\https://stackoverflow.com/questions/11418143/azure-queues-windows-phone\"">Azure queues Windows Phone</a>  </p> </blockquote>    <p>There are a lot of example how to add message into Queue on Windows Phone 7. But there are no examples how to get message. As I can understand there are slightly different procedure than windows console app to get that message  could anyone write couple of lines how to Pop message from Azure queue on WP7.</p>  <pre><code>IStorageCredentials credentials = new StorageCredentialsAccountAndKey(\""accountName\""  \""accountKey\""); var client = new CloudQueueClient(\""http://myaccount.queue.core.windows.net/queue1\""  credentials); var q = client.GetQueueReference(\""queueName\"");  q.GetMessage(); &lt; --- Problematic line  this method does not have RETURN Type. </code></pre>""",azure-storage
36095039,Remotely run .exe in Azure Virtual Machine from ASP.Net web app <p>I have created a C# console app that runs on an Azure virtual machine. The problem is this needs to be executed by a user from a web app because the timing of the data pull is restricted to a narrow window and is somewhat random (at the moment I am going on to the virtual machine and running it myself). </p>  <p>So  in short  I would like to be able to make a call to an Azure Virtual Machine from an ASP.Net web app  also hosted in Azure. I also would like to pass in a parameter to that .exe file and get it to run.</p>,azure-virtual-machine
41137623,Azure Function Firewall <p>I'm building a very lightweight API using Azure Functions  one thing I'm concerned about is abuse of the functions.  What's to stop someone hammering a single method and causing my costs to escalate? Are there any ways I can blacklist IP address' if they start acting suspicious?</p>  <p>I have a last resort of looking up the IP in Table Storage  but I'd ideally like to block the IP before it even makes it to the function  is this possible? (Programatically)</p>  <p>Nick.</p>,azure-functions
49153718,How to prepare a windows vm so that it`s os disk can be used to provision other vms <p>I am using create_option as from_image to create new vm and passing the old vhd url in it but it is not successfully provisioned.</p>  <p>What steps i need to follow to make it work ?</p>  <p>My vm is in azure from whose os disk i want to create new vms.</p>,azure-virtual-machine
53909417,"Azure Function V2 - Error :The connection with the server was terminated abnormally <p>I have developed the function app v2 with Service bus trigger - <a href=\https://oneprofilesyncappeus.azurewebsites.net\"" rel=\""nofollow noreferrer\"">https://oneprofilesyncappeus.azurewebsites.net</a> and deployed to the production three weeks back and seeing this issue being logged from 22nd Dec in the App insight. As per the error message and stack trace I see this error happening in the Azure function module well before message is received in my programming module.</p>  <p>Error Message:</p>  <pre><code>Error while copying content to a stream. The write operation failed  see inner exception.  Error 12030 calling WinHttpWriteData  'The connection with the server was terminated abnormally'. </code></pre>  <p>Stack Trace</p>  <pre><code>System.Net.Http.HttpRequestException: at System.Net.Http.HttpContent+d__47.MoveNext (System.Net.Http  Version=4.2.1.0  Culture=neutral  PublicKeyToken=b03f5f7f11d50a3a) at System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw (System.Private.CoreLib  Version=4.0.0.0  Culture=neutral  PublicKeyToken=7cec85d7bea7798e) at System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess (System.Private.CoreLib  Version=4.0.0.0  Culture=neutral  PublicKeyToken=7cec85d7bea7798e) at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification (System.Private.CoreLib  Version=4.0.0.0  Culture=neutral  PublicKeyToken=7cec85d7bea7798e) at System.Runtime.CompilerServices.ConfiguredTaskAwaitable+ConfiguredTaskAwaiter.GetResult (System.Private.CoreLib  Version=4.0.0.0  Culture=neutral  PublicKeyToken=7cec85d7bea7798e) at System.Net.Http.WinHttpHandler+d__131.MoveNext (System.Net.Http  Version=4.2.1.0  Culture=neutral  PublicKeyToken=b03f5f7f11d50a3a) at System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw (System.Private.CoreLib  Version=4.0.0.0  Culture=neutral  PublicKeyToken=7cec85d7bea7798e) at System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess (System.Private.CoreLib  Version=4.0.0.0  Culture=neutral  PublicKeyToken=7cec85d7bea7798e) at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification (System.Private.CoreLib  Version=4.0.0.0  Culture=neutral  PublicKeyToken=7cec85d7bea7798e) at System.Runtime.CompilerServices.ConfiguredTaskAwaitable+ConfiguredTaskAwaiter.GetResult (System.Private.CoreLib  Version=4.0.0.0  Culture=neutral  PublicKeyToken=7cec85d7bea7798e) at System.Net.Http.WinHttpHandler+d__105.MoveNext (System.Net.Http  Version=4.2.1.0  Culture=neutral  PublicKeyToken=b03f5f7f11d50a3a) at System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw (System.Private.CoreLib  Version=4.0.0.0  Culture=neutral  PublicKeyToken=7cec85d7bea7798e) at System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess (System.Private.CoreLib  Version=4.0.0.0  Culture=neutral  PublicKeyToken=7cec85d7bea7798e) at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification (System.Private.CoreLib  Version=4.0.0.0  Culture=neutral  PublicKeyToken=7cec85d7bea7798e) at System.Runtime.CompilerServices.ConfiguredTaskAwaitable`1+ConfiguredTaskAwaiter.GetResult (System.Private.CoreLib  Version=4.0.0.0  Culture=neutral  PublicKeyToken=7cec85d7bea7798e) at System.Net.Http.DiagnosticsHandler+d__2.MoveNext (System.Net.Http  Version=4.2.1.0  Culture=neutral  PublicKeyToken=b03f5f7f11d50a3a) Inner exception System.IO.IOException handled at System.Net.Http.HttpContent+d__47.MoveNext: at System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw (System.Private.CoreLib  Version=4.0.0.0  Culture=neutral  PublicKeyToken=7cec85d7bea7798e) at System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess (System.Private.CoreLib  Version=4.0.0.0  Culture=neutral  PublicKeyToken=7cec85d7bea7798e) at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification (System.Private.CoreLib  Version=4.0.0.0  Culture=neutral  PublicKeyToken=7cec85d7bea7798e) at System.Runtime.CompilerServices.ConfiguredValueTaskAwaitable+ConfiguredValueTaskAwaiter.GetResult (System.Private.CoreLib  Version=4.0.0.0  Culture=neutral  PublicKeyToken=7cec85d7bea7798e) at System.Net.Http.HttpContent+d__47.MoveNext (System.Net.Http  Version=4.2.1.0  Culture=neutral  PublicKeyToken=b03f5f7f11d50a3a) Inner exception System.Net.Http.WinHttpException handled at System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw: </code></pre>  <p>There two instance of function deployed in West US and East US and i see this exception being occurred only in East US although i don't see any CPU spike or configuration change between these two app service.</p>""",azure-functions
5412959,Azure Table Complex Data Best Practices <p>I'm working on a research project that needs to store complex data as entities in an Azure Table. The entities for the table are cells that contains many geometric points and lines  with references to parents and so on. </p>  <p>Unless I am mistaken  an entity can only contain simple types (string  int  bool  etc) but nothing like List. I'm working around this in the meantime by just serializing the entire structure and converting that to a base64 string and having the entity consist of just this string  as well as some other flags.</p>  <p>Now that is a ludicrous approach in the long run  but that hack will have to do for now until a more responsible/appropriate method is deployed.</p>  <p>What would the best practices be for complex data types and Azure? Write many blobs out and keep track of them with a table?</p>,azure-storage
54274697,"RabbitMQ container not reachable in Azure Web App for Containers <p>I have following docker-compose content:</p>  <pre><code>version: '3.4'  services:   reporting.service:     image: xxx.azurecr.io/beta/reporting.service     environment:       - ASPNETCORE_ENVIRONMENT=Docker     ports:       - \5003:80\""     messaging.bus:     image: rabbitmq:3-management     environment:       - RABBITMQ_DEFAULT_USER=user       - RABBITMQ_DEFAULT_PASS=user       - RABBITMQ_DEFAULT_VHOST=test     links:       - reporting.service     ports:       - \""15672\""       - \""5672\""    web.frontend:     image: xxx.azurecr.io/beta/web.frontend     ports:       - \""3000:80\"" </code></pre>  <p>When running above locally on my machine using docker everything works fine and my reporting.service is able to connect to the messaging.bus (RabbitMQ) without any problem.</p>  <p>Connection string looks something like this:</p>  <pre><code>\""EventBus\"": {     \""ConnectionString\"": \""amqp://user:user@messaging.bus:5672/test\""   }  </code></pre>  <p>When I push my images to Azure container registry and try to use it in Azure web app for containers then following exception is thrown in reporting.service container:</p>  <blockquote>   <p>RabbitMQ.Client.Exceptions.BrokerUnreachableException: None of the   specified endpoints were reachable ---> System.AggregateException: One   or more errors occurred. (Connection failed) --->   RabbitMQ.Client.Exceptions.ConnectFailureException: Connection failed   ---> System.Net.Internals.SocketExceptionFactory+ExtendedSocketException:   No such device or address</p> </blockquote>  <p>FYI  I implemented Polly retry policy in the reporting.service when connecting to the RabbitMQ so that code is executed multiple times in case of broker not available. To make sure that RabbitMQ container is up and running (which I confirmed also looking at the logs).</p>  <p>What I'm doing wrong? Why I'm not able to see rabbitMq instance from other containers?</p>  <p>Thanks for the help!</p>""",azure-web-app-service
56633533,"Publish fails - can't understand what to do <p>VS2017 15.9.13 and Azure Functions and Web Jobs Tools 15.10.2059.23219</p>  <p>Project builds but always fails to publish with these errors. Is this a bug or something I'm doing? This is a vanilla File New HTTP function - I haven't changed anything.</p>  <pre><code>C:\\Program Files\\dotnet\\sdk\\2.1.507\\Sdks\\Microsoft.NET.Sdk.Publish\\build\\netstandard1.0\\PublishTargets\\Microsoft.NET.Sdk.Publish.MSDeploy.targets(139 5): error : Web deployment task failed. (Web Deploy experienced a connection problem with the server and had to terminate the connection.  Contact your server administrator if the problem persists.  Learn more at: http://go.microsoft.com/fwlink/?LinkId=221672#ERROR_CONNECTION_TERMINATED.) [C:\\Users\\adm_someuser\\source\\repos\\FunctionApp1\\FunctionApp1\\FunctionApp1.csproj] C:\\Program Files\\dotnet\\sdk\\2.1.507\\Sdks\\Microsoft.NET.Sdk.Publish\\build\\netstandard1.0\\PublishTargets\\Microsoft.NET.Sdk.Publish.MSDeploy.targets(139 5): error :  [C:\\Users\\adm_someuser\\source\\repos\\FunctionApp1\\FunctionApp1\\FunctionApp1.csproj] C:\\Program Files\\dotnet\\sdk\\2.1.507\\Sdks\\Microsoft.NET.Sdk.Publish\\build\\netstandard1.0\\PublishTargets\\Microsoft.NET.Sdk.Publish.MSDeploy.targets(139 5): error : Web Deploy experienced a connection problem with the server and had to terminate the connection.  Contact your server administrator if the problem persists.  Learn more at: http://go.microsoft.com/fwlink/?LinkId=221672#ERROR_CONNECTION_TERMINATED. [C:\\Users\\adm_someuser\\source\\repos\\FunctionApp1\\FunctionApp1\\FunctionApp1.csproj] C:\\Program Files\\dotnet\\sdk\\2.1.507\\Sdks\\Microsoft.NET.Sdk.Publish\\build\\netstandard1.0\\PublishTargets\\Microsoft.NET.Sdk.Publish.MSDeploy.targets(139 5): error : Unexpected end of file has occurred. The following elements are not closed: results. Line 1  position 550. [C:\\Users\\adm_someuser\\source\\repos\\FunctionApp1\\FunctionApp1\\FunctionApp1.csproj]   Find all \\""error\""\""  Find Results 1  Current Document   (1084):1&gt;  Task \""Error\"" skipped  due to false condition; ( '$(_InvalidConfigurationError)' == 'true' ) was evaluated as ( '' == 'true' ).   (1097):1&gt;  Task \""Error\"" skipped  due to false condition; ('$(OutDir)' != '' and !HasTrailingSlash('$(OutDir)')) was evaluated as ('bin\\Release\\netstandard2.0\\' != '' and !HasTrailingSlash('bin\\Release\\netstandard2.0\\')).   (1098):1&gt;  Task \""Error\"" skipped  due to false condition; ('$(BaseIntermediateOutputPath)' != '' and !HasTrailingSlash('$(BaseIntermediateOutputPath)')) was evaluated as ('C:\\Users\\adm_someuser\\source\\repos\\FunctionApp1\\FunctionApp1\\obj\\' != '' and !HasTrailingSlash('C:\\Users\\adm_someuser\\source\\repos\\FunctionApp1\\FunctionApp1\\obj\\')).   (1099):1&gt;  Task \""Error\"" skipped  due to false condition; ('$(IntermediateOutputPath)' != '' and !HasTrailingSlash('$(IntermediateOutputPath)')) was evaluated as ('obj\\Release\\netstandard2.0\\' != '' and !HasTrailingSlash('obj\\Release\\netstandard2.0\\')).   (1100):1&gt;  Task \""Error\"" skipped  due to false condition; ( '$(_InitialMSBuildProjectExtensionsPath)' != '' And '$(MSBuildProjectExtensionsPath)' != '$(_InitialMSBuildProjectExtensionsPath)' ) was evaluated as ( 'C:\\Users\\adm_someuser\\source\\repos\\FunctionApp1\\FunctionApp1\\obj\\' != '' And 'C:\\Users\\adm_someuser\\source\\repos\\FunctionApp1\\FunctionApp1\\obj\\' != 'C:\\Users\\adm_someuser\\source\\repos\\FunctionApp1\\FunctionApp1\\obj\\' ).   Matching lines: 5 </code></pre>  <p>csproj</p>  <pre><code>&lt;Project Sdk=\""Microsoft.NET.Sdk\""&gt;   &lt;PropertyGroup&gt;     &lt;TargetFramework&gt;netstandard2.0&lt;/TargetFramework&gt;     &lt;AzureFunctionsVersion&gt;v2&lt;/AzureFunctionsVersion&gt;   &lt;/PropertyGroup&gt;   &lt;ItemGroup&gt;     &lt;PackageReference Include=\""Microsoft.NET.Sdk.Functions\"" Version=\""1.0.13\"" /&gt;   &lt;/ItemGroup&gt;   &lt;ItemGroup&gt;     &lt;None Update=\""host.json\""&gt;       &lt;CopyToOutputDirectory&gt;PreserveNewest&lt;/CopyToOutputDirectory&gt;     &lt;/None&gt;     &lt;None Update=\""local.settings.json\""&gt;       &lt;CopyToOutputDirectory&gt;PreserveNewest&lt;/CopyToOutputDirectory&gt;       &lt;CopyToPublishDirectory&gt;Never&lt;/CopyToPublishDirectory&gt;     &lt;/None&gt;   &lt;/ItemGroup&gt; &lt;/Project&gt; </code></pre>""",azure-functions
52871846,"EventHubTrigger C# with eventData object does not work <p>after I followed the instructions on the following articles</p>  <p><a href=\https://docs.microsoft.com/en-us/azure/azure-functions/functions-create-first-azure-function\"" rel=\""nofollow noreferrer\"">https://docs.microsoft.com/en-us/azure/azure-functions/functions-create-first-azure-function</a></p>  <p><a href=\""https://docs.microsoft.com/en-us/azure/azure-functions/functions-bindings-event-hubs\"" rel=\""nofollow noreferrer\"">https://docs.microsoft.com/en-us/azure/azure-functions/functions-bindings-event-hubs</a></p>  <p>I have created an EventHubTrigger  which looks like this:</p>  <pre><code>using System;  public static void Run(string myEventHubMessage  ILogger log) { log.LogInformation($'C# Event Hub trigger function processed a message: {myEventHubMessage}'); } </code></pre>  <p>This did work without any problems  but since I do need additional meta information  I changed the code to the following (described in the second linked article):</p>  <pre><code>#r 'Microsoft.ServiceBus' using System.Text; using System; using Microsoft.ServiceBus.Messaging;  public static void Run(EventData myEventHubMessage  ILogger log) { log.LogInformation($'EnqueuedTimeUtc={myEventHubMessage.EnqueuedTimeUtc}'); log.LogInformation($'SequenceNumber={myEventHubMessage.SequenceNumber}'); log.LogInformation($'Offset={myEventHubMessage.Offset}'); }  </code></pre>  <p>But this code results in the following error messages (btw I have also tied to use the deprected TraceWriter instead of ILogger to exactly follow the article but this results in the same error)</p>  <pre><code>2018-10-11T14:22:24.814 [Error] run.csx(1 1): error CS0006: Metadata file 'Microsoft.ServiceBus' could not be found  2018-10-11T14:22:24.903 [Error] run.csx(4 17): error CS0234: The type or namespace name 'ServiceBus' does not exist in the namespace 'Microsoft' (are you missing an assembly reference?)  </code></pre>  <p>My question is now  does anyone have a clue what to do in order to get this small piece of code running?</p>  <p>Of course it has to have something to do with the assemblies but the aricle states  that when working in the online portal-editor  there are no further steps to do .</p>  <p>Man thanks in advance</p>  <p>Felix</p>  <p>PS:</p>  <p>host.json :</p>  <pre><code>{    \""version\"": \""2.0\""  } </code></pre>  <p>Content of extensions.csproj is:</p>  <pre><code>&lt;Project Sdk=\""Microsoft.NET.Sdk\""&gt;    &lt;PropertyGroup&gt;      &lt;TargetFramework&gt;netstandard2.0&lt;/TargetFramework&gt;      &lt;WarningsAsErrors /&gt;    &lt;/PropertyGroup&gt;    &lt;ItemGroup&gt;      &lt;PackageReference Include=\""Microsoft.Azure.WebJobs.Extensions.EventHubs\"" Version=\""3.0.0\"" /&gt;      &lt;PackageReference Include=\""Microsoft.Azure.WebJobs.Extensions.ServiceBus\"" Version=\""3.0.0\"" /&gt;      &lt;PackageReference Include=\""Microsoft.Azure.WebJobs.Script.ExtensionsMetadataGenerator\"" Version=\""1.0.1\"" /&gt;    &lt;/ItemGroup&gt;  &lt;/Project&gt; </code></pre>""",azure-functions
51934951,"How do I Get rid of \MyFirstProject\"" <p>I have VS 2017 Pro and have a number of projects in the default path C:\\Users\\jjacobs\\Documents\\Visual Studio 2017\\Projects\\</p>  <p>I just started Team Source from my company MSDN subscription. I chose Team Services rather then GitHub. My last version control system was Visual Source Safe. VSTS is totally alien to me.</p>  <p>I have a worthless project in VSTS called MyFirstProject. How do I remove it? Thank you.</p>""",azure-devops
57060298,Is it possible to load-balance traffic between IIS on an Azure VM and an Azure App Service? <p>I have a web application that is currently running on IIS in 3 Azure VMs.  I have been working to make my application App-Services friendly  but would like to test the migration to App-Services in a safe / controlled environment.</p>  <p>Would it be possible to spin up the App-Service and use an Azure Load Balancer to redirect a percentage of traffic off the VM and onto the App-Service?</p>  <p>Is there any other technology that would help me get there?</p>,azure-virtual-machine
48399429,"2-step authentication to Gmail from Azure App service <p>I have a Spring boot application run on Azure App Service  from which I want to send emails to users.</p>  <p>I can already do that with a gmail account I created myself  I just needed to turn on \allow less secure apps\"" feature.</p>  <p>However  I'm required to use another gmail account which belongs to a organization and thus is forced to use 2-step verification as per the organization policy.</p>  <p>Is it possible to complete the 2-step verification process from Azure's App service? What other options do I have?</p>""",azure-web-app-service
41455568,"What is the Azure Resource Manager equivalent of VIP Swap? <p>Azure classic Cloud Services come with a built-in load balancer that allows a fast VIP swap from production to staging  and vice versa.  What equivalent is provided by Azure Resource Manager?  I can use DNS  but then I have the TTL delay.</p>  <p>I want the fast swap because my back-end servers are stateful and cannot process the same data in both staging and production without overwriting each other.  In my current system  out-of-date connections (e.g. because of HTTP keep-alive) are rejected and a reload is forced  forcing fresh connections.</p>  <p>I guess I might be able to do it using Azure Application Gateway  but it is not <a href=\https://docs.microsoft.com/en-us/azure/application-gateway/application-gateway-introduction\"" rel=\""nofollow noreferrer\"">listed as one of its features</a>.</p>""",azure-virtual-machine
57370170,"Azure Virtual Machine - Rest API calls are not working <p>We are developing a app on azure virtual machine and the VM has ngnix installed with TLS version 1.2. The app consists of two action which performs salesforce and office365 oauth flow. The app worked pretty fine on local and azure app service too.</p>  <p><strong>Problem</strong></p>  <p>For some reason  we are moving the app to azure VM. Here is the problem  after oauth the flow returns a code and we need to generate the access_token using that code through a https request to office365 endpoint. The endpoint response is either timeout or Error Read ECONNRESET.</p>  <p><strong>Analysis</strong></p>  <p>The only working URLs </p>  <ol> <li><a href=\http://169.254.169.254/metadata/identity/oauth2/token?api-version=2018-02-01&amp;resource=https%3A%2F%2Fvault.azure.net\"" rel=\""nofollow noreferrer\"">http://169.254.169.254/metadata/identity/oauth2/token?api-version=2018-02-01&amp;resource=https%3A%2F%2Fvault.azure.net</a></li> <li><a href=\""https://myapp.vault.azure.net/secrets/\"" rel=\""nofollow noreferrer\"">https://myapp.vault.azure.net/secrets/</a>{Secret-Name}?api-version=2016-10-01</li> </ol>  <p>Both the above is used to fetch the access token and key vault secrets. Luckily  this is working pretty fine and I am able to get all the secrets from azure key vault.</p>  <p>But the below urls are either no response timeout or Error: Read ECONNRESET</p>  <ol> <li><a href=\""https://login.microsoftonline.com/\"" rel=\""nofollow noreferrer\"">https://login.microsoftonline.com/</a>{Tenant-Id}/oauth2/v2.0/token</li> <li><a href=\""https://test.salesforce.com/services/oauth2/token\"" rel=\""nofollow noreferrer\"">https://test.salesforce.com/services/oauth2/token</a></li> </ol>  <p>I’ve also tried other public or fake rest APIs like </p>  <ol> <li><a href=\""https://reqres.in/\"" rel=\""nofollow noreferrer\"">https://reqres.in/</a></li> <li><a href=\""https://jsonplaceholder.typicode.com/\"" rel=\""nofollow noreferrer\"">https://jsonplaceholder.typicode.com/</a></li> </ol>  <p>None of them seems to be working. Does anyone faced this kind of issue?</p>""",azure-virtual-machine
54857396,Deploying ASP.NET web project to Azure gives OutputPath error <p>I am receiving the following error when trying to deploy a web project in Azure:</p>  <blockquote>   <p>Invalid restore input. Missing required property 'OutputPath' for   project type 'PackageReference'.</p> </blockquote>  <p>The project was created in VS2017 which consists of a main web project and two DLL projects. The web project references the two DLL projects. I have added the project valuable in the App Settings so it will build the correct project for deployment.</p>  <p>I am not sure why I am getting the above error. I suspect that the DLL projects are not being compiled and referenced to the web project. But sure how to define that relationship in Azure Web Services. If anyone can help thank you in advance.</p>,azure-web-app-service
7580649,EF with Azure - Mixing SQL Server and Windows Azure Storage <p>I want to use two different data sources in my <strong>Azure project</strong>:</p>  <ul> <li>a <strong>SQL Server</strong> that contains <strong>basic partial info</strong> regarding an item (allows indexable data and spatial search)</li> <li>a <strong>Windows Azure Storage</strong> that contains <strong>full remaining info</strong> regarding an item (retrieved by key)</li> </ul>  <p>In this way I can <em>combine the powerful of SQL Server with the easy scalability of Windows Azure Storage</em>.</p>  <p>Imagine this Domain POCO class:</p>  <pre><code>class Person {    string Id { get; set; }    string Name { get; set; }    byte[] Picture { get; set; }    string Biography { get; set; } } </code></pre>  <p>I would like to use Entity Framework with fluent mapping to let EF understand that the properties <strong>Picture and Biography must be loaded from Windows Azure Storage</strong> (table  blob) instead of SQL Server (possibly Lazy loaded).</p>  <p>There's a way with EF (or NHibernate) to do this or I have to implement my own ORM strategy?</p>  <p>Thanks</p>,azure-storage
14851640,"Azure DiagnosticsMonitorTraceListener not working <p>Azure is starting to do my nut  I am trying to get diagnostics tracing working and have followed various guides (all pretty much say the same thing). I now can't debug locally (I get errors) and RDP doesn't seem to want to connect. I have the following in the web config:</p>  <pre><code> &lt;system.diagnostics&gt; &lt;trace&gt;   &lt;listeners&gt;     &lt;add type=\Microsoft.WindowsAzure.Diagnostics.DiagnosticMonitorTraceListener  Microsoft.WindowsAzure.Diagnostics  Version=1.8.0.0  Culture=neutral  PublicKeyToken=31bf3856ad364e35\"" name=\""AzureDiagnostics\""&gt;       &lt;filter type=\""\"" /&gt;     &lt;/add&gt;   &lt;/listeners&gt; &lt;/trace&gt; </code></pre>  <p></p>  <p>And then this in the webrole.cs:</p>  <pre><code>public override bool OnStart()     {         var diagnostics = DiagnosticMonitor.GetDefaultInitialConfiguration();          diagnostics.Logs.ScheduledTransferLogLevelFilter = LogLevel.Undefined;         diagnostics.Logs.ScheduledTransferPeriod = TimeSpan.FromMinutes(1);         diagnostics.Logs.BufferQuotaInMB = 10;          CloudStorageAccount account = CloudStorageAccount.Parse(             RoleEnvironment.GetConfigurationSettingValue(\""Microsoft.WindowsAzure.Plugins.Diagnostics.ConnectionString\""));          DiagnosticMonitor.Start(account  diagnostics);          return base.OnStart();     } </code></pre>  <p>And this in the service definition file:</p>  <pre><code>&lt;Imports&gt;   &lt;Import moduleName=\""Diagnostics\"" /&gt;   &lt;Import moduleName=\""RemoteAccess\"" /&gt; &lt;/Imports&gt; </code></pre>  <p>And this in the service config file:</p>  <pre><code>&lt;ConfigurationSettings&gt;   &lt;Setting name=\""Microsoft.WindowsAzure.Plugins.Diagnostics.ConnectionString\"" value=\""DefaultEndpointsProtocol=https;AccountName=&lt;snip&gt;;AccountKey=&lt;snip&gt;\"" /&gt; </code></pre>  <p>I don't get any errors when the site is deployed  I tried a text listener locally which worked fine but I get nothing in table storage on Azure. This has worked before but I have since moved the deployment to another subscription and storage account. Because of my RDP problems  I can't even see if various files are created locally on the instance and I don't know what files to check for anyway!</p>  <p>Please help!</p>""",azure-storage
42378987,Configure CORS for Azure Functions Local Host <p>I'm testing an Azure Functions app locally with the Azure Functions CLI tooling. Is there any way I can configure CORS settings for the local host? </p>,azure-functions
51947804,Azure VM and AD Setup <p>Kindly let me know </p>  <p>Setup the Virtual machine - configure DHS  TCP/IP  Firewall setting </p>  <p>Map to Virtual Network and Subnet</p>  <p>create a vm in other region and set up the Activie directly to setup accces the vm based on user group </p>  <p>Access both VM and files in the vms based on  AD Settings Configure Apps based on AD Settings</p>,azure-virtual-machine
17927792,"Azure Table Storage: Same Query on Same Data returns different results <p><strong>Background Information:</strong></p>  <ol> <li>Using Azure Table Storage (not SQL Azure)</li> <li>I have a table called Reservations with a PK: Int (Id of Person/Organization making Reservation); RK: String (format of -)</li> <li>The query that is seen below does a compare (RowKey >= EntityName and RowKey &lt;= EntityNamea) so that we can get all rows that have a RowKey of a specific entity type as character \a\"" is less than \""-\"" in ASCII</li> <li>I'm running reports on reservations that have happened and reservations that are upcoming for different date ranges along with some other criteria based on other attributes.</li> <li>The table consists of roughly 5k-10k records</li> </ol>  <p><strong>Query on Azure taken from Fiddler:</strong></p>  <p><code>https://&lt;domain&gt;.table.core.windows.net/ReservationEntity()?$filter=(((((RowKey%20ge%20'ReservationEntity')%20and%20(RowKey%20lt%20'ReservationEntitya'))%20and%20(StartTime%20ge%20datetime'2013-07-31T00%3A00%3A00'))%20and%20(StartTime%20le%20datetime'2013-09-01T23%3A59%3A59'))%20and%20(Status%20eq%20'Pending'))%20and%20(PartyId%20eq%204)</code></p>  <p><strong>My Question:</strong></p>  <p>I run this query multiple times against the same table which contains the same data.  The table has at least 5k records and no more than 10k records as listed above.  When I run this query I get the following results: 12  19  35  35...and then it stays at 35 which is the correct amount. Is there something that I'm not understanding about TableStorage for this to be happening?  Are there any particular settings that I need to be paying attention to?</p>""",azure-storage
56500259,"Azure Function BlobTrigger fires  but blob not found <p>I finally reproduced this issue with the code below. I am simply triggering a durable function with a blob trigger  and in one of the activity functions I read the blob.  BUT... when I read the blob I get an error that the blob doesn't exist.</p>  <p>Can someone explain what I am doing wrong here?</p>  <p>Code:</p>  <pre><code>[FunctionName(\BlobTrigger\"")] public static async void Trigger( [BlobTrigger(\""incoming-blob/{filename}\""  Connection = \""\"")]Stream myBlob  [OrchestrationClient]DurableOrchestrationClient starter  string filename  ILogger log) {     var instanceId = await starter.StartNewAsync(\""Orchestrator\""  filename); }  [FunctionName(\""Orchestrator\"")] public static async Task RunOrchestrator(     [OrchestrationTrigger] DurableOrchestrationContext context) {     var filename = context.GetInput&lt;string&gt;();     await context.CallActivityAsync(\""Read_Blob\""  filename); }  [FunctionName(\""Read_Blob\"")] public static async Task Activity(     [ActivityTrigger] string filename      [Blob(\""incoming-blob\"")] CloudBlobContainer container      ILogger log) {     var stream = new MemoryStream();     var blob = container.GetBlockBlobReference(filename);     await blob.DownloadToStreamAsync(stream);     //EXCEPTION THROWN AT ABOVE LINE.     stream.Dispose(); } </code></pre>""",azure-functions
44372440,"Improving CD Pipeline with Service fabric <p>We have web API's build on <em>service fabric</em> as well as some web projects in <em>web apps</em> in Azure. We want to easily swap back to the older version of the applications at our deployments and improve the CD pipeline.</p>  <p>So what come up with is <strong><em>creating an other app for staging for service fabric</em></strong> and route traffic whether that's gradually move users to the instance of the new version  or just flip a switch and send all your traffic to the new version all at once. </p>  <blockquote>   <p>We need a solution that would both support Webapps and Service fabric.   Providing patterns and experience for stateful services would be   great.</p> </blockquote>  <p><strong>References</strong></p>  <p><strong>A.Web Apps Slot swapping</strong></p>  <p><a href=\https://azure.microsoft.com/en-us/resources/videos/azure-websites-deployment-slots-for-staging-sites/\"" rel=\""nofollow noreferrer\"">https://azure.microsoft.com/en-us/resources/videos/azure-websites-deployment-slots-for-staging-sites/</a></p>  <p><strong>B.Continuous Delivery Pipeline</strong><a href=\""https://i.stack.imgur.com/CAxS2.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/CAxS2.png\"" alt=\""enter image description here\""></a></p>  <p>PS: I know that swaps don't make sense for stateful services. So rolling upgrades are must if we want to keep your data and keep it consistent.</p>""",azure-web-app-service
39720203,"ASP.Net Core fails to publish to Azure App Service <p>I have an ASP.Net Core web application (DotNetCore.1.0.1 VS2015Tools.Preview2.0.2) which I'm trying to publish to an Azure App Service via Visual Studio.</p>  <p>The Azure App Service and Resource Group are both completely new.</p>  <p>The publish process fails after several minutes on 'Executing command [\C:\\Program Files (x86)\\IIS\\Microsoft Web Deploy V3\\msdeploy.exe\""'. The 'web publish activity' log in Visual Studio says \""Retrying the sync because a socket error (10054) occurred. Retrying operation 'Serialization' on object sitemanifest (sourcePath) Attempt 1 of 100.\"" There are many more errors 100 but that is the first one.</p>  <p>I've had this problem a LOT with ASP.Net core and never really resolved it as it just seems to work occasionally.</p>  <p>Can anyone shed any light?</p>  <p>My Publish.ps1 is as follows</p>  <pre><code>[cmdletbinding(SupportsShouldProcess=$true)] param($publishProperties=@{}  $packOutput  $pubProfilePath)  # to learn more about this file visit https://go.microsoft.com/fwlink/?LinkId=524327  try{     if ($publishProperties['ProjectGuid'] -eq $null){         $publishProperties['ProjectGuid'] = '28343c8d-220f-435e-9b48-bf90a3b9068d'     }      $publishModulePath = Join-Path (Split-Path $MyInvocation.MyCommand.Path) 'publish-module.psm1'     Import-Module $publishModulePath -DisableNameChecking -Force      # call Publish-AspNet to perform the publish operation     Publish-AspNet -publishProperties $publishProperties -packOutput $packOutput -pubProfilePath $pubProfilePath } catch{     \""An error occurred during publish.`n{0}\"" -f $_.Exception.Message | Write-Error } </code></pre>""",azure-web-app-service
56472315,"What exactly is Response Time metric from App Service <p>Is it the same as \Time Taken (time-taken)\"" from IIS Logs as described <a href=\""https://forums.iis.net/post/1969130.aspx\"" rel=\""nofollow noreferrer\"">here</a>?</p>  <blockquote>   <p>Time-taken is the time it takes from when IIS receives the first byte in the request until it sends out the last byte in that request. This includes network time getting to the client (for nearly all cases if you have a page that is less than 2KB  I think  that is cached) so a slow network connection will have a longer network time and thus time taken.   The start time of when the first byte is received by IIS is the \""time\"" field and the finish time when IIS sends out that the last byte is the \""time\"" field + the \""time-taken\"" field</p> </blockquote>""",azure-web-app-service
47044705,"read file from Azure Blob Storage into Azure SQL Database <p>I have already tested this design using a local SQL Server Express set-up.</p>  <p>I uploaded several .json files to Azure Storage In SQL Database  I created an External Data source:</p>  <p><code>CREATE EXTERNAL DATA SOURCE MyAzureStorage   WITH     (TYPE = BLOB_STORAGE      LOCATION = 'https://mydatafilestest.blob.core.windows.net/my_dir     );</code></p>  <p>Then I tried to query the file using my External Data Source:</p>  <pre><code>select * from OPENROWSET  (BULK 'my_test_doc.json'  DATA_SOURCE = 'MyAzureStorage'  SINGLE_CLOB) as data </code></pre>  <p>However  this failed with the error message \Cannot bulk load. The file \""prod_EnvBlow.json\"" does not exist or you don't have file access rights.\""</p>  <p>Do I need to configure a DATABASE SCOPED CREDENTIAL to access the file storage  as described here? <a href=\""https://docs.microsoft.com/en-us/sql/t-sql/statements/create-database-scoped-credential-transact-sql\"" rel=\""nofollow noreferrer\"">https://docs.microsoft.com/en-us/sql/t-sql/statements/create-database-scoped-credential-transact-sql</a></p>  <p>What else can anyone see that has gone wrong and I need to correct?</p>""",azure-storage
46788924,Calling AAD Authenticated Azure function from Javascript without ADAL? No Access-control-allow-origin header is present <p>Is it possible to call an AAD authenticated Azure function from javascript without an auth library like ADAL and also without registering the client application with Microsoft?   </p>  <p>Getting this error:   <strong>No 'Access-Control-Allow-Origin' header is present on the requested resource. Origin</strong> '</p>  <p>Both the simple web client app and azure function are registered under the same AAD. Both have the azurewebsites.net domain.</p>  <p>What's the lightest web client we can have?  </p>,azure-functions
40613024,"Error indexing method FunctionName does not resolve to a value <p>Does anyone know why I'm getting this error? Here is my SendGrid output binding:</p>  <pre><code>{   \bindings\"": [     {       \""name\"": \""docId\""        \""type\"": \""queueTrigger\""        \""direction\"": \""in\""        \""queueName\"": \""movedocument\""        \""connection\"": \""cpoffice365_STORAGE\""     }      {       \""type\"": \""sendGrid\""        \""name\"": \""message\""        \""apiKey\"": \""&lt;MYSENDGRIDKEY&gt;\""        \""from\"": \""&lt;MYFROMEMAIL&gt;\""        \""direction\"": \""out\""     }   ]    \""disabled\"": false } </code></pre>  <p>My code compiles  but then it throws this error in the log:</p>  <pre><code>Microsoft.Azure.WebJobs.Host: Error indexing method 'Functions.&lt;MYFUNCTIONAME&gt;'. Microsoft.Azure.WebJobs.Host: '&lt;MYSENDGRIDKEY&gt;' does not resolve to a value. </code></pre>""",azure-functions
1576225,When hosting an azure MVC app  my web.config's appSettings collection is empty <p>Using MVC 1.0  and Azure July 2009 SDK</p>  <p>I have an MVC application that appears to be working in the azure test framework  except for the fact that my appSettings collection is empty when running there.  (But if I just run the web project on it's own  it's fine.)</p>  <p>Is there something special I need to do to access the web.config from Azure?</p>,azure-web-app-service
54945769,"Why is the ILogger injected in my Azure Function v2 missing the APPINSIGHTS_INSTRUMENTATIONKEY? <p>I have an Azure Function v2  like this:</p>  <pre><code>public sealed class FindAccountFunction {     private readonly IAccountWorkflow m_accountWorkflow;      public FindAccountFunction(ILogger&lt;FindAccountFunction&gt; logger)     {         m_logger = logger;     }      [FunctionName(\FindAccount\"")]     public async Task&lt;IActionResult&gt; Run(             [HttpTrigger(AuthorizationLevel.Function  \""GET\""  Route = \""v1/accounts/\"")] HttpRequest httpRequest)     {         // Do stuff.         m_logger.LogInformation(\""Duuuddde\"");     } } </code></pre>  <p>As described in a <a href=\""https://stackoverflow.com/questions/54876798/how-can-i-use-the-new-di-to-inject-an-ilogger-into-an-azure-function-using-iwebj\"">different question</a>  the logger is being injected:</p>  <pre><code>[assembly: WebJobsStartup(typeof(Startup))]  public sealed class Startup : IWebJobsStartup {     public void Configure(IWebJobsBuilder webJobsBuilder)     {         // Registers other services...          // -- UPDATE - The AddLogging must be called here --         webJobsBuilder.Services.AddLogging();     } } </code></pre>  <p>Then I trigger my function through an HTTP request and go to the Function's portal on Azure DevOps to see if the logs is actually printed:</p>  <p><a href=\""https://i.stack.imgur.com/faKZ5.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/faKZ5.png\"" alt=\""Azure Function&#39;s portal\""></a></p>  <p>I only see the logs indicating that the function ran successfully however I do not see my log.</p>  <p><strong>Question</strong></p>  <p>Why is the <code>ILogger</code> injected in my Azure Function v2 missing the <code>APPINSIGHTS_INSTRUMENTATIONKEY</code>?</p>  <p><strong>Update</strong></p>  <p>When I look at the injected <code>ILogger</code>  I can see that the InstrumentationKey of the Application Insights Provider is not set. The same applies for a ctor injected ILogger  but also for the injected <code>ILogger</code> in the Run method.</p>  <p><a href=\""https://i.stack.imgur.com/udf5A.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/udf5A.png\"" alt=\""Instrumentation key\""></a></p>  <p>For my local tests  the instrumentation key is declared in the <code>local.settings.json</code> file:</p>  <p><a href=\""https://i.stack.imgur.com/bayDH.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/bayDH.png\"" alt=\""local.settings.json\""></a></p>""",azure-functions
23139632,"Does Visual Studio Online support SOAP WorkItem change notification? <p>The reason I ask  is that I've set up a WCF service following the guidance out there (specifics below)  and set up a SOAP notification in Visual Studio Online and my service doesn't appear to be called.  IIS 8.5 Logs show no attempt to make contact with the service from VSO servers.</p>  <p>In case it IS supported  here are relevant bits to see if I have something set up wrong on the service side.</p>  <p><strong>WCF Service - .NET 4.5.1 hosted as an Azure WebRole</strong></p>  <p>Contract and Implementation</p>  <pre class=\lang-csharp prettyprint-override\""><code>[ServiceContract(Namespace = \""http://schemas.microsoft.com/TeamFoundation/2005/06/Services/Notification/03\"")] public interface IWorkItemSubscriber {     [OperationContract(Action = \""http://schemas.microsoft.com/TeamFoundation/2005/06/Services/Notification/03/Notify\"")]     [XmlSerializerFormat(Style = OperationFormatStyle.Document)]     void Notify(string eventXml  string tfsIdentityXml); }  // Note  I've tried w/ and w/out this Compatibility Attribute [AspNetCompatibilityRequirements(RequirementsMode = AspNetCompatibilityRequirementsMode.Allowed)] public class WorkItemSubscriber : IWorkItemSubscriber {     public void Notify(string eventXml  string tfsIdentityXml)     {         // Do stuff     } } </code></pre>  <p>Web.Config</p>  <pre class=\""lang-xml prettyprint-override\""><code>&lt;configuration&gt;   &lt;system.web&gt;     &lt;compilation debug=\""true\"" targetFramework=\""4.5.1\"" /&gt;     &lt;customErrors mode=\""Off\""/&gt;   &lt;/system.web&gt;    &lt;system.serviceModel&gt;     &lt;bindings&gt;       &lt;wsHttpBinding&gt;         &lt;binding name=\""noSecurity\""&gt;           &lt;security mode=\""None\"" /&gt;         &lt;/binding&gt;       &lt;/wsHttpBinding&gt;     &lt;/bindings&gt;      &lt;services&gt;       &lt;service name=\""VsoNotificationService.Wcf.WorkItemSubscriber\"" behaviorConfiguration=\""eventServiceBehavior\""&gt;         &lt;endpoint address=\""\"" binding=\""wsHttpBinding\"" bindingConfiguration=\""noSecurity\"" contract=\""VsoNotificationService.Wcf.IWorkItemSubscriber\"" /&gt;       &lt;/service&gt;     &lt;/services&gt;      &lt;behaviors&gt;       &lt;serviceBehaviors&gt;         &lt;behavior name=\""eventServiceBehavior\""&gt;           &lt;serviceMetadata httpGetEnabled=\""true\""/&gt;           &lt;serviceDebug includeExceptionDetailInFaults=\""true\""/&gt;         &lt;/behavior&gt;       &lt;/serviceBehaviors&gt;     &lt;/behaviors&gt;     &lt;serviceHostingEnvironment multipleSiteBindingsEnabled=\""true\"" /&gt;   &lt;/system.serviceModel&gt;   &lt;system.webServer&gt;     &lt;modules runAllManagedModulesForAllRequests=\""true\"" aspNetCompatibilityEnabled=\""true\"" /&gt; &lt;!-- note: I've tried w/ and w/out the aspNetCompatibilityEnabled attribute --&gt;   &lt;/system.webServer&gt; &lt;/configuration&gt; </code></pre>  <p><strong>Visual Studio Online Configuration</strong></p>  <p><img src=\""https://i.stack.imgur.com/FWTwC.png\"" alt=\""Screencap of VSO configuration\""></p>  <p>I've confirmed I can hit the service  via creating my own client and calling the service.  Whatever code I put in the method is executed  and if I do remote debugging via Visual Studio 2013 I'll hit the method's breakpoint.  So the service is up and running  I just don't see traffic from Visual Studio Online (via code breakpoint  code content  nor IIS Logs).  Makes me think that feature is not working there?</p>""",azure-devops
37878617,"Create a new iteration using TFS REST API <p>I think there is a problem with the new <a href=\https://www.visualstudio.com/docs/integrate/api/overview\"" rel=\""nofollow\"" title=\""TFS REST API\"">TFS REST API</a>. Let me explain :</p>  <p>Here is an example of a <strong>classification node</strong>  which is basically an  \""inactive\"" iteration (not shown with the other sprint in TFS) :</p>  <pre><code>{   \""id\"": 126391    \""name\"": \""Web\""    \""structureType\"": \""area\""    \""hasChildren\"": false    \""_links\"": {     \""self\"": {       \""href\"": \""https://fabrikam.visualstudio.com/DefaultCollection/6ce954b1-ce1f-45d1-b94d-e6bf2464ba2c/_apis/wit/classificationNodes/Areas/Web\""     }      \""parent\"": {       \""href\"": \""https://fabrikam.visualstudio.com/DefaultCollection/6ce954b1-ce1f-45d1-b94d-e6bf2464ba2c/_apis/wit/classificationNodes/Areas\""     }   }    \""url\"": \""https://fabrikam.visualstudio.com/DefaultCollection/6ce954b1-ce1f-45d1-b94d-e6bf2464ba2c/_apis/wit/classificationNodes/Areas/Web\"" } </code></pre>  <p>Pay attention to the \""id\"" field. It's not a <strong>TFS GUID</strong>  it's a basic id.</p>  <p>Now  here is what you need to send to the API to append your classification node to a team  which is the way to active your classification node as an <strong>iteration</strong> : </p>  <pre><code>POST https://{instance}/DefaultCollection/{project}/{team}/_apis/work/TeamSettings/Iterations?api-version={version}  \""{\\\""id\\\"":\\\""a589a806-bf11-4d4f-a031-c19813331553\\\""}\"" </code></pre>  <p>This is the problem ! You need the <strong>GUID</strong> of your classification node to append it to a team but there is no way to retrieve it...</p>  <p>Can someone explain me how is it possible ? Thanks in advance.</p>  <p><strong>EDIT 6/24/2016</strong> Here's what I retrieve when I'm asking for all the classification nodes :</p>  <pre><code>https://{...}/_apis/wit/classificationNodes/iterations?$depth=2 </code></pre>  <p><a href=\""http://i.stack.imgur.com/HzysA.png\"" rel=\""nofollow\"">Classification nodes tree</a></p>""",azure-devops
29177797,Windows Azure Multi-region VMs and SQL Server <p>I am moving my website to windows azure. majority of my users are from India and USA. the website uses a SQL Server database and file system where users can upload images and view them. </p>  <p>I'm thinking about creating 2 VMs one in West US and another one in Southeast Asia and use a traffic manager to load balance between my web servers  but I don't know how to set up the database and file share. can anyone help me? </p>,azure-virtual-machine
48421275,"Moved azure resource has disappeared <p>I just moved my WebApp from one subscription to another and now I can't find it in the azure portal.</p>  <p>However  I see that the web application still works.  It has not been deleted.</p>  <p>It is not listed in the result of the call to <code>Get-AzureRmResource</code>.</p>  <p>Do you have an idea to diagnose this problem?</p>  <h1>Update</h1>  <p>I found an error entry in the target Resource Group activity log:</p>  <pre><code>\properties\"": {     \""statusCode\"": \""Conflict\""      \""statusMessage\"": \""{\\\""error\\\"":     {\\\""code\\\"":\\\""ResourceMoveFailed\\\"" \\\""message\\\"":... </code></pre>  <p><strong>BUT</strong> my resource is not  either  in my old resource group !!!</p>""",azure-web-app-service
50284214,"Azure function complains of JS syntax error when syntax is valid <p>I have an Azure function defined in JS</p>  <pre><code>module.exports = async function (context  req) {     if (req.query.name || (req.body &amp;&amp; req.body.name)) {          // generate mock result         const mockChecker = new mockCheckBuild();         const result = await mockChecker.runAsync();          context.res = {             body: result         };     }     else {         context.res = {             status: 400              body: \Please pass a name on the query string or in the request body\""         };     }     context.done(); };  function mockCheckBuild() {    this.statuses = ['Failed'  'Complete'];     this.branchId = 808;     this.buildNumbers = ['0.1.1.1023'  '0.1.1.1024'  '0.1.1.1025'];     this.runAsync = async function() {       return new Promise(resolve =&gt;          setTimeout(() =&gt;             resolve({                 branchId: this.branchId                  latestBuild: this.statuses.randomElement()                  buildStatus: this.buildNumbers.randomElement()             })           2000)       );    };     return this; }  Array.prototype.randomElement = function() {     const index = Math.floor(Math.random() * this.length);     return this[index]; }; </code></pre>  <p>which I've run through numerous syntax validators that validate it is correct JavaScript. I will also note that the Azure syntax highlighter is highlighting words like <code>async</code> and <code>const</code>. </p>  <p>However  when I run it I get </p>  <blockquote>   <p>\""Exception while executing function: Functions.CheckLatestBuild -> One   or more errors occurred. ->   D:\\home\\site\\wwwroot\\CheckLatestBuild\\index.js:1\\n(function   (exports  require  module  __filename  __dirname) { module.exports =   async function (context  req) {\\n<br>   ^^^^^^^^\\n\\nSyntaxError: Unexpected token function\\n    at   createScript (vm.js:56:10)\\n    at Object.runInThisContext   (vm.js:97:10)\\n    at Module._</p> </blockquote>  <p>Any idea why? Or any advice on how to better investigate?</p>""",azure-functions
49298337,How to change time zone in Azure Virtual Machine? <p>How to change the time zone from UTC to Arabian Standard Time in Azure virtual machine running the windows server?</p>,azure-virtual-machine
34518912,"Node.js azure-storage TableService has no methods <p>I've been trying to connect to my Azure storage account  but I'm having some problems with the azure-storage module. Specifically  once I create a TableService object  the object only has a filter method on it. Two methods I've tried have been queryTables and createTableIfNotExist. For example  createTableIfNotExistreturns \TypeError: aztd.createTableIfNotExistis not a function\"". Source code is below.</p>  <pre><code>var azure = require('azure-storage'); var aztd = azure.createTableService(); var azseg = azure.TableUtilities.entityGenerator; console.log(\""AZSEG \"" + Object.getOwnPropertyNames(azseg).filter(function (p) { return typeof azseg[p] === 'function'; })); console.log(\""AZTD \"" + Object.getOwnPropertyNames(aztd).filter(function (p) { return typeof aztd[p] === 'function'; })); aztd.createTableIfNotExist('table1'  function (e  result  res) {     if (result) console.log('Table created'); }); </code></pre>  <p>I'm not getting any additional errors aside from the function not found. The console log returns the functions for both variables:</p>  <pre><code>AZSEG Entity Int32 Int64 Binary Boolean String Guid Double DateTime AZTD filter </code></pre>  <p>I can see the entityGenerator is created fine  but am I missing anything for the TableService?</p>""",azure-storage
54827271,MessagingEntityNotFoundException when peeking DLQ on azure service bus <p>The last two days I have started getting MessagingEntityNotFoundException when my code calls Microsoft.Azure.ServiceBus.Core.MessageReceiver.PeekAsync on dead letter queue message receiver. The code have not been changed before the exception started to occur  and have been running without problems for the last two months.</p>  <p>The full exception message is </p>  <pre><code>Microsoft.Azure.ServiceBus.MessagingEntityNotFoundException: A request handler with id '56216' was not found in the entity management node $management.  </code></pre>  <p>The code runs in a time triggered Azure Function. </p>  <p>The code for setting up the message receivers:</p>  <pre><code>    using Microsoft.Azure.ServiceBus;     using Microsoft.Azure.ServiceBus.Core;     using Microsoft.Azure.ServiceBus.Management;      public class DeadLetterQueueMonitor {        private static List&lt;MessageReceiver&gt; _messageReceivers;         private async Task&lt;List&lt;MessageReceiver&gt;&gt; GetMessageReceivers(ILogger logger)        {          if (_messageReceivers == null)          {             _messageReceivers = new List&lt;MessageReceiver&gt;();             var managementClient = new ManagementClient(ConnectionStrings.ServiceBusConnectionString);             var topics = await managementClient.GetTopicsAsync();              foreach (var topic in topics)             {                 var subscriptions = await managementClient.GetSubscriptionsAsync(topic.Path);                 _messageReceivers.AddRange(subscriptions.Select(subscription =&gt;                 {                     string entityPath = EntityNameHelper.FormatDeadLetterPath(EntityNameHelper.FormatSubscriptionPath(topic.Path  subscription.SubscriptionName));                      return new MessageReceiver(ConnectionStrings.ServiceBusConnectionString  entityPath);                 }));             }          }           _messageReceivers = _messageReceivers              .Select(r =&gt; r.IsClosedOrClosing ? new MessageReceiver(ConnectionStrings.ServiceBusConnectionString  r.Path) : r)              .ToList();           return _messageReceivers;       }    } </code></pre>  <p>Any suggestions for what might be wrong?</p>  <p>EDIT 25/2-2019 (as response to comments):</p>  <p>I am using the following Nuget packages:</p>  <pre><code>Microsoft.Azure.Amqp 2.3.0 Microsoft.Azure.ServiceBus 3.1.0 Microsoft.Azure.Services.AppAuthentication 1.0.3 </code></pre>  <p>I have added a little more context for the method that creates the MessageReceivers.</p>,azure-functions
43105689,"How to unmount an Azure File Share <p>I've got a Windows Server VM on Azure. I also have a File Share. According to MS  one can mount the drive using the following command:</p>  <pre><code>net use &lt;drive-letter&gt;: \\\\&lt;storage-account-name&gt;.file.core.windows.net\\&lt;share-name&gt; </code></pre>  <p>This does indeed work  which is surprising given it is from <a href=\https://docs.microsoft.com/en-us/azure/storage/storage-dotnet-how-to-use-files\"" rel=\""nofollow noreferrer\"">MS documentation</a>.</p>  <p>Unfortunately  the documentation makes no mention of how to unmount the storage...</p>  <p>Does anyone know how to do this? </p>""",azure-virtual-machine
44516322,"Add a new state to a User Story in VSTS <p>I'm trying to add a new state to the user story Work Item type in VSTS. To do this I follow the instructions outlined here:</p>  <p><a href=\https://www.visualstudio.com/en-gb/docs/work/process/customize-process-workflow\"" rel=\""nofollow noreferrer\"">https://www.visualstudio.com/en-gb/docs/work/process/customize-process-workflow</a></p>  <p>However  when I get the states page the \""+ New state\"" option is greyed out and I cannot click on it.  I am a member of the \""Project Collection Administrators\"".</p>  <p>Can anyone tell me how to enable the \""+ New state\"" button?</p>""",azure-devops
45231709,Azure Function Request Tracing <p>I have enabled Application Insights in my Azure Functions app and can now track the function invocations. However  many functions invoke other functions and I would like to see the entire function invocation for a request. In Application Insights I found request ids and invocation ids but did not find how the correlate.</p>  <p>Is this possible or do I need to build this myself?</p>,azure-functions
51494736,"Azure function v2. Cannot reference dll from nuget <p>I am testing how to write a simple azure function that updates an azure sql database. From VS2017 I made a new Cloud->Azure function v2 with netstandars 2.0. My code is the following:</p>  <pre><code>[FunctionName(\Activate\"")]     public static IActionResult Run([HttpTrigger(AuthorizationLevel.Anonymous  \""get\""  \""post\""  Route = null)]HttpRequest req  TraceWriter log)     {         log.Info(\""C# HTTP trigger function processed a request.\"");          string serialNumber = req.Query[\""SerialNumber\""];          try         {             var str = \""CONNECTION_STRING_FOR AZURE SQL\"";             using (SqlConnection conn = new SqlConnection(str))             {                 conn.Open();                 var text = $\""UPDATE CLIENT SET ACTIVATION_DATE = '2018-07-23 WHERE SERIAL_NUMBER='{serialNumber}'\"";                  using (SqlCommand cmd = new SqlCommand(text  conn))                 {                     // Execute the command and log the # rows affected.                     var rows = cmd.ExecuteNonQuery();                     log.Info($\""{rows} rows were updated\"");                 }             }         }         catch (Exception ex)         {             return new BadRequestObjectResult(ex.Message);         }          return serialNumber != null             ? (ActionResult)new OkObjectResult($\""Hello  {serialNumber}\"")             : new BadRequestObjectResult(\""error\"");     } </code></pre>  <p>It compiles and can be run locally from visual studio:</p>  <pre><code>Hosting environment: Production Content root path: C:\\Projects\\xxx\\bin\\Debug\\netstandard2.0 Now listening on: http://localhost:7071 Application started. Press Ctrl+C to shut down. [24/7/2018 8:50:48 πμ] Reading host configuration file 'C:\\Projects\\xxx\\bin\\Debug\\netstandard2.0\\host.json' [24/7/2018 8:50:48 πμ] Host configuration file read: [24/7/2018 8:50:48 πμ] {} [24/7/2018 8:50:48 πμ] Starting Host (HostId=xxx-1133968365  InstanceId=58079dab-xxx-4bb9-aaf5-f24xxx63d3c  Version=2.0.11651.0  ProcessId=11304  AppDomainId=1  Debug=False  ConsecutiveErrors=0  StartupCount=1  FunctionsExtensionVersion=) [24/7/2018 8:50:48 πμ] Unable to configure java worker. Could not find JAVA_HOME app setting. [24/7/2018 8:50:48 πμ] [24/7/2018 8:50:48 πμ] Could not configure language worker Java. [24/7/2018 8:50:48 πμ] [24/7/2018 8:50:49 πμ] Generating 1 job function(s) [24/7/2018 8:50:49 πμ] Found the following functions: [24/7/2018 8:50:49 πμ] ClientFunctions.Run [24/7/2018 8:50:49 πμ] [24/7/2018 8:50:49 πμ] Host initialized (1511ms) [24/7/2018 8:50:49 πμ] Host started (1616ms) [24/7/2018 8:50:49 πμ] Job host started Listening on http://localhost:7071/ Hit CTRL-C to exit...  Http Functions:          Activate: http://localhost:7071/api/Activate </code></pre>  <p>But if I access it through postman I get:</p>  <pre><code>[24/7/2018 8:52:58 πμ] Executing 'Activate' (Reason='This function was programmatically called via the host APIs.'  Id=30cff68d-b8db-446e-bd6d-407990524198) [24/7/2018 8:52:58 πμ] Executed 'Activate' (Failed  Id=30cff68d-b8db-446e-bd6d-407990524198) [24/7/2018 8:52:58 πμ] System.Private.CoreLib: Exception while executing function: Activate. Mik3UpdateFunctionNew: Could not load file or assembly 'System.Data.SqlClient  Version=4.4.0.0  Culture=neutral  PublicKeyToken=b03f5f7f11d50a3a'. Could not find or load a specific file. (Exception from HRESULT: 0x80131621). System.Private.CoreLib: Could not load file or assembly 'System.Data.SqlClient  Version=4.4.0.0  Culture=neutral  PublicKeyToken=b03f5f7f11d50a3a'. </code></pre>  <p>What I find strange is that each time I start VS2017 and debug the program  a window appears that says downloading azure functions cli tools 2.3.2.</p>  <p>Can someone suggest anything?  Thanks</p>""",azure-functions
46096235,"VSTS Task - Azure RM Service Reference <p>I'm working on VSTS Task which will populate input data from AzureRM. Anyone know help to find out the data binding reference (marked as xxxxxxx)? I would like to get data about automation account  but i wasn't able to find it. Many thanks.</p>  <pre><code>\inputs\"":[     {         \""name\"": \""ConnectedServiceName\""          \""type\"": \""connectedService:AzureRM\""          \""label\"": \""Azure RM Subscription\""          \""required\"": true          \""helpMarkDown\"": \""Azure Resource Manager subscription\""      }      {         \""name\"": \""ResourceGroupName\""          \""label\"": \""Resource Group\""          \""type\"": \""pickList\""          \""required\"": true          \""helpMarkDown\"": \""Provide the name of a resource group.\""          \""properties\"": {         \""EditableOptions\"": \""True\""     }      {         \""name\"": \""AutomationAccount\""          \""type\"": \""pickList\""          \""label\"": \""Automation Account Name\""          \""required\"": true          \""helpMarkDown\"": \""Select or Type Automation Account Name\""          \""properties\"": {             \""EditableOptions\"": \""True\""         }     } ]  \""dataSourceBindings\"": [     {         \""target\"": \""ResourceGroupName\""          \""endpointId\"": \""$(ConnectedServiceName)\""          \""dataSourceName\"": \""AzureResourceGroups\""     }      {         \""target\"": \""AutomationAccount\""          \""endpointId\"": \""$(ConnectedServiceName)\""          \""dataSourceName\"": \""xxxxxxxxxxxxxxxxx\""     }  ] </code></pre>""",azure-devops
35796292,"External domain in web app <p>After I got my domain CNAME changed to azure service  I have to associate the azure web app with the address. When I try to do it I get the exclamation mark indicating error  and when I try to check what it says  it does not display any information (not a single sign). Does anyone experienced similar problem  and can tell me what is happening.</p>  <p><img src=\https://i.stack.imgur.com/6EHvz.jpg\"" alt=\""Here I upload the screenshot that shows the problem\""></p>""",azure-web-app-service
29838712,"Azure Role Assignment for Get-AzureVM? <p>I would like to use <a href=\http://azure.microsoft.com/en-us/documentation/articles/role-based-access-control-configure/\"" rel=\""nofollow\"">Role-based access control</a> to give an account the ability to administer certain VMs. The VMs are in a resource group.</p>  <pre><code>New-AzureRoleAssignment -Mail user@mycompany.onmicrosoft.com -RoleDefinitionName Reader -ResourceGroupName somevms  New-AzureRoleAssignment -Mail user@mycompany.onmicrosoft.com -RoleDefinitionName 'Virtual Machine Contributor' -ResourceGroupName somevms </code></pre>  <p>It doesn't seem to work for me. In order for the user to successfully run commands like Get-AzureVM  I have to add them as a subscription <code>Co-administrator</code> which is not what I want to do.</p>  <p>Is it possible to allow a user to do a <code>Get-AzureVM</code> using Role-based access control?</p>""",azure-virtual-machine
19951537,Generate Azure Shared Access Signature with out using Azure Storage API <p>I have seen that SAS can be generated using Storage API.<br> Is there a way to generate it from Management Studio or with out using API?</p>,azure-storage
18723959,"Cannot RDP to Azure VM after sysprep <p>I followed the instructions <a href=\http://www.windowsazure.com/en-us/manage/windows/how-to-guides/capture-an-image/\"" rel=\""nofollow noreferrer\"">listed here to capture an image of my Azure VM</a>: </p>  <p>Now I am unable to RDP to the VM - I get the generic message \""Remote Desktop can't connect to the remote computer for one of these reasons:1 2 3 etc\""</p>  <p>The VM I'm trying to connect to is: teamsitepoc.cloudapp.net:59207</p>  <p>Here's what I've tried:</p>  <ol> <li>I have checked that it's started. </li> <li>Tried re-sizing to extra small then back to small. </li> <li>Attached the disk that was captured  giving the following:</li> </ol>  <p>Could anyone please advise what else I can try to troubleshoot</p>  <p><img src=\""https://i.stack.imgur.com/MBQPZ.png\"" alt=\""enter image description here\""></p>""",azure-virtual-machine
46531875,"Why are Azure subscriptions at resource group level and also at app service plan level? <p>I noticed subscriptions can set at resource group level (which seems very logic) and inside that  you can create an app service plan with another subscription. </p>  <p>Why do we have to set the subscription in the ASP since it already resides in a RG with a subscription?</p>  <p><a href=\https://i.stack.imgur.com/gT0gP.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/gT0gP.png\"" alt=\""RG\""></a></p>  <p><a href=\""https://i.stack.imgur.com/fpD5m.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/fpD5m.png\"" alt=\""ASP\""></a></p>""",azure-virtual-machine
12611547,How do I do per-instance Azure Worker-Role configuration? <p>In need to deploy 3 different worker roles but each needs it's own configuration (user name  password  etc.) to connect to a trading server.  I can't share the credentials across the instances.</p>  <p>If anyone knows how to accomplish this I would be very appreciative!  </p>  <p>Thanks...</p>,azure-storage
44365088,"Which windows vm allowed to upload to azure? <p>In Azure  I can upload VM from my local vhd. I find <a href=\https://docs.microsoft.com/en-us/azure/virtual-machines/linux/endorsed-distros?toc=%2fazure%2fvirtual-machines%2flinux%2ftoc.json\"" rel=\""nofollow noreferrer\"">Linux VM List</a>  but I can't find the Windows list.</p>""",azure-virtual-machine
46987439,"Calling Azurefunction from a logic app throws \Runtime keys are stored on blob storage. This API doesn't support this configuration.\"" <p>I have a logic app  this calls several functionapps. this worked wonderfull  but suddently I got an error when the logic app calls the Function. The error was:</p>  <pre><code>{   \""Message\"": \""The 'code' query parameter provided in the HTTP request did not match the expected value.\"" } </code></pre>  <p>We didn't regenerate the key and the keys are valid  because we can execute the webhook functions with postman. </p>  <p>But when I isnpect the activity logs I got on the listkeys action the following Error:</p>  <pre><code>{     \""Message\"": \""An error has occurred.\""      \""ExceptionMessage\"": \""Runtime keys are stored on blob storage. This API doesn't support this configuration.\""      \""ExceptionType\"": \""System.InvalidOperationException\""      \""StackTrace\"": \""   at Kudu.Core.Functions.FunctionManager.&lt;GetKeyObjectFromFile&gt;d__9`1.MoveNext()\\\\r\\\\n--- End of stack trace from previous location where exception was thrown ---\\\\r\\\\n   at System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw()\\\\r\\\\n   at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task)\\\\r\\\\n   at Kudu.Core.Functions.FunctionManager.&lt;GetFunctionSecretsAsync&gt;d__12.MoveNext()\\\\r\\\\n--- End of stack trace from previous location where exception was thrown ---\\\\r\\\\n   at System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw()\\\\r\\\\n   at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task)\\\\r\\\\n   at Kudu.Services.Functions.FunctionController.&lt;GetSecrets&gt;d__12.MoveNext()\"" } </code></pre>  <p>Is there a way to change the storage of the keys? Why I got suddently without any change this message from one minute to another?</p>""",azure-functions
43877285,"How do I control the log level for Azure Diagnostic Logs? <p>I have built a ASPNET Core application and enabled logs with these statements:</p>  <pre><code>    loggerFactory.AddConsole(Configuration.GetSection(\Logging\""));     loggerFactory.AddDebug((category  logLevel) =&gt; (category.Contains(\""WEBAPI\"") &amp;&amp; logLevel &gt;= LogLevel.Trace));     loggerFactory.AddAzureWebAppDiagnostics(); </code></pre>  <p>Now the problem is that the Azure log has lots of other log detail coming from the Mircosoft packages that I am not interested in. I can't seem to pass my logging configuration to Azure though like I do for the Console log.</p>  <p>Am I missing how I should be using the Diagnostics system? </p>""",azure-web-app-service
38504470,"Azure App Service (Mobile) relogin hangs <p>I am using Azure Mobile Apps with deployment slots  with the service provider for login being Microsoft. I have some odd behaviour  during swapping and the users relogin.</p>  <p>Is the performance better/different for AD? [read that it was not for GA yet?]</p>  <p>I am developing in a developer slot with everything specifically configured for this environment  the test and updates are working. I upload the server to staging  now utilizing the same db and settings (except microsoft authentication). The server is again verified to be working both on client and server.</p>  <p>I then use swap to change the staging and production slots. The production slot has the microsoft account login settings.</p>  <p>Upon swap the login by users are continuing indefinitely (no timeout  i.e. several minutes running without any stop) if  the referesh token call is made  as per <a href=\https://cgillum.tech/2016/03/07/app-service-token-store/\"" rel=\""nofollow\"">this link</a>:</p>  <pre><code>//retrieve user info user = new MobileServiceUser(credential.UserName); credential.RetrievePassword(); //refresh token user.MobileServiceAuthenticationToken = credential.Password; JObject refreshJson = (JObject)await ((App)Application.Current).MobileService.InvokeApiAsync(                         \""/.auth/refresh\""                          System.Net.Http.HttpMethod.Get                          null); </code></pre>  <p>My initial question is therefore is it possible to insert a timeout e.g. 2 seconds on the call to force the user to re-enter their credentials? </p>  <p>Because it seems to work if the user logs out and then back in with normal login procedure:</p>  <pre><code>user = await ((App)Application.Current).MobileService.LoginAsync(provider); credential = new PasswordCredential(provider.ToString()  user.UserId  user.MobileServiceAuthenticationToken); vault.Add(credential); string newToken = refreshJson[\""authenticationToken\""].Value&lt;string&gt;(); </code></pre>  <h1>Question(s)</h1>  <p>Is it possible to insert timeout on <code>MobileServiceClient.invokeApiAsync</code> calls?</p>  <p>Is there some setting that can be set so the swap mechanism does not introduce this issue?</p>  <p>Is there a way to improve the login/relogin flow  the users are complaining that the login is failing often. I cannot replicate it in other instances than during the swap. Can this be because of distance to the server?  Therefore would <code>Traffic Manager</code> be a solution? However  I cannot see how it should be enabled if I am using microsoft login. Since a service is bound to an application name for authentication. How should the <code>Traffic Manager</code> be used in this respect?</p>""",azure-web-app-service
50551261,"How to deploy deployment slot specific appsettings from git repo? <p>I do realize I can use Azure AppSettings to override settings in Web.Config files.</p>  <p><a href=\https://docs.microsoft.com/en-us/azure/app-service/web-sites-staged-publishing\"" rel=\""nofollow noreferrer\"">https://docs.microsoft.com/en-us/azure/app-service/web-sites-staged-publishing</a> says:  </p>  <ul> <li>App settings (can be configured to stick to a slot)  </li> <li>Connection strings (can be configured to stick to a slot)</li> </ul>  <p>So far so good.<br> But how do I <strong>version</strong> these settings?<br> I don't want to add them manually through the Azure Portal.  </p>  <p>Also I don't exactly understand why I can add custom application settings in the Azure App Service release pipeline task. These settings are then copied to the configured slot. Consider following scenario...</p>  <p>There is a new appsetting (which would usually live in Web.Config). Okay Web.Config is not a good idea because it is specific per deployment slot. So you add it to the release task configuration - for your \""staging\"" slot. Next you swap staging and production - and of course the new production system has no clue about the new setting (not even the staging configuration which would anyway be equally bad).</p>""",azure-web-app-service
39638225,Azure Portal Error: Failed to start virtual machine 'xxxx'. Error: The Key Vault secret referenced with the URL 'xxxx' does not exist <p>I have deleted some Key Vaults from my resource manager after assuming that they are not used anywhere in my configuration and that those were some leftovers from my testing. Now I can't start my virtual machines and this error message appears.</p>  <blockquote>   <p>Failed to start virtual machine 'xxxx'. Error: The Key Vault secret   referenced with the URL 'xxxx' does not exist.</p> </blockquote>  <p>Could you please advise me how to put my virtual machines back on track since I can't afford the time building them again?</p>  <p>Thanks a lot.</p>,azure-virtual-machine
45271047,"FunctionInvocationException when Azure function is called <p>I'm having an issue with my Azure function. The function cannot startup because a FunctionInvocationException is being thrown each time. </p>  <p>The inner exception being an InvalidOperationException with the below message:</p>  <blockquote>   <p>PartitionKey must be supplied for this operation</p> </blockquote>  <p>I have two bindings in my function that connect to a Document DB  one is an in binding that retrieves a specific document from a collection  and the other is an out binding used for auditing.</p>  <p>These both work fine in my dev  qa  and uat environments it is only the production environment that is having an issue. Both collections (for the settings and the auditing) were created without a partition key  the same as every environment.</p>  <blockquote>   <p>System.InvalidOperationException:          at Microsoft.Azure.Documents.Client.DocumentClient+d__347.MoveNext (Microsoft.Azure.Documents.Client  Version=1.11.0.0  Culture=neutral  PublicKeyToken=31bf3856ad364e35)</p> </blockquote>  <p>Any ideas? </p>  <p>I've tried deleting and remaking the audit collection but that didn't work. I don't get why the other environments are fine  but this one isn't.</p>  <p>Edit:</p>  <p>The function.json</p>  <pre><code>{   \scriptFile\"": \""..\\\\bin\\\\Cso.Notification.Function.dll\""    \""entryPoint\"": \""Cso.Notification.Function.Program.Run\""    \""disabled\"": false    \""bindings\"": [     {       \""type\"": \""httpTrigger\""        \""direction\"": \""in\""        \""webHookType\"": \""genericJson\""        \""name\"": \""request\""        \""methods\"": [         \""post\""       ]     }      {       \""type\"": \""documentDB\""        \""name\"": \""subscriberSettings\""        \""databaseName\"": \""CSO\""        \""collectionName\"": \""Settings\""        \""id\"": \""SubscriberSettings\""        \""connection\"": \""CsoDocDb\""        \""direction\"": \""in\""     }      {       \""type\"": \""http\""        \""direction\"": \""out\""        \""name\"": \""res\""     }      {       \""type\"": \""documentDB\""        \""name\"": \""collector\""        \""databaseName\"": \""CSO\""        \""collectionName\"": \""AuditJSON\""        \""connection\"": \""CsoDocDb\""        \""direction\"": \""out\""     }   ] } </code></pre>""",azure-functions
38038566,"How to expand detached data disk in Azure RM <p>This link describes how to expand attached VM OS or data disks in an Azure resource group. I want to know how can I extend a detached data disk so that I could perform this action without restarting the machine. Is that achievable?</p>  <p><a href=\https://azure.microsoft.com/en-gb/documentation/articles/virtual-machines-windows-expand-os-disk/\"" rel=\""nofollow\"">https://azure.microsoft.com/en-gb/documentation/articles/virtual-machines-windows-expand-os-disk/</a></p>""",azure-storage
56834744,"'Allow duplicates to be skipped' warning and 409 error for NuGet push on Azure DevOps Server <p>In Azure DevOps Server (version 2019.0.1) running on a Windows Server 2019 agent  with the 'Allow duplicates to be skipped' option selected for NuGet push task  a warning is displayed:</p>  <blockquote>   <p>The 'Allow duplicates to be skipped' option is currently only available on Azure Pipelines. If NuGet.exe encounters a conflict  the task will fail.</p> </blockquote>  <p>The task results in the following error that causes the task to fail indicating that the above warning applies:</p>  <blockquote>   <p>Response status code does not indicate success: 409 (Conflict - The feed already contains 'MyPackage X.Y.Z'. (DevOps Activity ID: 1A57312F-3C56-4E4D-9E78-73C7072A288F)).</p> </blockquote>  <p>I'm wondering if this issue is particular to Azure DevOps Server (rather than Azure DevOps Services)  or if I'm doing something wrong  or if there is another workaround. I noticed someone else has the same issue from <a href=\https://stackoverflow.com/questions/46115212/ignore-duplicates-when-pushing-nuget-package-to-nuget-org-from-vsts/46151147#comment95472072_46151147\"">this comment</a> on another question where it was mentioned that the option was available after someone asked how to ignore error 409 (duplicate package).</p>  <p>I would like to ignore duplicate packages using the NuGet task and ideally the 'Allow duplicates to be skipped' option on Azure DevOps Server. I'm aware that it could be resolved using scripting  but I'd prefer to avoid that if possible. Any help appreciated.</p>""",azure-devops
55761637,Azure Webapps for Containers connection string in environment variables <p>My app running in a docker container on Azure Webapps for Containers tries to access a connection string through an environment variable. I've added it to the Application Settings in the Azure UI but I can't access it through my code  specifically my ASP.NET Core application is returning null.</p>  <p>I know that the logs won't show it being added as a <code>-e connstring=myconnstring</code> argument in the <code>docker run</code> command  but it should never the less be present in the container.</p>,azure-web-app-service
48988814,"Create blob storage container in c# using fluent API <p>I am using the <a href=\https://azure.microsoft.com/en-us/blog/azure-management-libraries-for-net-generally-available-now/\"" rel=\""nofollow noreferrer\"">C# management API of Azure</a> to create my resources in the cloud. I am stuck creating a container in the blob storage. I did create a storage account following <a href=\""https://github.com/Azure-Samples/storage-dotnet-manage-storage-accounts/blob/master/Program.cs\"" rel=\""nofollow noreferrer\"">these instructions</a>:</p>  <pre><code>// storageAccount here is a Microsoft.Azure.Management.Storage.Fluent.IStorageAccount instance var storageAccount = _azure.StorageAccounts                 .Define(name)                 .WithRegion(region)                 .WithExistingResourceGroup(resourceGroup)                 .WithBlobEncryption()                 .WithOnlyHttpsTraffic()                 .WithBlobStorageAccountKind()                 .WithAccessTier(AccessTier.Hot)                 .Create(); </code></pre>  <p>But I do not know how to go on from there. From the <a href=\""https://docs.microsoft.com/en-us/azure/storage/blobs/storage-dotnet-how-to-use-blobs#create-a-container\"" rel=\""nofollow noreferrer\"">Microsoft documentation</a> it seems that I have to retrieve a <code>Microsoft.WindowsAzure.Storage.CloudStorageAccount</code> instance  but the <code>storageAccount</code> instance I obtain with the above code lives in the namespace <code>Microsoft.Azure.Management.Storage.Fluent</code>  and I have not found any way to get the <code>CloudStorageAccount</code> from there. </p>  <p>Is it possible to create containers directly with the API in the fluent namespace? If not  how do I get the <code>CloudStorageAccount</code> instance from my <code>IStorageAccount</code> one?</p>  <p><a href=\""https://stackoverflow.com/questions/23607446/create-a-blob-storage-container-programmatically\"">This answer in SO</a> is not helpful because it does use the <code>Microsoft.WindowsAzure</code> namespace directly.</p>""",azure-storage
50714378,"Export certificate in Azure App Services <p>Would it be possible to export a SSL wildcard certificate used for HTTPS connection in Azure app services? The option to export and used the wildcard cert to another server with the same domain name seems to be missing in Azure App Services as seen below:</p>  <p><a href=\https://i.stack.imgur.com/aumMc.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/aumMc.png\"" alt=\""enter image description here\""></a></p>""",azure-web-app-service
43913677,"XML::Twig - identifying blobs that do not contain an element   <p>I am using <a href=\https://metacpan.org/pod/XML::Twig\"" rel=\""nofollow noreferrer\""><code>XML::Twig</code></a> to parse output of Azure's <code>list-blob</code> REST API.</p>  <p>In particular  I am looking to identify and delete uncommitted orphan blobs  and I am unsure as to how best go about using <code>XML::Twig</code> efficiently to do this. I don't even know where to start.</p>  <p>Ultimately I need to retrieve the <code>&lt;Name&gt;</code> element of the orphaned blobs.</p>  <p>The <a href=\""https://docs.microsoft.com/en-us/rest/api/storageservices/list-blobs\"" rel=\""nofollow noreferrer\"">Azure documentation</a> states:</p>  <blockquote>   <p><strong>Uncommitted Blobs in the Response</strong></p>      <p>Uncommitted blobs are listed in the response only if the   <em>include=uncommittedblobs</em> parameter was specified on the URI.   Uncommitted blobs listed in the response do not include any of the   following elements:</p>  <pre class=\""lang-none prettyprint-override\""><code>Last-Modified Etag Content-Type Content-Encoding Content-Language Content-MD5 Cache-Control Metadata </code></pre> </blockquote>  <p>Therefore  in the following simplified example  you can see an orphan blob called \""test\""  because the <code>&lt;Blob&gt;&lt;/Blob&gt;</code> block does not contain any of the above elements.</p>  <pre class=\""lang-xml prettyprint-override\""><code>&lt;?xml version=\""1.0\"" encoding=\""utf-8\""?&gt; &lt;EnumerationResults ServiceEndpoint=\""https://my**account.blob.core.windows.net/\""   ContainerName=\""testonly\""&gt;   &lt;Blobs&gt;     &lt;Blob&gt;       &lt;Name&gt;test&lt;/Name&gt;       &lt;Properties&gt;         &lt;Content-Length&gt;0&lt;/Content-Length&gt;         &lt;BlobType&gt;BlockBlob&lt;/BlobType&gt;         &lt;LeaseStatus&gt;unlocked&lt;/LeaseStatus&gt;         &lt;LeaseState&gt;available&lt;/LeaseState&gt;       &lt;/Properties&gt;     &lt;/Blob&gt;   &lt;/Blobs&gt;   &lt;NextMarker/&gt; &lt;/EnumerationResults&gt; </code></pre>  <p>UPDATE :</p>  <p>Actually  I might have oversimplified.  The accepted answer does not appear to work with the below  it prints everything :</p>  <pre class=\""lang-none prettyprint-override\""><code>&lt;?xml version=\""1.0\"" encoding=\""utf-8\""?&gt; &lt;EnumerationResults ServiceEndpoint=\""https://my**account.blob.core.windows.net/\"" ContainerName=\""testonly\""&gt; &lt;Blobs&gt;     &lt;Blob&gt;         &lt;Name&gt;data/users/docx&lt;/Name&gt;         &lt;Properties&gt;             &lt;Last-Modified&gt;Wed  10 May 2017 20:21:25 GMT&lt;/Last-Modified&gt;             &lt;Etag&gt;0x8D497E221E7A5AF&lt;/Etag&gt;             &lt;Content-Length&gt;125632&lt;/Content-Length&gt;             &lt;Content-Type&gt;application/octet-stream&lt;/Content-Type&gt;             &lt;Content-Encoding/&gt;             &lt;Content-Language/&gt;             &lt;Content-MD5/&gt;             &lt;Cache-Control/&gt;             &lt;Content-Disposition/&gt;             &lt;BlobType&gt;BlockBlob&lt;/BlobType&gt;             &lt;LeaseStatus&gt;unlocked&lt;/LeaseStatus&gt;             &lt;LeaseState&gt;available&lt;/LeaseState&gt;         &lt;/Properties&gt;     &lt;/Blob&gt;     &lt;Blob&gt;         &lt;Name&gt;test&lt;/Name&gt;         &lt;Properties&gt;             &lt;Content-Length&gt;0&lt;/Content-Length&gt;             &lt;BlobType&gt;BlockBlob&lt;/BlobType&gt;             &lt;LeaseStatus&gt;unlocked&lt;/LeaseStatus&gt;             &lt;LeaseState&gt;available&lt;/LeaseState&gt;         &lt;/Properties&gt;     &lt;/Blob&gt; &lt;/Blobs&gt; &lt;NextMarker/&gt; &lt;/EnumerationResults&gt; </code></pre>  <p>My code :</p>  <pre class=\""lang-none prettyprint-override\""><code>sub blob_parse {         my $blob = $_;         $blob-&gt;first_child($_) and return         for qw( Last-Modified Etag Content-Type Content-Encoding                 Content-Language Content-MD5 Cache-Control Metadata);         say \""orph: \"".$blob-&gt;first_child('Name')-&gt;text; }  sub parseAndDelete {         ### ORPHAN         $twig_handlers = {'Blobs/Blob' =&gt; \\&amp;blob_parse};         $twig = new XML::Twig(twig_handlers=&gt;$twig_handlers);         $twig-&gt;parse($message); } </code></pre>""",azure-storage
52641590,"Deploy a docker container on Azure App Service Linux <p>I have a simple app built as docker image (ubuntu) and put it into docker container. It has few volumes attached to it. I want to push this container to Azure AppService Linux. I tried a few options but with no success.</p>  <ol> <li><p>Azure CLI to create a web app and push container to azure container registry and then deploy that to web app.  </p>  <p>Gives <code>invalid reference format</code> error. </p></li> <li><p>Uploaded container to <code>acr</code> and updated web app container settings to load this container into web app.</p>  <p>Gives <code>image not found</code> or <code>invalid reference format</code> errors.</p></li> </ol>  <p>Not sure how to proceed on this. Any help is highly appreciated. I would also like to know how to use persistent storage for volumes here. Azure <code>fileshare</code> is better option but not sure how to map that to container path.</p>  <p>Below is my sample <code>docker-compose</code> file.</p>  <pre><code>version: \3.3\"" services:   test-backend:     image: test-002     container_name: test-002     restart: always     volumes:      - ./assets:/opt/test_files      - ./medialibrary:/opt/test_medialibrary      - ./app-configs:/opt/test_configs      - ./logs/backend:/opt/test-backend-logs     extra_hosts:      test-converter: \""127.0.0.1\""     ports:      - \""8000:8000\"" volumes:   test-data:   test-data2: </code></pre>""",azure-web-app-service
50681158,"Cannot connect to CosmosDB from VS Code Azure Function <p>I created Azure Function (2.0v) from C# HTTP template . Then I added output binding to CosmosDB based on <a href=\https://docs.microsoft.com/en-us/azure/azure-functions/functions-bindings-cosmosdb#output---example\"" rel=\""nofollow noreferrer\"">CosmosDB docs</a>:</p>  <pre class=\""lang-cs prettyprint-override\""><code>public static class AddEvent  {     [FunctionName(\""AddEvent\"")]     public static void Run(          [HttpTrigger(AuthorizationLevel.Anonymous  \""get\""  \""post\""  Route = null)]             HttpRequest req           [CosmosDB(\""SomeDatabase\""  \""SomeCollection\""  Id = \""id\""           ConnectionStringSetting = \""myCosmosDB\""  CreateIfNotExists = true)]              out dynamic document)     {         document = new { Text = \""something\""  id = Guid.NewGuid() };     } } </code></pre>  <p>Packages  that I use (csproj file):</p>  <pre><code>&lt;PackageReference Include=\""Microsoft.Azure.WebJobs.Extensions.CosmosDB\"" Version=\""3.0.0-beta7\"" /&gt; &lt;PackageReference Include=\""Microsoft.NET.Sdk.Functions\"" Version=\""1.0.11\"" /&gt; </code></pre>  <p>This is my local.settings.json. I based them on values from CosmosDB emulator:</p>  <pre><code>{     \""IsEncrypted\"": false      \""Values\"": {         \""AzureWebJobsStorage\"": \""UseDevelopmentStorage=true\""          \""AzureWebJobsDashboard\"": \""\""          \""myCosmosDB\"": \""AccountEndpoint=https://localhost:8081/;AccountKey=C2y6yDjf5/R+ob0N8A7Cgv30VRDJIWEHLM+4QDU5DE2nQ9nDuVTqobD4b8mGGyPMbIZnqyMsEcaGQy67XIw/Jw==\""     } } </code></pre>  <p>Unfortunately  when I hit HTTP trigger I get:</p>  <pre><code>System.Private.CoreLib: Exception while executing function: AddEvent. Microsoft.Azure.WebJobs.Host: Exception binding parameter 'document'. Microsoft.Azure.DocumentDB.Core: The type initializer for 'Microsoft.Azure.Documents.UserAgentContainer' threw an exception.  Object reference not set to an instance of an object. </code></pre>  <p>What does this exception means? I cannot find any relevant information about it and it completely stops my local work. Function works well without CosmosDB attribute.</p>""",azure-functions
44983669,"Azure function (VS2017) SQL table binding <p>I'm trying to bind data from AF to Azure SQL. It's easy to do in Azure Portal adding the binding params in function.json file</p>  <pre><code> {   \type\"": \""apiHubTable\""    \""name\"": \""outputTable\""    \""dataSetName\"": \""default\""    \""tableName\"": \""SpeechToText\""    \""connection\"": \""sql_SQL\""    \""direction\"": \""out\"" } </code></pre>  <p>But I cant do this in VS2017 preview(  Binding to Azure SQL is unavailable)</p>  <p><img src=\""https://i.stack.imgur.com/Xz3B6.jpg\"" alt=\""enter image description here\""></p>""",azure-functions
47152475,Azure: disable .ppk file for ssh connection <p>I'm using macos and required to connect to an azure server via ssh. The previous system admin provided me with a .ppk file which he was using to open ssh connection via putty. I want to connect to the server via ssh shell  I believe I need to convert the .ppk file to .pem but the when I run the below command it's prompting me for passphrase which I don't have. </p>  <pre><code>puttygen server.ppk -O private-openssh -o server.pem   </code></pre>  <p>I'm thinking of connecting to the server from a windows pc and disable the .ppk file requirement on the server so that I can connect to the server just with username and password. How can I do that? Or does anybody know other alternative to connect to the server via ssh(creating a new ssh user account in azure portal?)</p>  <p>PS: We will be moving AWS soon so these servers will be decommissioned. Hence I'm not worried about the security.</p>,azure-virtual-machine
57315316,How do I set the container user in an AzureDevops Pipeline YAML? <p>I have this yaml file that I am using with Azure DevOps to build a project on github:</p>  <pre><code>resources:   containers:   - container: fedora-29     image: fedora:29     options: --user 0  jobs:   - job: RunInContainer     pool:       vmImage: 'Ubuntu-16.04'     strategy:       matrix:         fedora-29:           containerResource: fedora-29      container: $[ variables['containerResource'] ]      steps:     - bash: |         dnf install 'dnf-command(copr)' -y       timeoutInMinutes: 30 </code></pre>  <p>This yaml files uses a <code>fedora:29</code> container. Fedora 29 doesn't include <code>sudo</code> out of the box and uses a non-root user by default.</p>  <p>So the <code>dnf</code> command fails:</p>  <pre><code>Error: This command has to be run under the root user. </code></pre>  <p>If I add a <code>sudo</code> before <code>dnf</code>  the error is:</p>  <pre><code>line 1: sudo: command not found </code></pre>  <p>Is there a way to do the equivalent of the <code>USER</code> command in a Dockerfile via the yaml file? Or can I pass the <code>--user 0</code> flag to <code>docker run</code> somehow?</p>,azure-devops
51636479,"Tfssecurity - Set Permission for Release and Deployment Groups <p>at the moment i´m writing a script for setting TFS-Permissions with Tfssecurity.exe. I solved the stuff for about all areas in TFS  but now i´m getting stuck with \Release\"" and \""Deployment Group\"" permissions. For \""Release\"" i found in the securitynamesspace Json a Namespace called \""ReleaseManagement\"" - if i do a tfssecurity /a i can´t find that namespace. If i try to set permission with tfssecurity.exe /a+ Release Management it also tells me that there is not Workspace with that name  also if i write it without space between (ReleaseManagement). Also i can´t find anything for Deployment Groups.</p>  <p>So i hope to get a hint from you guys for these two permission areas (namespaces). ==> System: VSTS</p>  <p>Here are the namespaces i´m getting with /a: Hey  thx for your answer. My problem is that on VSTS i don´t get this namespace back with /a => I´m getting all namespaces  but this one is missing and also tells me it can´t find it. The only way i got it back is in the json i get from <a href=\""https://XXXXXX.visualstudio.com/_apis/securitynamespaces/00000000-0000-0000-0000-000000000000?api-version=4.1\"" rel=\""nofollow noreferrer\"">https://XXXXXX.visualstudio.com/_apis/securitynamespaces/00000000-0000-0000-0000-000000000000?api-version=4.1</a>. Here are the namespaces i´m getting with /a:</p>  <pre><code> WorkItemTrackingAdministration  DistributedTask  WorkItemQueryFolders  Git Repositories  VersionControlItems2  EventSubscriber  WorkItemTrackingProvision  ServiceEndpoints  ServiceHooks  Chat  Collection  Proxy  Plan  Process  AccountAdminSecurity  Library  Project  EventSubscription  CSS  TeamLabSecurity  ProjectAnalysisLanguageMetrics  Tagging  MetaTask  Iteration  Favorites  Registry  Graph  ViewActivityPaneSecurity  Job  WorkItemTracking  StrongBox  Server  TestManagement  SettingEntries  BuildAdministration  Location  UtilizationPermissions  WorkItemsHub  WebPlatform  VersionControlPrivileges  Workspaces  CrossProjectWidgetView  WorkItemTrackingConfiguration  Discussion Threads  DataProvider  Social  Security  IdentityPicker  ServicingOrchestration  Build  DashboardsPrivileges  VersionControlItems  Identity </code></pre>""",azure-devops
46707825,Azure Function - NodeJs - Sqlite - mscorlib - Error: A dynamic link library (DLL) initialization routine failed <p>I have nodejs azure function that using sqlite3 lib. after running the function. i got this error. </p>  <pre><code>2017-10-12T10:49:16.036 Function started 2017-10-12T10:49:19.434 Exception while executing function: Functions.sqlite.  mscorlib: One or more errors occurred. Error: A dynamic link library (DLL)  initialization routine failed.  \\?\D:\home\site\wwwroot\sqlite\node_modules\sqlite3\lib\binding\node-v48-win32-ia32\node_sqlite3.node at Error (native) at Object.Module._extensions..node (module.js:597:18) at Module.load (module.js:487:32) at tryModuleLoad (module.js:446:12) at Function.Module._load (module.js:438:3) at Module.require (module.js:497:17) at require (internal/module.js:20:19) at Object.&lt;anonymous&gt; (D:\home\site\wwwroot\sqlite\node_modules\sqlite3\lib\sqlite3.js:4:15) at Module._compile (module.js:570:32) at Object.Module._extensions..js (module.js:579:10). 2017-10-12T10:49:19.449 Function completed (Failure  Duration=3415ms) </code></pre>  <p>any idea how to solve this error?  </p>,azure-functions
54770991,Connection and getting specific files from an FTPS using Azure Functions <p>is it possible to get the files in an FTPS using Azure Functions?</p>  <p>So what i'm looking for is being able to connecting to an FTPS and getting files that start with a special name and then process the file and return the content to a logic app for example.</p>,azure-functions
48193418,"Azure - Is there a way to generalize the Image after capturing it already? <p>Recently  I tried to generalize a specific VM in Azure to be used as an image for a future scale set.</p>  <p>After doing that (the wrong way)  I tried to create a VM using this image and I got this error - </p>  <pre><code>\OS Provisioning for VM 'MyVM_10' did not finish in the allotted time. However  the VM guest agent was detected running. This suggests the guest OS has not been properly prepared to be used as a VM image (with CreateOption=FromImage). To resolve this issue  either use the VHD as is with CreateOption=Attach or prepare it properly for use as an image\"" </code></pre>  <p>Which means that I did not sysprep it properly.<br> Is there a way to sysprep it now? Or do I have to start all over again and there is no use of the image file that was created in this process?</p>""",azure-virtual-machine
30523409,"Delete folder(s) inside Azure Blob storage container <p>I have a container named <em>\pictures\""</em>  and have some folders named <em>\""Folder1\""  \""Folder2\""</em> inside of it. So files of my blob will be addressed like this <em>\""<a href=\""http://optimus.blob.core.windows.net/pictures/Folder1/IMG123.png\"" rel=\""noreferrer\"">http://optimus.blob.core.windows.net/pictures/Folder1/IMG123.png</a>\""</em>. Using the below C# code to delete the files inside folders  </p>  <pre><code>CloudStorageAccount storageAccount = CloudStorageAccount.Parse(*AzureConnectionString*);  CloudBlobClient blobClient = storageAccount.CreateCloudBlobClient();  CloudBlobContainer container = blobClient.GetContainerReference(\""pictures\"");  var blobs = container.ListBlobs(\""Folder1\""  true); foreach (var blob in blobs) {   container.GetBlockBlobReference(((CloudBlockBlob)blob).Name).DeleteIfExists(); } </code></pre>  <p>after deleting all those files in <em>\""Folder1\""</em> it will be empty. I m trying to delete the empty folder  but can't get a way to do it. Is it possible to delete the folder(s)? Any help will be much appreciated. Thanks in advance.</p>""",azure-storage
47647354,Is it possible to run two or more Azure functions simultanously? <p>I have function app(by default it is consumption plan) which is created by visual studio and has multiple functions including timer trigger and HTTP trigger. So am having some confusion how azure function runs? </p>  <p>does timer trigger stop execution of other function when any other function runs?</p>  <p>Example: When HTTP trigger runs which takes long time to process if in between my timer trigger runs(which runs for every 5 minutes) it is stopping execution of HTTP trigger for 5 minutes.</p>  <p>Does any azure function runs one by one or two functions at a time?.</p>  <p>If I go app service plan for function app. will the same happens while execution of azure function ?</p>,azure-functions
48095386,"Azure function powershell  Why azure table storage only has one row inserted? <p>I tried to insert log into azure table storage  but it seems it can not append rows. Here is my powershell script below:</p>  <pre><code>$requestBody = Get-Content $req -Raw | ConvertFrom-Json $name = $requestBody.name  # GET method: each querystring parameter is its own variable if ($req_query_name)  {     $name = $req_query_name  } function LogToAzureTable( $log ) {     $time = Get-Date -Format O     $entity = [PSObject]@{         PartitionKey = $EXECUTION_CONTEXT_INVOCATIONID         RowKey = \PID($PID): ($time)\""         LogContent = $log     }     $entity | ConvertTo-Json | Out-File $outputTable     $outputTable.done } Out-File -Encoding Ascii -FilePath $res -inputObject \""Hello $name\""  LogToAzureTable \""test log 1\"" LogToAzureTable \""test log 201\"" </code></pre>  <p>But the \""test log 1\"" has never been inserted.  Below is the azure table content:</p>  <p><a href=\""https://i.stack.imgur.com/u5bQB.jpg\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/u5bQB.jpg\"" alt=\""enter image description here\""></a>   </p>""",azure-functions
31830866,Visual Studio Online CI daily builds fail since switching to VS 2015 and using C# 6 Roslyn features <p>Since switching from <code>VS 2013</code> to <code>VS 2015</code> and using some new <code>C# 6</code> features  our daily builds in <code>Visual Studio Online</code> have begun failing.</p>  <p>The errors on the build are all pointing to the new auto property feature but I assume all new features will cause this.</p>  <p>An example piece of code that causes a failure is using:</p>  <pre><code>public int MyFavouriteNumber { get; set; } = 7; </code></pre>  <p>instead of</p>  <pre><code>private int _myFavouriteNumber = 7; public int MyFavouriteNumber      {          get { return _myFavouriteNumber; }          set { _myFavouriteNumber = value; }      } </code></pre>  <p>I've had a look around my build configuration  but I can't see anything that relates to <code>C# 6</code> or <code>Roslyn</code>.</p>  <p>What do I have to change to make my daily builds work again?</p>  <p><strong>Edit</strong></p>  <p>Here's an example error (they're all the same  for auto properties).</p>  <blockquote>   <p>Models\Core\Bookings\BookingProduct.cs (29  0)   Invalid token '=' in class  struct  or interface member declaration</p>      <p>Models\Core\Bookings\BookingProduct.cs (29  0)   Invalid token '(' in class  struct  or interface member declaration</p> </blockquote>  <p>And here is the offending line:</p>  <pre><code>public virtual IList&lt;BookingPricingAddon&gt; AddonsPricing { get; set; } = new List&lt;BookingPricingAddon&gt;(); </code></pre>,azure-devops
39144241,"/v:diag stops powershell command working from MSBuild <p>When I enable diagnostic logging the following command incorrectly includes the MSBuild TaskId in the Environment variable being set  what do I need to change to stop this happening?</p>  <pre><code>&lt;Exec Command=\powershell -Command Write-Host ##vso[task.setvariable variable=AutoBuildNumber;]$(BuildNumber)\"" /&gt; </code></pre>  <p>If my build number is 999 the 'AutoBuildNumber' should be set to <code>999</code> if <code>/v:diag</code> is set the environment variable will be  <code>999 (TaskId:6)</code></p>""",azure-devops
20493782,"Azure Worker Role - attach a disk that can be re-used between deployments <p>The files are Dlls that I need to link to dynamically  so can't use Azure Storage for this.</p>  <p>I can attach Disk to Azure virtual machine according to: <a href=\http://www.windowsazure.com/en-us/manage/windows/how-to-guides/attach-a-disk/\"" rel=\""nofollow\"">http://www.windowsazure.com/en-us/manage/windows/how-to-guides/attach-a-disk/</a></p>  <p>But how can I do same for worker role?</p>  <p>The reasons are:</p>  <ol> <li><p>Store some files that all instances of Worker role can access at the same time.  So don't have to duplicate/sync files to all local drives of each instance.</p></li> <li><p>The files need to persist when I deploy new version of web role.</p></li> </ol>""",azure-virtual-machine
52304052,It’s possible to have many different app services pointing to the same subdomain? <p>I saw that is possible creating only one app service with many virtual directories  but I’m not sure if this is a good practice.</p>  <p>I want the following:</p>  <ol> <li>foo.mywebsite.com/web1 -> foo-web1.azurewebsites.net</li> <li>foo.mywebsite.com/web2 -> foo-web2.azurewebsites.net</li> </ol>  <p>Any idea?</p>,azure-web-app-service
45881506,"Add a Certificate to an Azure App Service for Calling an External API <p>I'm calling an external API from within my App Service. This API is secured with a Thwate certificate which doesn't seem to be installed into the App Service's certificate store by default. Therefore I can't connect to the external API.</p>  <p>How can I add the certificate  one of the <a href=\https://www.thawte.com/roots/\"" rel=\""nofollow noreferrer\"">Thwate Roots</a>  into my App Service?</p>  <p>The portal only accepts .pfx certificates. I have seen solutions that involve running startup scripts in conjunction with the service definition files  but that feels very hacky. I'm sure there is/should be an easy way to do this. It must be a common requirement.</p>  <h3>Update</h3>  <p>This isn't a certificate I should need to install for the communication. This is a regular call to an https endpoint. The issue is that Azures doesn't seem to have the correct root/intermediary certificates in the cert store. I need to add the intermediary to the cert store (or the equivalent on the App Service)</p>""",azure-web-app-service
54739640,Linking R codes to azure <p>I developed an algorithm using R 5.2 and now I need to import this into the azure platform. I'm confused with the way to link the code file to azure. I'm using the following packages and has formed a function called 'clustering'. I plan to link this function with azure and all I have to do is import the relevant variables to the function to get the output. I would appreciate any help with this. Thanks  </p>  <pre><code>library(timeSeries) library(TSdist) library(tseries) library(lubridate) library(TSclust) library(bizdays) library(dtwclust) library(cluster) library(ggplot2) library(forecast) library(ggthemes) library(base) library(factoextra) library(NbClust) library(TSdist) library(dbscan) library(data.tree)      clustering = function(codes1  m) </code></pre>,azure-web-app-service
52943825,Azure storage table support for Localization <p>I have a client application which reads data from Azure storage table using the OData REST services. The table contains the list of Products in English  Now I want to support for localization of product names.</p>  <p>To implement the localization support I have 2 ideas:</p>  <ol> <li>Create a new column for maintaining the language code and query according to the language.</li> <li>Create new tables for each language with a suffix of language code.</li> </ol>  <p>In both the case  if the translation is missing for any product  the default language (English) value will not be omitted from service. </p>  <p>Is there any support in Azure to localize the storage table content based on the accept-language header of web service request? If not  is an alternative best suitable approach to achieve this?</p>,azure-storage
49991096,How to write Flink Streaming data into Azure Blob Storage <p>I'm trying to implement a Flink Streaming job to consume the data from Kafka and then write the data into Azure Blob Storage  I have a hadoop cluster (yarn) and then I run Flink on it  I submit the flink streaming job on that yarn cluster  but I got an error:</p>  <pre><code>java.lang.NoSuchMethodError: org.apache.hadoop.conf.Configuration.getPassword(Ljava/lang/String;)[C at org.apache.hadoop.fs.azure.SimpleKeyProvider.getStorageAccountKey(SimpleKeyProvider.java:47) at org.apache.hadoop.fs.azure.ShellDecryptionKeyProvider.getStorageAccountKey(ShellDecryptionKeyProvider.java:40) at org.apache.hadoop.fs.azure.AzureNativeFileSystemStore.getAccountKeyFromConfiguration(AzureNativeFileSystemStore.java:934) at org.apache.hadoop.fs.azure.AzureNativeFileSystemStore.createAzureStorageSession(AzureNativeFileSystemStore.java:1023) at org.apache.hadoop.fs.azure.AzureNativeFileSystemStore.initialize(AzureNativeFileSystemStore.java:507) at org.apache.hadoop.fs.azure.NativeAzureFileSystem.initialize(NativeAzureFileSystem.java:1281) at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2397) at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:89) at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2431) at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2413) at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:368) at org.apache.hadoop.fs.Path.getFileSystem(Path.java:296) at org.apache.flink.yarn.Utils.createTaskExecutorContext(Utils.java:398) at org.apache.flink.yarn.YarnApplicationMasterRunner.runApplicationMaster(YarnApplicationMasterRunner.java:316) at org.apache.flink.yarn.YarnApplicationMasterRunner$1.call(YarnApplicationMasterRunner.java:194) at org.apache.flink.yarn.YarnApplicationMasterRunner$1.call(YarnApplicationMasterRunner.java:191) at java.security.AccessController.doPrivileged(Native Method) at javax.security.auth.Subject.doAs(Subject.java:422) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1556) at org.apache.flink.runtime.security.HadoopSecurityContext.runSecured(HadoopSecurityContext.java:41) at org.apache.flink.yarn.YarnApplicationMasterRunner.run(YarnApplicationMasterRunner.java:191) at org.apache.flink.yarn.YarnApplicationMasterRunner.main(YarnApplicationMasterRunner.java:124) </code></pre>  <p>If anyone knows how to integrate Flink with Azure Blob Storage?</p>,azure-storage
55612598,Unable to access Azure DB from Azure VM if TransactionScope is used <p>I have .net 4.6.1 desktop application that migrates DB from 'old' version to the 'current' version.</p>  <p>It works perfectly fine when I test it locally. But I need to deploy the DB on Azure SQL Server and then migrate the DB. I wanted to do that from Azure VM but I get the following error:</p>  <pre><code>System.Data.SqlClient.SqlException (0x80131904): A transport-level error has occurred when receiving results from the server. (provider: TCP Provider  error: 0 - An existing connection was forcibly closed by the remote host.) ---&gt; System.ComponentModel.Win32Exception (0x80004005): An existing connection was forcibly closed by the remote host    at System.Data.SqlClient.SqlInternalConnectionTds..ctor(DbConnectionPoolIdentity identity  SqlConnectionString connectionOptions  SqlCredential credential  Object providerInfo  String newPassword  SecureString newSecurePassword  Boolean redirectedUserInstance  SqlConnectionString userConnectionOptions  SessionData reconnectSessionData  DbConnectionPool pool  String accessToken  Boolean applyTransientFaultHandling  SqlAuthenticationProviderManager sqlAuthProviderManager)    at System.Data.SqlClient.SqlConnectionFactory.CreateConnection(DbConnectionOptions options  DbConnectionPoolKey poolKey  Object poolGroupProviderInfo  DbConnectionPool pool  DbConnection owningConnection  DbConnectionOptions userOptions)    at System.Data.ProviderBase.DbConnectionFactory.CreateNonPooledConnection(DbConnection owningConnection  DbConnectionPoolGroup poolGroup  DbConnectionOptions userOptions)    at System.Data.ProviderBase.DbConnectionFactory.TryGetConnection(DbConnection owningConnection  TaskCompletionSource`1 retry  DbConnectionOptions userOptions  DbConnectionInternal oldConnection  DbConnectionInternal&amp; connection)    at System.Data.ProviderBase.DbConnectionInternal.TryOpenConnectionInternal(DbConnection outerConnection  DbConnectionFactory connectionFactory  TaskCompletionSource`1 retry  DbConnectionOptions userOptions)    at System.Data.ProviderBase.DbConnectionClosed.TryOpenConnection(DbConnection outerConnection  DbConnectionFactory connectionFactory  TaskCompletionSource`1 retry  DbConnectionOptions userOptions)    at System.Data.SqlClient.SqlConnection.TryOpenInner(TaskCompletionSource`1 retry)    at System.Data.SqlClient.SqlConnection.TryOpen(TaskCompletionSource`1 retry)    at System.Data.SqlClient.SqlConnection.Open() </code></pre>  <p>I tried the same from my local machine  accessing Azure SQL Server with my tool and it succeeded  but when I tried to do the same from Azure VM it failed. I tried with Win10  Win Server 2012 and Win Server 2016 VMs.</p>  <p>After some more attempts  I noticed that the issue was caused by using <code>TransactionScope</code> class.</p>  <p>My code is:</p>  <pre><code>using (TransactionScope ts = new TransactionScope()) {     using (SqlConnection connection = new SqlConnection(connectionString))     {     connection.Open();     // some stuff     }     ts.Complete(); } </code></pre>  <p>Any ideas?</p>,azure-virtual-machine
51999542,"Start and stop windows service on a Azure VM using powershell <p>Using powershell  I need to do the following steps.<br> 1. Login to Azure account.<br> 2. Create a VM from the Image.<br> 3. In the image   there is windows service.So when we created the VM  that windows service is already running on it.Stop that service.<br> 4. Copy some binaries into the VM to a specific folder.<br> 5. Start the service again.  </p>  <p>Out of all these  I was able to acheive 1 and 2 steps. And I couldn't find any relevant procedure for rest of the steps.   Below is the script I have used to do 1 and 2.</p>  <pre><code>Login-AzureRMAccount      $UserName = \username@organization.com\"" $Password = ConvertTo-SecureString \""password\"" -AsPlainText -Force $psCred = New-Object System.Management.Automation.PSCredential($UserName  $Password)     New-AzureRmVm `     -ResourceGroupName \""RGN\"" `     -Name \""VMName\"" `     -ImageName \""ImageName\"" `     -Location \""West US\"" `     -Credential $psCred </code></pre>  <p>So can anyone help me or guide me how the rest of the steps be done.<br> Thanks in advance for your time.</p>  <p><strong>EDIT</strong> : The command for stopping the service is<br>     Stop-Service -Name \""CPS Dev UniSimServices\"" -Force</p>  <p>But this works  if I log into the VM and run this command. I want to connect to the newly created VM through powershell from the remote machine itself (without logging into it)  and stop the service. How can I do that?</p>""",azure-virtual-machine
55864335,"How to set Azure Functions Core Tools environment and what impact has it? <p>I set up a maven project with the azure-function archetype and successfully ran it with <code>azure-functions:run</code>. The log shows:</p>  <pre><code>Azure Functions Core Tools (2.6.1048 Commit hash: f289117b0d44b321307bae9c96cd910f92057735) Function Runtime Version: 2.0.12408.0 Skipping 'AzureWebJobsStorage' from local settings as it's already defined in current environment variables. ... [04/26/2019 08:45:14] Starting JobHost [04/26/2019 08:45:14] Starting Host (HostId=wkmde9368071-516426360  InstanceId=d72816a7-a9d9-4bba-8d62-f7ba13877edd  Version=2.0.12408.0  ProcessId=31468  AppDomainId=1  InDebugMode=False  InDiagnosticMode=False  FunctionsExtensionVersion=) [04/26/2019 08:45:14] Loading functions metadata [04/26/2019 08:45:14] 1 functions loaded [04/26/2019 08:45:14] WorkerRuntime: java. Will shutdown other standby channels [04/26/2019 08:45:14] Generating 1 job function(s) [04/26/2019 08:45:14] [INFO] {DefaultClassLoaderProvider.addUrl}: Loading file URL: file:/target/azure-functions/test-20190426102909343/test-0.1-SNAPSHOT.jar [04/26/2019 08:45:14] Found the following functions: [04/26/2019 08:45:14] Host.Functions.HttpTrigger-Java [04/26/2019 08:45:14]  [04/26/2019 08:45:14] Host initialized (164ms) [04/26/2019 08:45:14] Host started (171ms) [04/26/2019 08:45:14] Job host started Hosting environment: Production </code></pre>  <p>I couldn't find where \Hosting Environment\"" nor why it says \""Production\"". Is there documentation available on how to set and what this indicates? </p>""",azure-functions
27438091,How to list blobs from virtual directory without prefix? <p>I have the following list of blobs:</p>  <ul> <li>VirtualDirectroy1/VirtualSubDirectory1/Blob1</li> <li>VirtualDirectroy2/VirtualSubDirectory2/Blob2</li> <li>VirtualDirectroy3/VirtualSubDirectory3/Blob3</li> </ul>  <p>I need to list Blob1  Blob2 and Blob3  so that when accessing the CloudBlockBlob.Name property it returns just Blob1  Blob2 or Blob 3 WITHOUT prefix of virtual directories.</p>  <p>How can I archive this?</p>  <p>Best Wishes  Oleg </p>,azure-storage
36438923,"Azure Blob Storage - Uploading Http/StreamContent to a CloudBlockBlob from WebApi Controller <p>I am sending a PDF file to my WebAPI Controller via a POST request using Angular as such:</p>  <pre><code>  $scope.upload = Upload.upload({         url: \../api/Locker/Upload\""  // webapi url         method: \""POST\""          file: controllerFile    }) </code></pre>  <p>which in my POST method on my controller I get the StreamContent of that file as follows: </p>  <pre><code> public async Task&lt;HttpResponseMessage&gt; Post()     {         HttpRequestMessage request = this.Request;         if (!request.Content.IsMimeMultipartContent())         {             request.CreateResponse(HttpStatusCode.UnsupportedMediaType);         }          var result = await Request.Content.ReadAsMultipartAsync&lt;CustomMultipartFormDataProvider&gt;(new CustomMultipartFormDataProvider());          string fileName = result.FileData[0].Headers.ContentDisposition.FileName;         var fileData = result.Contents[0];    } </code></pre>  <p>It is saying that results.Contents[0] is of type HttpContent but in the Immediate window when I type fileData it says it is of StreamContent type. </p>  <p>I am trying to upload to Azure Blob Storage this fileData so that I can then retrieve it using a GET request later on  but am having trouble doing so. </p>  <pre><code>    //in post method     CloudStorageAccount storageAccount = CloudStorageAccount.Parse(blobConnectionString);     CloudBlobClient blobClient = storageAccount.CreateCloudBlobClient();     CloudBlobContainer container = blobClient.GetContainerReference(blobContainer);     await container.CreateIfNotExistsAsync();      string blobId = Guid.NewGuid().ToString();      UploadToBlob(container  blobId  fileData); </code></pre>  <p>and method where I am stuck:</p>  <pre><code>  private async void UploadToBlob(CloudBlobContainer container  string blobId  HttpContent fileData)     {         CloudBlockBlob block = container.GetBlockBlobReference(blobId);         block.UploadFromStream(fileData);     } </code></pre>  <p>error on block.UploadFromStream because fileData is not a Stream of course.</p>  <p>What can I do if I am expecting a HTTP Response with content being of type: arraybuffer so that I can expose the file in my web application such as:</p>  <pre><code>  //angular get request  .success(function (data  status  headers  config) {         // file is uploaded successfully         console.log(data);          var fileBack = new Blob([(data)]  { type: 'application/pdf' });         var fileURL = URL.createObjectURL(fileBack);  } </code></pre>""",azure-storage
48150362,"Host name resolution error (DNS) while accessing to app service <p>Recently  I have noticed that many requests to my app service fails due to a DNS issue (on daily basis).</p>  <p>I use the app service to run a web service to my platform (app service is located in west UK).</p>  <p>I get the same errors from both Android&amp;IOS applications being used by my users.</p>  <p>The error says: \unable to resolve host ***.azurewebsites.net\""</p>  <p>In addition  I would like to specify that I created a new app service (located in west Europe)  but still</p>  <p>get the same errors.</p>  <p>The errors seems to be received randomly  on different times and from different devices.</p>  <h2>Update</h2>  <p>I created a new app service and add some simple logic in the client side  in which I switched between the two app services upon dns error detected.</p>  <p>After exploring my logs  I have noticed that sometimes I had success (no dns issue when switching to the secondary app service)  and sometimes  the dns error keep occurring.</p>""",azure-web-app-service
39902798,Running an exe in azure at a regular interval <p>I have an app (.exe) that picks up a file and imports it into a database.  I have to move this set up into Azure.  I am familiar with Azure SQL and Azure File Storage.  What I am not familiar with is how I execute am app within Azure.  </p>  <p>My app reads rows out of my Azure database to determine where the file is (in Azure File Storage) and then dumps the data into a specified table.  I'm unsure if this scenario is appropriate for Azure Scheduler or if I need an App Service to set up a WebJob.  </p>  <p>Is there any possibility I can put my app in a directly in Azure File Storage and point a task to that location to execute it (then it might be easier to resolve the file locations of the files to be imported).</p>  <p>thanks.</p>,azure-storage
45046627,"How do I set Automatic Updates on Azure DevTest Lab VM <p>I have a Windows VM set up in a Azure DevTest lab running Windows Server 2016  based on the Windows Server 2016 Datacenter Gallery Image. This is serving as a Custom Build Agent for VSTS.</p>  <p>I cannot find how to set it to automatically apply Windows Updates.</p>  <p>I found this article <a href=\https://social.technet.microsoft.com/Forums/windowsserver/en-US/0a46b8ac-0b16-4b87-a881-260c8d5609f7/disabling-windows-update-via-group-policy?forum=winserverGP\"" rel=\""nofollow noreferrer\"">https://social.technet.microsoft.com/Forums/windowsserver/en-US/0a46b8ac-0b16-4b87-a881-260c8d5609f7/disabling-windows-update-via-group-policy?forum=winserverGP</a> but the Wuau.admin template does not exist on the server.</p>  <p>This article <a href=\""https://www.rootusers.com/configure-automatic-updates-for-windows-server-2016/\"" rel=\""nofollow noreferrer\"">https://www.rootusers.com/configure-automatic-updates-for-windows-server-2016/</a> references the Group Policy Editor tool in Server Manager...but the Azure VM doesn't have that as a tool in Server Manager. Nor does the local GPE have the Group Policy Management section in the tree view as shown in the article.</p>  <p>I am probably missing something very simple  but I'm not really that familiar with server management. My goal is to get the VM set up so that it keeps itself patched and running smoothly.</p>""",azure-virtual-machine
57075294,"Does Azure App Service for Linux with Multi-Containers allow multiple yaml files? <p>I'm experimenting with Azure App Service for Linux + Multi-Container apps (aka Docker-Compose).</p>  <p>On my localhost development machine I have:</p>  <ul> <li><code>docker-compose.yml</code> (main file)</li> <li><code>docker-compose.override.yml</code> (localhost dev settings  via environment vars)</li> <li><code>docker-compose.development.yml</code> (azure development experiment settings via environment vars)</li> </ul>  <p>the main <code>docker-compose.yml</code> file has about 8 images in it  from a reverse-proxy to some web sites and then some background hosts that do background work.</p>  <p>All work 100% awesome on my localhost.</p>  <p>Now  I'm trying to see if this can get put up to azure with the new Azure App Service for Linux + Multi-Containers. This is part of the UI:</p>  <p><img src=\https://i.stack.imgur.com/DgQYZ.png\"" alt=\""\""></p>  <p>It's only allowing me 1x yaml file to use as the configuration. So I have no idea how to <em>also</em> add my <code>docker-compose.development.yml</code> file as a second file which will override any existing settinsg from the main file. </p>  <p>Similar if I do <code>docker-compose -f docker-compose.yml docker-compose.development.yml up</code></p>  <p>Is this possible with Azure App Service for Linux + Multi-Containers?</p>""",azure-web-app-service
56444215,"Automating SharePoint Online access for External Users through Flow/Azure <p>I'm quite new to SharePoint/Azure/PowerShell  so apologies if what I'm asking is a stupid question!</p>  <p>We currently have client SharePoint sites hosted on our O365 tenant  with access to each site to be rolled out to each of our respective clients shortly. Initially  only the senior management of each client will have access to the sites  however as time goes on it's likely we'll be adding everyone else too; To streamline the new user process and save us from having to add each individual staff member  we've been considering using a Flow to automate user access instead  with the goal of adding authenticated external users without much real input from administrators other than a simple approval/rejection process.</p>  <p>The overall plan is as follows:</p>  <p>Visio Outline&lt;<br> <a href=\https://i.stack.imgur.com/01UVt.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/01UVt.png\"" alt=\""enter image description here\""></a></p>  <ol> <li>Each Client site has a SharePoint Custom List  titled \""Employee Access List\"". Said list will have the following columns: Request ID (Text)  First Name (Text)  Last Name (Text)  Job Title (Text)  Company (Text)  Contact Number (Text)  E-Mail (Text)  SharePoint Access (Yes/No Boolean).</li> <li>If a member of staff requires access to the SharePoint site  then their respective manager will add the staff member to the list and fill in all the above fields  setting the \""SharePoint Access\"" item value to \""Yes\"".</li> <li>This will trigger the flow and an approval email to be sent to myself and another administrator  with said email detailing the user to be created  and who has submitted the request.</li> <li><strong>Script insertion somehow - This would then run if the request was approved  and set the user up with access.</strong></li> <li>Email notification is automatically then sent to the creator of SharePoint list item  notifying them that the user now has access.</li> </ol>  <p>Step 4 is where I'm a little stuck in regards to what to do if the request is approved - I've written a little PowerShell script below which nearly achieves what I'm going for  in that it creates an external user PnP Group and PnP Role Definition (If there isn't one already)  pulls what's in the \""E-mail\"" fields on the \""Employee Access\"" list and runs Add-PnPUsertoGroup to pull the users to the PnP group  which then sends the users an email with a link to the SharePoint site  allowing them to access it. However:</p>  <ul> <li>The script I've written targets everyone on the SharePoint List  whereas ideally I would just want the script to target the sole user that's been newly added to the list/is listed in the approval email  and only them. I'm assuming that I'd have to pipe information from the Flow into a script  which I'm not even sure is possible  and if it is  I haven't got a clue how to do it.</li> <li>I know that that Azure Functions and Azure Automation can be used to insert scripts into Flows  but I don't have experience of either so I'm not sure which is the more suitable option. Is there any guidance on how to insert PowerShell scripts with them  and how to pipe what's in a flow into said scripts?</li> </ul>  <p>PowerShell Script as follows:<br></p>  <p><a href=\""https://i.stack.imgur.com/Y2QM2.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/Y2QM2.png\"" alt=\""enter image description here\""></a></p>  <p>Hope this all makes sense - Any guidance would be appreciated.</p>  <p>Thank you!</p>  <p>EDIT: Just as a bit of extra information  here is the Flow as it currently is:</p>  <p><a href=\""https://i.stack.imgur.com/EMh83.png\"" rel=\""nofollow noreferrer\"">Flow Part 1</a></p>  <p><a href=\""https://i.stack.imgur.com/B0StK.png\"" rel=\""nofollow noreferrer\"">Flow Part 2</a></p>  <p><a href=\""https://i.stack.imgur.com/n7J1f.png\"" rel=\""nofollow noreferrer\"">Flow Part 3</a></p>""",azure-functions
46470549,"Last logging parameter of Azure Function (ILogger or TraceWriter) not accepted <p>After upgrading my own project from an earlier (a few months back) version of Azure Functions to current  I get the following error upon launching from VS.</p>  <blockquote>   <p>GetLoginUrl: Microsoft.Azure.WebJobs.Host: Error indexing method 'Login.GetLoginUrl'. Microsoft.Azure.WebJobs.Host: Cannot bind parameter 'log' to type ILogger. Make sure the parameter Type is supported by the binding. If you're using binding extensions (e.g. ServiceBus  Timers  etc.) make sure you've called the registration method for the extension(s) in your startup code (e.g. config.UseServiceBus()  config.UseTimers()  etc.).</p> </blockquote>  <p>Before  I used to have <code>TraceWriter log</code> as the last parameter to my methods but then I found out I should be using <code>ILogger</code> instead. Before I made the change  I was getting the same error as above.</p>  <p>The <code>ILogger</code> seems to be mapped to assembly <code>Microsoft.Extensions.Logging.Abstractions</code>. Perhaps this is why it is not recognized? Which <code>ILogger</code> should be used? Here is the method signature.</p>  <pre><code>[FunctionName(\GetLoginUrl\"")] public static HttpResponseMessage GetLoginUrl(     [HttpTrigger(AuthorizationLevel.Anonymous  \""get\""  Route = null)]HttpRequestMessage req      ILogger log) </code></pre>  <p>I did not try to deploy this to Azure.</p>  <p>Unfortunately  creating a brand new Functions project does not help as there are no .CS files to look up to in order to correct this.</p>""",azure-functions
35985790,"Calling into my own DLL when depolyed on Azure <p>I have a simple Windows Azure cloud service that does random number generation running on my local machine.  I have then published this to azure  </p>  <pre><code>    public string GetNumber()     {         Random number = new Random();         return \number = \"" + number.Next(1  100).ToString() + \"" number \"";     } </code></pre>  <p>When I call this method from my client everything works fine. ie</p>  <pre><code>        ServiceReference1.RandomNumbersClient client = new ServiceReference1.RandomNumbersClient();          Console.WriteLine(\""Starting .... \"");         Console.WriteLine(client.GetNumber()); </code></pre>  <p>Now   the next step is I have added some code that requires \""C:\\Program Files (x86)\\Reference Assemblies\\Microsoft\\Framework.NETFramework\\v4.5.2\\System.Speech.dll\"" to be available in the project.  This is easy on my local server as I just add the reference to the dll in my VS project.</p>  <p>New method ....</p>  <pre><code>    public string GetNumberAsString()     {         Random number = new Random();          SpeechSynthesizer synth = new SpeechSynthesizer();         synth.SetOutputToDefaultAudioDevice();                    synth.Speak(\""This example demonstrates a basic use of Speech Synthesizer\"");          return \""number = \"" + number.Next(1  100).ToString() + \"" number \"";     } </code></pre>  <p>Problem now is when I publish to Azure.  How do I make the DLL available to my app running in Azure? When I call the GetNumber() method it works fine but any call to GetNumberAsString() fails because of the additional code. </p>  <pre><code>        ServiceReference1.RandomNumbersClient client = new ServiceReference1.RandomNumbersClient();          Console.WriteLine(\""Starting .... \"");         Console.WriteLine(client.GetNumberAsString()); </code></pre>  <p>How do I actually inspect the logs for the Webservice running on Azure so I can make a start at finding out what the problem is.</p>""",azure-web-app-service
52910974,Stop direct traffic to Azure WebApp and only allow traffic through CDN <p>When I place a CDN  or something like Azure Front Door  in front of a webapp  how do I stop traffic from directly hitting the .azurewebsite.net domain name?</p>,azure-web-app-service
54050083,"upload video to blob storage not working in Internet Explorer <p>i want to upload video to azure blob storage using Angular-4 and it working in all browser except IE i get error </p>  <blockquote>   <p>SCRIPT7002: XMLHttpRequest: Network Error 0x80070005  Access is denied.</p> </blockquote>  <p>i am using put blob method for uploading video here is a code for it. I have searched for this error found many solutions but didn't work here some link that i have tried but didn't work</p>  <p><a href=\https://stackoverflow.com/questions/37755782/prevent-ie11-caching-get-call-in-angular-2/44561162#44561162\"">Prevent IE11 caching GET call in Angular 2</a></p>  <p><a href=\""https://stackoverflow.com/questions/16098430/angular-ie-caching-issue-for-http\"">Angular IE Caching issue for $http</a></p>  <pre><code>  upload(config: UploadConfig) {     debugger;     var options = new RequestOptions();     if (options == null) {         options = new RequestOptions();     }      const state = this.initializeState(config);     const reader = new FileReader();     reader.onloadend = (evt: any) =&gt; {         if (evt.target.readyState === 2 &amp;&amp; !state.cancelled) {             debugger;             const uri = state.fileUrl + '&amp;comp=block&amp;blockid=' + state.blockIds[state.blockIds.length - 1];             const requestData = evt.target.result;             options.headers = new Headers();             const requestData2 = new Uint8Array(evt.target.result);             options.headers.append('x-ms-blob-type'  'BlockBlob');             options.headers.append('Content-Type'  'application/octet-stream');              this.http.put(uri  requestData  options).retryWhen(error =&gt; {                 return error                     .flatMap((error: any) =&gt; {                         if (error.status === 503) {                             return Observable.of(error.status).delay(1000)                         }                         return Observable.throw({ error: 'No retry' });                     })                     .take(5)                     .concat(Observable.throw({ error: 'Sorry  there was an error (after 5 retries)' }));             })                 .subscribe(elem =&gt; {                     state.bytesUploaded += requestData2.length;                     const percentComplete = ((state.bytesUploaded / state.file.size) * 100).toFixed(2);                     if (state.progress) {                         state.progress();                     }                      this.uploadFileInBlocks(reader  state);                 }  err =&gt; {                     this.messageService.showClientSideErrors('Oops something went wrong while uploading  please try again.')                      this.loaderService.displayBar(false);                 });         }     };      this.uploadFileInBlocks(reader  state);      return {         cancel: () =&gt; {             state.cancelled = true;         }     }; } </code></pre>  <p>i have debugged this code and found that below line of code</p>  <pre><code> this.http.put(uri  requestData  options).retryWhen(error =&gt; {                 return error                     .flatMap((error: any) =&gt; {                         if (error.status === 503) {                             return Observable.of(error.status).delay(1000)                         }                         return Observable.throw({ error: 'No retry' });                     })                     .take(5)                     .concat(Observable.throw({ error: 'Sorry  there was an error (after 5 retries)' }));             }) </code></pre>  <p>i get status=0 and in another browser it's working fine. what's the problem? Version IE-11 Win-10</p>""",azure-storage
49114454,"Copying files and deploying to Azure without building using Visual Studio Team Services <p>I'm attempting to deploy a web site to Azure using VSTS. Basically  I commit code to the GIT repo and have it setup to run CI  so it begins building as soon as I commit. However  once it hits the release section  it never copies the code to the Azure web app  rather  it gives me this line:</p>  <blockquote>   <p>Info: Updating file ({projectname}\\error.txt).</p> </blockquote>  <p>It doesn't copy the files I changed  but rather always just copies this file. I checked and there is indeed an error.txt file in my website directory in Azure  but it is always blank.</p>  <p>This build/deploy process isn't \standard\"" because the build step only downloads from source code  it doesn't build  because the website isn't a \""web application\""  but rather just a \""web site\""  meaning it doesn't need to be built.</p>  <p>So my build step is as follows:</p>  <ul> <li><p>Get Sources</p></li> <li><p>Run on Agent - this step is empty</p></li> </ul>  <p>so the idea is that it just downloads everything from source control  that's it.</p>  <p>Then  my release step is as follows:</p>  <ul> <li><p>Artefacts are from build step above</p></li> <li><p>deploy to environment 1 (dev)</p></li> <li>Azure app service deploy  using \""package or folder\"" as <code>$(System.DefaultWorkingDirectory)/</code></li> </ul>  <p>Any idea what I might be doing wrong here?</p>""",azure-devops
54428049,"How to bind to MessageSender in an Azure function? <p>I'm working with a service bus queue and an Azure function. Failures are handled differently depending on some business logic. Some messages needs to sent to the dead letter queue  others need to be modified then explicitly added back to the queue.</p>  <p>Consider the following code: </p>  <pre class=\lang-cs prettyprint-override\""><code>[FunctionName(\""ServiceBusTask\"")] public static async Task Run(     [ServiceBusTrigger(\""myQueue\""  Connection = \""myConnectionString\"")]     Message message       MessageReceiver messageReceiver       //MessageSender messageSender       ILogger log) {     //some business logic that can fail      if( condition for dead letter)     {         await messageReceiver.DeadLetterAsync(message.SystemProperties.LockToken);     }     else if( condition for a manual retry)     {         QueueClient qc = new Queueclient(\""myQueue\""  \""myConnectionString\"");         Message updatedMessage = GetUpdatedMessage(message);         await qc.SendAsync(updatedMessage);         //await messageSender.SendAsync(updatedMessage);     } } </code></pre>  <p>The messageReceiver works just fine to send messages to the dead letter queue but it bothers me that I need to create a <code>QueueClient</code> to send messages to the queue. Knowing that <code>MessageSender</code> exists  I tried to add it to the parameters but I'm getting an error saying:</p>  <blockquote>   <p>Cannot bind parameter 'messageSender' to type MessageSender. Make sure the parameter Type is supported by the binding. If you're using binding extensions (e.g. Azure Storage  ServiceBus  Timers  etc.) make sure you've called the registration method for the extension(s) in your startup code (e.g. builder.AddAzureStorage()  builder.AddServiceBus()  builder.AddTimers()  etc.).</p> </blockquote>  <p>I'm not too sure why it's telling me about startup code  I have no such thing so I'm guessing the error message wasn't updated...</p>  <p>Reading <a href=\""https://github.com/Azure/azure-webjobs-sdk/issues/1743\"" rel=\""nofollow noreferrer\"">this issue on the Azure webjobs SDK</a>  I get the impression that it should be supported (do correct me if I'm reading it wrong!).</p>  <p><strong>My question</strong></p>  <p>Is it possible to use <code>MessageSender</code> like this and if so  what do I need to do to make it work?</p>""",azure-functions
54326155,Azure Topic Subscription Rule created with Service Bus Explorer not triggering <p>I am using Service Bus Explorer as a quick way of testing a rule that does not work when deployed via ARM.</p>  <p>In JavaScript in the Azure Function I am setting the Topic message to:</p>  <pre><code>context.bindings.outputSbMsg = { Indicator: 'Itinerary'}; </code></pre>  <p>In Service Bus Explorer I am setting a Rule on a Subscription with this string:</p>  <pre><code>Indicator = 'Itinerary' </code></pre>  <p>But messages sent to the Topic do not go to this Subscription ( they go to another with the rule 1 = 1)</p>  <p>Question: What am I missing here?</p>  <p>Supplementary info: </p>  <ol> <li><p>I do not seem to have access to the Indicator property. As a test I created an action on the  1=1 rule that appended to the Indicator property and the result was empty.</p></li> <li><p>I am able to access the Indicator property in JavaScript if I have a Function that is triggered by the 1 = 1 rule  so the property is there.</p></li> </ol>,azure-functions
51589911,"Cannot see a team project that I was able to see before <p>I'm using VS 2010 Professional. There was a team project that I was able to see and use in the past  that I now can't.</p>  <p>I can't understand why this has changed  I checked permissions and everything looks fine (also checked this solution: <a href=\https://stackoverflow.com/questions/28304194/added-team-member-cannot-see-project-despite-similar-permissions\"">Added team member cannot see project despite similar permissions</a>).</p>  <p>Tried reconnecting and some other quick solutions but nothing seems to work.</p>  <p>Any ideas what I can do to fix this?</p>  <p>Thanks.</p>""",azure-devops
43866245,Visual Studio Team Services build variable <p>I'm setting up Visual Studio Team Services online and I have everything working how I want it however I'm using</p>  <pre><code>C:\a\1\s </code></pre>  <p>instead of $(build.something) or $(agent.something)</p>  <p>Does anyone know what the variable is for a\1\s</p>  <p>Thanks</p>,azure-devops
55799038,"Azure Multiple Deployments 409 Conflict <p>We have a deployment process through the CircleCI to the Azure Web Service zip deploy. We have multiple deployments per day to the development instance(it's being automatically deployed once PR is merged to the <code>development</code> branch). But we sometimes into following error: CircleCI run jobs in parallel  which also includes deploy script. If Azure receives multiple deploy requests at the same time(or until one is not finished) it goes down and after all  always responds with the 409(Conflict) error.</p>  <p>Is there any way to fix this?</p>  <p>P.S. I'm currently thinking about this solution <a href=\https://circleci.com/orbs/registry/orb/eddiewebb/queue#usage-examples\"" rel=\""nofollow noreferrer\"">https://circleci.com/orbs/registry/orb/eddiewebb/queue#usage-examples</a> for the CircleCi to not run multiple parallel deployments. But what about Azure? Can I somehow restart/reboot it?</p>""",azure-web-app-service
22448392,Allowing another user to start/stop/configure Azure VM <p>I have an VM in Azure  and I'd like a colleague to manage it as well. </p>  <p>I've added him as </p>  <ol> <li><p>a Global Administrator in Azure Active Directory. </p></li> <li><p>Coadministrator for my account</p></li> </ol>  <p>However  the VM does not show up when he logs in?</p>,azure-virtual-machine
22371547,How to avoid race condition in Windows Azure Queue <p>We have a Queue and multiple instances of same worker role reading the messages from the queue. The processing of each message is very fast. How do we avoid a case where two instances try to read same message from the queue at exact same point of time. </p>,azure-storage
54872737,"Need an example of URI to generate SAS Blob connection token and URI <p>I created the webless app on Azure for <a href=\https://github.com/Azure-Samples/functions-dotnet-sas-token/\"" rel=\""nofollow noreferrer\"">https://github.com/Azure-Samples/functions-dotnet-sas-token/</a>  but there is no sample URI for how to ask that running service for a URI for my blob file.  There is descriptions but no functional POST uri as an example</p>""",azure-storage
56611574,"Azure Pipeline (YAML) deploys an empty solution to my FunctionApp <p>I'm building a CI-CD azure pipeline with YAML to deploy an azure function app. Everything works fine  I can even set some properties for the function app  but my function app remains empty.</p>  <p>I downloaded the zip artifact and it looks just fine.</p>  <pre><code>trigger: - master variables:   variables:   buildConfiguration: 'Release'   Parameters.RestoreBuildProjects: '**/TestFunction.csproj' stages: - stage: Build   jobs:   - job:     pool:       vmImage: 'vs2017-win2016'       continueOnError: false     steps:         - task: DotNetCoreCLI@2       displayName: 'Restore'       inputs:         command: 'restore'         projects: '$(Parameters.RestoreBuildProjects)'         feedsToUse: 'select'         vstsFeed: '/0856b234-f3a6-4052-b5a6-ed9f6ec9c635'     - task: DotNetCoreCLI@2       displayName: Build       inputs:         projects: '$(Parameters.RestoreBuildProjects)'         arguments: '--configuration $(BuildConfiguration)'     - task: DotNetCoreCLI@2       displayName: 'Publish Build'       inputs:         command: publish         arguments: '--configuration $(BuildConfiguration)'         projects: '$(Parameters.RestoreBuildProjects)'         publishWebProjects: false         modifyOutputPath: true         zipAfterPublish: false     - task: ArchiveFiles@2       displayName: \Archive Files\""       inputs:         rootFolderOrFile: \""$(System.DefaultWorkingDirectory)\""         includeRootFolder: false         archiveFile: \""$(System.DefaultWorkingDirectory)/build$(Build.BuildId).zip\""     - task: PublishBuildArtifacts@1       inputs:         PathtoPublish: '$(System.DefaultWorkingDirectory)/build$(Build.BuildId).zip'         ArtifactName: 'drop'     - stage: Deploy   jobs:     # track deployments on the environment   - deployment:     pool:       vmImage: 'vs2017-win2016'     # creates an environment if it doesn’t exist     environment: 'dev'     strategy:       # default deployment strategy       runOnce:         deploy:           steps:           - task: DownloadBuildArtifacts@0             displayName: 'Download Artifacts'             inputs:               buildType: 'current'               downloadType: 'specific'               downloadPath: '$(System.ArtifactsDirectory)'                   - task: AzureFunctionApp@1             displayName: 'Azure Function App Deploy: ngproductionfetcherfuncref'             inputs:               azureSubscription: 'Agder Energi Sandbox (1aa9cf92-9d42-49a6-8d31-876ac2dff562)'               appType: functionApp               appName: myFunctionApp               package: '$(System.ArtifactsDirectory)/**/*.zip'               appSettings: '-name0 value0 -name1 value1' </code></pre>  <p>The pipeline is all green:</p>  <p>Got service connection details for Azure App Service:'myFunctionApp' Updating App Service Application settings. Data: {\""WEBSITE_RUN_FROM_PACKAGE\"":\""1\""} {\""WEBSITE_RUN_FROM_ZIP\"":{\""value\"":\""\""}} Updated App Service Application settings and Kudu Application settings. Package deployment using ZIP Deploy initiated. Successfully deployed web package to App Service. Updating App Service Application settings. Data: {\""name0\"":\""value0\"" \""name1\"":\""value1\""} undefined Updated App Service Application settings and Kudu Application settings.</p>""",azure-functions
45595777,"Using VSTS can I install extensions other than those listed in the dropdown? <p>I would like to install a Web App extension as part of my VSTS build/deployment. The list of options only includes a few options (mostly Python). How/can I install other extensions?</p>  <p><a href=\https://i.stack.imgur.com/D4B9k.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/D4B9k.png\"" alt=\""enter image description here\""></a></p>""",azure-web-app-service
56926795,"how to bind to a container in order to iterate through blobs <p><strong>Is it possible to iterate through the blobs inside of a container?</strong></p>  <p>Currently  I've added this attribute:</p>  <pre><code>[Blob(\%MyFunc:InputContainer%\"")]CloudBlobContainer inputContainer </code></pre>  <p>However  I've not found any documentation on how to iterate through the the blobs inside of the <code>inputContainer</code>.</p>""",azure-functions
41521465,"AzureFunctions binding to SendGrid <p>Trying to figure out how to use SendGrid from an azure function. Not much docs to find  but this is what I've tried:</p>  <pre><code>#r \SendGrid\"" using SendGrid.Helpers.Mail; using System;  public static void Run(string myQueueItem  out Mail message  TraceWriter log) {     log.Info($\""C# Queue trigger function processed: {myQueueItem}\"");     message=new Mail(); } </code></pre>  <p>I've hardcoded to  from  subject and body  together with api key in the integrate output section. This is my function.json:</p>  <pre><code>{ \""bindings\"": [ {   \""name\"": \""myQueueItem\""    \""type\"": \""queueTrigger\""    \""direction\"": \""in\""    \""queueName\"": \""send-email-request\""    \""connection\"": \""myStorage\"" }  {   \""type\"": \""sendGrid\""    \""name\"": \""message\""    \""apiKey\"": \""SG.xxxxxxxxxxx\""    \""direction\"": \""out\""    \""to\"": \""me@gmail.com\""    \""from\"": \""me@gmail.no\""    \""subject\"": \""hardcoded\""    \""text\"": \""test213\"" } ]  \""disabled\"": false } </code></pre>  <p>I get the following error:</p>  <pre><code>Function ($SendEmailOnQueueTriggered) Error: Microsoft.Azure.WebJobs.Host: Error indexing method 'Functions.SendEmailOnQueueTriggered'. Microsoft.Azure.WebJobs.Host: 'SG.xxxxxx' does not resolve to a value. Session Id: 9426f2d7e4374c7ba7e0612ea5dc1814 Timestamp: 2017-01-07T12:18:01.930Z </code></pre>  <p>I've granted the Apikey full access in SendGrid. Any ideas what I've missed?</p>  <p>Larsi</p>""",azure-functions
52434939,All Functiona Apps turn to Read only mode after publishing Azure function project via visual stuido 2017 <p>I have a Function Apps created via Portal  another one created by visual studio. The latter one cause both apps to become read only  with message below:</p>  <blockquote>   <p>Your app is currently in read-only mode because you have published a   generated function.json. Changes made to function.json will not be   honored by the Functions runtime</p> </blockquote>  <p>Is this feature correct?</p>  <p>VS: 15.8.5</p>,azure-functions
49306041,"Azure Table Storage - Search on RowKey that ends with a particular string <p>I am using Azure table storage which provides very less options to query the table storage. I have my RowKey as a composed key in the following way:</p>  <pre><code>\b844be0d-2280-49f7-9ad7-58c36da80d22_2518908336099522182\""  \""b844be0d-2280-49f7-9ad7-58c36da80d22_2518908336099522183\""  \""b844be0d-2280-49f7-9ad7-58c36da80d22_2518908336099522184\""  \""b844be0d-2280-49f7-9ad7-58c36da80d22_2518908336099522185\"" </code></pre>  <p>The first part is a Guid  and the second part after the separator(_) is the timeticks.</p>  <p>I want to search on azure storage using its operators for rowkeys ending with \""2518908336099522182\""</p>  <p>There is no \""Contains\"" operator that can help here  What do i do to get it working for \""EndsWith\"" kind of filtering?</p>""",azure-storage
38092164,Adding existing Azure VMs (classic) to a virtual network <p>On Azure  I have a two-VM set (both classic)  whereby my web application resides on one VM  my database on another. Both map to the same DNS and belong to the same Resource Group  but both are acting as standalone cloud services at the moment. Let me explain: currently the web application communicates with the database over <em>the public DNS</em>. However  I need them to be on the same lan  so I can de-risk security and improve latency. </p>  <p>I know for a fact that they're not part of a virtual network because when I try to affix a static private IP to my database VM  I'm shown the following prompt in the portal:</p>  <blockquote>   <p>This virtual machine can't be configured with a static private IP   address because it's not deployed in a virtual network.</p> </blockquote>  <p>How should I proceed to fix this misconfiguration and what should my next concrete step be? The website is live  and I don't want to risk service interruption. Ideally  both VMs should be in the same virtual network  and should communicate with eachother via a static internal IP. Please forgive my ignorance. Any help would be greatly appreciated.</p>,azure-virtual-machine
22345009,"Enabling monitoring in azure cloud service <p>I want to monitor a cloud service in azure portal . When I go to the azure portal   I get the message as \LEVELThis setting is not currently available.\"" under monitoring tab.</p>  <p>Then I learnt from the msdn that   right click on web role in visual studio and check the \""enable diagnostics\"" checkbox. </p>  <p>Then I redeployed the application azure portal . Still the monitoring option is not configurable. What could be the issue ? What am I missing here?</p>""",azure-storage
49177142,"Trying to configure build agent to work with a proxy server <p>I'm trying to make my build agent work with an already configured proxy server. The proxy server address is : <a href=\http://MY_SERVER_DNS:8081\"" rel=\""nofollow noreferrer\"">http://MY_SERVER_DNS:8081</a></p>  <p>On my build machine inside the agent directory I created a .proxy file which contains the above proxy address and created the relevant environment variables (VSTS_HTTP_PROXY_USERNAME  VSTS_HTTP_PROXY_PASSWORD).</p>  <p>After a restart to the build agent service the indicator in VSTS goes red (instead of green). A partial (most relevant I guess) agent log is attached:</p>  <pre><code>{ Request = Method: GET  RequestUri: 'https://siemplify.visualstudio.com/_apis/connectionData?connectOptions=1&amp;lastChangeId=-1&amp;lastChangeId64=-1'  Version: 1.1  Content: &lt;null&gt;  Headers: {   User-Agent: VSServices/15.255.65000.0   User-Agent: (NetStandard; Microsoft Windows 6.3.9600)   User-Agent: VstsAgentCore-win7-x64/2.120.2   User-Agent: (Microsoft Windows 6.3.9600)   X-VSS-E2EID: 5aadb1b3-6269-4998-b258-4a5fcc1b9345   Accept-Language: en-US   X-TFS-FedAuthRedirect: Suppress   X-TFS-Session: 13f3aaa0-7f5c-40e1-8af0-0b5feb53d4bc   Expect: 100-continue }  LoggingRequestId = ab31853f-a392-486f-b288-f9ca4bdee28c  Timestamp = 237057153 } [2018-03-08 14:15:50Z INFO HttpTrace] Trace System.Net.Http.Response event: { Response = StatusCode: 400  ReasonPhrase: 'Bad Request'  Version: 1.1  Content: System.Net.Http.StreamContent  Headers: {   Connection: close   Date: Thu  08 Mar 2018 14:15:32 GMT   Server: Microsoft-HTTPAPI/2.0   Content-Length: 324   Content-Type: text/html; charset=us-ascii }  LoggingRequestId = ab31853f-a392-486f-b288-f9ca4bdee28c  TimeStamp = 237507550 } [2018-03-08 14:15:51Z ERR  VisualStudioServices] GET request to https://siemplify.visualstudio.com/_apis/connectionData?connectOptions=1&amp;lastChangeId=-1&amp;lastChangeId64=-1 failed. System.Net.Http.HttpRequestException: Error while copying content to a stream. ---&gt; System.IO.IOException: Unable to read data from the transport connection. The connection was closed before all data could be read. Expected 324 bytes  read 0 bytes. </code></pre>  <p>Any help would be greatly appreciated!</p>""",azure-devops
29627558,"Pricing Calculation for Azure File Service <p>I am having a query related to pricing for Azure File Service that how pricing happens like as per usage of GB data of file or will it be based on available size for file share like 5TB per share.</p>  <p>I am referring this link <a href=\http://azure.microsoft.com/en-us/pricing/details/storage/\"" rel=\""nofollow\"">http://azure.microsoft.com/en-us/pricing/details/storage/</a> but this is not giving me the exact pricing.</p>  <p>My Scenario is like let’s say:- 1)   for two months I would require 4GB file data on File Share and then for another 4 month I would require 5GB of file data so how the costing will happen? 2)  Would I require two VMs for this to maintain the availability and how the costing will happen for two VMs usage?</p>  <p>Kindly help me on this.</p>""",azure-storage
56085085,How can I restart an Azure Web App instance programmatically? <p>I have a set of Azure Web Apps which occasionally have single instances become unhealthy. We've identified that restarting that specific instance via Advanced Diagnostics brings the instance back up.</p>  <p>We'd like to build some automation such that once this unhealthy instance is detected  we will automatically go and restart that instance (note  we only want to restart the instance  not the whole webapp).</p>  <p>We have found <code>public static Task RestartAsync(this IWebAppsOperations operations  string resourceGroupName  string name  bool? softRestart = null  bool? synchronous = null  CancellationToken cancellationToken = default);</code> in <code>Microsoft.Azure.Management.AppService.Fluent</code> -> <code>WebAppsOperationsExtensions</code>  and similar in the non-Fluent ARM library. However this only allows us to restart the entire webapp. We want to minimise disruption and only target a specific instance with the restart.</p>  <p>Is there a mechanism through either a .NET library  or REST API (where we would build the request ourselves) to restart a single webapp instance?</p>,azure-web-app-service
55198903,Azure container often connecting to 23.97.221.176:11041. What is this port for? <p>I'm monitoring my App Service Linux containers on Azure. I use netstat to see which outgoing connections are made. I can explain them all except one: 23.97.221.176:11041</p>  <p>Is there someone out there who knows which service uses port 11041?</p>,azure-web-app-service
45499221,Storing the data to Azure storage  blob or table? <p>I have a Web app with database where the consumption data are stored in SQL database. I want to consolidate the data data older than 3 months to SQL database and save the unconsolidated data to storage. The data will not be often accessed because the consolidated info will be available in SQL it's only for purpose that somethink will go wrong. It is better to use table or blob storage? Thanks for your advices.</p>  <p>The data will be accesed separately or based on from which building they are comming. For example I have building A and someone comes and want to know the detailed consumption for a week or day half year ago. I will go to storage and get the data. The data in SQL are stored every 5 minutes.</p>,azure-storage
52783690,"Need to upgrade Azure VM Standard HDD to SSD? <p>I got the email from Azure :  \Adjust your disk throughput or upgrade to premium disk storage You’re receiving this email because you’re running infrastructure as a service virtual machine (VM) workloads on a Standard HDD or Standard SSD Disk in Azure Storage  and your disk traffic exceeds 60 MB/s.\"" Background: The VMs are used in a service is going to be shut down and replaced  in afew months.  Can I leave the VMS unchanged ? Any comments ? Thanks    Peter </p>""",azure-virtual-machine
50378398,"Coded UI C# - How to Upload Captured Image to Azure Storage Container <p>From a Coded UI test method  what is the way to upload a captured image into Azure Storage and not saving in local drive? </p>  <p>To save a captured image into a local file  I am doing the following  it works fine: </p>  <pre><code>BrowserWindow window = new BrowserWindow(); Image cml1 = window.CaptureImage(); cml1.Save(screenshotDir + screenshotDirClickMainLinks + \1\"" +  CMLelectAndNaturalGas + DateTime.Now.ToString(dateTime) + fileSuffix);  </code></pre>  <p>How to upload \""cml1\"" into Azure Storage without saving it in a local drive? Do I convert cml1 one into a stream that can be input into an Azure storage object? This <a href=\""https://stackoverflow.com/questions/1668469/system-drawing-image-to-stream-c-sharp\"">link</a> looks to have some info  but it does not talk about Azure Storage. This <a href=\""https://docs.microsoft.com/en-us/dotnet/api/microsoft.windowsazure.storage.blob.cloudblockblob.uploadfromstream?view=azure-dotnet\"" rel=\""nofollow noreferrer\"">link</a> has \""UploadFromStream\"" method for CloudBlockBlob  but no example is given.</p>  <p>For Azure Storage  I know <a href=\""https://stackoverflow.com/questions/50301353/c-sharp-azure-storage-how-to-upload-a-file-to-an-already-existing-container\"">how to create a container and upload a local file into that container</a>. Here is the code segment: </p>  <pre><code>if (CloudStorageAccount.TryParse(storageConnectionString  out storageAccount)) {     // Get the reference of the storage blob     CloudBlobClient client = storageAccount.CreateCloudBlobClient();      CloudBlobContainer container = client.GetContainerReference(\""testresult\"");       container.CreateIfNotExists();  CloudBlockBlob cloudBlockBlob = container.GetBlockBlobReference(localFileName); cloudBlockBlob.UploadFromFile(sourceFile);  // Uploading second file  CloudBlobContainer container2 = client.GetContainerReference(\""testresult\"");             container2.CreateIfNotExists();   CloudBlockBlob cloudBlockBlob2 = container2.GetBlockBlobReference(localFileName2); cloudBlockBlob2.UploadFromFile(sourceFile2); </code></pre>  <p>}</p>  <p>How do I use \""cml1\"" reference to upload the captured image into Azure Storage directly without saving it into a local folder first?</p>  <p>Thank you.</p>""",azure-storage
57366125,"Node app deployed to Azure App Service : Error: The service is unavailable <p>I followed a <a href=\https://code.visualstudio.com/tutorials/app-service-extension/getting-started\"" rel=\""nofollow noreferrer\"">tutorial</a> on deploying a simple Node app from VSCode using the Azure App Service extension.</p>  <p>The app runs fine locally.</p>  <p>When I deploy I get this output:</p>  <pre><code>Creating resource group \""appsvc_linux_centralus\"" in location \""centralus\""... Successfully created resource group \""appsvc_linux_centralus\"". Ensuring App Service plan \""appsvc_linux_centralus\"" exists... Creating App Service plan \""appsvc_linux_centralus\""... Successfully created App Service plan \""appsvc_linux_centralus\"". Creating new web app \""XXX-node-users-api\""... Created new web app \""XXX-node-users-api\"": https://XXX-node-users-api.azurewebsites.net 21:28:12 XXX-node-users-api: Creating zip package... 21:28:33 XXX-node-users-api: Starting deployment... Error: The service is unavailable. </code></pre>  <p>In the portal there is nothing listed in <code>Diagnose and solve problems</code>. How can I tell why the service in unavailable (which it does show when I click on the link)?</p>  <p>UPDATE: I followed the same process with a different Node app (which I got from another <a href=\""https://docs.microsoft.com/en-us/azure/app-service/containers/quickstart-nodejs\"" rel=\""nofollow noreferrer\"">MS tutorial</a>) and I got this:</p>  <pre><code>Using existing resource group \""appsvc_linux_centralus\"". Ensuring App Service plan \""appsvc_linux_centralus\"" exists... Successfully found App Service plan \""appsvc_linux_centralus\"". Creating new web app \""nodejs-docs-hello-world-20190805\""... Created new web app \""nodejs-docs-hello-world-20190805\"": https://nodejs-docs-hello-world-20190805.azurewebsites.net 22:13:06 nodejs-docs-hello-world-20190805: Creating zip package... 22:13:07 nodejs-docs-hello-world-20190805: Starting deployment... 22:14:31 nodejs-docs-hello-world-20190805: Fetching changes. 22:14:31 nodejs-docs-hello-world-20190805: Cleaning up temp folders from previous zip deployments and extracting pushed zip file /tmp/zipdeploy/59khfmlp.zip (0.00 MB) to /tmp/zipdeploy/extracted 22:14:31 nodejs-docs-hello-world-20190805: Central Directory corrupt. Error: Deployment to \""nodejs-docs-hello-world-20190805\"" failed. See output channel for more details. </code></pre>  <p>I get the feeling I'm doing something obvious wrong or the extension is mangling the code. Where do I start?</p>  <p>Thanks</p>""",azure-web-app-service
27008119,Setting up Duplicate VM's in Azure for an Availability Set <p>We're setting up VM's on azure in an availability set to ensure maximum uptime and perf.</p>  <p>We just want to have multiple identical VM's so that traffic can be distributed using Azure load balancer and also fault tolerance if one box goes down.</p>  <p>I'm struggling to workout how to make sure each VM is identical and also stays in sync  we are constantly adding stuff to our web VM. I get that we can create an image of VM 1 and just use that to create VM 2 and so on. But if a file gets added to VM 1 than i need to make sure that is reflected on all the other VM's as well. Is there a way to achieve this?</p>  <p>Any advice is appreciated.</p>  <p>Thanks</p>,azure-virtual-machine
7309015,Local sync with Azure Table Storage <p>I want to sync data in the Azure Table Storage with a local windows desktop client. The desktop client should work without being online all the time so he has to download the newest data from the ATS and upload any changes which are made to the local data.</p>  <p>Is there something premade to take care of that or do I have to code this from scratch?</p>  <p>Maybe there are some articles on the net I didn't see yet. I suppose the Sync Framework is the way to go here but I did not find anything specific on usage with the Azure Table Storage.</p>,azure-storage
49809615,"Azure functions using Java - How to created @BlobTrigger <p>i need to created Azure function BlobTrigger using Java to monitor my storage container for new and updated blobs.</p>  <p>tried with below code</p>  <pre><code>import java.util.*; import com.microsoft.azure.serverless.functions.annotation.*; import com.microsoft.azure.serverless.functions.*; import java.nio.file.*; import java.io.*; import java.net.URL; import java.net.URLConnection; import java.time.LocalDateTime; import java.time.format.DateTimeFormatter; import com.microsoft.azure.storage.*; import com.microsoft.azure.storage.blob.*;  @FunctionName(\testblobtrigger\"")  public String testblobtrigger(@BlobTrigger(name = \""test\""  path = \""testcontainer/{name}\"") String content) {      try {          return String.format(\""Blob content : %s!\""  content);       } catch (Exception e) {          // Output the stack trace.          e.printStackTrace();          return \""Access Error!\"";      }  } </code></pre>  <p>when executed it is showing error</p>  <blockquote>   <p>Storage binding (blob/queue/table) must have non-empty connection. Invalid storage binding found on method:</p> </blockquote>  <p>it is working when added connection string </p>  <pre><code>public String kafkablobtrigger(@BlobTrigger(name = \""test\""  path = \""testjavablobstorage/{name}\"" connection=storageConnectionString) String content) { </code></pre>  <p>why i need to add connection string when using blobtrigger?</p>  <p>in C# it is working without connection string:</p>  <pre><code>public static void ProcessBlobContainer1([BlobTrigger(\""container1/{blobName}\"")] CloudBlockBlob blob  string blobName) {     ProcessBlob(\""container1\""  blobName  blob); } </code></pre>  <p>i didn't see any Java sample for Azure functions for @BlobTrigger.</p>""",azure-functions
53581584,"How to verify\\check hardening of an Azure VM? <p>I install hardening feature on my Azure VM with DSC. With this script: <a href=\https://luke.geek.nz/Using-dsc-for-windows-hardening\"" rel=\""nofollow noreferrer\"">https://luke.geek.nz/Using-dsc-for-windows-hardening</a> </p>  <p>How do I know it worked.</p>""",azure-virtual-machine
49473480,"Install extension on both Classic and ARM VMs with single PowerShell command <p>I have a script that installs OMS extensions to all ARM VMs in the subscription. The problem is that I have subscriptions that contain only ARM VMs  subscriptions that contain only Classic VMs  and subscription that have both types of VMs. How can I modify the script to work in all of the conditions? The script is:</p>  <pre><code>#This script installs OMS Monitoring Agent to all VMs in the selected Subscription. #Before running this script  the user must login to Azure account and select target subscription. #Example: #Login-AzureRmAccount #Select-AzureRmSubscription 'SubscriptionName'  $WorkspaceID = 'Provide Workspace ID here' $WorkspaceKey = 'Provide Workspace key here' $VMs = Get-AzureRmVM  $VMs.where({$_.osprofile.windowsconfiguration}) | ForEach-Object {     \Installing Microsoft.EnterpriseCloud.Monitoring.MicrosoftMonitoringAgent Extension: {0}\"" -f $_.id     Set-AzureRmVMExtension -ResourceGroupName $_.ResourceGroupName -VMName $_.Name -Name omsAgent -Publisher 'Microsoft.EnterpriseCloud.Monitoring' `     -ExtensionType 'MicrosoftMonitoringAgent' -AsJob -TypeHandlerVersion '1.0' -Location $_.Location -ForceRerun 'yesh' `     -SettingString ( \""{'workspaceId': '$WorkspaceID'}\"") `     -ProtectedSettingString \""{'workspaceKey': '$WorkspaceKey'}\"" |      Add-Member -Name VM -Value $_.Id -MemberType NoteProperty } </code></pre>""",azure-virtual-machine
46834602,Azure Logic App gets csv file from SFTP Server and inserts into Azure SQL Database Table <p>Can someone please recommend the best way of doing this using Azure Logic App:</p>  <p>The scenario that i have is to:</p>  <p>i) Connect to SFTP Server</p>  <p>ii) Get csv file from the SFTP Server</p>  <p>iii) Parse the csv file and move the load to an Azure SQL Database Table</p>  <p>After getting the csv file from the SFTP server using the SFTP Connector  should i pass the content of the file to an Azure Function?</p>  <p>Then in the Azure Function  parse the file content and then use a stored procedure within the Function?</p>  <p>Or pass the transformed file content back to the logic app to execute the stored procedure to insert the records into Azure SQL?</p>  <p>Or any other recommendations</p>,azure-functions
54724709,"How to create Virtual Machine in Azure Free Services without cost <p>Azure says <a href=\https://azure.microsoft.com/en-us/free/?ref=VSDevEssentials\"" rel=\""nofollow noreferrer\"">here</a> that </p>  <blockquote>   <p>750 Hours of B1S VM and 64 GB X 2 Managed Disks  2 P6 SDDs</p> </blockquote>  <p>and some others are free each month for 12 months.</p>  <p>On VM create in Azure Portal  There are Basics  Disks and other tabs  In Basics  I could able to select Image Size to B1S VM but in Disks tab  there is no option to select Managed Disk of 64GB of P6 SDDs.</p>  <p>There are only three options i.e Premium SSD  Standard SSD  Standard HDD. Whatever I select and proceed further  VM takes default of 128 GB C Drive and 4 GB of Temp Drive and starts billing.</p>  <p>Where can I select that free 64 GB X 2 Managed Disks  2 P6 SDDs.?</p>""",azure-virtual-machine
22149208,Visual studio online build minutes when using own build server <p>Currently I am analysing a setup for a sharepoint development project in Windows Azure. I would like to use Visual studio online (TFS online).</p>  <p>Since Visual Studio online doesn't support building sharepoint projects (missing ddl's in de GAC)  we need to use an own build server (either a VM in windows azure or a server on-premise).</p>  <p>Now  when you build a project with Visual studio online  you are being charged every minute you build. Because you use CPU power. But do you also pay those minute's if you use you're own custom buildserver?</p>  <p>I cannot find the awnser on any of the sites of windows  so does anyone have expirience with this?</p>  <p>Thanks in advance!!!</p>,azure-devops
49046786,Enumerate all function descriptors from within an Azure function invocation <p>I have a precompiled function C#/.NET and I would like to list all the <code>FunctionDescriptor</code> instances. Something similar to how the <code>ApiExplorer</code> works in WebApi 2.</p>  <p>Is there such an API? I've only been able to get at the metadata for the currently running function  not all the other functions contained in a function project.</p>  <p>I guess I can read the <code>function.json</code> file and go from there but I was hoping that there actually was a simple public API to actually enumerate all the functions that can be invoked  this to not have to implement HTTP binding work that has already been implemented.</p>  <p>...or even if there's a way to simply read the <code>function.host</code> file. (and of course  I know that I can simply read the file but you have to map the types and figure out the bindings  this is what I was hoping there would be a somewhat straightforward API for)</p>  <p>I've checked around the source but I'm getting turned around and a lot of the APIs appear to be <code>internal</code></p>,azure-functions
50351797,"Azure App Service Application settings <p>As far as I know we can store connection strings in azure <code>Applications settings</code> under <code>Connection string</code> section. My question is  can we store below configuration in Application settings.</p>  <pre><code>\IdentityConfig\"": {     \""Authority\"": \""http://myapp.azurewebsites.net\""   } </code></pre>  <p>When I deploy application I don't want to change Authority value each time into different environments. This section belongs to <code>appsettings.json</code> file in a ASP.NET CORE project.</p>""",azure-web-app-service
39597466,"How to add user in VSTS to the \Team Foundation Service Accounts\"" Group? <p>I want to migrate/transfer some workitems from a tfs  on premise server to a VSTS project.</p>  <p>Therefore the user who executes the TFS Integration tool must be a member of the VSTS \""Team Foundation Service Accounts\"" group. How can be added my user to this group in VSTS? The add button is disabled. My user is a member of project collection admins.</p>  <p>At tfs on premise this was done with the command console using the \""tfssecurity.exe\"" command. But now on VSTS?</p>  <p>I would be very grateful for any help</p>""",azure-devops
444528,"How Would I know my Azure Table Storage AccountName? <p>I'm trying to move some table storage in Azure from local storage to the cloud.  I had been using the \devstoreaccount1\"" for local access  but I'm not sure what I need to put there for moving to the cloud.</p>  <p>It's not the user account I used to sign up for my Azure accounts  is it?  That's just my email address  and that didn't seem to work.  I've tried the project name without luck either.</p>  <p>Is there anywhere in the portal that lists this account name?</p>""",azure-storage
57660750,"http timeout even after making a server call ( ajax call ) every 3 mins (180 sec) to have server respond and keep the http connection alive <p>i am working on a django application currently deployed on azure app service.i includes generation of report in docx. format. in some scenerios i takes upto 5-6 minutes. at first i encountered activity timeout after 70 sec which i solved by using applicationHost.xdt to configure activitytimeout and request timeout. then another timeout happened after 230 sec almost. which according to my knowledge is due to load balancer. i understand it is not configurable in app service.. do i tried another technique which basically does is that it keeps pinging backend from client after every 180 sec. but the problem didn't go away. pasting detailed code below.  Thanks in advance </p>  <pre><code>   function pinger(stop) {   if (status == true)   {     return;   }   else   {     $.ajax({     async   : false        url:\{% url 'DummyUrl' %}\""      type: \""GET\""      data: {}      beforeSend:function()     {        console.log('starting dummy')     }      success:function(response){     console.log('success dummy')      console.log(response.data)      }      complete:function(){}      error:function (xhr  textStatus  thrownError){}    });   return;   }  }      function generate_report() {        var status = false;      $.ajax({     async   : true      url:\""{% url 'GenerateReport' %}\""      headers: { \""X-CSRFToken\"": '{{csrf_token}}' }      type: \""POST\""      data: {}      beforeSend:function()     {           console.log('starting');       console.log('readonly');     }      success:function(response){       if (response.data.toString().includes('.docx'))           {             console.log(response);             var url_mask = \""{% url 'download report' filename=12345 %}\"".replace(/12345/  response.data.toString());             console.log('document generated successfully here is the link');             status = true;             show_download_link(url_mask);            }        else{ console.log(response)}        }      complete:function(){       console.log('completed')     }      error:function (xhr  textStatus  thrownError){       Error_Link();       console.log('error+')     }    });           // pinger(stop)   setTimeout(function(){ pinger(status); }  180000);   // setInterval(pinger(stop)   120000);    }     $(\""#generate_report_form\"").on('submit'  function(event){     event.preventDefault();     generate_report();  }); </code></pre>  <p>the code above calls two APIs simultaneously one for report generation and one for keeping connection alive. but timeout still happens. Please help....</p>""",azure-web-app-service
55179728,"Can we use Bitbucket Data center to create build pipelines in Azure Devops / VSTS? <p>I have used Github and Azure Git repo to build Azure DevOps build and release pipelines.  Now I have to use Bitbucket Data center to do the same. Is it possible to use Bitbucket data center? If yes  how do I go about and what option to choose in the Select repo (Visual designer) form to create it? <a href=\https://i.stack.imgur.com/tu2ZY.jpg\"" rel=\""nofollow noreferrer\"">Select repo in Azure devops</a></p>""",azure-devops
49713179,Is it possible to download from my MSDN Subcription directly to my Azure File storage without an Azure VM? <p>I have an MSDN Subcription which allows me to download and install various Microsoft products.</p>  <p>I would like to download from there the Sql Server 2016 Developer edition. But for the reasons that are irrelevant for this question  I would like to keep the downloaded ISO file not on the local machine  but on an Azure File share I have in my Azure account.</p>  <p>Right now  I first download from MSDN to my machine and then upload to the Azure File Storage.</p>  <p>Wasteful  it would be much more efficient if I could somehow download it directly to Azure Files from MSDN.</p>  <p>I understand that if I had an Azure VM  that would be possible. But I do not. So  I am wondering if it is possible to do it anyway without an Azure VM.</p>,azure-virtual-machine
46749729,"Azure Functions - how to return a location header <p>I'm new to Azure Functions and have a simple question about how to generate a <strong>Location</strong> header for a newly created resource. I have created a simple function that is used to create a Person (original eh?).</p>  <p>In my example I'm using DocumentDB for storage. I want to return a Location header to the client that they can then de-reference should they wish to  but to do that I need to know about routing.</p>  <p>My code is as follows...</p>  <pre><code>public static class PersonProcessing {     [FunctionName(\person\"")]     public static async Task&lt;HttpResponseMessage&gt; Create(         [HttpTrigger(AuthorizationLevel.Anonymous  \""post\"")]HttpRequestMessage req          [DocumentDB(\""Test\""  \""People\""  CreateIfNotExists = true)]ICollector&lt;Person&gt; outTable          TraceWriter log)     {         var tx = await req.Content.ReadAsAsync&lt;Person&gt;();          tx.Id = Guid.NewGuid();          outTable.Add(tx);          var response = req.CreateResponse(HttpStatusCode.Created  tx);         response.Headers.Location = new Uri($\""{req.RequestUri}/{tx.Id}\"");         return response;     }      public class Person     {         [JsonProperty(\""id\"")]         public Guid Id { get; set; }          public string Name { get; set; }     } } </code></pre>  <p>I have created the Location header based on the incoming <strong>RequestUri</strong>  but is there a better (or more standard) way to do this with Azure Functions? </p>  <p>Is what I have done here accepted wisdom - I can't find any useful resources on the web hence my question?</p>  <p>Thanks in advance for your responses.</p>""",azure-functions
49121999,Azure Function how to move appsettings from local to server and vice versa <p>I m a little new to Azure.</p>  <p>Issue is I m developing Azure Functions and some times I have to work locally (code/ test etc) and other times on Azure. Every time I switch I have to compare and change app settings manually. </p>  <p>Is there a way I can avoid it ? Something where if I run locally I may get latest from server without manual and when I go to server Azure may be aware of my changes ?</p>  <p>Thanks </p>,azure-functions
56581102,"Files Transform : EPERM: operation not permitted in Azure DevOps <p>I am trying to make Release in Azure DevOps for .Net Core Web Application. </p>  <p>I am using the <strong>File Transform</strong> task of Release. for Dev environment it's working perfectly fine. but when I am trying to make release defination for Test it's giving me error that  ##[error]Error: EPERM: operation not permitted  stat '\\(ServerName)\\d$\\www(sitename)'</p>  <p><a href=\https://i.stack.imgur.com/gwYUU.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/gwYUU.png\"" alt=\""enter image description here\""></a></p>  <p>Any one have idea about that?</p>""",azure-devops
54538716,"Where can I find what \Fields\"" are in my Azure Storage Blob Container for use with Azure Search Index? <p>I can't seem to find this information in any MSFT documentation. I'm wanting to create a new search index from an already existing Storage Blob Container  but can't seem to do so by clicking on the \""Add Search\"" button from the storage view. So  I decided to go the other way and create the index by linking to the blob storage  but selecting \""Import Data >  existing blob\"" gives another error when trying to validate the data: </p>  <p>Error detecting index schema from data source: \""\""</p>  <p>Searching on that error led me to this:  <a href=\""https://stackoverflow.com/questions/45762131/azuresearch-error-on-detecting-index-schema-from-data-source\"">AzureSearch- Error on detecting index schema from data source</a></p>  <p>which was not helpful.</p>""",azure-storage
9904588,Whats the correct code for Microsoft.Practices.TransientFaultHandling.RetryPolicy? <p>I use following code:</p>  <p>Create a retry policy  when error  retry after 1 second  then wait 3 seconds  then 5 seconds. based on Azure SLA  retry within 10 seconds must success (No throttled  I sure this. because error even happens on unique partition and table which no traffic yet)</p>  <pre><code>var retryStrategy = new Incremental(3  TimeSpan.FromSeconds(1)  TimeSpan.FromSeconds(2)); var FaultHandlingRetryPolicy = new RetryPolicy&lt;StorageTransientErrorDetectionStrategy&gt;(retryStrategy); </code></pre>  <p>Then I use this code to get data</p>  <pre><code>FaultHandlingRetryPolicy .ExecuteAction(() =&gt;         {             var results = (from q in Query select new q).ToList();         }); </code></pre>  <p>I DO NOT KNOW if its retried or not  because the error log not shown</p>  <p>Errors:</p>  <pre><code>System.Net.WebException: Unable to connect to the remote server ---&gt; System.Net.Sockets.SocketException: No connection could be made because the target machine actively refused it 70.37.127.112:443    at System.Net.Sockets.Socket.DoConnect(EndPoint endPointSnapshot  SocketAddress socketAddress)    at System.Net.ServicePoint.ConnectSocketInternal(Boolean connectFailure  Socket s4  Socket s6  Socket&amp; socket  IPAddress&amp; address  ConnectSocketState state  IAsyncResult asyncResult  Int32 timeout  Exception&amp; exception)    --- End of inner exception stack trace ---    at System.Net.HttpWebRequest.GetResponse()    at System.Data.Services.Client.QueryResult.Execute()    at System.Data.Services.Client.DataServiceRequest.Execute[TElement](DataServiceContext context  QueryComponents queryComponents)    at System.Data.Services.Client.DataServiceQuery`1.Execute()    at System.Data.Services.Client.DataServiceQuery`1.GetEnumerator()    at System.Collections.Generic.List`1..ctor(IEnumerable`1 collection)    at System.Linq.Enumerable.ToList[TSource](IEnumerable`1 source)    at Microsoft.Practices.TransientFaultHandling.RetryPolicy.&lt;&gt;c__DisplayClass1.&lt;ExecuteAction&gt;b__0()    at Microsoft.Practices.TransientFaultHandling.RetryPolicy.ExecuteAction[TResult](Func`1 func) </code></pre>  <p>Please let me know if this code will retry  thanks</p>,azure-storage
56804741,"Azure Web Functions Consuming SOAP service - how to make async / WinHttpHandler error <p>I am trying to consume a soap web service from an Azure web functions project.  I am having difficultly coding the call to the soap service.  I have successfully added a WCF web service reference.  The reference.cs file has been generated and the SOAP service is asynchronous. </p>  <p>The code is written in C# DOT.NET core 2.0  connecting to a database hosted in an Azure environment.  </p>  <p>I believe I should be using threading and making call to an Asynchronous function. When I try to reference code in a separate class file  I get errors relating to using the static keyword.    </p>  <pre><code>public class ExpireData {     private readonly string _Endpoint;      public ExpireData(IConfiguration config)     {         _Endpoint = config[\ServiceURL\""];     }     [FunctionName(\""ExpireData\"")]     public void Run([TimerTrigger(\""0 * * * * *\"")]TimerInfo myTimer  ILogger log)     {          BasicHttpBinding binding = new BasicHttpBinding();         EndpointAddress address = new EndpointAddress(_Endpoint);         ServiceSoapClient client = new ServiceSoapClient(binding  address);          var result = client.ExpireDataAsync();         } </code></pre>  <p>The value stored in result is: Id = 1018  Status = WaitingForActivation  Method = \""{null}\""  Result = \""{Not yet computed}\""</p>""",azure-functions
47776353,"Unable to stop VMs using Azure Automation <p>We have an Azure Service Fabric cluster set up and I'm attempting to use Azure Automation to stop the virtual machine scale set and restart on a schedule. The scale set is assigned to a resource group as follows</p>  <p><a href=\https://i.stack.imgur.com/JzQSy.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/JzQSy.png\"" alt=\""enter image description here\""></a></p>  <p>My Exteral_Start_ResourceGroupNames and External_Stop_ResourceGroupNames  which the ScheduledStartStop_Parent runbook uses is as follows:</p>  <p><a href=\""https://i.stack.imgur.com/gm16F.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/gm16F.png\"" alt=\""enter image description here\""></a></p>  <p>You can see the resource group name matches the resource group name for my VM scaleset. My understanding is that when the runbook fires  all VMs in this resource group  and  therefore  the VM set  should be stopped. However  when the runbook fires  it's not finding any VMs to stop.</p>  <p>Can anyone see what's wrong?</p>""",azure-virtual-machine
39660134,"Azure - WebApp - authenticate requests by certificate <p>I would like to use certificate authentication for requests on my website. But when I set clientCertEnabled to true (through <a href=\https://resources.azure.com/\"" rel=\""nofollow\"">https://resources.azure.com/</a>) I am getting 403 forbidden error when I try to reach my site through https.</p>  <p>Through browser I get blue screen Error 403 - This web app is stopped but I can still access web site through http. When I switch clientCertEnabled back to false https is working.</p>  <p>Through fiddler I get 403 as well (client certificate is included in request) with no additional info.</p>  <p>I followed this <a href=\""https://azure.microsoft.com/en-us/documentation/articles/app-service-web-configure-tls-mutual-auth/\"" rel=\""nofollow\"">https://azure.microsoft.com/en-us/documentation/articles/app-service-web-configure-tls-mutual-auth/</a> but there is nothing else mentioned to be required to make this work.</p>  <p>Do I have to upload client certificates somewhere?</p>""",azure-web-app-service
20022620,"How to enable sound on Windows Azure VM <p>I would like to use a Windows Azure Virtual Machine as an development machine. I want to enable sound on that machine in order to hear the event sounds (errors  warrnings etc) and listen to the music from last.fm.</p>  <p>Is it possible to have sound on the Azure virtual machines?</p>  <p>I tried: <a href=\http://www.wikihow.com/Hear-Audio-from-the-Remote-PC-when-Using-Remote-Desktop\"" rel=\""nofollow\"">http://www.wikihow.com/Hear-Audio-from-the-Remote-PC-when-Using-Remote-Desktop</a> but it does not help.</p>  <p>OS: Windows Server 2012 R2 / Windows Server 2013</p>""",azure-virtual-machine
47007836,AcquireDiskLeaseFailed issue in MS azure <p>I am using the multiple cloud computers provided by microsoft azure.</p>  <p>While using it  I removed all the virtual machines in azure by my mistake.</p>  <p>So I tried to recover it using <code>vhd</code> files by following the manual but it also failed. The error message was <code>AcquireDiskLeaserFailed</code> and it is relevant to the blob. However  I didn't know how to solve this issue although the error message find the cause.</p>  <p>I would appreciate it if you could find the my issue. </p>  <p>Thanks.</p>,azure-virtual-machine
57152668,"Azure App Service Deploy error: \msdeploy.exe failed with return code: 4294967295\"" <p>I am using Azure DevOps Server 2019.0.1 version. I'm trying to deploy a .Net Core Web API from a built <em>.zip file and I am getting a weird error when trying to connect to the app for deployment(Task: Azure App Service Deploy(3.</em>)).</p>  <p>Here is a sample of the error message:</p>  <p>2019-07-22T19:09:17.7807521Z Error: C:\\Program Files (x86)\\IIS\\Microsoft Web Deploy V3\\msdeploy.exe failed with return code: 4294967295 2019-07-22T19:09:17.7807958Z     at ChildProcess. (C:\\agent_work_tasks\\AzureRmWebAppDeployment_497d490f-eea7-4f2b-ab94-48d9c1acdcb1\\3.4.16\\node_modules\\vsts-task-lib\\toolrunner.js:568:30) 2019-07-22T19:09:17.7808050Z     at emitTwo (events.js:106:13) 2019-07-22T19:09:17.7808194Z     at ChildProcess.emit (events.js:191:7) 2019-07-22T19:09:17.7809218Z     at maybeClose (internal/child_process.js:886:16) 2019-07-22T19:09:17.7810272Z     at Process.ChildProcess._handle.onexit (internal/child_process.js:226:5) 2019-07-22T19:09:17.7810699Z    Retrying to deploy the package.</p>  <p>2019-07-22T19:09:18.0954502Z Info: Using ID 'e91f0d00-f62e-4918-8242-3215abeb8ecb' for connections to the remote server. 2019-07-22T19:09:39.2740289Z Error: C:\\Program Files (x86)\\IIS\\Microsoft Web Deploy V3\\msdeploy.exe failed with return code: 4294967295 2019-07-22T19:09:39.2740487Z     at ChildProcess. (C:\\agent_work_tasks\\AzureRmWebAppDeployment_497d490f-eea7-4f2b-ab94-48d9c1acdcb1\\3.4.16\\node_modules\\vsts-task-lib\\toolrunner.js:568:30) 2019-07-22T19:09:39.2740965Z     at emitTwo (events.js:106:13) 2019-07-22T19:09:39.2741020Z     at ChildProcess.emit (events.js:191:7) 2019-07-22T19:09:39.2741074Z     at maybeClose (internal/child_process.js:886:16) 2019-07-22T19:09:39.2741146Z     at Process.ChildProcess._handle.onexit (internal/child_process.js:226:5) 2019-07-22T19:09:39.2741211Z    Retrying to deploy the package.</p>  <p>2019-07-22T19:09:39.5880914Z Info: Using ID 'd5158a2c-8fbe-4b69-83db-abc89116e8fa' for connections to the remote server. 2019-07-22T19:10:00.7577558Z ##[error]Failed to deploy web package to App Service. 2019-07-22T19:10:00.7583992Z ##[error]Error Code: ERROR_DESTINATION_NOT_REACHABLE</p>""",azure-devops
57493364,How do I log to an additional log provider in a Azure Function 2.0 <p>We want to log to a log provider (Seq) in our functions in addition to Application Insights. </p>  <p>We are having a hard time to understand how to set this up in our extension of FunctionsStartup  where we set up other dependencies.</p>  <p>The way we see it this can be resolved in (at least) two ways.</p>  <p>1) Bootstrap our function app with the default logger (which logs to App Insights) <em>in addition</em> to our custom logger (A Serilog logger which is setup with a sink to Seq)</p>  <p>2) Do a runtime Dependency Injection resolve of ILogger and perform the logging to App Insights on this one <em>in addition</em> to logging to Seq. Then we could have a Singleton ICompanyLogger which logs to both.</p>  <p>Does anyone know how to do a runtime DI resolve in a function and/or how to setup multiple sinks in Microsoft.Extensions.Logging.ILogger ?</p>,azure-functions
56979977,"Powershell Invoke-RestMethod not authenticated with PAT for Azure DevOps <p>I'm trying to invoke the REST API of our Azure DevOps project  and I'm getting some results I don't expect.</p>  <p>I can get results using LinqPad  but using Powershell fails.</p>  <h2>My Script</h2>  <pre><code>$env:Build_BuildId = 2468 $token = [System.Convert]::ToBase64String([System.Text.Encoding]::ASCII.GetBytes(\myPAT\"")) $env:System_TeamProject = \""myProject\""  $url = \""https://dev.azure.com/myorg/$env:System_TeamProject/_apis/build/builds/$env:Build_BuildId/changes?api-version=5.0\""  $response = Invoke-RestMethod -Uri $url -Method Get -ContentType \""application/json\"" -Headers @{      Authorization = \""Basic $token\""  }  Write-Host $response </code></pre>  <h2>The Response</h2>  <pre><code>&lt;!DOCTYPE html PUBLIC \""-//W3C//DTD XHTML 1.0 Strict//EN\"" \""http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd\""&gt;     &lt;html lang=\""en-US\""&gt; &lt;head&gt;&lt;title&gt;              Azure DevOps Services | Sign In  &lt;/title&gt;&lt;meta http-equiv=\""X-UA-Compatible\"" content=\""IE=11;&amp;#32;IE=10;&amp;#32;IE=9;&amp;#32;IE=8\"" /&gt;     &lt;link rel=\""SHORTCUT ICON\"" href=\""/favicon.ico\""/&gt;      &lt;link data-bundlelength=\""508485\"" data-bundlename=\""commoncss\"" data-highcontrast=\""/_static/tfs/M154_20190628.18/_cssbundles/HighContrast/vss-bundle-commoncss-vAEI_yKFIiS9jTVmCtAOiwe4cLPqdXnp6QCUVseU7jzk=\"" data-includedstyles=\""jQueryUI-Modified;Core;Splitter;PivotView\"" href=\""/_static/tfs/M154_20190628.18/_cssbundles/Default/vss-bundle-commoncss-vqjKBNZxfVQkGGn0rrvF7eh9DJDj__wqtFN85fVrIQn8=\"" rel=\""stylesheet\"" /&gt; &lt;link data-bundlelength=\""116162\"" data-bundlename=\""viewcss\"" data-highcontrast=\""/_static/tfs/M154_20190628.18/_cssbundles/HighContrast/vss-bundle-viewcss-v356iHjTFccxhkNidRJIEefQ92VqpWpa7rO4mdtAnDpM=\"" data-includedstyles=\""VSS.Controls\"" href=\""/_static/tfs/M154_20190628.18/_cssbundles/Default/vss-bundle-viewcss-vXHgBtK2hntEJYzWnMNhcJkJC-nUhp2m3BtF-jVlzOZA=\"" rel=\""stylesheet\"" /&gt; ... etc. etc. </code></pre>  <p>I imagine that the request is given a response that would be rendered by a browser to be the signin landing page for azure devops.</p>  <p><a href=\""https://i.stack.imgur.com/qz4dW.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/qz4dW.png\"" alt=\""enter image description here\""></a></p>  <p>I have double and triple checked my PAT and even create a few new full access versions w/ no change in behavior.</p>  <hr>  <p>Ultimately this script is going to be run on the hosted agent  so I'm not too worried about this in the end  but I would like to not run the pipeline for testing the script if I don't need to.</p>""",azure-devops
17965272,"Publishing Web.Config to Azure removes Azure storage connection string <p>I've got a web.config that contains my SQL connection string and my Azure Blob storage connection string.</p>  <p>A Web.Config transformation replaces my Local SQL connection string with the Azure one.</p>  <p>When I publish the site to Azure  the Blob storage connection string is deleted and replaced with a duplicate SQL connection string  but with the blob storage string's name.</p>  <p>The only way I've found to fix is to log in via FTP and manually change the erroneous Storage connection string with the correct one from my local machine.</p>  <p>How do I get VS to publish my web config to Azure and leave it alone!!!</p>  <p>Web.Config</p>  <pre><code>      &lt;connectionStrings&gt;     &lt;add name=\DefaultConnection\"" connectionString=\""Data Source=(LocalDB)\\v11.0;AttachDbFilename=|DataDirectory|\\.mdf;Integrated Security=True\"" providerName=\""System.Data.SqlClient\"" /&gt;     &lt;add name=\""StorageConnectionString\"" connectionString=\""DefaultEndpointsProtocol=https;AccountName=;AccountKey=\"" /&gt;   &lt;/connectionStrings&gt; </code></pre>  <p>Web.Release.Config</p>  <pre><code>  &lt;connectionStrings&gt; &lt;add name=\""DefaultConnection\""      connectionString=\""Server=.database.windows.net 1433;Database=;User ID=@;Password=!;Trusted_Connection=False;Encrypt=True;Connection Timeout=30;\""      providerName=\""System.Data.SqlClient\""      xdt:Transform=\""SetAttributes\"" xdt:Locator=\""Match(name)\""/&gt; </code></pre>""",azure-storage
23204435,Upgrading from Windows Azure Storage Client Library 2.1 to 3.0 <p>I'm upgrading a project from .NET MVC 4.0 to 5.0.  Mostly just upgrading NuGet packages has worked without changes to the code; however  there appear to be some rather large changes when upgrading the Azure Storage Client.  </p>  <p>I now have a ton of build errors - the BlobRequestOptions class seems to have lost several members like the DeleteSnapshotsOption and UseFlatBlobOption members  and CloudBlobContainer no longer has the function CreateIfNotExists.  </p>  <p>Does anyone know of a migration guide for upgrading from previous Azure Storage Client versions to 3.0?  Or maybe I'm missing something dumb and easy?</p>,azure-storage
50755995,"Is it possible for an Azure Application Insights Alert to trigger another function? <p>I would like to use Application Insights to monitor a Logic App that chains several Azure Functions. I want the chain to be as safe as possible  and i if something goes wrong i want to have the http request that failed to be processed correctly by the functions. I figured i could raise alerts from Application Insights when something goes wrong  however i'm not sure how to get the message that failed into a blob or a \failed message queue\"".</p>  <p>Is it possible for an Application Insights Alert to be a trigger for a function that would add data to a blob?</p>""",azure-functions
55253445,"Cannot Create DevOps Project / Link Azure DevOps Services organization to Azure subscription <p>Wondering if anyone has insight into what would cause Azure linkiage with DevOps to be so flakey. I previously had a MSDN subscripiton that worked great for creating devops projects... here is what has changed</p>  <ul> <li>New Enterprise MSDN subscription</li> <li>Switched my main MSDN account email ... this seems to have reflected fine everywhere (azure + devops)</li> </ul>  <p>I opened a Support Ticket - Billing CC was not setup / Spending limit in place - suggest addeding a CC and removed limit for this month ... done same issue</p>  <p>When i try to Setup Billing - Link a DevOps organization - Azure activity monitor has some bogus failures - Error code: UnknownException:</p>  <pre><code>{     \authorization\"": {         \""action\"": \""microsoft.visualstudio/account/write\""          \""scope\"": \""/subscriptions/REDACTED/resourcegroups/REDACTED/providers/microsoft.visualstudio/account/REDACTED\""     }      \""caller\"": \""REDACTED@outlook.com\""      \""channels\"": \""Operation\""      \""claims\"": {         REDACTED     }      \""correlationId\"": \""5278b019-d722-4f3e-b217-60ce0146c365\""      \""description\"": \""\""      \""eventDataId\"": \""e9ae6d73-1197-47a0-9b97-1ed0d1d9a0bd\""      \""eventName\"": {         \""value\"": \""EndRequest\""          \""localizedValue\"": \""End request\""     }      \""category\"": {         \""value\"": \""Administrative\""          \""localizedValue\"": \""Administrative\""     }      \""eventTimestamp\"": \""2019-03-20T03:45:54.7266723Z\""      \""id\"": \""/subscriptions/REDACTED/resourcegroups/REDACTED/providers/microsoft.visualstudio/account/REDACTED/events/e9ae6d73-1197-47a0-9b97-1ed0d1d9a0bd/ticks/636886503547266723\""      \""level\"": \""Error\""      \""operationId\"": \""9e3f6e94-3719-4c6d-963f-84e0def54fd6\""      \""operationName\"": {         \""value\"": \""microsoft.visualstudio/account/write\""          \""localizedValue\"": \""Update Visual Studio account\""     }      \""resourceGroupName\"": \""REDACTED\""      \""resourceProviderName\"": {         \""value\"": \""microsoft.visualstudio\""          \""localizedValue\"": \""Visual Studio Online\""     }      \""resourceType\"": {         \""value\"": \""microsoft.visualstudio/account\""          \""localizedValue\"": \""microsoft.visualstudio/account\""     }      \""resourceId\"": \""/subscriptions/REDACTED/resourcegroups/REDACTED/providers/microsoft.visualstudio/account/REDACTED\""      \""status\"": {         \""value\"": \""Failed\""          \""localizedValue\"": \""Failed\""     }      \""subStatus\"": {         \""value\"": \""InternalServerError\""          \""localizedValue\"": \""Internal Server Error (HTTP Status Code: 500)\""     }      \""properties\"": {         \""statusCode\"": \""InternalServerError\""          \""serviceRequestId\"": null          \""statusMessage\"": \""{\\\""code\\\"":\\\""UnknownException\\\"" \\\""message\\\"":\\\""Unknown Exception\\\"" \\\""target\\\"":\\\""FallbackOrThrowWithTrace\\\""}\""     }      \""relatedEvents\"": [] } </code></pre>  <p>If it try to deploy a DevOps project i get a similarly non descript error as well.</p>  <p>Any insights?!</p>""",azure-devops
54558564,"Freezer component not working in Azure Web App <p><a href=\https://github.com/haga-rak/Freezer\"" rel=\""nofollow noreferrer\"">https://github.com/haga-rak/Freezer</a></p>  <p>we are trying to capture a screenshot of a web page using Freezer component. everything seems working as expected locally  but when it is hosted in Azure Web API  the call is failing with below error</p>  <pre><code>RemoteWorker has shutdown at Freezer.Pools.WorkerEngine.CaptureUrl(String baseUrl  TimeSpan timeOut) at Freezer.Engines.CaptureEngine.CaptureRawUrl(String baseUrl  TimeSpan timeOut) at Freezer.Core.ScreenshotHelper.FreezeTaskABytes(ScreenshotJob task) at Freezer.Core.ScreenshotJob.Freeze() </code></pre>""",azure-web-app-service
47722722,Azure Functions and Caching <p>We are planning to develop an Azure function for which the input trigger is a service bus message and the output will be blob storage. The service bus message will contain a image url and the function will resize the image to a predefined resolution and will upload to azure blob storage.</p>  <p>The resolution to which the image should be resized is stored in the database and the Azure function needs to make a call to database to get to know the resolution that is supposed to be used for the image in the input message. The resolution would actually be a master data configured based on the source of the input message.</p>  <p>Making a database call would be a expensive call as it would have to go to the database for each call. Is there any way to cache the data and use it without calling the database. Like in memory caching?</p>,azure-functions
46086240,"Azure functions with Entity Framework Core 2.0 and .NET 4.7 <p>I am running into issues running Entity Framework queries from within an Azure Function. The same code runs perfectly fine from a Console Application.</p>  <p>Here is the exact error I am getting:   </p>  <pre><code>\Could not load file or assembly 'System.ValueTuple  Version=0.0.0.0  Culture=neutral  PublicKeyToken=cc7b13ffcd2ddd51' or one of its dependencies. The system cannot find the file specified.\"":\""System.ValueTuple  Version=0.0.0.0  Culture=neutral  PublicKeyToken=cc7b13ffcd2ddd51\"" </code></pre>  <p>Notice how it can't find the right version. Could this be an issue?</p>  <p>Here is my setup: 1. My Class Libraries that contain the Data Models are using <code>.NET Standard 2.0</code> and <code>.NET 4.7</code> as Target Frameworks. I manually changed the project to have the following: <code>&lt;TargetFrameworks&gt;netstandard2.0;net47&lt;/TargetFrameworks&gt;</code></p>  <ol start=\""2\""> <li>The Azure Functions target .NET 4.7</li> <li>After reviewing the issue  I also manually installed the <code>ValueTuple DLL</code> from Nuget and I still am not seeing </li> </ol>  <p>Is there anything that I am missing? Would love to hear if someone is facing a similar issue.</p>  <p>Thank You  Anup</p>""",azure-functions
48922064,Paging Support in Azure Function CosmosDB Input binding <p>I'm trying to export data from CosmosDB to a different collection  by query.</p>  <p>I created a function with that query as CosmosDB binding parameter.</p>  <p>The function keeps timing out because the query results set is too large  and takes more than 5 minutes to retrieve. </p>  <p>Any suggestions how to run the export using Azure functions? Or should I take a different approach?</p>,azure-functions
54864294,Not able to connect Linux Azure VM from Windows Azure VM <p>I have 2 azure VMs 1st is Linux machine(ubuntu 18.04) and 2nd is windows azure vm. I have MySql database in Linux machine. I want to move the data from Linux MySql database to SQL Server Database which is hosted on windows Azure machine. I am creating a SSIS package to perform this operation but I am not able to connect to the Linux machine  I have open all the required ports (22 3306 1433) ports in all inbound and outbound rules in both vm but still I am not able to create successful connection.<br> Both the servers are in same vnet and load balancer is not applicable.</p>,azure-virtual-machine
47458490,Windows docker container vs Linux docker container <p>I am new to the Docker/Kubernetes world in general. </p>  <p>As i am just starting with the whole architecture i have the following:</p>  <ul> <li>Azure Container Service -- up and running using Linux for master and agents</li> <li>Docker for windows on my machine -- up and running</li> <li>automated build for a .NetCore application on VSTS using Docker task to build and push the image to the Azure Container registry</li> <li>Kubectl running as well kubernetes UI from master nodes</li> </ul>  <p>when building the .NetCore application from my machine using Docker commands and then publish it to the registry  Kubernetes is able to pull it and run it  but when the image is built and pushed by the VSTS build tasks kubernetes is failing to pull the images. after researching the error a bit  it turned out that the image coming from the VSTS build is made for windows and therefor cannot be pulled. </p>  <p>What is the difference between Docker Container for Windows and Linux  and how can we convert or specify the type while building the image.</p>,azure-devops
51071963,"Create VM and deploy application on to Azure VM via Ansible <p>I am new to Ansible Azure modules. What I need is the ability to create VM's(n) and deploy an application on all of them. From what I read online  <a href=\https://docs.ansible.com/ansible/2.4/azure_rm_virtualmachine_module.html\"" rel=\""nofollow noreferrer\"">azure_rm_virtual</a> machine can be used to create VM(Assuming vnet  subnet and other networking jazz is in place). I am trying to figure out how do I deploy(copy bits and run my app installer) my application onto the newly created VM's? Can my app deployment be part of the VM creation process? If so what are the options? I looked into <a href=\""https://docs.microsoft.com/en-us/azure/ansible/ansible-matrix#introduction-to-azurepreviewmodule\"" rel=\""nofollow noreferrer\"">other modules</a> but couldn't find any relevant one's. Didn't find any on the azure documentation too.  Thanks.</p>""",azure-virtual-machine
39713000,"Error 407 after computer name change: Visual studio Team Services / TFS <p>My infrastructure changed the name of my computer. When I opened visual studio to connect to TFS  I got a message saying that \Workspace 'X' does not reside on this computer.  If this computer was recently renamed  the workspace may be updated by running tf workspaces /updateComputerName:oldComputerName.</p>  <p>So I ran this for my local workspace and it worked just fine.  Now I'm trying to run it for a workspace that is connected to visualstudio.com and I'm getting a 'HTTP code 407: Proxy Authentication Required' error.</p>  <p>I have already made some changes to my vsenv.exe.config for proxy as below.  I also tried to add the same thing to tf.exe.config  with no luck.</p>  <pre><code>&lt;system.net&gt;     &lt;defaultProxy useDefaultCredentials=\""true\"" enabled=\""true\""&gt;     &lt;proxy usesystemdefault=\""True\"" /&gt;     &lt;/defaultProxy&gt;     &lt;settings&gt;         &lt;ipv6 enabled=\""true\""/&gt;     &lt;servicePointManager expect100Continue=\""false\"" /&gt;     &lt;/settings&gt; &lt;/system.net&gt; </code></pre>  <p>Anyone have any ideas how to get around this proxy issue?</p>""",azure-devops
53151727,Run single-threaded in parallel in Azure <p>I have a simulation that can run only one at a time and takes 50-100 ms (CPU intensive). It is available behind an HTTP API. The requirement is to execute around 1000 HTTP requests per second (or around 100 instances in parallel).</p>  <p>I tried Azure Functions hoping they will increase the number instances as the number of requests grows  but I only got 2 running (using both Consumption and App Service plan).</p>  <p>Is there some solution for this scenario?</p>,azure-functions
52928268,"Setting custom response header with Azure Function in proxies.json <p>I am trying to add a custom HTTP header to all of my responses of my Azure Functions - lets call it X-Custom. Then I add a proxies.json file like this to my functions project:</p>  <pre><code>{   \$schema\"": \""http://json.schemastore.org/proxies\""    \""proxies\"": {     \""add-custom-header-to-response\"": {       \""matchCondition\"": {         \""route\"": \""/{*restOfPath}\""       }        \""responseOverrides\"": {         \""response.headers.X-Custom\"": \""Custom value\""       }     }   } } </code></pre>  <p>And this works as expected  I do get the X-Custom header  but my response content has gone missing. What am I missing in the proxies.json file?</p>  <p><strong>Update</strong></p>  <p>Thanks to Baskar I came to the solution (I was missing backendUri):</p>  <pre><code>{   \""$schema\"": \""http://json.schemastore.org/proxies\""    \""proxies\"": {     \""add-custom-header-to-response\"": {       \""matchCondition\"": {         \""route\"": \""/api/1/{*restOfPath}\""       }        \""backendUri\"": \""https://localhost/api/1/{restOfPath}\""        \""responseOverrides\"": {         \""response.headers.X-Custom\"": \""Custom value\""       }     }   } } </code></pre>  <p>Also see:</p>  <p><a href=\""https://docs.microsoft.com/en-us/azure/azure-functions/functions-proxies#reference-localhost\"" rel=\""nofollow noreferrer\"">https://docs.microsoft.com/en-us/azure/azure-functions/functions-proxies#reference-localhost</a> <a href=\""https://docs.microsoft.com/en-us/azure/azure-functions/functions-proxies#route-template-parameters\"" rel=\""nofollow noreferrer\"">https://docs.microsoft.com/en-us/azure/azure-functions/functions-proxies#route-template-parameters</a></p>""",azure-functions
3740865,"How do I convert a number to a custom 2char BaseX and back?  (aka: How to do Azure Table property compression) <p>Similar in how one would count from 0 to F in Hex  I have an array of numbers and letters I want to \count\"" from... and when I hit the max value  I want to start all over again in the \""tens\"" column.</p>  <p>I need this to increase storage efficiency in Azure Table  and to keep my PrimaryKeys tiny (so I can use them in a tinyURL).  First consider that only these characters are permitted as a propertyName  as documented <a href=\""http://msdn.microsoft.com/en-us/library/dd179338.aspx\"" rel=\""nofollow noreferrer\"">here</a>.  In the array below  each character is positioned according to how Azure will sort it.</p>  <pre><code>  public static string[] AzureChars = new string[]    {         \""0\"" \""1\"" \""2\"" \""3\"" \""4\"" \""5\"" \""6\"" \""7\"" \""8\"" \""9\"" \""A\""          \""B\"" \""C\"" \""D\"" \""E\"" \""F\"" \""G\"" \""H\"" \""I\""          \""J\"" \""K\"" \""L\"" \""M\"" \""N\"" \""O\"" \""P\"" \""Q\""          \""R\"" \""S\"" \""T\"" \""U\"" \""V\"" \""W\"" \""X\"" \""Y\""          \""Z\"" \""a\"" \""b\"" \""c\"" \""d\"" \""e\"" \""f\"" \""g\""          \""h\"" \""i\"" \""j\"" \""k\"" \""l\"" \""m\"" \""n\"" \""o\""          \""p\"" \""q\"" \""r\"" \""s\"" \""t\"" \""u\"" \""v\"" \""w\""          \""x\"" \""y\"" \""z\""           }; </code></pre>  <p>My goal is to use 2 string/ASCII characters to count from the string \""00\"" to lowercase \""zz\"".</p>  <p>What is the best way to approach this concept using C#?<br> -- Is an array the correct object to use?<br> -- How will I associate a given character (uppercase 'Y') with it's position in the Array?</p>  <p>I'm just experimenting with this idea.  At first brush it seems like a good one  but I haven't seen anyone consider doing things this way.  What do you think?</p>""",azure-storage
46018805,"Azure Web service Manage your accout link giving error: 26 - Error Locating Server/Instance Specified) <p>So this is my first web application that I have launched user Azure  so I am a little new to this.  I finally managed to get the AD authentication working properly  but now once a user is logged in they can not  access the \Manage your account\"" tab that are automatically created for you when you produce a asp.net web app generally found in the /accounts/* directory.</p>  <p>When the user clicks on their AD name that directs them to the /Accounts/Manage page they will get this error:</p>  <pre><code>A network-related or instance-specific error occurred while establishing a  connection to SQL Server. The server was not found or was not accessible.  Verify that the instance name is correct and that SQL Server is configured to  allow remote connections. (provider: SQL Network Interfaces  error: 26 - Error Locating Server/Instance Specified)  </code></pre>  <p>This process works perfectly fine when I run the app locally on my machine but not when its using the AD account information.</p>  <p>My question is why is it doing this? and where can I fix it?</p>""",azure-web-app-service
49875144,"not able to download files from azure blob <p>Hi using <code>fileUris</code> in Azure extension of template  not able to download file in VM while launching VM from template.</p>  <p>It throws following error:</p>  <blockquote>   <p>VM has reported a failure when processing extension 'customScript'. Error message: \Enable failed: processing file downloads failed: failed to download file[1]: failed to download file: unexpected status code: got=404 expected=200\"".</p> </blockquote>""",azure-virtual-machine
56220839,can I have a real time threat protection on azure app services <p>I have azure app service where I am running a tomcat application  is there a way / or any in-build anti-malware option is available if not how to implement threat protection in this app service</p>,azure-web-app-service
25304395,byte[] formatting of Cerebrata Azure Management Studio <p>I am trying to debug an issue where my data is stored in Azure Table Store as a byte[]. I am using the Cerebrata Azure Management Studio and it shows the byte[] column as: </p>  <p>16000000010000000E00000001010400000031343230</p>  <p>Does anyone know what format this is stored in? How can I convert this into a byte array? It does not look like a base 64 or UTF encoded string.</p>,azure-storage
47209038,"SQL connection over Azure function works only on localhost <p>I ran azure function over Visual Studio. The function returns some data from SQL database hosted also on Azure (SQL Server)  on localhost works everything fine  but when I publish it to the azure  it returns 500 error. </p>  <p>On Azure SQL  I have checked accessing from other Azure services and my IP address.</p>  <p>local.settings.json</p>  <pre><code>{   \IsEncrypted\"": false    \""Values\"": {     \""AzureWebJobsStorage\"": \""\""      \""AzureWebJobsDashboard\"": \""\""   }    \""ConnectionStrings\"": {     \""MySqlConnectionString\"": {       \""ConnectionString\"":         \""Server=tcp:webappgtoproject.database.windows.net 1433;Initial Catalog=database;Persist Security Info=False;User ID=xxx;Password=yyy;MultipleActiveResultSets=False;Encrypt=True;TrustServerCertificate=False;Connection Timeout=30;\""        \""providerName\"": \""System.Data.SqlClient\""      }   } } </code></pre>  <p>Code</p>  <pre><code>string str = ConfigurationManager.ConnectionStrings[\""MySqlConnectionString\""].ConnectionString;  using (SqlConnection conn = new SqlConnection(str)) {     conn.Open();      // Check PC     string text2 = \""command text\"";      using (SqlCommand cmd = new SqlCommand(text2  conn))     {     }      return true; } </code></pre>  <p>Without that SQL connect it works fine on Azure.</p>""",azure-functions
52144239,How to do a partial search on a row key in azure table storage? <p>I am using Azure table storage along with node js for a ticketing app.  I am using the client's name as a partition key and ticket id as a row key.  For example: </p>  <p><code>RowKey: {'_': 232344}</code></p>  <p>I want the row key to be a combination of ticketid and customer's phone number.  Ex:</p>  <p><code>RowKey: {'_': 232344_9393944392} or RowKey: {'_': 2323449393944392}</code></p>  <p>and be able to do a partial search on row key using the customer's phone number and retrieve all tickets raised by a customer. How can I do it in node js?</p>  <p>The following code is how I am querying table storage.</p>  <pre><code>const azure = require('azure-storage'); const query = new azure.TableQuery().where('PartitionKey eq ?' client).and('Rowkey eq?' ticketId); </code></pre>  <p>This is where I am stuck as I do not how to do a partial search on the row key.</p>,azure-storage
34802929,"Visual Studio Team Services ignore files <p>I'm transpiling TypeScript files from my web project into wwwroot as part of my gulp build.  I want Visual Studio Team Services to ignore the output js files in wwwroot  but it constantly detects them as added files and I have to undo.  The server is @visualstudio.com.  In my wwwroot folder I have a .tfignore file with the following text  which should ignore all files in these folders:</p>  <pre><code>lib\\*.* app\\*.* </code></pre>  <p>I have also attempted to add a .tfignore file at the higher level (project root)  just to see if I could get it to ignore js files:</p>  <pre><code>wwwroot\\app\\**\\*.js </code></pre>  <p>I've also added the following lines to my .xproj  which seems to have no effect.</p>  <pre><code>  &lt;ItemGroup&gt;     &lt;DnxInvisibleFolder Include=\wwwroot\\app\\\"" /&gt;     &lt;DnxInvisibleFolder Include=\""wwwroot\\lib\\\"" /&gt;   &lt;/ItemGroup&gt; </code></pre>  <p>How do I ignore these folders/files?  This is a VS2015 / Asp.net 5 project.</p>  <p><a href=\""https://i.stack.imgur.com/Ktkok.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/Ktkok.png\"" alt=\""enter image description here\""></a></p>  <p><a href=\""https://i.stack.imgur.com/AcHo0.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/AcHo0.png\"" alt=\""enter image description here\""></a></p>""",azure-devops
14380588,"Unable to Upload File to Windows Azure Blob <p>I'm trying to upload a file to a Windows Azure storage blob. I feel like I'm trying something really basic. I have a new ASP.NET MVC 4 Web Application (as in File->New Project...). When I get to the line shown below that reads \CloudStorageAccount.FromConfigurationSetting\""  an exception is thrown. That exception has the following information:</p>  <pre><code>Type: System.Runtime.InteropServices.SEHException Message: External component has thrown an exception. </code></pre>  <p>Here is the code that I have:</p>  <pre><code>// Setup the Windows Aure blob client CloudStorageAccount.SetConfigurationSettingPublisher((configName  configSetting) =&gt; configSetting(RoleEnvironment.GetConfigurationSettingValue(configName))); CloudStorageAccount storageAccount = CloudStorageAccount.FromConfigurationSetting(\""BlobStorage\""); </code></pre>  <p>What am I doing wrong?</p>""",azure-storage
50693963,Azure and the old .Net remoting <p>By .Net remoting I mean the 10 year old predecessor to WCF</p>  <p>Does Azure support it? I assume it does inside a VM but for VM to VM communication? What about from an App Service to a VM?</p>  <p>I appreciate it's not the most heavily used of technologies these days  the name is a little difficult to Google on as remoting is a fairly common phrase</p>,azure-virtual-machine
23901808,Public Static IP for Azure VM <p>Is there any ways to assign <strong>public static IP for Azure VM</strong>? Do I have to do through the Azure Virtual Network or I need to do it when setting up the VM?</p>  <p>Would appreciate that if somebody could provide me some tutorial and steps to achieve it.</p>  <p>Thank you.</p>,azure-virtual-machine
35778016,TFS Online - TFS30040: The database is not correctly configured. Contact your TFS administrator <p>I and some of my colleges have started getting the following error on one of my TFS Online projects when I try to get all.</p>  <p><strong>The database is not correctly configured. Contact your TFS administrator.</strong></p>  <p>If I undo all my pending changes I can then get all  not always helpful.</p>  <p>Does anyone know of a proper solution?</p>,azure-devops
54314806,Can we deploy nodejs app and spring-boot app in same Azure-App-Service? <p>We are using 2 frameworks for developing backend:</p>  <ul> <li>NodeJS</li> <li>Spring-Boot</li> </ul>  <p>Can we deploy both builds on the same Azure AppService instance? Any suggestions?</p>,azure-web-app-service
30163618,"Azure Table Storage - TableEntity map column with a different name <p>I am using Azure Table Storage as my data sink for my Semantic Logging Application Block. When I call a log to be written by my custom <code>EventSource</code>  I get columns similar to the ff.:</p>  <ul> <li>EventId</li> <li>Payload_username</li> <li>Opcode</li> </ul>  <p>I can obtain these columns by creating a <code>TableEntity</code> class that matches the column names exactly (except for <code>EventId</code>  for some reason):</p>  <pre><code>public class ReportLogEntity : TableEntity {     public string EventId { get; set; }     public string Payload_username { get; set; }     public string Opcode { get; set; } } </code></pre>  <p>However  I would like to store the data in these columns in differently named properties in my <code>TableEntity</code>:</p>  <pre><code>public class ReportLogEntity : TableEntity {     public string Id { get; set; } // maps to \EventId\""     public string Username { get; set; } // maps to \""Payload_username\""     public string Operation { get; set; } // maps to \""Opcode\"" } </code></pre>  <p>Is there a mapper/attribute I can make use of to allow myself to have the column name different from the <code>TableEntity</code> property name?</p>""",azure-storage
54597719,Azure VM complete replication <p>I have a azure vm setup that contains custom software  files  folders blah blah. At any point I will need to create multiple identical instances of the existing vm (maybe up to 30). I used the sysprep in the vm  in the azure portal I used the capture image for the vm and tried to create a new VM from the image. The new vm created from the image did not contain any of the files from the previous vm. </p>  <p>What would be the best approach in preserving a complete image of the vm and be able to mass deploy from it at any given time? </p>,azure-virtual-machine
56393103,Azure Function (C#  v1): Logging does not work properly <p>I implemented an Azure Function that is time triggered. It shall run e.g. every 15 minutes. But when I look into the logs from Application Settings I don't see every run despite the Azure Function actually runs every 15 minutes. Why is this happening?</p>,azure-functions
40583317,Python Anaconda and azure-storage module <p>I am using a Data Science virtual machine on Azure that has anaconda python installed.</p>  <p>I need to access module Azure storage blob using:</p>  <pre><code>from azure.storage.blob import BlockBlobService </code></pre>  <p>When dealing with this command I receive the message that the module <code>azure.blob.storage</code> is not found. I have forced the update for the module <code>azure-storage</code>:</p>  <pre><code>pip install azure-storage --upgrade </code></pre>  <p>The missing module instead is present on the installed modules using:</p>  <pre><code>pip freeze </code></pre>  <p>After removing Anaconda and using the standard Python distro everything works well.</p>  <p>How can I continue using Anaconda with azurestorage support? Has anyone experimented this issue and solved it?</p>,azure-storage
57708006,"ASP.NET MVC controller - TempData works fine locally  but not as ASP.NET Core web app <p>I'm passing a value using TempData to an action result  when I build it locally  the value gets passed and is fine in the Thankyou action result. </p>  <p>However  when I publish this as an Azure ASP.NET Core web app  it fails - any values I pass as TempData are always empty/null.</p>  <p>Any ideas what I'm doing wrong here?</p>  <pre class=\lang-cs prettyprint-override\""><code>[HttpPost] public IActionResult Index() {     // some code here     TempData[\""activeId\""] = activeId;     return RedirectToAction(\""Thankyou\""); }  public ActionResult Thankyou() {     object activeId;     if (!TempData.TryGetValue(\""activeId\""  out activeId))     {         // This is true - it fails on Azure  but works locally     }     if (activeId == null)     {         // This is true - it null on Azure  but works locally     }     ViewBag.activeId = activeId;     return View(); }  </code></pre>""",azure-web-app-service
55377132,"Leave specified folder intact when publishing to Azure Web app <p>I'm using VS Code with the Azure App Service extension to publish to Azure. I have tested publishing to a staging slot and swapping slots with production. All is working well so far.</p>  <p>The trouble is that I have a script which uploads a new SSL certificate every 3 months (letsencrypt) to a folder called /.well-known. Each time I publish the site it's going to over-write this folder as the VS Code extension only seems capable of doing a complete publish of the whole site.</p>  <p>Is there a way of somehow \protecting\"" this folder so it never gets swapped out or over-riden?</p>  <p>I realise that if it wasn't for the automated nature of the SSL being uploaded I could just put the SSL in my repository and upload it each time. Or I could download this folder and include it in my project before each publish but this is error-prone.</p>""",azure-web-app-service
55801331,"Why is EasyAuth returning a 401 Unauthorized status when a client post an access token on /.auth/login/aad endpoint? <p>I started to migrate my Live SDK registered applications to the new Application Registration Portal as Microsoft is deprecating their support:</p>  <p><a href=\https://i.stack.imgur.com/SMRbq.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/SMRbq.png\"" alt=\""Application Registration Portal\""></a></p>  <p>I went on the App Registrations (Preview) page in the Azure Portal and choose to create a new application.</p>  <p>Then  I went to my Function App's <code>Authentication / Authorization</code> page to put the information of the newly registered AAD application.</p>  <p>My client iOS application is getting the <code>authorization code</code> first and then a valid <code>access token</code> from these endpoints:</p>  <pre><code>https://login.microsoftonline.com/&lt;tenantId&gt;/oauth2/v2.0/authorize  https://login.microsoftonline.com/&lt;tenantId&gt;/oauth2/v2.0/token </code></pre>  <p>With the <code>access token</code> in hand  the iOS application is trying to <code>POST</code> the token on the AAD endpoint (<code>/.auth/login/aad</code>) but it fails. </p>  <p>However  if I get an <code>authorization code</code> and an <code>access token</code> using a google account and then <code>POST</code>ing the <code>access token</code> to the <code>/.auth/login/google</code> endpoint  it succeeds. </p>  <p><strong>Question</strong></p>  <p>Why is EasyAuth returning a <code>401 Unauthorized</code> status when a client post an <code>access token</code> on <code>/.auth/login/aad</code> endpoint?</p>  <p><strong>Update</strong></p>  <p>I am at a point where I am able to retrieve the access token from this token endpoint <code>https://login.microsoftonline.com/&lt;tenantId&gt;/oauth2/v2.0/token</code> and using <code>Insomnia</code> / <code>Postman</code> to <code>POST</code> the following object <code>application/json</code> to the <code>/.auth/login/aad</code> endpoint:</p>  <pre><code>{     \""access_token\"": \""eY....\"" } </code></pre>  <p>The response that I get is a <code>401 Unauthorized</code> with the following message:</p>  <pre><code>You do not have the permission to view this directory or page. </code></pre>  <p>I am following the exact same procedure as I am doing for Google accounts. I also made sure that my registered application allows user from my Azure Active Directory as well as personal account. Here is a screenshot of these settings:</p>  <p><a href=\""https://i.stack.imgur.com/TvYvs.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/TvYvs.png\"" alt=\""AAD settings\""></a></p>""",azure-functions
12137906,when I delete a VM's endpoint  visit public ip failed <p>This is an windows azure issue: I have 2 load balance Virtual Machines and run my software on them  when one machine's service is down  I try to delete its public endpoint to make my software can be visited so I will have time to fix the bad one. Now when I delete it  I can't not visit the public IP for a few minutes  it seems like there has a restart time for deleting an endpoint?  So who can tell me why? And If there is 3 load balance machine and I delete one will be better?</p>  <p>(sorry for the bad English  hope you will understand me) </p>,azure-virtual-machine
42521958,"Options for editing MS Word documents in Azure Storage <p>This question follows on from a <a href=\https://stackoverflow.com/questions/41604979/editing-ms-office-files-stored-in-azure-storage-using-shared-access-signatures\"">previous question</a> that went unanswered.</p>  <p>I've got a requirement in an Azure web app to edit a Document  instead of:-</p>  <ol> <li>Downloading the file</li> <li>Open the downloaded file in MS Office Word</li> <li>Editing and saving it locally</li> <li>Clicking a button on a web form</li> <li>Browsing to the edited file and then clicking OK to upload it</li> </ol>  <p>The client would like an experience similar to what you get in Sharepoint i.e.</p>  <ol> <li>Click a link to a word document </li> <li>MS Office Word starts on the client</li> <li>They edit and save the (online) document</li> </ol>  <p>One solution I've found is...</p>  <p>Store the Documents in a Azure File Share. Create a login script which would run on every windows client access to set the user name and password for the Azure File Share....</p>  <pre><code>cmdkey /add:&lt;storage_account&gt;.file.core.windows.net /user:AZURE\\&lt;storage_account&gt; /pass:&lt;storage_account_key&gt; </code></pre>  <p>Use links in the html like...</p>  <pre><code>&lt;a href='file://///&lt;storage_account&gt;.file.core.windows.net/&lt;storage_container&gt;/test.docx'&gt;Test.doc&lt;/a&gt; </code></pre>  <p>There's a number of issues with this.  </p>  <ol> <li>It's not a cross browser solution. Whilst this link will cause MS Office Word to be launched and load the document successfully in Firefox and Internet Explorer  it doesn't work in Chrome (which downloads file) and Edge (which doesn't process it at all).</li> <li>It's inherently insecure  requiring a single set of credentials being distributed to all the clients that need to access the system.</li> </ol>  <p>Can anyone suggest alternative solutions?</p>""",azure-storage
56562977,How to know will the selected azure hosting plan will work for my web app hosting <p>I want to host 1 web app in windows OS with SQL server database. I have selected b1 instance and selected S0 database. I have selected app service and storage is these 2 things are enough to host a app? can we run this app for 24 hrs?</p>  <p>app is smart city dashboard app. <strong>concurrent</strong> users will be  max of <strong>10</strong>. 10 department person may watch the app concurrently the app. this app is not for public user. this will be for the office admin purpose to monitor city utilities like transformer temperature  intrusion detection. some of the web pages have page refresh of 30 seconds. so the app will refresh every 30 seconds and it will check the database in every 30 seconds.</p>  <p>app is already developed in asp.net mvc with sql server database with entity framework.</p>  <pre><code>APP SERVICE PLAN B1  CORES   1    RAM     1.75 GB STORAGE 10 GB   database - single database Purchase Model - DTU Service Tier- General Purpose  PLAN    S0 DTUS    10 INCLUDED STORAGE 250GB MAX STORAGE      250 GB </code></pre>  <p>my queries</p>  <p>according to selected plan there is 10 gb space. so is that space for app deployment.or it is for .net framework installation and sql server management studio installation.</p>  <p>there is mentioned  only 10 DTU in database. can i fetch data from database any number of times or 10 times only i can fetch data.</p>,azure-web-app-service
38928346,"Finding azure Availability sets using Azure in classic mode <p>I am trying to find the availability sets in a Azure Cloud Service using powershell. The Cloud Service was created using classic model. </p>  <p>I am not sure if this is the right answer:</p>  <pre><code>get-AzureService -ServiceName \myService\""  </code></pre>""",azure-virtual-machine
1276737,"error occured while consuming a webservice hosted in Azure <p>I have created a web service which is internally consuming  SSDS service (<a href=\https://database.windows.net/soap/v1/\"" rel=\""nofollow noreferrer\"">https://database.windows.net/soap/v1/</a>). I was able to sucessfully host my web service in cloud also placed client access policy and cross doamin policy in place. But when I am trying to consume this web service in Silverlight hosted on cloud it its throwing exception  :-  </p>  <p>Metadata contains a reference that cannot be resolved: '<a href=\""http://xxx.cloudapp.net:20000/xxx.asmx?wsdl\"" rel=\""nofollow noreferrer\"">http://xxx.cloudapp.net:20000/xxx.asmx?wsdl</a>'. There was an error downloading '<a href=\""http://xxx.cloudapp.net:20000/xxx.asmx?wsdl\"" rel=\""nofollow noreferrer\"">http://xxx.cloudapp.net:20000/xxx.asmx?wsdl</a>'. The request failed with HTTP status 502: Proxy Error ( Connection refused ). Metadata contains a reference that cannot be resolved: '<a href=\""http://xxx.cloudapp.net/xxx.asmx\"" rel=\""nofollow noreferrer\"">http://xxx.cloudapp.net/xxx.asmx</a>'. Metadata contains a reference that cannot be resolved: '<a href=\""http://xxx.cloudapp.net/xxx.asmx\"" rel=\""nofollow noreferrer\"">http://xxx.cloudapp.net/xxx.asmx</a>'. If the service is defined in the current solution  try building the solution and adding the service reference again.</p>  <p>What can be the problem?</p>  <p>When I hit the hosted web service on browser i am able to see the then  service desciption properly.</p>  <pre><code>'http://xxx.cloudapp.net:20000/xxx.asmx?wsdl' </code></pre>""",azure-web-app-service
49864475,Access to Azure Blob Storage with Firewall from Azure Function App <p>I have an Azure blob storage account which is fire walled to selected networks only. I would like to access this storage account from a function app running on a dynamic plan whose outbound IP addresses are known to me. Problem is that I add these outbound ips to the Allowed IP addresses in Firewall and Virtual Network settings of the blob storage but I still continue to get an error which says: </p>  <p><strong>This request is not authorized to perform this operation.</strong></p>  <p>Can someone please point out where I am going wrong? </p>  <p>N.B. I am using PythonSDK for accessing the blob storage with the account name and the account key!</p>,azure-functions
48693725,"Storing SQL Database Connection Strings in Azure Key Vault <p>I'm moving application secrets from a source controlled web.config (with transforms) to Azure Key Vault secrets. This works well for things like passwords  but SQL database connection strings seem difficult to move out of the web.config. There are various references to the connection strings elsewhere in the web.config (e.g. role providers  membership providers  profile providers  entity framework  etc.).</p>  <p>Are there any patterns and best practices to help with this migration? I was planing to use the connection string name as the secret name and the connection string value as the secret value. However  I'm not sure what to do with the connection string provider name.</p>  <p>Also  ideally  only the key vault URL would be in the web.config  but then how do existing configurations in the web.config integrate with Key Vault if they are currently referencing an actual connection string.</p>  <p>The IIS hosted ASP.NET application is currently running within an Azure Virtual Machine  but local development must also be taken into consideration.</p>  <p><strong>UPDATE</strong> What about configuration like the following added and used by other libraries/packages?</p>  <pre><code>&lt;sessionState mode=\InProc\"" customProvider=\""DefaultSessionProvider\""&gt;   &lt;providers&gt;     &lt;add name=\""DefaultSessionProvider\""          type=\""System.Web.Providers.DefaultSessionStateProvider  System.Web.Providers  Version=2.0.0.0  Culture=neutral  PublicKeyToken=31bf3856ad364e35\""          connectionStringName=\""DefaultConnection\"" /&gt;   &lt;/providers&gt; &lt;/sessionState&gt; &lt;profile defaultProvider=\""DefaultProfileProvider\""&gt;   &lt;providers&gt;     &lt;add name=\""DefaultProfileProvider\""          type=\""System.Web.Providers.DefaultProfileProvider  System.Web.Providers  Version=2.0.0.0  Culture=neutral  PublicKeyToken=31bf3856ad364e35\""          connectionStringName=\""DefaultConnection\"" applicationName=\""/\"" /&gt;   &lt;/providers&gt; &lt;/profile&gt; &lt;membership defaultProvider=\""DefaultMembershipProvider\""&gt;   &lt;providers&gt;     &lt;add name=\""DefaultMembershipProvider\""          type=\""System.Web.Providers.DefaultMembershipProvider  System.Web.Providers  Version=2.0.0.0  Culture=neutral  PublicKeyToken=31bf3856ad364e35\""          connectionStringName=\""DefaultConnection\"" enablePasswordRetrieval=\""false\""          enablePasswordReset=\""true\"" requiresQuestionAndAnswer=\""false\"" requiresUniqueEmail=\""false\""          maxInvalidPasswordAttempts=\""5\"" minRequiredPasswordLength=\""6\""          minRequiredNonalphanumericCharacters=\""0\"" passwordAttemptWindow=\""10\"" applicationName=\""/\"" /&gt;   &lt;/providers&gt; &lt;/membership&gt; &lt;roleManager defaultProvider=\""DefaultRoleProvider\""&gt;   &lt;providers&gt;     &lt;add name=\""DefaultRoleProvider\""          type=\""System.Web.Providers.DefaultRoleProvider  System.Web.Providers  Version=2.0.0.0  Culture=neutral  PublicKeyToken=31bf3856ad364e35\""          connectionStringName=\""DefaultConnection\"" applicationName=\""/\"" /&gt;   &lt;/providers&gt; &lt;/roleManager&gt; </code></pre>""",azure-virtual-machine
44391120,Logging when an Azure (Basic) Web App Exceeds Quotas <p>Running a basic  free Windows Azure Web application for testing purposes I often exceed the CPU Time (short) quota of 3 minutes. </p>  <p>For example  when trialling the image optimisation Nuget package AzureImageOptimizer which is implemented as a Web Job  the initial optimisation run exceeded the limit and stopped the server.</p>  <p>I notice these events are not being recorded in the Web App's Activity Log. Why?</p>  <p>Questions:</p>  <ul> <li>Are these events logged?  </li> <li>Is it because this is a Free Web App?  </li> <li>Can the Web App be configured so that they are logged?  </li> <li>Is there an alternative way to catch these events?</li> </ul>  <p>Bonus question: </p>  <ul> <li>Can I receive a notification before a quota is exceeded?</li> </ul>,azure-web-app-service
56274274,"How to log custom application logs generated by Java/Spring Boot app in Azure Application Logs? <p>I have a Spring Boot application that uses log4j2 to create a log file into \D:/home/LogFiles/azurefileapp/\"" folder in Azure Web App. The application can write logs to this folder properly without any issues.</p>  <p>Now the issue I have is I want to share these logs with other developers who are not having access to the Azure Portal. I thought of providing them with below cmd that downloads these logs (using Service Principal).</p>  <p>az webapp log download --resource-group   --name </p>  <p>With above cmd the logs get downloaded but the current log file to which the app is writing the logs won't get downloaded as it is currently under write lock and locked by a process.</p>  <p>I already tried switching from log4j2 to slf4j. But same happens. The latest log file will not get downloaded. Once I stop the web app  I can download the latest log file without any issues.</p>  <p>Is there any way by which any of the following can be done? 1. The latest log file too can be downloaded without stopping the web app using the same \""az webapp log download\"" cmd? 2. Or else  is there a way by which I can directly write to the log files that Azure Web App generates by itself when we switch on Application Logging. 3. Is there a way I can write my custom logs to the Azure Storage Blob through Spring Boot?</p>""",azure-web-app-service
47275617,"Error with writing Parquet files to local disk <p>I am writing spark dataframes on local disk and I cannot read it back. </p>  <pre><code>val path = \file:///mnt/resources/.....\"" df.write.parquet(path)  val d = spark.read.parquet(path) </code></pre>  <p>I get the following error: </p>  <pre><code>org.apache.spark.sql.AnalysisException: Unable to infer schema for Parquet. It must be specified manually.; </code></pre>  <p>I am fine with reading and writing from/to Azure Datalake or Storage  but not with local disk.  Has anyone face the same issue? how to solve it?  I tested with .csv files also  and in that case  it says the file does not exist  even I can see the file when I login to the worker nodes. </p>""",azure-storage
36278583,azure availability set second VM shuts down first VM <p>I've got two Ubuntu VMs in one availability set. When I start the second VM it takes a few minutes and the first VM stops.</p>,azure-virtual-machine
53566452,Is it normal for the Azure Function Runtime to release a blob listener? <p>I have a Azure Function (v2) (edit: on a consumption plan) that fails to run when blobs are changed in the container it is monitoring.  If I manually jump-start the function to run by viewing it on the Azure Portal  it processes all blobs since last run  as expected.  After less than 10 minutes  however  it seems like it stops polling the container:</p>  <pre><code>Hosting stopping Stopping JobHost Singleton lock released (cafectoweretl/WebJobs.Internal.Blobs.Listener) </code></pre>  <p>I'm trying to understand what is happening behind the scenes here.  Is the Function runtime polling the container (or the logs) outside of the WebJobs.Internal.Blobs.Listener?  If so  where is this activity logged?</p>,azure-functions
41829911,"Azure rest api put blob <p>I am trying to put a blob with Azure rest api. i made a \GET\"" request successfully but i had issues with \""PUT\"" request. When i try to make \""PUT\"" request i get a 404error (i have seen same post in stackoverflow but it didnt help me).i am not sure if the MessageSignature that i use is correct(i have tried MessageSignaturePut but didnt work). Any suggestions?</p>  <pre><code>public void UploadBlobWithRestAPI(string uri   DateTime now) {     string blobName = \""test.txt\"";     string method = \""PUT\"";     string sampleContent = \""This is sample text.\"";     int contentLength = Encoding.UTF8.GetByteCount(sampleContent);     string queryString = (new Uri(uri)).Query;     string blobContainerUri = uri.Substring(0  uri.Length - queryString.Length);     string requestUri = string.Format(CultureInfo.InvariantCulture  \""{0}/{1}{2}\""  blobContainerUri  blobName  queryString);     HttpWebRequest request = (HttpWebRequest)WebRequest.Create(requestUri);     string nnow = now.ToString(\""R\""  System.Globalization.CultureInfo.InvariantCulture);      request.Method = method;     request.Headers.Add(\""x-ms-version\""  \""2015-02-21\"");     request.Headers.Add(\""x-ms-date\""  nnow);     request.ContentType = \""text/plain; charset=UTF-8\"";     request.Headers.Add(\""x-ms-blob-type\""  \""BlockBlob\"");     request.ContentLength = contentLength;      using (Stream requestStream = request.GetRequestStream())     {         requestStream.Write(Encoding.UTF8.GetBytes(sampleContent)  0  contentLength);     }      request.Headers.Add(\""Authorization\""  AuthorizationHeader(method  now  request  \""\""  \""\""));      using (HttpWebResponse resp = (HttpWebResponse)request.GetResponse())     {         MessageBox.Show(resp.StatusCode.ToString());     } }   public string AuthorizationHeader(string method  DateTime now  HttpWebRequest request          string ifMatch = \""\""  string md5 = \""\"") {     string MessageSignature;     string StorageKey = \""xxx\"";     string StorageAccount = \""upgradedevstorage\"";      MessageSignature = String.Format(\""{0}\\n\\n\\n{1}\\n{5}\\n\\n\\n\\n{2}\\n\\n\\n\\n{3}{4}\""          method          (method == \""GET\"" || method == \""HEAD\"") ? String.Empty : request.ContentLength.ToString()          ifMatch          GetCanonicalizedHeaders(request)          GetCanonicalizedResource(request.RequestUri  StorageAccount)          md5         );   ???   //string MessageSignaturePut= String.Format(\""{0}\\n\\n{1}\\n\\n{2}{3}\""      //    method      //    \""text/plain; charset=UTF-8\""      //    GetCanonicalizedHeaders(request)      //    GetCanonicalizedResource(request.RequestUri  StorageAccount)     //    );      byte[] SignatureBytes = System.Text.Encoding.UTF8.GetBytes(MessageSignature);      System.Security.Cryptography.HMACSHA256 SHA256 =         new System.Security.Cryptography.HMACSHA256(Convert.FromBase64String(StorageKey));      string signature = Convert.ToBase64String(SHA256.ComputeHash(SignatureBytes));      string AuthorizationHeader = \""SharedKey \"" + StorageAccount         + \"":\"" + Convert.ToBase64String(SHA256.ComputeHash(SignatureBytes));      return AuthorizationHeader; } </code></pre>""",azure-storage
40430342,"using IoC container in azure functions <p>I have been used to writing Windows Services using <a href=\http://topshelf-project.com/\"" rel=\""nofollow noreferrer\"">TopShelf</a> to do all stuff which cannot be done in a web request and am slowly moving to using azure functions.</p>  <p>With topshelf I could generally do</p>  <ol> <li>scan and register on start of a service</li> <li>use nested container for each ticket / request</li> </ol>  <p>How can I use IOC in an azure function call ? Should I be using it at all ?</p>""",azure-functions
53041301,Use password in powershell for Azure Scale Set <p>I'm using a powershell script for automatically add new vm's in a scale set to my domain via Custom Script Extension. In the script I wrote the password blank (in testing environment only)  because it has to be without any prompt. But this isn't very secure so I want to use another way.</p>  <p>At my local computer I can write my password encrypted in a script  but in a Scale Set it isn't possible  otherwise we had the same problem with the prompt.</p>  <p>Another idea is to write the password with powershell in a .txt file (encrypted) and store this file in Azure  so the new vm has to connect to Azure to get this file. But then we have the same issue with the authorization.</p>  <p>I hope you understand my problem  do you have any suggestions?</p>  <p>Best regards</p>,azure-virtual-machine
25578551,SQL Azure Firewall Rules on New Portal (2014) <p>Another year and another Azure portal redesign. I'm now running in the new Preview and I cannot find where to allow a firewall rule so that outside IP addresses (Visual Studio on my own machine) can access Azure SQL.</p>  <p>Does anyone know where this can be set?</p>,azure-storage
27329840,Is there a limit for number of projects you can have in Visual Studio Team Services for free? <p>Is there projects number limitation in free Visual Studio Team Services?<br /> It will be appreciate if you describe more about limitation of free Visual Studio Team Services.</p>,azure-devops
32591217,Failure to build on VS Online because of Nuget  works locally <p>Running locally in VS2015. Everything builds fine. If I deploy to VS Online  the build fails as it cannot find HTML Agility Pack  which is in the solution as a Nuget package. I have checked that Restore NuGet Packages is ticked in VS Online.</p>  <p>Any thoughts on anything I'm not doing.</p>,azure-devops
54237939,"Equivalent for TeamCity's system.build.start.date in Azure Pipelines <p>Is there an equivalent for the TeamCity variable <code>system.build.start.date</code> in Azure Pipelines? I couldn't find it in the predefined variables (<a href=\https://docs.microsoft.com/en-us/azure/devops/pipelines/build/variables?view=vsts\"" rel=\""nofollow noreferrer\"">https://docs.microsoft.com/en-us/azure/devops/pipelines/build/variables?view=vsts</a>)</p>""",azure-devops
53418625,"'Could not get the storage context' error when using Set-AzureStorageBlobContent in VSTS Azure Powershell task <p>I am using an Azure Powershell task in an Azure (VSTS) Pipeline to try and upload a file to an Azure Classic container.<br> As part of setting up the Azure Powershell task (ver 3.1.10)  I added the Azure Classic subscription that this container lives in to the Project Settings\\Service connections: <a href=\https://i.stack.imgur.com/uyoMq.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/uyoMq.png\"" alt=\""service connection\""></a></p>  <p>I then select that subscription in the pipeline task: <a href=\""https://i.stack.imgur.com/K5asg.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/K5asg.png\"" alt=\""select subscription\""></a></p>  <p>When I execute the script  the logs seem to show that the task is both setting and selecting the expected subscription:<br> <a href=\""https://i.stack.imgur.com/oidrf.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/oidrf.png\"" alt=\""logs\""></a></p>  <p>However  if I don't explicitly (re-)create and pass in the AzureStorageContext to the Set-AzureStorageBlobContent function  the task fails with:  </p>  <p><code>[error]Could not get the storage context.  Please pass in a storage context or set the current storage context.</code>  </p>  <p><strong>Is this expected behavior?<br> Is there any way around having to re-create and pass in the context when it appears that it already exists?</strong><br> <em>For example  is there an environment variable that might contain the context that was automatically created/selected that I can just pass in?</em></p>  <p><strong>Update:</strong> I suspect that if the  <code>Select-AzureSubscription</code> call seen in the logs used the -Current switch  this would work as I'm expecting it to. However  since that command is automatically ran with no way to configure it via the pipeline task  it's not verifiable.<br> Perhaps this needs to be a feature request?</p>  <p>Excerpts from script:</p>  <pre><code>#Not passing in the context results in the error Set-AzureStorageBlobContent -File \""$file\"" -Blob \""$blobpath/$blah\"" -Container $blobname -Properties $properties -Force  #Passing in the context works:   $azureKey = Get-AzureStorageKey \""$accountName\"" $storagekey = [string]$azureKey.Primary $context = New-AzureStorageContext \""$accountName\"" -StorageAccountKey $storagekey   Set-AzureStorageBlobContent -File \""$file\"" -Blob \""$blobpath/$blah\"" -Container $blobname -Properties $properties -Context $context -Force </code></pre>""",azure-devops
43989472,"Error starting selenium grid hub via powershell - VSTS/TFS <p>I'm struggling to start selenium grid on an azure VM via a powershell script in my build due to the following error....</p>  <blockquote>   <p>System.Management.Automation.RuntimeException: The running command stopped because the preference variable \ErrorActionPreference\"" or common parameter is set to Stop: Error: Unable to access jarfile selenium-server-standalone-3.4.0.jar</p> </blockquote>  <p>The script simply contains <code>java -jar selenium-server-standalone-3.4.0.jar -role hub</code> and it runs fine locally. Java is installed on the VM. </p>  <p>Does anyone know what the issue is?</p>  <p>Thanks  </p>""",azure-virtual-machine
37746405,"Uploading a Blob to Azure storage doesnt work for local development emulator using NodeJs <p>I am trying to upload a local file to blob storage using NodeJs. The server sends me the following details</p>  <pre><code>{hostName: \StorageAccount\""  containerName:\""containerName\""  \""blobName\"": blobName  sasToken: \""sasToken\""} </code></pre>  <p>and following is the code written for uploading the file</p>  <pre><code>var azure = require('azure-storage'); var blobSvc = azure.createBlobServiceWithSas(result.hostName result.sasToken); blobSvc.createBlockBlobFromLocalFile(result.containerName result.blobName 'server.json'   function(error  result  response){   if(!error){    // file uploaded  } }); </code></pre>  <p>above code works fine if its a real storage information in Azure  but throws \""Specified resource not found\"" error if its on local development storage.</p>  <p>Any help is greatly appreciated. Thanks</p>""",azure-storage
56804170,".Net Core Web Api Authentication with Azure App Service Authentication <p>We have an ASP .Net Core 2.2 Web Api which is currently using Auth0 as the authentication server. We have recently moved our API to Azure and so are now hosting it there as an App Service. I noticed earlier today that there is an \Authentication / Authorization\"" tab in the Azure Portal. Navigating to it  I see there is a switch labelled \""App Service Authentication\"" which can be turned on.</p>  <p>My question is  would this essentially be the same as Auth0? Can I use this Azure \""App Service Authentication\"" feature to replace Auth0? Does it serve the same purpose? I.e. will it protect my API the way Auth0 and be able to see who's logged in  allow social logins  etc?</p>  <p>The app/api is not live yet  so if we can rather use Azure as our authentication server instead of Auth0  we'd like to do the switch now.</p>  <p>Thanks</p>""",azure-web-app-service
38162266,Extra Resources Created In Azure For VM <p>When I create a VM in Azure  it is creating an accompanying Cloud Service and Network Resource. I found that the Cloud Service is there as a deployment layer. I have not found why the Network Interface is there. </p>  <p>Since this particular circumstance is not going to have a deployment associated with it as it is used as an Elasticsearch server  I technically will not be needing the Cloud Service. However  when I delete the service  it takes the VM with it even though I do not expressly select it for delete.</p>  <p>My two specific questions: 1st - Why is there a Cloud Service created and not able to be deleted without repercussions when there is not deployment necessary? 2nd - Why is the Network Interface created and not able to be deleted without repercussions?</p>  <p>Both questions are with the understanding that this is an Elasticsearch VM.</p>,azure-virtual-machine
53575000,"Can i safely Disable Windows feature Hyper V on my Azure Virtual Machine <p>I am using Azure VM with o/s Windows 10. I am using Visual Studio 2017 to develop xamarin cross platform app targeting all 3   windows  android  ios.</p>  <p>When i try to run my android avd i get this warning: <a href=\https://hemantmahajan08.files.wordpress.com/2018/12/nexus.png\"" rel=\""nofollow noreferrer\"">link</a></p>  <p>If i continue avd is loaded but no App is displayed.</p>  <p>Should i disable hyper V on the VM and install intel HAXM? Is it safe? <a href=\""https://hemantmahajan08.files.wordpress.com/2018/12/windows-features.png\"" rel=\""nofollow noreferrer\"">link</a>  </p>""",azure-virtual-machine
54575349,"Polybase doesn't create external file format <p>I get the good old </p>  <blockquote>   <p>Incorrect syntax near 'EXTERNAL'.</p> </blockquote>  <p>error. I am exactly doing what <a href=\https://stackoverflow.com/questions/47603542/how-to-make-a-file-format-in-sql-server/52961148#52961148\"">this answer describes</a>. But SQL Server returns the aforementioned error when I come to this code-chunk:</p>  <pre><code>CREATE EXTERNAL FILE FORMAT csvformat  WITH (      FORMAT_TYPE = DELIMITEDTEXT       FORMAT_OPTIONS (FIELD_TERMINATOR =' ')  ); GO </code></pre>  <p>What am I doing wrong? </p>  <p><strong>What I tried</strong></p>  <ul> <li>Java runtime environment is installed (Java 8 Update 201)</li> <li>PolyBase is installed with \""PolyBase Query Service for External Data\""</li> <li>I enabled PolyBase with <code>EXEC sp_configure 'hadoop connectivity'  4;</code>. I also set that option to <code>1</code> and <code>7</code> - I still get that error</li> <li>Using <code>EXEC sp_configure</code>  I also set <code>'polybase enabled'</code> to <code>1</code></li> <li>I checked <code>SELECT SERVERPROPERTY ('IsPolybaseInstalled') AS IsPolybaseInstalled;</code> - it returns <code>1</code></li> <li>My TCP is enabled</li> <li>My PolyBase is running:</li> </ul>  <p><a href=\""https://i.stack.imgur.com/oIpd6.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/oIpd6.png\"" alt=\""enter image description here\""></a> Setup: SQL Server 2019 on a Virtual Machine (Azure)  no Azure SQL Server or Azure DWH. </p>""",azure-virtual-machine
39724189,"VS Team Services & Git for Windows error \fatal: Authentication failed ...\"" <p>Running Git for Windows and the Git Credential Manager on a shared  4 user  developer VM.</p>  <p>Upon cloning a repository  the GCM kicks in and authenticates me  but Git still reports <code>fatal: Authentication failed ...</code></p>  <p>I can see in my Team Services (previously VSO) account that the GCM created a new personal access token:</p>  <p><code>Git: https://company.visualstudio.com/ on SHARED-VM-HOSTNAME</code></p>  <p>I've revoked previous ones and it creates a new one  so that mechanism is working.</p>  <p>Git (version 2.10) and the GCM don't seem to be playing ball. We have it working elsewhere on other machines.</p>  <p>It works for only one shared user RDP'ed onto this VM.</p>  <p>Just asking IT to reinstall latest versions of all software (again  again).</p>  <p>IP web traffic I think is routing directly/no proxy.</p>  <p>Any ideas?</p>""",azure-devops
53194536,TFS Prepare for Shutdown/Restart <p>I am new to TFS.</p>  <p>Is there anyway to notify TFS to not to start new build/test/releases as we are about to restart/shutdown the TFS server?</p>  <p>Jenkins has a similar feature  where it puts up a banner saying 'Jenkins is going to shut down' and stop queuing new builds. Does TFS have such a feature?</p>,azure-devops
54160812,Running azure powershell script on web app during release task <p>I have an 'azure powershell task' running in my VSTS release after my 'deploy to azure site' task.  In the powershell script  i have some transformations that i need to run on several of the files on the website  all based on the deployments variables.</p>  <p>The problem is I can't find the directory for the website.  The root directory that the task is run under is something like:</p>  <blockquote>   <p>D:\a_tasks\AzurePowerShell_71a1931a-effb-3d2e-8fd8-f7472a07cb62\3.1.18\</p> </blockquote>  <p>how do i point it to the d:\home\site\wwwroot\   is there a build/release variable that automatically picks the deployment site location?  Or can i just write out 'd:\home\site\wwwroot\' and expect that to not change in the future?</p>,azure-devops
55657025,Microsoft azure devops on hadoop <p>I am working on building pipelines for hive. I tried to use the SQL Execute plugin to run some SQL scripts but the connection to hive has not been successful.</p>  <p>The ODBC details in the yaml build file do not help either.</p>  <p>I also tried to connect to the edge node using the SSH service connection but the password is not helping either.</p>  <p>Please let me know if anyone had worked on this before.</p>,azure-devops
55075807,"XDT Transformations don't get applied to AppSettings section <p>I have a build and release pipelines in Azure DevOps (Visual Studio Online) for an ASP.NET (Non-Core) Website on .Net Framework 4.6.1.</p>  <p>After the deployment is finished  the <code>Web.config</code> file has empty <code>value</code> attribute for all the <code>AppSettings</code> <code>keys</code> that I've set in the XDT Transformation file.</p>  <p>Web.config used by my local IIS has values like these:</p>  <pre><code>&lt;appSettings&gt;     &lt;add key=\testKey1\"" value=\""testValue1\"" /&gt;     &lt;add key=\""testKey2\"" value=\""testValue2\"" /&gt;     ….     …. &lt;/appSettings&gt; </code></pre>  <p>After the deployment is finished  this is how <code>AppSettings</code> looks like in <code>Web.config</code>:</p>  <pre><code>&lt;appSettings&gt;     &lt;add key=\""testKey1\"" value=\""\"" /&gt; &lt;!-- Notice how the value is empty --&gt;     &lt;add key=\""testKey2\"" value=\""\"" /&gt;     ….     …. &lt;/appSettings&gt; </code></pre>  <p>As a note: this is pulled from the server directly.</p>  <p>My transformation file is named as <code>Web.MyTestEnvironment.config</code> and MyTestEnvironment is the same name as the stage in Azure DevOps which has the task to deploy/publish the artifact.</p>  <p>In the logs  I can see <code>azure app service deploy (Version 4.x if that matters)</code> applying those transformations one by one and reporting success (I've set <code>System.Debug</code> to <code>true</code> in pipeline variables to get this).</p>  <p>I tried downloading the artifact zip file and saw that <code>parameters.xml</code> file has all the XPath locators set but <code>SetParameters.xml</code> file looks like this:</p>  <pre><code>&lt;parameters&gt;     &lt;setParameter value=\""\"" name=\""testKey1\"" /&gt; &lt;!-- Also notice how value is empty --&gt;     &lt;setParameter value=\""\"" name=\""testKey2\"" /&gt; &lt;/parameters&gt; </code></pre>  <p>I've tried everything I can think of and I've been looking online for similar issues but to no avail.</p>  <p>This is how the FileTransform is set in the CI task:</p>  <p><a href=\""https://i.stack.imgur.com/ycLdV.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/ycLdV.png\"" alt=\""enter image description here\""></a></p>  <p>Any ideas why my transforms are being ignored? or maybe being overridden by the <code>SetParameters.xml</code> file?</p>  <p>I've followed this guide to set up the transformations in Azure DevOps: <a href=\""https://docs.microsoft.com/en-us/azure/devops/pipelines/tasks/transforms-variable-substitution?view=azure-devops\"" rel=\""nofollow noreferrer\"">https://docs.microsoft.com/en-us/azure/devops/pipelines/tasks/transforms-variable-substitution?view=azure-devops</a> </p>  <p>Also  looked at countless StackOverflow questions but those weren't describing my scenario.</p>  <p>Any help is much appreciated.</p>""",azure-devops
38588896,deleting the entries in Azure Table Storage that Are Certain Days Old Automation <p>I want to automate to delete One month before entries in Azure Table Storage. </p>  <p>Now in Azure Table Storage I have one year entries. I delete it manually. but for the future  I need to automate this process. I need to delete one month old entries from Azure table storage.  </p>,azure-storage
54842005,How do I demand a 64-bit agent? <p>In the documentation for Azure Pipelines  it allows for <code>demands</code> to be provided which will force a task to select an agent with <code>capabilities</code> that meet the demands.</p>  <p>However  I can't find a definitive list of the capabilities provided by the Microsoft-hosted agents.</p>  <p>How can I specify a demand that will only allow for 64-bit agents?</p>,azure-devops
22563029,"Azure Blob Storage Emulator Error <p>I am trying to write a test app that will allow me to access Azure Blob Storage. I am using VS2013 and have Azure SDK V2.2 installed.  The Azure Storage Emulator is running. However  the location used by the storage emulator </p>  <p>C:\\Users[UserName]\\AppData\\Local\\dftmp\\wadd</p>  <p>seems to be different to the location used in VS2013 IDE. I'm not sure where that location is. I can create a container and upload files using the VS2013 IDE  but I then don't see them in the Storage Emulator location  so I have assumed they are different.</p>  <p>More simportantly  the code below fails with a <strong>The remote server returned an error: (400) Bad Request.</strong> error when it executes the line: </p>  <pre><code>blobContainer.CreateIfNotExists(); </code></pre>  <p>Any ideas what is going on and why I can't get this to work in VS2013 using the emulator? It works just fine if I substitute my actual Azure credentials and write the file to the Azure Storage. I really want to build this test solution and do some debugging before moving a solution completely onto Azure.</p>  <pre><code>public partial class Form1 : Form {     public Form1()     {         InitializeComponent();     }      // Storage Emulator credentials     string connectionString = \UseDevelopmentStorage=true\"";     string myContainer = \""images\"";      CloudStorageAccount cloudStorageAccount;     CloudBlobClient blobClient;     CloudBlobContainer blobContainer;     BlobContainerPermissions containerPermissions;     StorageCredentials storageCredentials;      private void InitialiseBlobStorage()     {         cloudStorageAccount = CloudStorageAccount.Parse(connectionString);         blobClient = cloudStorageAccount.CreateCloudBlobClient();         blobContainer = blobClient.GetContainerReference(myContainer);         blobContainer.CreateIfNotExists();     }      private void Form1_Load(object sender  EventArgs e)     {      }      private void button1_Click(object sender  EventArgs e)     {         InitialiseBlobStorage();          // Add code to upload image here     } } </code></pre>""",azure-storage
42576427,"Concurrency Handelling in Azure Mobile Services <p>I am an iOS developer &amp; currently working on Azure Mobile service. I am using Azure iOS client SDK. I have query on concurrency model in Azure as I found below links</p>  <p><a href=\https://azure.microsoft.com/en-in/blog/managing-concurrency-in-microsoft-azure-storage-2/\"" rel=\""nofollow noreferrer\"">Link 1</a></p>  <p><a href=\""https://docs.microsoft.com/en-us/azure/storage/storage-concurrency\"" rel=\""nofollow noreferrer\"">Link 2</a></p>  <p>But I am unable to understand how I should manage concurrency from iOS app as I am not using SQLite for database.</p>""",azure-storage
54347481,receive a large amount of data from Azure Storage and process it <p>I need to migrate some data from Azure Storage to Sql db.</p>  <p>I have the following code :</p>  <pre><code>class AzureDataAccessManager : IAzureDataAccessManager {     private readonly CloudTable tableClient;      private readonly CloudStorageAccount storageAccount;      public string TableName { get; }      public AzureDataAccessManager(string connectionString  string tableName)     {         TableName = tableName ?? throw new ArgumentNullException(nameof(tableName));          if (connectionString == null) throw new ArgumentNullException(nameof(connectionString));          storageAccount = CloudStorageAccount.Parse(connectionString);          tableClient = storageAccount.CreateCloudTableClient().GetTableReference(TableName);     }      public List&lt;T&gt; QueryAllRecords&lt;T&gt;() where T : class  ITableEntity  new()     {         TableContinuationToken token = null;          var entities = new List&lt;T&gt;();         do         {             var queryResult = tableClient.ExecuteQuerySegmented(new TableQuery&lt;T&gt;()  token);             entities.AddRange(queryResult.Results);             token = queryResult.ContinuationToken;          } while (token != null);          return entities;     } } </code></pre>  <p>And I am getting all the records like this :</p>  <pre><code>var result = azureTableManager.QueryAllRecords&lt;AzureCpaDataEntity&gt;(); </code></pre>  <p>The problem is I don't know  how many rows I'll have there. What if it will be too large? Maybe get via some ranges (10 thousands or whatever)  but as I see there is no respective method in List.</p>  <p>Help me with some solutions or ideas  please!</p>  <p>Thanks!  </p>,azure-storage
48906300,"Using IConfigurationRoot when registering services for DI in Azure Functions beta? <p>I want to be able to use dependency injection in my Azure Functions VS 2017 project (I'm using SDK v1.0.6). DI doesn't seem to work out-of-the-box yet  so I'm using <a href=\https://blog.wille-zone.de/post/azure-functions-proper-dependency-injection/\"" rel=\""nofollow noreferrer\"">Boris Wilhelms workaround</a>.</p>  <p>When I register some services  I need to be able to use a connection string from a configuration object. I found <a href=\""https://blog.jongallant.com/2018/01/azure-function-config/\"" rel=\""nofollow noreferrer\"">a good article by Jon Gallant</a> that describes the new way to build an IConfigurationRoot object. However  that approach relies on a ExecutionContext object  which I don't think is available in Boris' InjectConfiguration class.</p>  <p>Any ideas how I can use my </p>""",azure-functions
50150160,"Remove Server header on response on 500 HTTP Error <p>I have a REST API service deployed as an Azure App Service and i been trying to remove the Server header from response.</p>  <p>I tried adding a custom outgoing rule to Rewrite module.</p>  <p>In web.config i have</p>  <pre><code>&lt;rewrite&gt;         &lt;outboundRules&gt;         &lt;rule name=\Change Server Header\""&gt;           &lt;match serverVariable=\""RESPONSE_Server\"" pattern=\"".+\"" /&gt;           &lt;action type=\""Rewrite\"" value=\""My Server\"" /&gt;           &lt;/rule&gt;        &lt;/outboundRules&gt;  &lt;/rewrite&gt;   </code></pre>  <p>I also applied a applicationHost.xdt transformation to applicationHost.config in order to add the RESPONSE_Server variable</p>  <pre><code>&lt;?xml version=\""1.0\""?&gt;   &lt;configuration xmlns:xdt=\""http://schemas.microsoft.com/XML-Document-Transform\""&gt;    &lt;configSections&gt;      &lt;sectionGroup name=\""system.webServer\"" xdt:Locator=\""Match(name)\""&gt;        &lt;sectionGroup name=\""rewrite\"" xdt:Locator=\""Match(name)\""&gt;          &lt;section name=\""allowedServerVariables\"" overrideModeDefault=\""Allow\"" xdt:Locator=\""Match(name)\"" xdt:Transform=\""SetAttributes(overrideModeDefault)\"" /&gt;       &lt;/sectionGroup&gt;      &lt;/sectionGroup&gt;    &lt;/configSections&gt;     &lt;system.webServer&gt;          &lt;rewrite&gt;              &lt;allowedServerVariables&gt;              &lt;add name=\""RESPONSE_Server\"" xdt:Transform=\""InsertIfMissing\"" xdt:Locator=\""Match(name)\"" /&gt;            &lt;/allowedServerVariables&gt;          &lt;/rewrite&gt;       &lt;/system.webServer&gt;   &lt;/configuration&gt; </code></pre>  <p>But i still see the Server response http header on a request like following which returns a 500 HTTP status code</p>  <p><a href=\""https://api.internaltest.com/%3a/\"" rel=\""nofollow noreferrer\"">https://api.internaltest.com/%3a/</a></p>  <p>The rewrite rule works in local IIS it removes the http header successfully... but not when doing it in Azure App Service.</p>  <p>Please tell me what i'm missing.</p>  <p>I mention that i have removeServerHeader=\""true\"" in web.config also but it only removes the server header on 404 bad request  not on 500 status code.</p>  <pre><code>&lt;security&gt;       &lt;requestFiltering removeServerHeader=\""true\""&gt;         &lt;requestLimits maxAllowedContentLength=\""2147483647\"" /&gt;       &lt;/requestFiltering&gt;     &lt;/security&gt; </code></pre>  <p>Hope anyone can help me </p>  <p>Thank you</p>""",azure-web-app-service
54876330,Why git core is deleted everyday on Azure webapp? <p>I've installed git-core on Azure webapp and during the next day the git commands won't work. Every day I need to reinstall the git-core and the other components.</p>  <p>I need to put this script everyday :</p>  <pre><code>apt-get update apt-get install -y git-core apt-get install -y mysql-server </code></pre>  <p>Are there parameters to set in the azure portal interface or a script to insert in appservice files content ?</p>,azure-web-app-service
45198981,"Azure storage API: download entire folder / prefix / directory <p>I need to be able to download a folder with its contents from a blob storage account using the Azure Storage REST API only.</p>  <p>I have created a function (<code>New-StorageAccountAthorisationHeader</code>) that creates the (authentication) header that I can download a single file  but I cannot find any reference on how I might go about downloading the whole folder.</p>  <p>If I pass the folder as the <code>$blob</code> parameter  I get a <code>BlobNotFound</code> error.</p>  <p>The URL of the said folder is: <a href=\https://mystorageaccount.blob.core.windows.net/acontainer/somefolder\"" rel=\""nofollow noreferrer\"">https://mystorageaccount.blob.core.windows.net/acontainer/somefolder</a>. The contents of \""somefolder\"" looks like:</p>  <pre><code>Folder1   FolderA      FileA.txt   FolderB     FileB.txt     FileC.txt </code></pre>  <p>New-StorageAccountAthorisationHeader:</p>  <pre><code>function New-StorageAccountAuthorizationHeader {     [cmdletbinding()]     param     (         [string]$StorageAccountName          [string]$Container          [string]$Blob          [string]$accesskey           [string]$ResourceUri          [string]$xmsversion = \""2017-04-17\""     )      $xmsdate = Get-Date     $xmsdate = $xmsdate.ToUniversalTime()     $xmsdate = $xmsdate.toString('r')      function GetRestApiParameters     {         [cmdletbinding()]         param         (             [Parameter(Mandatory=$true)]             [string]$Uri         )          if($Uri.Contains(\""?\""))         {             Write-Verbose \""URI to extract REST parameters: $uri\""             return ($Uri.Split(\""?\"")[1]).Split(\""&amp;\"")         }     }      Write-Verbose \""Generating string for signature encryption...\""      $partUrl = \""/$StorageAccountName/\""      if($Container)     {         $partUrl = $partUrl + \""$Container/\""     }      if($Blob)     {         $parturl = $partUrl + \""$Blob\""     }  ######Don't change the line count or indentation of the here-string##### $hereString = @\"" GET            x-ms-date:$xmsdate x-ms-version:$xmsversion $partUrl \""@       $hereString =$hereString -replace \""$([char]13)$([char]10)\"" \""$([char]10)\"" #Change `r`n to just `n      $empty = $oSignature = New-Object System.Text.StringBuilder     $empty = $oSignature.Append($hereString)      Write-Verbose \""Appending parameters from URI into authorisation string...\""      $restParameters = GetRestApiParameters -Uri $ResourceUri -Verbose      if ($restParameters -ne $null)     {         foreach ($param in $restParameters)         {             $empty = $oSignature.Append(\""$([char]10)$($param.Replace('=' ':'))\"")            }     }      #$oSignature.toString()      Write-Verbose \""Encrypting string...\""     $hmacsha = New-Object System.Security.Cryptography.HMACSHA256     $hmacsha.key = [Convert]::FromBase64String($accesskey)     $signature = $hmacsha.ComputeHash([Text.Encoding]::UTF8.GetBytes($oSignature.ToString()))     $signature = [Convert]::ToBase64String($signature)      Write-Verbose \""Building header...\""     $headers = New-Object \""System.Collections.Generic.Dictionary[[String] [String]]\""     $headers.Add(\""x-ms-version\""  $xmsversion)     $headers.Add(\""x-ms-date\""  $xmsdate)     $headers.Add(\""Authorization\""  \""SharedKey \"" + $StorageAccountName + \"":\"" + $signature)     #$headers.Add(\""x-ms-blob-type\"" \""BlockBlob\"")     #$headers.Add(\""Content-Type\""  \""application\\xml\"")      Write-Verbose (\""Header: $($headers | Out-String)\"")      Return $headers } </code></pre>  <p>And I would call it:</p>  <pre><code>$StorageAccountName = \""mystorageaccount\"" $container = \""acontainer\"" $blob = \""somefile.txt\""  $uriToDownloadBlobs = \""https://\"" + $StorageAccountName + \"".blob.core.windows.net/$container/$blob\""  $header = $null $header = New-StorageAccountAuthorizationHeader -StorageAccountName $StorageAccountName -ResourceUri $uriToDownloadBlobs -Verbose -Container $container -Blob $blob  $result = Invoke-WebRequest -Headers $header -Uri $uriToDownloadBlobs -OutFile C:\\Temp\\$blob -PassThru  $result </code></pre>  <p>So this works  but as I said  I'm after any hints to help with downloading the whole folder.</p>""",azure-storage
49916780,"Terraform - Copy Files to an existing Azure VM from Local <p>This question has a Ref. to <a href=\https://stackoverflow.com/questions/48882420/connection-timeout-during-file-provision-to-azurerm-vm\"">Connection timeout during file provision to azurerm vm</a>. I don't want to create a new VM  which already exists. I have WinRM activated in my VM for http and I could able to connect to VM through Powershell using http. But terraform not able to copy the file using below .tf with provisioner</p>  <pre><code>resource \""null_resource\"" \""test\"" {   provisioner \""file\"" {     source      = \""D:/JAISH/TERRAFORM/output.txt\""     destination = \""D:/jaish/output.txt\""      connection {       type     = \""winrm\""       user     = \""uid\""       password = \""pwd\""       host     = \""IP\""       port     = \""5985\""       timeout  = \""20m\""     }   } } </code></pre>  <p>It's always showing like below without any status change.</p>  <pre><code>null_resource.test: Still creating... (18m21s elapsed) null_resource.test: Still creating... (18m31s elapsed) null_resource.test: Still creating... (18m41s elapsed) null_resource.test: Still creating... (18m51s elapsed) null_resource.test: Still creating... (19m1s elapsed) null_resource.test: Still creating... (19m11s elapsed) null_resource.test: Still creating... (19m21s elapsed) </code></pre>  <p>Not sure what's wrong here.</p>""",azure-virtual-machine
49737823,"SVG compression with Angular 5 app hosted on Azure App Service <p>I'm having some trouble getting SVG's to gzip in our Angular 5 application hosted as an Azure Web App. </p>  <p>I tried to follow this article  although it does say that Azure plans to have SVG's gzip automatically in the future  and this was written quite some time ago:</p>  <p><a href=\https://coryrylan.com/blog/svg-gzip-windows-azure\"" rel=\""nofollow noreferrer\"">https://coryrylan.com/blog/svg-gzip-windows-azure</a></p>  <p>I've confirmed that without this article  SVG's dont compress. When I try to add to my web.config the lines suggested in the above article  I can a generic error that the application can't load  so it's causing a pretty fundamental problem. I believe this could potentially have something to do with it conflicting with the Angular rewrite rules I need for routing of an Angular application. </p>  <p>This is my web.config with the modifications suggested in the previous article:</p>  <pre><code>&lt;configuration&gt;   &lt;system.webServer&gt;     &lt;rewrite&gt;       &lt;rules&gt;         &lt;rule name=\""AngularJS Routes\"" stopProcessing=\""true\""&gt;           &lt;match url=\"".*\"" /&gt;           &lt;conditions logicalGrouping=\""MatchAll\""&gt;             &lt;add input=\""{REQUEST_FILENAME}\"" matchType=\""IsFile\"" negate=\""true\"" /&gt;             &lt;add input=\""{REQUEST_FILENAME}\"" matchType=\""IsDirectory\"" negate=\""true\"" /&gt;           &lt;/conditions&gt;           &lt;action type=\""Rewrite\"" url=\""/\"" /&gt;         &lt;/rule&gt;       &lt;/rules&gt;     &lt;/rewrite&gt;     &lt;staticcontent&gt;          &lt;mimemap fileextension=\"".svg\"" mimetype=\""image/svg+xml\""/&gt;     &lt;/staticcontent&gt;     &lt;httpcompression&gt;          &lt;statictypes&gt;            &lt;remove mimetype=\""*/*\""/&gt;            &lt;add mimetype=\""image/svg+xml\"" enabled=\""true\""/&gt;            &lt;add mimetype=\""*/*\"" enabled=\""false\""/&gt;          &lt;/statictypes&gt;     &lt;/httpcompression&gt;   &lt;/system.webServer&gt; &lt;/configuration&gt; </code></pre>  <p>Has anyone had any luck compressing SVG's on an Azure Web App? SVG's are a large portion of our website and I'd really like to be able to reduce the file sizes involved there.</p>""",azure-web-app-service
42942438,azure - static outgoing ip for all VMs in a vnet <p>I have multiple VMs in a vnet. Vnet has a static ip attached to it's interface. The network interfaces attached to individual VMs do not have any public ip associated. My expectation is that all outgoing traffic would get routed through the vnet ip  but it isn't the case. Each VM has a different public going IP. I have tried using <code>curl ipinfo.io</code> to test. </p>  <p>I need to ensure that all of the internet traffic from any VM in the vnet would get routed through a static ip address.</p>,azure-virtual-machine
39641967,How can I locate my missing azure virtual machines <p>I have created 4 Azure VM a while back. I can still log in to them and I know they are live. But I can find in all the subscriptions account I have  ;-(. Can you help me out how I can locate them back?</p>  <p>Thanks for your help in advance.</p>,azure-virtual-machine
54169414,"Azure function Calculated MD5 does not match existing property <p>Hello i have this error since yesterday when debuging Azure Function i think it have to do with local dev storage cuz when i publish in azure all work well.</p>  <p>my local.settings.json is:</p>  <pre><code>{   \IsEncrypted\"": false    \""Values\"": {     \""AzureWebJobsStorage\"": \""UseDevelopmentStorage=true\""      \""AzureWebJobsDashboard\"": \""UseDevelopmentStorage=true\""      \""schedule\"": \""*/1 * * * * *\""   }    \""ConnectionStrings\"": {     \""crypto_dbEntities\"": //.................   } </code></pre>  <p>ERROR:</p>  <blockquote>   <p>[13/01/2019 13:33:29] The listener for function 'Function1' was unable   to start. Microsoft.WindowsAzure.Storage: Calculated MD5 does not   match existing property. [13/01/2019 13:33:29] The listener for   function 'Function1' was unable to start.   Microsoft.WindowsAzure.Storage: Calculated MD5 does not match existing   property.</p> </blockquote>  <p>How can i fixe this?.</p>""",azure-functions
52741041,"Blob binding in httpTrigger not working in VS2017 Azure function template <p>I want to pass the filename of blob to the httptrigger  through get request as below. </p>  <pre><code>http://localhost:7071/api/CSVDataMigrationHttpTrigger/testdata.csv </code></pre>  <p>Code for the azure function </p>  <pre><code>public static async Task&lt;HttpResponseMessage&gt; Run(         [HttpTrigger(AuthorizationLevel.Function  \get\""  \""post\""  Route = \""CSVDataMigrationHttpTrigger/{name}\"")]         HttpRequest req  string name          [Blob(\""csvdata-upload/{name}\""  FileAccess.Read  Connection = \""AzureWebJobsStorage\"")]         Stream inputBlob  ILogger log)     {} </code></pre>  <p><strong>inputBlob parameter is not resolved and it returns null.</strong></p>  <p>But if i give filename as \""testData.csv\"" as below in the Blob parameter  then inputBlob get resolved properly. </p>  <pre><code>  public static async Task&lt;HttpResponseMessage&gt; Run(             [HttpTrigger(AuthorizationLevel.Function  \""get\""  \""post\""  Route = \""CSVDataMigrationHttpTrigger/{name}\"")]             HttpRequest req  string name              [Blob(\""csvdata-upload/testData.csv\""  FileAccess.Read  Connection = \""AzureWebJobsStorage\"")]             Stream inputBlob  ILogger log){} </code></pre>""",azure-functions
52070549,"How to get the IP address of the newly created Azure VM via Powershell <p>I'm trying to automate some processes in our project which includes some steps like  create the VM  connect to the newly created VM and run some commands remotely.  </p>  <p>Now previously what I used to do is run this commands in sequence manually.</p>  <p>1.Create a VM</p>  <pre><code>New-AzureRmResourceGroupDeployment -Name VmDeployment -ResourceGroupName XYZ`   -TemplateFile \C:\\Templates\\template.json\"" `   -TemplateParameterFile \""C:\\Templates\\parameters.json\"" </code></pre>  <p>2.Connect to the VM.</p>  <pre><code>Set-Item WSMan:\\localhost\\Client\\TrustedHosts -Value  100.9.4.12      $UserName = \""100.9.4.12\\admin\"" $Password = ConvertTo-SecureString \""admin@123\"" -AsPlainText -Force $psCred = New-Object System.Management.Automation.PSCredential($UserName  $Password) $s = New-PSSession -ComputerName 100.9.4.12 -Credential $psCred Invoke-Command -Session $s -ScriptBlock {Get-Service 'ServiceName'} </code></pre>  <p>In this the IP address is used to add that in the trusted hosts on the client.I used to check the generated IP address on Azure Portal  replace that IP in the command and run them manually. But now   since I'm automating  there will be no manual intervention in the process.   </p>  <p>So how should I retrieve the IP address of the newly created VM?   </p>""",azure-virtual-machine
53676820,"Kudu npm install failed <p>I'm getting a very strange error when trying to deploy my project with kudu on Azure. </p>  <p>I have build my project with dotnet with VueJs. I have used the following template \<a href=\""https://github.com/MarkPieszak/aspnetcore-Vue-starter\"" rel=\""nofollow noreferrer\"">https://github.com/MarkPieszak/aspnetcore-Vue-starter</a>\""</p>  <p>I have tried setting the WEBSITE_NODE_DEFAULT_VERSION to a few different version now without any luck. </p>  <p>Here are the out from Kudu: </p>  <pre><code>Command: \""D:\\home\\site\\deployments\\tools\\deploy.cmd\"" Handling ASP.NET Core Web Application deployment.   Restore completed in 735.88 ms for D:\\home\\site\\repository\\projectx.csproj. Microsoft (R) Build Engine version 15.9.20+g88f5fadfbe for .NET Core Copyright (C) Microsoft Corporation. All rights reserved.    Restore completed in 345.52 ms for D:\\home\\site\\repository\\projectx.csproj.   projectx -&gt; D:\\home\\site\\repository\\bin\\Release\\netcoreapp2.1\\projectx.dll   projectx -&gt; D:\\home\\site\\repository\\bin\\Release\\netcoreapp2.1\\projectx.Views.dll   NPM Installing dependencies...   npm WARN package.json assert@1.4.1 assert is also the name of a node core module.   npm WARN package.json buffer@4.9.1 buffer is also the name of a node core module.   npm WARN package.json events@1.1.1 events is also the name of a node core module.   npm WARN package.json indexof@0.0.1 No repository field.   npm WARN package.json punycode@2.1.1 punycode is also the name of a node core module.   npm WARN package.json querystring@0.2.0 querystring is also the name of a node core module.   npm WARN package.json string_decoder@1.1.1 string_decoder is also the name of a node core module.   npm WARN package.json url@0.11.0 url is also the name of a node core module.   npm WARN package.json util@0.10.4 util is also the name of a node core module.   npm WARN package.json vue-template-es2015-compiler@1.6.0 No repository field. EXEC : npm ERR! error : Method Not Allowed [D:\\home\\site\\repository\\projectx.csproj]   npm ERR!     at errorResponse (D:\\Program Files (x86)\\npm\\1.4.28\\node_modules\\npm\\lib\\cache\\add-named.js:260:10)   npm ERR!     at D:\\Program Files (x86)\\npm\\1.4.28\\node_modules\\npm\\lib\\cache\\add-named.js:203:12   npm ERR!     at saved (D:\\Program Files (x86)\\npm\\1.4.28\\node_modules\\npm\\node_modules\\npm-registry-client\\lib\\get.js:167:7)   npm ERR!     at Object.oncomplete (fs.js:108:15)   npm ERR! If you need help  you may report this *entire* log    npm ERR! including the npm and node versions  at:   npm ERR!     &lt;http://github.com/npm/npm/issues&gt;    npm ERR! System Windows_NT 6.2.9200   npm ERR! command \""node\"" \""D:\\\\Program Files (x86)\\\\npm\\\\1.4.28\\\\node_modules\\\\npm\\\\bin\\\\npm-cli.js\"" \""install\"" \""--ignore-scripts\""   npm ERR! cwd D:\\home\\site\\repository   npm ERR! node -v v0.10.40   npm ERR! npm -v 1.4.28   npm ERR! code E405 D:\\home\\site\\repository\\projectx.csproj(25 5): error MSB3073: The command \""npm install --ignore-scripts\"" exited with code 1. Failed exitCode=1  command=dotnet publish \""D:\\home\\site\\repository\\projectx.csproj\"" --output \""D:\\local\\Temp\\8d65c86f4c7808a\"" --configuration Release An error has occurred during web site deployment. \\r\\nD:\\Program Files (x86)\\SiteExtensions\\Kudu\\79.11121.3655\\bin\\Scripts\\starter.cmd \""D:\\home\\site\\deployments\\tools\\deploy.cmd\"" </code></pre>  <p>Anybody who has a idea? The project runs fine on my computer. </p>""",azure-web-app-service
54623520,"How to get Devops OwnerID <p>In this article <a href=\https://docs.microsoft.com/en-us/rest/api/azure/devops/account/accounts/list?view=azure-devops-rest-5.0\"" rel=\""nofollow noreferrer\"">https://docs.microsoft.com/en-us/rest/api/azure/devops/account/accounts/list?view=azure-devops-rest-5.0</a> of microsft  Im wondering where can i get this ownerId? <a href=\""https://i.stack.imgur.com/RtUtk.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/RtUtk.png\"" alt=\""enter image description here\""></a></p>  <p>Thanks!</p>""",azure-devops
51304256,"Azure Functions Newtonsoft.Json load error <p>This is driving me crazy. I am getting a load error with Azure functions with Newtonsoft.Json. </p>  <p>This is a .netstandard2.0 project and I have version 11.0.2 installed. I have looked on the web and most others that have had this are using an old version of the  Microsoft.NET.Sdk.Functions : 1.0.13 But I am using 1.0.14</p>  <p>See my project file below :</p>  <pre><code>&lt;Project Sdk=\Microsoft.NET.Sdk\""&gt;   &lt;PropertyGroup&gt;     &lt;TargetFramework&gt;netstandard2.0&lt;/TargetFramework&gt;     &lt;AzureFunctionsVersion&gt;v2&lt;/AzureFunctionsVersion&gt;     &lt;RootNamespace&gt;modoapi&lt;/RootNamespace&gt;   &lt;/PropertyGroup&gt;   &lt;ItemGroup&gt;     &lt;PackageReference Include=\""Autofac\"" Version=\""4.2.1\"" /&gt;     &lt;PackageReference Include=\""Microsoft.Azure.WebJobs\"" Version=\""3.0.0-beta5\"" /&gt;     &lt;PackageReference Include=\""Microsoft.Azure.WebJobs.ServiceBus\"" Version=\""3.0.0-beta5\"" /&gt;     &lt;PackageReference Include=\""Microsoft.NET.Sdk.Functions\"" Version=\""1.0.14\"" /&gt;     &lt;PackageReference Include=\""Newtonsoft.Json\"" Version=\""11.0.2\"" /&gt;   &lt;/ItemGroup&gt;   &lt;ItemGroup&gt;     &lt;None Update=\""host.json\""&gt;       &lt;CopyToOutputDirectory&gt;PreserveNewest&lt;/CopyToOutputDirectory&gt;     &lt;/None&gt;     &lt;None Update=\""local.settings.json\""&gt;       &lt;CopyToOutputDirectory&gt;PreserveNewest&lt;/CopyToOutputDirectory&gt;       &lt;CopyToPublishDirectory&gt;Never&lt;/CopyToPublishDirectory&gt;     &lt;/None&gt;   &lt;/ItemGroup&gt; &lt;/Project&gt; </code></pre>  <p>I have looked at all the dependencies for my project and they all point to Newtonsoft.Json 11.0.2. </p>  <p>The file exists in my output bin folder. I have cleaned the solution. Updated to latest VS and Azure Functions and WebJobs Tools 15.0.40608.0</p>  <p>The Function App starts ok but when I add a message to the queue to invoke a trigger I get the following error in the console.</p>  <blockquote>   <p>[12/07/2018 10:56:36] Executed 'ExecuteWorkItem' (Failed    Id=6d87f5e9-c331-4934-a3f3-b9bebf756b54) [12/07/2018 10:56:36]   System.Private.CoreLib: Exception while executing function:   ExecuteWorkItem. test-api: Could not load file or assembly   'Newtonsoft.Json  Version=11.0.0.0  Culture=neutral    PublicKeyToken=30ad4fe6b2a6aeed'. Could not find or load a specific   file. (Exception from HRESULT: 0x80131621). System.Private.CoreLib:   Could not load file or assembly 'Newtonsoft.Json  Version=11.0.0.0    Culture=neutral  PublicKeyToken=30ad4fe6b2a6aeed'.</p> </blockquote>  <p>Here is the signature for my function</p>  <pre><code>public static class ExecuteWorkItem {     [FunctionName(\""ExecuteWorkItem\"")]     public static async Task Run(         [QueueTrigger(\""work-item\"")]string queueItem          TraceWriter log          ExecutionContext executionContext          [Inject(typeof(IWorkItemEngine))]IWorkItemEngine workItemEngine          [Table(\""ResultData\""  Connection = \""AzureWebJobsStorage\"")] CloudTable resultTable          [Table(\""SimulationNodeData\""  Connection = \""AzureWebJobsStorage\"")] CloudTable simulationNodeTable)     {} </code></pre>  <p>Any ideas would be really appreciated right now  the only other person that seems to be having a similar problem is this guy here:  <a href=\""https://github.com/Azure/Azure-Functions/issues/874\"" rel=\""noreferrer\"">Go to the bottom of his post</a></p>  <p>He had no reply to his query and he is on a Mac environment whereas I am on windows 10.</p>  <p>Any help would be really appreciated.</p>  <p>Thanks in advance</p>""",azure-functions
51717292,step by step process : create a firewall in a virtual machine <p>Please help me to create a firewall in a virtual machine. I know how to create a firewall of a virtual network. And select firewall from Networking option.</p>,azure-virtual-machine
50492793,Authentication with ASP.NET Azure WebApp and Managed Service Identity <p>I have an Azure Web App that authenticates users using an Azure AD application. </p>  <pre><code>       app.UseOpenIdConnectAuthentication(             new OpenIdConnectAuthenticationOptions             {                 ClientId = ClientId                  Authority = Authority                  PostLogoutRedirectUri = PostLogoutRedirectUri                   Notifications = new OpenIdConnectAuthenticationNotifications()                 {                     // If there is a code in the OpenID Connect response  redeem it for an access token and refresh token  and store those away.                     AuthorizationCodeReceived = (context) =&gt;                     {                         var code = context.Code;                         var credential = new ClientCredential(ClientId  AppKey);                         var signedInUserId = context.AuthenticationTicket.Identity.FindFirst(ClaimTypes.NameIdentifier).Value;                         var token = authenticationService.GetADALTokenCache(signedInUserId);                         var authContext = new AuthenticationContext(Authority  token);                          return authContext.AcquireTokenByAuthorizationCodeAsync(                             code  new Uri(HttpContext.Current.Request.Url.GetLeftPart(UriPartial.Path))  credential  GraphResourceId);                     }                 } </code></pre>  <p>This works 100% fine with the config I pass in. I have now added a Managed Service Identity so that I can grant access to other resources (e.g. Key Vault) to the web app. Sweet.</p>  <p>This makes the app identity I use for the OpenIdConnectAuthentication feel redundant. Am I able to just use the Managed Service Identity to do the authentication instead of having two accounts - one for the MSI and one for the user authentication? </p>  <p>When using the MSI  I don't want to have to supply a ClientID and AppKey from config  I just want it to flow all the way through  using my account for local dev (and running on localhost) and the MSI assigned to the web app when deployed. </p>  <p>I am using the full .Net Framework (i.e. Not Core)</p>,azure-web-app-service
23893358,"Using SignalR with Azure Table Storage - What architecture? <p>I have a smart grid system where multiple hardware devices are sending raw sensor data to an Azure Queue. Each device sends a single data packet once every minute. Multiple Worker Roles process the data packets on the queue and push the data to Table Storage.  I have a Web Role which holds the application for users to view their device data and a host of other alerts and messages relating to their smart energy system.  At the moment the web application just uses ajax polling at one minute intervals to get the latest data updates and any other messages and alerts.  Instead of using ajax 'pulling'  I'd like to use SignalR instead and 'push' the updates from the cloud when they become available.  I'm not sure on what the overall architecture might look like.</p>  <p>So far I have added a SignalR Hub to my Web Role  just to see if I could do that.  And it works fine.  However  how do I trigger updates from this Hub when there are changes in Table Storage?  Should I host the Hub with the Worker Roles that process the raw data  and then make a cross-domain SignalR connection from the web app (client)?  Can I even associate an endpoint with a Worker Role?  If I have many Worker Roles wouldn't I only be able to connect to one of them  and therefore miss data updates from other Worker Roles?  </p>  <p>Perhaps I should create a separate Web Role to host the SignalR hub  but then how do I communicate the changes from the Worker Roles that process the raw data to the hub?  Maybe I need to include another Azure Queue that takes messages from the Worker Roles regarding data updates  alerts  and any other messaging  and that queue is processed by the SignalR server.  However  would this approach be scalable?  If I have multiple instances of the SignalR server processing the message queue(s)  would they share the same end point and be aware of all the client connections across the instances?  Or maybe the Worker Roles themselves connect as clients to the SignalR server and the messages forwarded from there to the clients.</p>  <p>Is SignalR even the right approach to take if data is being generated at a predictable rate of once every minute for each device.  Maybe for updates of this regular data ajax 'pulling' is the best approach  and I should just be using SignalR for the infrequent alerts and messages  although  again  how do I communicate these events from the Worker Roles to the SignalR server?</p>  <p>What overall architecture would suit my needs here?</p>  <p>EDIT 06-09-2014  Half the problem solved</p>  <p>I came across <a href=\http://www.asp.net/signalr/overview/signalr-20/performance-and-scaling/scaleout-with-windows-azure-service-bus\"" rel=\""nofollow\"">http://www.asp.net/signalr/overview/signalr-20/performance-and-scaling/scaleout-with-windows-azure-service-bus</a> which seems to be exactly what I am after.  This deals with the problem of multiple Hub server (Web Role) instances.  Now I just need a SignalR client library that can run on the Worker Roles so that they can notify the Hub that new data is available  and the Hub class can then be enhanced to route the new data to the appropriate connected web clients.</p>  <p>EDIT 06-10-2014   A workable solution found</p>  <p>I have added an answer to my question of \""What architecture\"".  I thought a quick summary of my setup might be useful.  I have many remote devices associated with different users posting real-time data to Azure Queues.  The data posted to these queues are parsed and saved to Table Storage  by a number of Worker Roles.  Web Roles provide the MVC5 web application for the users (clients) to log on and review their data.  I wanted a mechanism by which when new data was posted  any connected clients would receive a real-time notification (and data tables and charts in the client apps could be updated accordingly).  SignalR with Service Bus scaleout proved to be the answer.</p>""",azure-storage
54629500,"What are the permission needed in VSTS to create Agent pool? <p>I am trying to setup Build and Release process in on-premises VSTS. I am getting permission error in Agent Pool Creation steps. I was already assigned Administartor role by our TFS Admin Team still I am getting below error. </p>  <p><a href=\https://i.stack.imgur.com/4zWF2.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/4zWF2.png\"" alt=\""Agent Pool Creation Error\""></a></p>""",azure-devops
57171773,"What's calling Admin Functions? <p>I have an app service running in Azure  and has been running very smoothly.  Recently  in the last week or so  I have been seeing dependency failures (404) in Application Insights showing a GET for \admin/functions\"" route.</p>  <p>The host URL is my app service  with that route along with api-version appended to the end as a query string.</p>  <p>what would be causing this?</p>  <p>the routes are:</p>  <p>{AppServiceHostUrl}/admin/functions?api-version=2018-11-01 {AppServiceHostUrl}/admin/host/synctriggers?api-version=2018-11-01</p>""",azure-web-app-service
45827810,"VSTS - configuring PHP settings for Azure WebApp during a deployment <p>I'm working for an Azure project where the deployments can only be made using the ARM templates from Visual Studio CI and we have only read access to the Azure Portal.</p>  <p>Also I'm not use if I'm able to use Kudu as I can't access from Portal.</p>  <p>What I'm trying to do is overriding some PHP settings and enable some extra extensions for an Azure Web App. Using Kudu this is pretty easy but I can't figure out how I can upload two excluded file types <code>.dll</code>and <code>.ini</code> files during a release before web app deployment. </p>  <p>So far I tried below steps which made sense to me but apparently It's not working and a wrong approach. I would be glad if someone could guide me with the right steps.</p>  <p>I have set <code>PHP_INI_SCAN_DIR=d:\\home\\site\\ini</code> as described in <a href=\https://docs.microsoft.com/en-us/azure/app-service-web/web-sites-php-configure\"" rel=\""nofollow noreferrer\"">https://docs.microsoft.com/en-us/azure/app-service-web/web-sites-php-configure</a></p>  <p>I'm uploading the files with the below tasks and can see them uploaded in logs. I also tried to use paths with defined variables such as <code>$(Agent.ReleaseDirectory)</code> instead of absolute paths but it didn't change anything.</p>  <p><a href=\""https://i.stack.imgur.com/IscJZ.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/IscJZ.png\"" alt=\""Release tasks\""></a></p>  <p><a href=\""https://i.stack.imgur.com/mZukS.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/mZukS.png\"" alt=\""enter image description here\""></a></p>  <p>It seems PHP is looking <code>d:\\home\\site\\ini</code> folder but can't find any ini file. Also the other options I have set  did not changed.</p>  <p><a href=\""https://i.stack.imgur.com/SquH3.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/SquH3.png\"" alt=\""enter image description here\""></a></p>  <p>The content of the ini file;</p>  <pre><code>; extensions.ini ; Enable Extensions extension=d:\\home\\site\\ext\\php_redis.dll ; Settings memory_limit = 256M upload_max_filesize = 10M </code></pre>  <h3>UPDATE</h3>  <p>Also the App Service deploy task </p>  <p><a href=\""https://i.stack.imgur.com/yVnTH.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/yVnTH.png\"" alt=\""enter image description here\""></a></p>  <p>And Virtual applications and directories from Application Settings</p>  <p><a href=\""https://i.stack.imgur.com/PSxgx.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/PSxgx.png\"" alt=\""enter image description here\""></a></p>""",azure-devops
56937021,"Azure App Service: \There is not enough space on the disk.\"" Although 300MB/50GB <p>We have an app service running in a service plan which has a storage limit of 50GB.</p>  <p>The app service is the only one part of the service plan.</p>  <p>We have a .NET web service running on <code>D:\\home\\site\\services&gt;</code> with an folder where we periodically create <code>.docx</code> and <code>.pdf</code> files.</p>  <p>A couple of months ago  we only received <code>There is not enough space on the disk</code> after storing multiple gigabytes in that upload folder. But after time  that exception was thrown sooner and sooner - which we fixed by emptying the upload folder.</p>  <p>By now  we get this exception when there is even less than 100 of files in the upload folder. Although the total storage of the app service is only at 400MB/50GB...</p>  <p>Here's the top part of the stacktrace:</p>  <pre><code>System.IO.IOException: There is not enough space on the disk.     at System.IO.__Error.WinIOError(Int32 errorCode  String maybeFullPath)    at System.IO.FileStream.WriteCore(Byte[] buffer  Int32 offset  Int32 count)    at System.IO.FileStream.Write(Byte[] array  Int32 offset  Int32 count)    at Xceed.Words.NET.DocX.Save()    at Xceed.Words.NET.DocX.SaveAs(String filename) </code></pre>  <p>Does anyone know what we're doing wrong?</p>  <p><strong>EDIT:</strong> both the app service  and the app service plan has a quota of 50GB. I don't see any storage limits hit at all.</p>""",azure-web-app-service
16601379,"How many tables can you put in one windows azure storage account? <p>The documentation I see says that there can be \Many\"" tables in one storage account.</p>  <p>Does anyone actually know the limit?</p>""",azure-storage
10233969,"Service Error when accessing windows azure DB from windows phone <p>receiving the error:</p>  <p>The EntitySet 'User' is not defined in the EntityContainer 'festDBEntities'. Near simple identifier  line 1  column 46.</p>  <p>my app code:</p>  <pre><code>using System; using System.Collections.Generic; using System.Linq; using System.Net; using System.Windows; using System.Windows.Controls; using System.Windows.Documents; using System.Windows.Input; using System.Windows.Media; using System.Windows.Media.Animation; using System.Windows.Shapes; using Microsoft.Phone.Controls; using FestCloud.festDBService;  namespace FestCloud {     public partial class MainPage : PhoneApplicationPage     {         private Service1Client _serviceClient;          // Constructor         public MainPage()         {             InitializeComponent();             _serviceClient = new Service1Client();             _serviceClient.LoginUserCompleted += new EventHandler&lt;LoginUserCompletedEventArgs&gt;(_serviceClient_LoginUserCompleted);         }          void _serviceClient_LoginUserCompleted(object sender  LoginUserCompletedEventArgs e)         {             if ((e.Error == null) &amp;&amp; (e.Result != null))             {                 MessageBox.Show(\Welcome \"" + e.Result + \"" !\"");             }             else             {                 MessageBox.Show(\""Could not log in. Please check user name/password and try again.\"");             }         }          private void logInButton_Click(object sender  RoutedEventArgs e)         {             _serviceClient.LoginUserAsync(userNameTextBox.Text  passwordTextBox.Text);         }          private void newAccountButton_Click(object sender  RoutedEventArgs e)         {             NavigationService.Navigate(new Uri(\""/Register.xaml\""  UriKind.Relative));         }     } } </code></pre>  <p>and my service code:</p>  <pre><code>using System; using System.Collections.Generic; using System.Linq; using System.Runtime.Serialization; using System.ServiceModel; using System.ServiceModel.Web; using System.Text; using System.Data.Objects;  namespace CloudServiceRole {     // NOTE: You can use the \""Rename\"" command on the \""Refactor\"" menu to change the class name \""Service1\"" in code  svc and config file together.     public class Service1 : IService1     {         public void AddUser(string userName  string password)         {             using (var context = new festDBEntities())             {                 context.AddToUsers(new User()                 {                     UserName = userName                      Password = password                   });                 context.SaveChanges();             }         }          public string LoginUser(string username  string password)         {             string query = @\""SELECT value User.UserName FROM festDBEntities.User AS User WHERE User.UserName = @username AND User.Password = @password\"";              ObjectParameter[] parameters = new ObjectParameter[2];              parameters[0] = new ObjectParameter(\""username\""  username);             parameters[1] = new ObjectParameter(\""password\""  password);              using (var context = new festDBEntities())             {                 ObjectQuery&lt;string&gt; results = context.CreateQuery&lt;string&gt;(query  parameters);                  foreach (string result in results)                 {                     if (result != null)                     {                         return result;                     }                 }             }             return null; ;         }     } } </code></pre>  <p>my IService.cs file:</p>  <pre><code>using System; using System.Collections.Generic; using System.Linq; using System.Runtime.Serialization; using System.ServiceModel; using System.ServiceModel.Web; using System.Text;  namespace CloudServiceRole {     // NOTE: You can use the \""Rename\"" command on the \""Refactor\"" menu to change the interface name \""IService1\"" in both code and config file together.     [ServiceContract]     public interface IService1     {         [OperationContract]         void AddUser(string userName  string password);          [OperationContract]         string LoginUser(string userName  string password);         // TODO: Add your service operations here     }  } </code></pre>  <p>My DB contains UserId(int)-PK  UserName(nvarchar)  Password(nvarchar) with others to be added after I get basics working. any ideas on whats causing the error or my code in general? Many thanks MH</p>""",azure-storage
56131607,"How to get a Java app in Azure App Services to connect to an Azure PostgreSQL database using SSL? <p>How do I connect an Azure Java WebApp to an Azure PostgreSQL database using SSL? It seems that the Azure PostgreSQL database needs a specific root certificate.</p>  <p>I have a Java application running as a .war deployed within an Azure \App Services\"" web application. This is running in a Tomcat 8.5 container  in Java 8.</p>  <p>This is connecting to a PostgreSQL 10 database running within Azure as an 'Azure Database for PostgreSQL'. The database is currently configured so that it only accepts SSL connections.</p>  <p>I can connect to the database correctly using SSL from my local development machine.</p>  <p>I can run the Java web application locally  and it happily connects to the PostgreSQL database using SSL (JDBC driver string includes <strong>'?ssl=true'</strong>).</p>  <p>However  when I run the same application within the Azure Web App using SSL  it fails to connect (I <em>can</em> connect with SSL disabled): <em>\""Could not open SSL root certificate file D:\\local\\AppData\\postgresql\\root.crt\""</em></p>  <pre><code>2019-05-13 15:16:58 ERROR HikariPool:574 - HikariPool-1 - Exception during pool initialization. org.postgresql.util.PSQLException: Could not open SSL root certificate file D:\\local\\AppData\\postgresql\\root.crt.     at org.postgresql.ssl.LibPQFactory.&lt;init&gt;(LibPQFactory.java:120) ~[postgresql-42.2.5.jar:42.2.5]     ... </code></pre>  <p>It seems that the JRE which Microsoft is making available within the Azure App Services (Azul  I think) does not have this root certificate installed (and therefore the postgres driver looks for <strong>root.crt</strong>)  whereas my local JDK (AdoptOpenJDK jdk-8.0.212.03-hotspot) does have this installed</p>  <p>The Microsoft documentation states that you may need to install their <strong>BaltimoreCyberTrustRoot.crt</strong> as a root.crt certificate on the <em>client</em> end of the connection. <a href=\""https://docs.microsoft.com/en-us/azure/postgresql/concepts-ssl-connection-security\"" rel=\""nofollow noreferrer\"">https://docs.microsoft.com/en-us/azure/postgresql/concepts-ssl-connection-security</a></p>  <p>Can anyone suggest the best way to get the App Service to allow access to this root certificate  given that I cannot install extra root certificates into the App Service  and I do not have access to simply upload files into D:\\local\\AppData\\postgresql. Microsoft provide a mechanism to allow certificates to be made available to Web Apps  but these don't get placed into a location where the JDBC driver will pick them up. <a href=\""https://docs.microsoft.com/en-us/azure/app-service/app-service-web-ssl-cert-load\"" rel=\""nofollow noreferrer\"">https://docs.microsoft.com/en-us/azure/app-service/app-service-web-ssl-cert-load</a></p>  <p>Points to note: This SSL validation was enhanced on the most recent version of the PostgreSQL JDBC driver: Version 42.2.5 now has an extra feature: <em>\""ssl=true implies sslmode=verify-full  that is it requires valid server certificate\""</em> <a href=\""https://jdbc.postgresql.org/\"" rel=\""nofollow noreferrer\"">https://jdbc.postgresql.org/</a></p>  <p>I can work-around the SSL validation problem in two ways  but neither is satisfactory:</p>  <p>a) I can explicitly downgrade to an older version of the PostgreSQL JDBC driver. This still uses SSL but is vulnerable to MITM attacks.</p>  <p>b) I can explicitly turn off the requirement to use SSL and/or turn off certificate validation.</p>  <p>I don't want to do either of these. Does anyone have any better suggestions?</p>  <p>Note that these are a couple of related Stackoverflow threads  but these don't really address this Java use-case:</p>  <p><a href=\""https://stackoverflow.com/questions/41776109/installing-certificates-to-the-trusted-root-certificate-store-on-azure-web-apps\"">Installing certificates to the trusted root certificate store on azure web apps</a></p>  <p><a href=\""https://stackoverflow.com/questions/33884634/how-can-i-trust-an-active-directory-root-ca-certificate-in-an-azure-web-applicat\"">How can I trust an Active Directory Root CA Certificate in an Azure Web Application?</a></p>""",azure-web-app-service
56891704,"Microsoft Reports LocalReport in Azure Function: ReportProcessingException <p>I created a basic <a href=\https://docs.microsoft.com/en-us/azure/azure-functions/\"" rel=\""nofollow noreferrer\"">Azure Function</a> (.NET)  I have a basic Project which generates a <a href=\""https://docs.microsoft.com/en-us/previous-versions/visualstudio/visual-studio-2010/ms255056(v%3Dvs.100)\"" rel=\""nofollow noreferrer\"">LocalReport</a> (WinForms based). This works within a ASP.NET MVC Application and within Unit Tests  but not in Azure Function.</p>  <p>Not quite exactly as this  but you get the Idea:</p>  <pre><code>[FunctionName(\""Report\"")] public static async Task&lt;HttpResponseMessage&gt; Report([HttpTrigger(AuthorizationLevel.Function  \""POST\""  Route = \""Report\"")]HttpRequestMessage req  ILogger log) {     Microsoft.Reporting.WinForms.LocalReport lr = new Microsoft.Reporting.WinForms.LocalReport();     lr.ReportPath = \""Sales.rdlc\"";     lr.DataSources.Add(new ReportDataSource(\""Sales\""  GetSalesData()));      // this line fails:     var bytes = lr.Render(\""PDF\""  null  out mimeType  out encoding  out streamids  out warnings);      response.Content = new ByteArrayContent(bytes);     response.Content.Headers.ContentType = new MediaTypeHeaderValue(\""application/pdf\"");      return await Task.FromResult(response); } </code></pre>  <p>When <code>lr.Render(\""PDF\""  ...)</code> is executed  the following error is raised:</p>  <pre><code>Microsoft.Reporting.WinForms.LocalProcessingException   HResult=0x80131500   Message=An error occurred during local report processing.   Source=Microsoft.ReportViewer.WinForms   StackTrace:    at Microsoft.Reporting.WinForms.LocalReport.InternalRender(String format  Boolean allowInternalRenderers  String deviceInfo  PageCountMode pageCountMode  CreateAndRegisterStream createStreamCallback  Warning[]&amp; warnings)    at Microsoft.Reporting.WinForms.LocalReport.InternalRender(String format  Boolean allowInternalRenderers  String deviceInfo  PageCountMode pageCountMode  String&amp; mimeType  String&amp; encoding  String&amp; fileNameExtension  String[]&amp; streams  Warning[]&amp; warnings)    at Microsoft.Reporting.WinForms.LocalReport.Render(String format  String deviceInfo  PageCountMode pageCountMode  String&amp; mimeType  String&amp; encoding  String&amp; fileNameExtension  String[]&amp; streams  Warning[]&amp; warnings)    at Microsoft.Reporting.WinForms.Report.Render(String format  String deviceInfo  String&amp; mimeType  String&amp; encoding  String&amp; fileNameExtension  String[]&amp; streams  Warning[]&amp; warnings)  Inner Exception 1: ReportProcessingException: Failed to load expression host assembly. Details: Could not load file or assembly 'Microsoft.ReportViewer.Common  Version=15.0.0.0  Culture=neutral  PublicKeyToken=89845dcd8080cc91' or one of its dependencies. </code></pre>  <p>I don't really see what the missing assembly could be  but I have loads of related assemblies right in my <code>bin</code> folder  including:</p>  <ul> <li>Microsoft.ReportViewer.Common.dll</li> <li>Microsoft.ReportViewer.Common.resources.dll</li> <li>Microsoft.ReportViewer.DataVisualization.dll</li> <li>Microsoft.ReportViewer.DataVisualization.resources.dll</li> <li>Microsoft.ReportViewer.Design.dll</li> <li>Microsoft.ReportViewer.Design.resources.dll</li> <li>Microsoft.ReportViewer.ProcessingObjectModel.dll</li> <li>Microsoft.ReportViewer.WinForms.dll </li> <li>Microsoft.ReportViewer.WinForms.resources.dll</li> <li>Microsoft.SqlServer.Types.dll</li> <li>Any many more...</li> </ul>  <p>Could this be related to the \""sandbox\"" issue? If yes  why is this error message so misleading?</p>  <p>Has anybody got Microsoft local reports running inside Azure Functions?</p>""",azure-functions
24185441,Access Azure Virtual Machine by IP Address <p>I have setup a Virtual Machine on Windows Azure and deployed my application that listens to a port; Can I access my application with IP Address of that Machine ?</p>,azure-virtual-machine
48123331,"Cannot access Azure VM anymore <p>Following on from the latest Azure maintenance  we cannot remote desktop to one of our VMs and fix potential issue on the IIS server of this machine. Everything was working fine for over 1 year.</p>  <p>The Agent status is now set to \Not Ready\"" when looking at the properties of the VM in the Azure portal.</p>  <p>We obviously tried to restart the machine but no effect. We cannot redeploy the machine to another node as the VM agent seems to be down.</p>  <p>The outbound NSG rules do not block outbound connection to internet (so that the machine should be able to write to its azure storage).</p>  <p>This user seems to have a similar issue on a VM scale set: <a href=\""https://stackoverflow.com/questions/48093121/azure-vm-scale-sets-not-accessible-and-cannot-restart\"">Azure VM scale sets not accessible and cannot restart</a> </p>  <p>Any idea on how to resolve this issue ?</p>""",azure-virtual-machine
54562154,"Azure Function App Publish Target Missing in Visual Studio <p>I'm trying to publish an Azure Function to already deployed Azure Function App  which is in my subscription.</p>  <p>But Publish target for the Function app is missing.</p>  <p>This is a newly created Function and all other existing function has the publish target visible.</p>  <p>Do I need to configure something on the subscription side or the function .csproj to enable publish target?</p>  <p>One that has azure resource as publish target is running on 1.x runtime.</p>  <p>One that does not have azure resource as publish target is running on 2.x runtime</p>  <p><a href=\https://i.stack.imgur.com/08ZJr.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/08ZJr.png\"" alt=\""Ones that does not show azure function as target\""></a></p>  <p><a href=\""https://i.stack.imgur.com/8OVaT.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/8OVaT.png\"" alt=\""One that shows azure function as target\""></a></p>""",azure-functions
44245175,"Azure Function VS2017 preview tooling - how to bind to CloudBlockBlob? <p>NOTE: I've already solved this  but I'm posting it here anyway so other people can hopefully find the answer more quickly than I did :-)</p>  <p>I have an Azure Functions \class library\"" project that I created in VS2015  and I'm now trying to migrate that project to the new \""Azure Functions\"" project type in VS2017 15.3 Preview (with Visual Studio 2017 Tools for Azure Functions).</p>  <p>In VS2015  the C# function signature looks like this:</p>  <pre><code>public static HttpResponseMessage Run(HttpRequestMessage req  CloudBlockBlob myFile) </code></pre>  <p>and my function.json looks like this:</p>  <pre class=\""lang-json prettyprint-override\""><code>{   \""bindings\"": [     {       \""type\"": \""httpTrigger\""        \""direction\"": \""in\""        \""name\"": \""req\""        \""methods\"": [         \""get\""       ]        \""authLevel\"": \""anonymous\""        \""route\"": \""files/{id}/download\""     }      {       \""type\"": \""http\""        \""direction\"": \""out\""        \""name\"": \""res\""     }      {       \""name\"": \""myFile\""        \""type\"": \""blob\""        \""direction\"": \""inout\""        \""path\"": \""mycontainer/{id}\""        \""connection\"": \""[my connection string]\""     }   ]    \""disabled\"": false } </code></pre>  <p>In VS2017  I have to use binding attributes instead of function.json  so I tried this:</p>  <pre><code>public static HttpResponseMessage Run(     [HttpTrigger(AuthorizationLevel.Anonymous  \""get\""  Route = \""files/{id}/download\"")] HttpRequestMessage req      [Blob(\""mycontainer/{id}\""  FileAccess.Read)] CloudBlockBlob myFile) </code></pre>  <p>However  when I try to run this I get this error message:</p>  <pre class=\""lang-none prettyprint-override\""><code>[Function Name]: Microsoft.Azure.WebJobs.Host: Error indexing method '[Function Name]'. Microsoft.Azure.WebJobs.Host: Cannot bind blob to CloudBlockBlob using access Read. </code></pre>""",azure-functions
54236862,"Cannot GET index.html Azure Linux Web App <p>We created a Linux Web App in Microsoft Azure. The application is static written with React (html and Javascript). We copied the code into the wwwroot folder  but the application only showing only hostingstart.html and when we try to get page index.html we have this error: <code>Cannot GET /index.html</code></p>  <p>We tried with a sample of Azure in GitHub (<a href=\https://github.com/Azure-Samples/html-docs-hello-world\"" rel=\""nofollow noreferrer\"">https://github.com/Azure-Samples/html-docs-hello-world</a>) but the error is the same. The url is this: <a href=\""https://consoleadmin.azurewebsites.net/index.html\"" rel=\""nofollow noreferrer\"">https://consoleadmin.azurewebsites.net/index.html</a></p>  <p>Last week the application was running correctly.</p>  <p>We forget to do something?</p>""",azure-web-app-service
14821004,Error Creating Power View sheets from SSAS Tabular <p>I am getting a strange error when creating Excel 2013 Power View sheets off an Analysis Services (SSAS) <strong>Tabular</strong> instance running on an Azure VM in the cloud. Here is the error:</p>  <blockquote>   <p>Sorry  something went wrong while loading the model for the item or data source 'xxxxxx.cloudapp.net Tabular Model'. Verify that the connection information is correct and that you have permissions to access the data source.</p> </blockquote>  <p>The weird thing is that I can successfully create normal connected PivotTables from it; I only get the error when I try to make Power View sheets. Which would lead me to believe I am connecting to a multidimensional SSAS database  but I am not. Here are some things I have tried already:</p>  <ul> <li>Forwarded the default SSAS port 2383 in Azure and opened it in windows firewall (this allowed me to browse the cube with connected PivotTables)</li> <li>Ensured my login has permissions on the SSAS database (I am <strong>not</strong> using windows authentication)</li> <li>Checked the SSAS Tabular compatability version  it is 1103</li> <li>Checked the SSAS Tabular SSDT project compatability level  it is also 1103</li> <li>Made sure SQL Server Browser was running (I read somewhere that might be an issue)</li> <li>Tried opening port 80 and 443 in case those were needed for something  didn't help...</li> <li>Tried monitoring Excel's port usage to see if it was trying other ports  couldn't see anything besides 2383</li> <li>Sucessfully connected to an intranet SSAS Tabular database (comparability 1101)  and created a Power View sheet from it (which means there shouldn't be anything wrong with my Excel client)</li> </ul>  <p>Here are some details of my setup:</p>  <h3>Server</h3>  <ul> <li>Windows Server 2012</li> <li>SQL Server 2012 SP1</li> <li>SSAS Tabular default instance (compatability level 1103)</li> </ul>  <h3>Client</h3>  <ul> <li>Windows 8</li> <li>Excel 2013 (15.0.4426.1017) MSO (15.0.4454.1002) 32-bit</li> </ul>  <p><strong>Update (2/12/2013):</strong> I installed Excel 2013 on the server and can successfully create Power View sheets connected to the Tabular database. This implies that my tabular SSAS instance is setup just fine  but the problem still exists when trying to create sheets through the internet.</p>  <p><strong>Update (2/15/2013):</strong> I updated my Excel to 15.0.4454.1503 with Windows Update to no avail. I had a coworker successfully connect with a slightly older version of Excel 2013. I am totally stumped. I also attempted installing a fresh copy of Excel on a VM that I updated to v 15.0.4454.1503 and it was giving me the same error.</p>  <p><strong>Update (2/20/2013):</strong> I installed a fresh <em>local</em> VM with Windows Server 2012  SQL Server 2012  and SSAS Tabular compat 1103. I STILL cannot successfully make Power View reports from that server. I <strong>strongly</strong> believe there is some kind of bug with the Excel 2013 client.</p>,azure-virtual-machine
50775200,Azuure app service and GoDaddy domain <p>I am newbie in web hosting. I have a domain name on GoDaddy <code>www.mydomain.com</code>. My web app is hosted on Azure App Service <code>myapp.azurewebsites.net</code>.</p>  <p>Now  I have configured my GoDaddy domain to point to azure web app. Azure app service is configured to accept request from <code>www.mydomain.com</code>  so anyone accessing my domain <code>www.mydomain.com</code> can see the app hosted on azure. This thing is working fine.</p>  <p>For example  I enter a URL <code>www.mydomain.com</code>  I get the expected result - web app hosted on azure with the <code>www.mydomain.com</code> URL in browser. The issue is  if I enter only subdomain name i.e. <code>mydomain.com - without WWW prefix</code>  I get the web app running on azure  but the URL gets replaced by azure app service URL <code>myapp.azurewebsites.net</code>.</p>  <p>What could be wrong here? My domain is configured for <code>CNAME</code>  and Azure App is also configured to accept custom domain with <code>CNAME</code>. Should I use <code>A Record</code> settings so that if I enter <code>mydomain.com</code> it gets replaced by <code>www.mydomain.com</code> instead of <code>myapp.azurewebsites.net</code>?</p>  <p>Thanks in advance!</p>,azure-web-app-service
11507662,Querying azure table for multiple entities <p>I'm writing azure application. My questions concerns querying azure table for specific entities.</p>  <p>Application stores statistics of words used by users. In table partitionkey is the language and row key is the word.</p>  <p>I need to query for multiple words. To speed up the process I want to pull in one query all relevant entities.</p>  <p>I know how to 'batch insert' group of entities that have the same partitionkey. How to query for like 50 diffrent entities with the same partitionkey but different rowkey.</p>  <p>Is there possibility of specifying query as string ?</p>  <p>Regards</p>,azure-storage
47301391,"Set-AzureRmVMDiskEncryptionExtension : Long running operation <p>While trying to encrypt a VM  I am getting the below error:</p>  <blockquote>   <p>Set-AzureRmVMDiskEncryptionExtension : Long running operation failed   with status 'Failed'. ErrorCode: VMExtensionProvisioningError   ErrorMessage: VM has reported a failure when processing extension   'AzureDiskEncryptionForLinux'. Error message: \Enable failed.\"".   StartTime: 11/15/2017 11:12:30 AM EndTime: 11/15/2017 11:14:38 AM   OperationID: 004051ca-bf73-4a37-a145-5e0ac30bc30a Status: Failed At   line:1 char:1   + Set-AzureRmVMDiskEncryptionExtension -ResourceGroupName $resourceGrou ...   + ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~       + CategoryInfo          : CloseError: (:) [Set-AzureRmVMDiskEncryptionExtension]  ComputeCloudException       + FullyQualifiedErrorId : Microsoft.Azure.Commands.Compute.Extension.AzureDiskEncryption.SetAzureDiskEncryptionExtensionCommand</p> </blockquote>  <p>Please help me to resolve this issue.</p>""",azure-virtual-machine
35398727,Azure Cloud Service Endpoint for VM to only allow internal access <p>I have a VM running SQL Server. I have port 1433 open on the Windows firewall and an Endpoint on the corresponding cloud service forwarding port 57501 to 1433. I haven't specified any ACLs on that endpoint. I want the endpoint to only be accessible from a specific subnet in the VNet where the VM exists. </p>  <p>If I set that in the ACL  it doesn't work - the ACL only seems to care about the public IP of the client. Since the public IP may change  this isn't an option. </p>  <p>What's the recommended approach here? Note that I don't want to connect directly to the VM hostname because I want to use the CNAME that the cloud service sets up for me (the actual Windows computer name is a random long string).</p>,azure-virtual-machine
43475749,"Can I use Oauth with MS Dynamics integrate it to my web application <p>We are an ISV and we are building a web application and a managed solution for Dynamics CRM. We want MS Dynamics users to be able to access our web application by using Oauth authentication. Our web application does not need to connect to Dynamics; we only want to restrict the use of this application to Dynamics users.</p>  <p>The problem I am facing is as follows: what CRM Root service do I use as I want to support all Dynamics users from all domains  in our web application.</p>  <p>We have set up our client id etc in Azure. But we want to make user that the user is a user of dynamics CRM and we want to get the CRM domain for the user and make sure that domain is registered with us.</p>  <pre><code>// TODO Substitute your correct CRM root service address  // what CRM Root service do I use as I want to support all  string resource = \https://&lt;which domain to use&gt;.crm.dynamics.com\"";    // TODO Substitute your app registration values that can be obtained after you // register the app in Active Directory on the Microsoft Azure portal. string clientId = \""&lt;we have this&gt;\""; string redirectUrl = \""http://localhost/SdkSample\""; </code></pre>""",azure-web-app-service
11129761,"Unable to get queue length / message count from Azure <p>I have a Use Case where I need to queue a select number of messages when the current queue length drops below a specified value. Since I'm running in Azure  I'm trying to use the <code>RetrieveApproximateMessageCount()</code> method to get the current message count. Everytime I call this I get an exception stating <code>StorageClientException: The specified queue does not exist.</code>. Here is a review of what I've done:</p>  <ol> <li><p>Created the queue in the portal and have successfully queued messages to it.</p></li> <li><p>Created the storage account in the portal and it is in the Created/Online state</p></li> <li><p>Coded the query as follows (<em>using http and https options</em>):</p>  <pre><code>var storageAccount = new CloudStorageAccount(         new StorageCredentialsAccountAndKey(_messagingConfiguration.StorageName.ToLower()          _messagingConfiguration.StorageKey)  false);  var queueClient = storageAccount.CreateCloudQueueClient(); var queue = queueClient.GetQueueReference(queueName.ToLower()); int messageCount;  try {     messageCount = queue.RetrieveApproximateMessageCount(); } catch (Exception) {     //Booom!!!!! in every case }  // ApproximateMessageCount is always null  messageCount = queue.ApproximateMessageCount == null ? 0 : queue.ApproximateMessageCount.Value; </code></pre></li> <li><p>I've confirmed the name is cased correctly with not special characters  numbers  or spaces and the resulting <code>queue</code> Url appears as though its correct formed based on the API documentations (<em>e.g. <a href=\http://myaccount.queue.core.windows.net/myqueue\"" rel=\""noreferrer\"">http://myaccount.queue.core.windows.net/myqueue</a></em>)</p></li> </ol>  <p>Can anyone help shed some light on what I'm doing wrong.</p>  <hr>  <p><strong>EDIT</strong></p>  <p>I've confirmed that using the <code>MessageFactory</code> I can create a <code>QueueClient</code> and then enqueue/dequeue messages successfully. When I use the <code>CloudStorageAccount</code> the queue is never present so the counts and GetMessage routines never work. I am guessing these are not the same thing??? Assuming  I'm correct  what I need is to measure the length of the Service Bus Queue. Is that possible?</p>""",azure-storage
18545850,"Windows Azure project not working <p>I am using Visual Studio 2012 using C#.</p>  <p>I am getting error while opening the project at my PC  this project is working fine on another system.</p>  <p><img src=\https://i.stack.imgur.com/Nl8R7.png\"" alt=\""I am getting this error\""></p>  <p>Very frequently I am also getting this error too.</p>  <p><img src=\""https://i.stack.imgur.com/7AclR.png\"" alt=\""enter image description here\""></p>""",azure-storage
51379414,"how to set message body size limit for azure custom connector or azure function <p>I have a workflow where a series of functions are hosted as custom connectors which can be called from logic apps. The azure function has a max message size limit of 100mb. I am passing a 300kb message body which the azure function handles fine when debugging alone   but when the same thing is hosted as custom connector or azure function   it throws this error. I can't find any documentation where to specify the limits for message body size for a  custom connector. Thanks</p>  <p><a href=\https://i.stack.imgur.com/6MnXb.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/6MnXb.png\"" alt=\""Logic App connector Output\""></a></p>  <p><strong>Kindly help</strong></p>""",azure-functions
52212715,Accessing Azure Virtual Machine via RDP for the first time  stops at a command prompt <p>I've created a virtual machine using all the defaults and when once it's up and running  I try to access it via RDP.   I connect okay  the initial user setup screens pop up and then disappear as you'd expect  but one of the command prompt boxes stays open at the directory </p>  <p><code>c:\users\theusername</code></p>  <p>and nothing else happens.    I can type into the box here  with all the DOS commands  but can get no further.   Typing <code>exit</code> closes the command prompt and then I'm stuck with a black screen that just sits there.</p>  <p>I've tried restarting the VM via the Azure portal  I've trying deleting and creating new VMs with various settings all with the same result.</p>  <p>I'm wondering if there's something wrong with the account  but can't see anything that's obvious and Google's been no help.   Any ideas how to get a VM to start up properly to the desktop?</p>,azure-virtual-machine
41143906,VSO How to build a single solution in a Repository containing multiple <p>We are using <strong>Visual Studio Team Services</strong> as our source repository and for Build and Release. </p>  <p><strong>What I Want to do?</strong> We have a Repository that contains multiple directories in its root  each folder representing an ASP.NET Web Application. I want to use the Build feature to build a single solution in that repository.</p>  <p><strong>The Problem</strong> I can see the Build Agent downloading all source files for all folders/solutions in the Repository rather than just the solution I have selected.</p>  <p>Can someone provide the steps I need to take in order to only build one of the Solutions?</p>  <p>Thanks</p>,azure-devops
43132160,Firewall (iptables) settings after changing Azure Ubuntu-based VM size <p>I use Azure virtual machines  and recently scaled up the VM size to DS14. My question is: during this scale up  the VM was restarted. Would my firewall set up in <code>iptables</code> from the previous machine have carried over to the new machine? I unfortunately didn't keep a backup of that  so need to be sure either way. Thanks!</p>,azure-virtual-machine
47007031,Component testing Azure Functions <p>I am using Azure Functions backed by a SQL database using the Entity Framework.</p>  <p>To ensure code correctness  I would like to perform full automated component tests on my local machine. </p>  <p>Injecting a connection string which points to a local database solves the SQL server issue  but I am yet to find a way to spin up a local instance of Azure Functions programmatically. As VS exposes this behavior using the “Debug” functionality  it should theoretically possible.</p>  <p>How do I programmatically spin up a local version of Azure Functions using a project which is located in the same solutions as my testing project? </p>,azure-functions
12627658,Download .vhd image from Azure to local machine  and upload to another Azure account <p>I'd like to download a VM image to my local machine  so I can use it locally and upload it to another credential of Azure. I know that there is blob URL but wget didn't help to download it  because it occurs</p>  <pre><code>&lt;Error&gt; &lt;Code&gt;ResourceNotFound&lt;/Code&gt; &lt;Message&gt; The specified resource does not exist. RequestId:e7ffa746-b35c-44f3-a354-af2abfdaa823 Time:2012-09-27T18:07:00.3196644Z &lt;/Message&gt; &lt;/Error&gt; </code></pre>  <p>Any ideas? I also tried to migrate a VM image from one Azure account to another using Azure CMDLets  but got trouble because CMDLets doesn't work properly in multiple credentials.</p>,azure-storage
49895187,"How can I see full commit messages in the (GIT) commit list in VSTS? <p>We're using a GIT repository in VSTS.</p>  <p>The VSTS website has a list of all commits  but the \Message\"" column only shows the first line of each commit message.</p>  <p>You can see the full message if you hover over the displayed message text  but that is not a good way to read through the log.</p>  <p>Is there a way to have that list show the full message text?</p>""",azure-devops
51728709,Is there a way to assign tasks from a project into a different project's iteration? <p>I have the problem whereby we have lots of projects. 1 for each client.</p>  <p>We have 1 project set up to represent a specific team's work load (bugs from the other projects)... it gathers tickets and tasks from the aforementioned projects via queries.</p>  <p>This has been fine... but i would now like to start creating sprints for the tasks that are coming from other projects.</p>  <p>I have tried to create tasks that have url references to the original tickets. this means i can utilise estimates and capacity... but it's a faff re-creating the items essentially.</p>  <p>Is there a way of doing this?</p>,azure-devops
17558365,"Windows Azure Shared Access Signature always gives: Forbidden 403 <p>I am trying to get a shared access signature for a single blob and then download the blob using the REST api. However  I always get a forbidden 403 error message. Both on storage emulator and the cloud. Here is my code:</p>  <pre><code>CloudStorageAccount storageAccount = CloudStorageAccount.Parse(\myConnectionStringHere...\"");  CloudBlobClient blobClient = storageAccount.CreateCloudBlobClient(); CloudBlobContainer container = blobClient.GetContainerReference(\""containerName\""); CloudBlob blob = container.GetBlobReference(\""blobName\"");  string sasToken = blob.GetSharedAccessSignature(new SharedAccessPolicy()             {                 Permissions = SharedAccessPermission.Read                  SharedAccessExpiryTime = DateTime.UtcNow + TimeSpan.FromHours(24)             }             );  string completeUri = string.Format(CultureInfo.InvariantCulture  \""{0}{1}\""  blob.Uri  sasToken);  // now use the uri to make the rest call and download HttpWebRequest request = (HttpWebRequest)WebRequest.Create(completeUri); request.Method = \""GET\""; using (HttpWebResponse resp = (HttpWebResponse)request.GetResponse()) {     using (Stream s = resp.GetResponseStream())         {             using (FileStream fs = new FileStream(\""test.jpg\""  FileMode.Create  FileAccess.Write))                 {                         byte[] buffer = new byte[8 * 1024];                         int len;                         while ((len = s.Read(buffer  0  buffer.Length)) &gt; 0)                         {                             fs.Write(buffer  0  len);                         }                     }                 }             } </code></pre>  <p>I keep getting the 403 error when invoking GetResponse. Any help appreciated!</p>  <p>EDIT: forgot to mention: I am using the latest azure sdk (2.0)</p>  <p>EDIT 2: I experimented a lot and found a tool called Azure Management Studio. This tool is able to create an SAS token. I did that  and used it with my REST call code. This worked just fine  so the error has to be inside the token creation code I have written. However  the format of the sas string is exactly the same. I don't know what else to try out</p>""",azure-storage
53813976,Azure service bus client in timer triggered azure function <p>I have a service bus where some of messages must be handled in the correct order  which is not always the order they were added to the service bus. </p>  <p>I am receiving the messages in an Azure function and I basically need batch functionality  which I know is not available. </p>  <p><strong>Question</strong> I would like to know if I can make a timer triggered function that empties the service bus each time it is called?</p>,azure-functions
39817992,Set up SSL on Azure VM (Linux) <p>I currently have an Azure VM (linux) configuration with a custom domain name. Can someone please provide a tutorial (or explain) how I can go about setting up a SSL certificate?</p>  <p>Tried searching but no luck - appreciate all the help!</p>,azure-virtual-machine
57490886,"Issue with Body Argument for POST request <p>I am attempting to create a new team in our instance of Azure Devops through the Devops REST API.  This is being done through R with the package 'httr' for the POST request and 'jsonlite' for the toJSON function.</p>  <p>I have been utilising the documentation on Microsoft (<a href=\https://docs.microsoft.com/en-us/rest/api/azure/devops/core/teams/create?view=azure-devops-rest-5.1\"" rel=\""nofollow noreferrer\"">https://docs.microsoft.com/en-us/rest/api/azure/devops/core/teams/create?view=azure-devops-rest-5.1</a>) to structure the request correctly but keep getting a 400 error (Bad Request).</p>  <p>I am an administrator for the group so have permissions to create teams and the url is correct as I can return data with a GET request.</p>  <p>For the body argument I am using the following code;</p>  <pre><code>    args &lt;- list(name = \""my new team\"")     body &lt;- toJSON(args  auto_unbox = TRUE) </code></pre>  <p>Printing 'body' to the console returns</p>  <pre><code>    {\""name\"":\""my new team\""} </code></pre>  <p>which looks consistent with the JSON request body in the Microsoft documentation.</p>  <p>The code for the POST request is below;</p>  <pre><code>    create.task &lt;- POST(paste0(\""https://dev.azure.com/\"" org.id \""/_apis/projects/\""                     project.id \""/teams?api-version=5.1\"")                      encode = \""json\""                      authenticate(username  token  type = \""basic\"")                      body = body                     verbose()) </code></pre>  <p>This will return the following error message rather than creating the new Team in Devops.</p>  <pre><code>    \""HTTP/1.1 400 Bad Request     &lt;- Cache-Control: no-cache     &lt;- Pragma: no-cache     &lt;- Content-Length: 446     &lt;- Content-Type: application/json; charset=utf-8     &lt;- Expires: -1\"" </code></pre>  <p>Unfortunately  this is not reproduce-able but I wanted to see if there is an obvious error that I am making.</p>  <p>Thanks.</p>""",azure-devops
39234271,Terminate a Azure Virtual machine and belongings <p>I want to Terminate a <strong>Azure Virtual machine</strong> and all of it's belongings.</p>  <p><strong>What i have done --</strong></p>  <pre><code>I have stopped the Virtual machine </code></pre>  <p>It seems the by stopping Virtual Machine all of it's belongings are also stopped.</p>  <p>Now my question is --</p>  <pre><code>Since i don't need this Virtual Machine ever  how can i remove everything which belongs to a Azure Subscription ! </code></pre>  <p>Any one knows any solution !</p>,azure-storage
55903869,How to deploy artifacts from Azure devops to Apache Tomcat? <p>I am setting up CI CD jobs and publish/deploy artifacts from Azure Devops [VSTS] to Apache Tomcat  which is best way to do this?</p>,azure-devops
57143531,HttpTrigger Execute one after another using python <p>I have created one HttpTrigger Azure functions using python. But I want to create another one HttpTrigger Azure Functions using python in the same project. In this application I want to execute first HttpTrigger Azure functions after that second HttpTrigger Azure functions execute. How can I implement that?</p>  <p>Because in Python Azure Functions there is no Durable Functions. That's why I am not able to understood how can I execute one after another azure function executes.</p>,azure-functions
51481375,Intranet TFS on VSTS <p>Can we use intranet TFS for Code along with VSTS for building it using self hosted agents?</p>  <p>i.e. code should be hosted on intranet TFS to avoid sharing of code and Build should be run on local self hosted agent .. but build creation is done on VSTS</p>,azure-devops
52260712,"GET requests are working  POST requests are not (Microsoft Azure South Central US) <p>Not sure what is going on  but it looks as though POST requests for Azure Functions are not working. I've tested this with Postman and I'm getting a null response from a POST request to my function  but I'm getting the default response when I send a GET request.</p>  <p>My resources are also located in the South Central US data center... I believe this is contributing... but just to make sure I'd like to know if anyone else is getting this error? Could there be something I'm doing wrong for GET to work and not POST?</p>  <p>EDIT: It is returning code 500 internal server error. Here is the call stack from Application Insights: </p>  <pre><code>Microsoft.Azure.WebJobs.Host.FunctionInvocationException:    at System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw (System.Private.CoreLib  Version=4.0.0.0  Culture=neutral  PublicKeyToken=7cec85d7bea7798e)    at Microsoft.Azure.WebJobs.Host.Executors.FunctionExecutor+&lt;ExecuteWithLoggingAsync&gt;d__17.MoveNext (Microsoft.Azure.WebJobs.Host  Version=3.0.0.0  Culture=neutral  PublicKeyToken=nullMicrosoft.Azure.WebJobs.Host  Version=3.0.0.0  Culture=neutral  PublicKeyToken=null: C:\\projects\\azure-webjobs-sdk-rqm4t\\src\\Microsoft.Azure.WebJobs.Host\\Executors\\FunctionExecutor.csMicrosoft.Azure.WebJobs.Host  Version=3.0.0.0  Culture=neutral  PublicKeyToken=null: 293)    at System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw (System.Private.CoreLib  Version=4.0.0.0  Culture=neutral  PublicKeyToken=7cec85d7bea7798e)    at System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess (System.Private.CoreLib  Version=4.0.0.0  Culture=neutral  PublicKeyToken=7cec85d7bea7798e)    at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification (System.Private.CoreLib  Version=4.0.0.0  Culture=neutral  PublicKeyToken=7cec85d7bea7798e)    at System.Runtime.CompilerServices.TaskAwaiter1.GetResult (System.Private.CoreLib  Version=4.0.0.0  Culture=neutral  PublicKeyToken=7cec85d7bea7798e)    at Microsoft.Azure.WebJobs.Host.Executors.FunctionExecutor+&lt;TryExecuteAsync&gt;d__14.MoveNext (Microsoft.Azure.WebJobs.Host  Version=3.0.0.0  Culture=neutral  PublicKeyToken=nullMicrosoft.Azure.WebJobs.Host  Version=3.0.0.0  Culture=neutral  PublicKeyToken=null: C:\\projects\\azure-webjobs-sdk-rqm4t\\src\\Microsoft.Azure.WebJobs.Host\\Executors\\FunctionExecutor.csMicrosoft.Azure.WebJobs.Host  Version=3.0.0.0  Culture=neutral  PublicKeyToken=null: 89) Inner exception System.InvalidOperationException handled at System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw:    at Microsoft.Azure.WebJobs.Host.Executors.DelayedException.Throw (Microsoft.Azure.WebJobs.Host  Version=3.0.0.0  Culture=neutral  PublicKeyToken=nullMicrosoft.Azure.WebJobs.Host  Version=3.0.0.0  Culture=neutral  PublicKeyToken=null: C:\\projects\\azure-webjobs-sdk-rqm4t\\src\\Microsoft.Azure.WebJobs.Host\\Executors\\DelayedException.csMicrosoft.Azure.WebJobs.Host  Version=3.0.0.0  Culture=neutral  PublicKeyToken=null: 27)    at Microsoft.Azure.WebJobs.Host.Executors.FunctionExecutor+&lt;ExecuteWithWatchersAsync&gt;d__24.MoveNext (Microsoft.Azure.WebJobs.Host  Version=3.0.0.0  Culture=neutral  PublicKeyToken=nullMicrosoft.Azure.WebJobs.Host  Version=3.0.0.0  Culture=neutral  PublicKeyToken=null: C:\\projects\\azure-webjobs-sdk-rqm4t\\src\\Microsoft.Azure.WebJobs.Host\\Executors\\FunctionExecutor.csMicrosoft.Azure.WebJobs.Host  Version=3.0.0.0  Culture=neutral  PublicKeyToken=null: 478)    at System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw (System.Private.CoreLib  Version=4.0.0.0  Culture=neutral  PublicKeyToken=7cec85d7bea7798e)    at System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess (System.Private.CoreLib  Version=4.0.0.0  Culture=neutral  PublicKeyToken=7cec85d7bea7798e)    at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification (System.Private.CoreLib  Version=4.0.0.0  Culture=neutral  PublicKeyToken=7cec85d7bea7798e)    at System.Runtime.CompilerServices.TaskAwaiter.GetResult (System.Private.CoreLib  Version=4.0.0.0  Culture=neutral  PublicKeyToken=7cec85d7bea7798e)    at Microsoft.Azure.WebJobs.Host.Executors.FunctionExecutor+&lt;ExecuteWithLoggingAsync&gt;d__23.MoveNext (Microsoft.Azure.WebJobs.Host  Version=3.0.0.0  Culture=neutral  PublicKeyToken=nullMicrosoft.Azure.WebJobs.Host  Version=3.0.0.0  Culture=neutral  PublicKeyToken=null: C:\\projects\\azure-webjobs-sdk-rqm4t\\src\\Microsoft.Azure.WebJobs.Host\\Executors\\FunctionExecutor.csMicrosoft.Azure.WebJobs.Host  Version=3.0.0.0  Culture=neutral  PublicKeyToken=null: 444)    at System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw (System.Private.CoreLib  Version=4.0.0.0  Culture=neutral  PublicKeyToken=7cec85d7bea7798e)    at System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess (System.Private.CoreLib  Version=4.0.0.0  Culture=neutral  PublicKeyToken=7cec85d7bea7798e)    at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification (System.Private.CoreLib  Version=4.0.0.0  Culture=neutral  PublicKeyToken=7cec85d7bea7798e)    at System.Runtime.CompilerServices.TaskAwaiter.GetResult (System.Private.CoreLib  Version=4.0.0.0  Culture=neutral  PublicKeyToken=7cec85d7bea7798e)    at Microsoft.Azure.WebJobs.Host.Executors.FunctionExecutor+&lt;ExecuteWithLoggingAsync&gt;d__17.MoveNext (Microsoft.Azure.WebJobs.Host  Version=3.0.0.0  Culture=neutral  PublicKeyToken=nullMicrosoft.Azure.WebJobs.Host  Version=3.0.0.0  Culture=neutral  PublicKeyToken=null: C:\\projects\\azure-webjobs-sdk-rqm4t\\src\\Microsoft.Azure.WebJobs.Host\\Executors\\FunctionExecutor.csMicrosoft.Azure.WebJobs.Host  Version=3.0.0.0  Culture=neutral  PublicKeyToken=null: 249) Inner exception Newtonsoft.Json.JsonSerializationException handled at Microsoft.Azure.WebJobs.Host.Executors.DelayedException.Throw:    at Newtonsoft.Json.Serialization.JsonSerializerInternalReader.CreateNewObject (Newtonsoft.Json  Version=11.0.0.0  Culture=neutral  PublicKeyToken=30ad4fe6b2a6aeed)    at Newtonsoft.Json.Serialization.JsonSerializerInternalReader.CreateObject (Newtonsoft.Json  Version=11.0.0.0  Culture=neutral  PublicKeyToken=30ad4fe6b2a6aeed)    at Newtonsoft.Json.Serialization.JsonSerializerInternalReader.CreateValueInternal (Newtonsoft.Json  Version=11.0.0.0  Culture=neutral  PublicKeyToken=30ad4fe6b2a6aeed)    at Newtonsoft.Json.Serialization.JsonSerializerInternalReader.Deserialize (Newtonsoft.Json  Version=11.0.0.0  Culture=neutral  PublicKeyToken=30ad4fe6b2a6aeed)    at Newtonsoft.Json.JsonSerializer.DeserializeInternal (Newtonsoft.Json  Version=11.0.0.0  Culture=neutral  PublicKeyToken=30ad4fe6b2a6aeed)    at Newtonsoft.Json.Linq.JToken.ToObject (Newtonsoft.Json  Version=11.0.0.0  Culture=neutral  PublicKeyToken=30ad4fe6b2a6aeed)    at Newtonsoft.Json.Linq.JToken.ToObject (Newtonsoft.Json  Version=11.0.0.0  Culture=neutral  PublicKeyToken=30ad4fe6b2a6aeed)    at Microsoft.Azure.WebJobs.Extensions.Http.HttpTriggerAttributeBindingProvider+HttpTriggerBinding.ConvertValueIfNecessary (Microsoft.Azure.WebJobs.Extensions.Http  Version=3.0.0.0  Culture=neutral  PublicKeyToken=nullMicrosoft.Azure.WebJobs.Extensions.Http  Version=3.0.0.0  Culture=neutral  PublicKeyToken=null: C:\\azure-webjobs-sdk-extensions\\src\\WebJobs.Extensions.Http\\HttpTriggerAttributeBindingProvider.csMicrosoft.Azure.WebJobs.Extensions.Http  Version=3.0.0.0  Culture=neutral  PublicKeyToken=null: 406)    at Microsoft.Azure.WebJobs.Extensions.Http.HttpTriggerAttributeBindingProvider+HttpTriggerBinding.ApplyBindingData (Microsoft.Azure.WebJobs.Extensions.Http  Version=3.0.0.0  Culture=neutral  PublicKeyToken=nullMicrosoft.Azure.WebJobs.Extensions.Http  Version=3.0.0.0  Culture=neutral  PublicKeyToken=null: C:\\azure-webjobs-sdk-extensions\\src\\WebJobs.Extensions.Http\\HttpTriggerAttributeBindingProvider.csMicrosoft.Azure.WebJobs.Extensions.Http  Version=3.0.0.0  Culture=neutral  PublicKeyToken=null: 228)    at Microsoft.Azure.WebJobs.Extensions.Http.HttpTriggerAttributeBindingProvider+HttpTriggerBinding+&lt;BindAsync&gt;d__10.MoveNext (Microsoft.Azure.WebJobs.Extensions.Http  Version=3.0.0.0  Culture=neutral  PublicKeyToken=nullMicrosoft.Azure.WebJobs.Extensions.Http  Version=3.0.0.0  Culture=neutral  PublicKeyToken=null: C:\\azure-webjobs-sdk-extensions\\src\\WebJobs.Extensions.Http\\HttpTriggerAttributeBindingProvider.csMicrosoft.Azure.WebJobs.Extensions.Http  Version=3.0.0.0  Culture=neutral  PublicKeyToken=null: 174)    at System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw (System.Private.CoreLib  Version=4.0.0.0  Culture=neutral  PublicKeyToken=7cec85d7bea7798e)    at System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess (System.Private.CoreLib  Version=4.0.0.0  Culture=neutral  PublicKeyToken=7cec85d7bea7798e)    at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification (System.Private.CoreLib  Version=4.0.0.0  Culture=neutral  PublicKeyToken=7cec85d7bea7798e)    at System.Runtime.CompilerServices.TaskAwaiter`1.GetResult (System.Private.CoreLib  Version=4.0.0.0  Culture=neutral  PublicKeyToken=7cec85d7bea7798e)    at Microsoft.Azure.WebJobs.Host.Triggers.TriggeredFunctionBinding1+&lt;BindCoreAsync&gt;d__8.MoveNext (Microsoft.Azure.WebJobs.Host  Version=3.0.0.0  Culture=neutral  PublicKeyToken=nullMicrosoft.Azure.WebJobs.Host  Version=3.0.0.0  Culture=neutral  PublicKeyToken=null: C:\\projects\\azure-webjobs-sdk-rqm4t\\src\\Microsoft.Azure.WebJobs.Host\\Triggers\\TriggeredFunctionBinding.csMicrosoft.Azure.WebJobs.Host  Version=3.0.0.0  Culture=neutral  PublicKeyToken=null: 57) </code></pre>  <p>And here is the function code:</p>  <pre><code>using Alexa.NET.Request; using Alexa.NET.Response; using Alexa.NET.Request.Type; using System.Data.SqlClient; using Microsoft.Azure.WebJobs; using Microsoft.Azure.WebJobs.Extensions.Http; using Microsoft.AspNetCore.Mvc; using Microsoft.Azure.WebJobs.Host; using System.Data; using Alexa.NET; using System;   namespace MyFunction {      public static class MyFunction     {          static readonly string azureConnection = \---Connection String---\"";         static SqlConnection connection;         static string welcomeMessage = \""Welcome.\"";          [FunctionName(\""FuncCall\"")]         public static SkillResponse Run([HttpTrigger(AuthorizationLevel.Anonymous  \""get\""  \""post\""  Route = null)][FromBody]SkillRequest incomingRequest  TraceWriter log)         {               SkillResponse skillResponseForBuilder;             PlainTextOutputSpeech outputSpeech = new PlainTextOutputSpeech();              switch (incomingRequest.Request)             {                 case LaunchRequest launch:                      outputSpeech.Text = welcomeMessage;                     SkillResponse skillResponse = new SkillResponse();                     skillResponse.Version = \""1.0\"";                     skillResponse.SessionAttributes = null;                     skillResponse.Response = new ResponseBody();                     skillResponse.Response.OutputSpeech = outputSpeech;                     skillResponse.Response.ShouldEndSession = false;                     return skillResponse;                   case IntentRequest intent:                     string intentName = intent.Intent.Name;                     if (intentName.Equals(\""RollTheDice\""))                     {                         return RollDiceHandler(incomingRequest);                     }                     else if (intentName.Equals(\""CheckIn\""))                      {                         return CheckInHandler(incomingRequest);                     }                     else                     {                         DataTable funcdt = new DataTable();                         using (connection = new SqlConnection(azureConnection))                         using (                             SqlCommand cmd = new SqlCommand(\""SPCallFunction\""  connection)                             {                                 CommandType = CommandType.StoredProcedure                             })                          {                             connection.Open();                             cmd.Parameters.Add(new SqlParameter(\""@IntentKey\""  intentName));                             SqlDataReader funcdr = cmd.ExecuteReader();                             funcdt.Load(funcdr);                             if (funcdt.Rows.Count != 0)                             {                                 outputSpeech.Text = funcdt.Rows[0][\""IntentValue\""].ToString();                                 connection.Close();                             }                             else                             {                                 outputSpeech.Text = incomingRequest.GetRequestType().ToString();                                 connection.Close();                             }                          }                     }                      skillResponseForBuilder = ResponseBuilder.Tell(outputSpeech);                     return skillResponseForBuilder;                   default:                     outputSpeech.Text = \""Error.\"";                     skillResponseForBuilder = ResponseBuilder.Tell(outputSpeech.Text);                     return skillResponseForBuilder;             }         }          // Test dialog handler         public static SkillResponse RollDiceHandler(SkillRequest req)         {             SkillResponse skillResponse = new SkillResponse();             PlainTextOutputSpeech outputSpeech = new PlainTextOutputSpeech();             var request = req.Request as IntentRequest;             if (request.DialogState == DialogState.Started)             {                 return ResponseBuilder.DialogDelegate(req.Session  request.Intent);             }             else if (request.DialogState != DialogState.Completed)             {                 return ResponseBuilder.DialogDelegate(req.Session);             }             else             {                 skillResponse.Response = new ResponseBody();                 skillResponse.Response.ShouldEndSession = false;                 if (request.Intent.Slots[\""DiceType\""].Value != null)                 {                     var numSides = request.Intent.Slots[\""DiceType\""].Value;                     var rollResults = new Random().Next(Math.Max(1  Convert.ToInt32(numSides) - 1)) + 1;                     outputSpeech.Text = \""I rolled a \"" + numSides + \"" sided die and got a \"" + rollResults;                     skillResponse.Response.OutputSpeech = outputSpeech;                     skillResponse.Response.ShouldEndSession = true;                     skillResponse.Version = \""1.0\"";                  }                 else                 {                     outputSpeech.Text = \""Hello.\"";                     skillResponse.Response.OutputSpeech = outputSpeech;                     skillResponse.Version = \""1.0\"";                     if (request.Intent.Slots[\""DiceType\""].Value != null)                     {                         var numSides = request.Intent.Slots[\""DiceType\""].Value;                         var rollResults = new Random().Next(Math.Max(1  Convert.ToInt32(numSides) - 1)) + 1;                         outputSpeech.Text = \""I rolled a \"" + numSides + \"" sided die and got a \"" + rollResults;                         skillResponse.Response.OutputSpeech = outputSpeech;                         skillResponse.Response.ShouldEndSession = true;                         skillResponse.Version = \""1.0\"";                     }                  }                 return skillResponse;             }         }           public static SkillResponse CheckInHandler(SkillRequest req)         {             SkillResponse skillResponse = new SkillResponse();             PlainTextOutputSpeech outputSpeech = new PlainTextOutputSpeech();             var request = req.Request as IntentRequest;             if (request.DialogState == DialogState.Started)             {                 return ResponseBuilder.DialogDelegate(req.Session  request.Intent);             }             else if (request.DialogState != DialogState.Completed)             {                 return ResponseBuilder.DialogDelegate(req.Session);             }             else             {                 skillResponse.Response = new ResponseBody();                 skillResponse.Response.ShouldEndSession = false;                 if (request.Intent.Slots[\""TechnicianName\""].Value != null &amp;&amp; request.Intent.Slots[\""TicketNumber\""].Value != null)                 {                     var techName = request.Intent.Slots[\""TechnicianName\""].Value;                     var ticketNumber = request.Intent.Slots[\""TicketNumber\""].Value;                     if (request.Intent.Slots[\""TechnicianCompany\""].Value != null)                     {                         var techCompany = request.Intent.Slots[\""TechnicianCompany\""].Value;                      }                                          outputSpeech.Text = \""Thank you.\"";                      skillResponse.Response.OutputSpeech = outputSpeech;                     skillResponse.Response.ShouldEndSession = true;                     skillResponse.Version = \""1.0\"";                 }                 return skillResponse;             }         }      }    } </code></pre>  <p>`</p>""",azure-functions
57299854,Adding an Entity to an Azure Cosmos Table with Javascript Azure Function <p>In Azure  I have a javascript HTTPTrigger Function App with:</p>  <pre><code>const azure = require('azure-storage') const tableSvc = azure.createTableService(     process.env.COSMOS_TABLE_ACCOUNT      process.env.COSMOS_TABLE_KEY      process.env.COSMOS_TABLE_ENDPOINT ) const entGen = azure.TableUtilities.entityGenerator const testData = {     PartitionKey: entGen.String('test')      RowKey: entGen.String(1)      name: entGen.String('It works!') }  const insertTestData = () =&gt; new Promise((resolve  reject) =&gt; {     tableSvc.insertEntity('tests'  testData  (error  res) =&gt; {         if (error) return reject(error)         resolve(res)     }) }) ... </code></pre>  <p>I've confirmed that the environment variables are all set and populated with the values from Azure Cosmos DB -> Cosmos Table Instance -> Connection String.</p>  <p>I've also tried connecting with:</p>  <pre><code>const tableSvc = azure.createTableService(     process.env.COSMOS_TABLE_CONNECTION_STRING ) </code></pre>  <p>When I call <code>insertTestData()</code>  I'm getting back an error back from the <code>.insertEntity</code> callback with an empty object: <code>{}</code>. No entities are being added to my <code>tests</code> table  as confirmed by the Data Explorer.</p>  <p>Any ideas how to perform this operation or get more information in my debugger? I have an Insight monitor attached to the process  but it reports a successful completion.</p>,azure-functions
54205588,Migrating azure subscription from CSP to pay as you go <p>We currently have an Azure account set up through a third party who happens to be a CSP. As expected  this took several hours to set up and configure.</p>  <p>We're looking to move from that CSP partner to an account that we manage ourselves. The feedback we're getting is that that's not something easily done.</p>  <p>Has anyone experienced difficulties moving from a CSP to a pay as you go subscription  or is this company we're dealing with holding something back? I obviously want to avoid the several hours of re-setting up all of our resources.</p>,azure-web-app-service
55980254,"There was an error sending this message to your bot: HTTP status code NotFound <p>I tried to deploy the bot in azure. Initially I created a web app bot in azure and then I download the code from azure. After that I added all the production files like .bot  .env  web.config files in my git repository. After that I added my git repository to the azure. I also included the microsoft app id and app password in app.js file and web.config files.</p>  <p>When I start giving test in web chat it is not running properly instead it shows \<strong>There was an error sending this message to your bot: HTTP status code NotFound</strong>\""</p>  <p>Where I missed  please help me.</p>""",azure-web-app-service
19217940,"The specified blob does not exist --even when the bob does exists <p>With my code below  I am getting an error message:</p>  <blockquote>   <p>The specified blob does not exist</p> </blockquote>  <p>when I debug my code  at <code>.CreateBlobContainer</code> -I can see the specified bob got created  Then outside the my code I manually copied and pasted a text file into my blob.Then when I reach the last line of the code  <code>.DownloadToStream</code>   it throws exception error saying the specified blob doesnot exist.  --even when the bob does exists</p>  <p>What's wrong with my sample code below:</p>  <pre><code>        string testContainerName = \xyz\""+Common.GenerateRandomEightCharString().ToLower();          var testBlobClient = BlobClientFactory.CreateBlobClient(true);         var testContainer = BlobClientFactory.CreateBlobContainer(testBlobClient  testContainerName);         var zipOutputStream = new ZipOutputStream(Response.OutputStream)         {             CompressionLevel = CompressionLevel.Default         };         zipOutputStream.CompressionLevel = CompressionLevel.Default;         zipOutputStream.EnableZip64 = Zip64Option.AsNecessary;         CloudBlob testBlob = testBlobClient.GetBlobReference(testBlobClient.BaseUri.ToString() + testContainerName);         zipOutputStream.PutNextEntry(testContainerName);         BlobRequestOptions options = new BlobRequestOptions();         options.Timeout = TimeSpan.FromSeconds(20.0);         testBlob.DownloadToStream(zipOutputStream  options); //Exception error here </code></pre>  <p>Here is the exception message .</p>  <pre><code>Microsoft.WindowsAzure.StorageClient.StorageClientException was unhandled by user code   HResult=-2146233088   Message=The specified blob does not exist.   Source=Microsoft.WindowsAzure.StorageClient   StackTrace:        at Microsoft.WindowsAzure.StorageClient.Tasks.Task`1.get_Result()        at Microsoft.WindowsAzure.StorageClient.Tasks.Task`1.Execute()        at Microsoft.WindowsAzure.StorageClient.RequestWithRetry.RequestWithRetrySyncImpl[TResult](ShouldRetry retryOracle  SynchronousTask`1 syncTask)        at Microsoft.WindowsAzure.StorageClient.TaskImplHelper.ExecuteSyncTaskWithRetry[TResult](SynchronousTask`1 syncTask  RetryPolicy policy)        at Microsoft.WindowsAzure.StorageClient.CloudBlob.DownloadToStream(Stream target  BlobRequestOptions options)        at ............................        at System.Web.Mvc.ActionMethodDispatcher.Execute(ControllerBase controller  Object[] parameters)        at System.Web.Mvc.ReflectedActionDescriptor.Execute(ControllerContext controllerContext  IDictionary`2 parameters)        at System.Web.Mvc.ControllerActionInvoker.InvokeActionMethod(ControllerContext controllerContext  ActionDescriptor actionDescriptor  IDictionary`2 parameters)        at System.Web.Mvc.ControllerActionInvoker.&lt;&gt;c__DisplayClass15.&lt;InvokeActionMethodWithFilters&gt;b__12()        at System.Web.Mvc.ControllerActionInvoker.InvokeActionMethodFilter(IActionFilter filter  ActionExecutingContext preContext  Func`1 continuation)   InnerException: System.Net.WebException        HResult=-2146233079        Message=The remote server returned an error: (404) Not Found.        Source=System        StackTrace:             at System.Net.HttpWebRequest.GetResponse()             at Microsoft.WindowsAzure.StorageClient.EventHelper.ProcessWebResponseSync(WebRequest req  EventHandler`1 handler  Object sender)        InnerException:  </code></pre>""",azure-storage
38314386,"SSRS 2016 Scale-Out on Azure VMs not working <p><strong>Setup</strong></p>  <p>I'm running an AlwaysOn SQL Server Availability Set (from the <a href=\https://azure.microsoft.com/en-us/blog/sql-server-alwayson-cluster-template-updated-with-internal-listeners-and-optimized-performance/\"" rel=\""nofollow\"">Azure Always On SQL Server Availability Set Template</a>)  and trying to utilize the two SQL Servers in a scale-out NLB setup (I haven't figured out exactly what virtual appliance to use yet) for SSRS. I've never actually utilized a scale-out set-up for SSRS but it seems relatively straight-forward:</p>  <pre><code>1. Set up one instance of SSRS 2. Create reportserver db 3. Connect to same report server db from a second SSRS instance 4. Accept the join request from SSRS Configuration tool of the first instance </code></pre>  <p>Everything* seems to work fine up until step 4 when the join request doesn't appear <a href=\""http://i.stack.imgur.com/TRY5S.png\"" rel=\""nofollow\"">(see the screenshot)</a>.  The part of this that I imagine might be causing some issues is that due to the AlwaysOn Setup I am using an internal load balancer with sql listener for my SSRS connection string  and this can be pointed to either SQL Server instance at any given time based on failover  but I'm not sure how this could be troublesome.</p>  <p><strong>Things I've Tried</strong></p>  <p><em>The below resulted in: 2nd instance not available to join  despite successful connection to database.</em></p>  <ul> <li>Scaling Out before adding Report Server to AlwaysOn</li> <li>Scaling Out after adding Report Server to AlwaysOn</li> <li>Using rskeymgmt Utility from the 1st instance (indicates success but no change on restarting SSRS service)</li> </ul>  <p><em>The below resulted in: Primary scale-out instance changed from one instance to the other.</em></p>  <ul> <li>Restore encryption key from 1st instance to the 2nd instance after connecting to RS database.</li> </ul>  <p>None of this seems to work and I'm not sure if this is a bug in SQL Server 2016 or something wrong with my methodology.  Any help would be appreciated.</p>  <p>Thanks!</p>  <p><strong>*Note</strong>: I ran into some initial problems with loopbacks  but disabled strictnamechecking and allowed the specific dns names through the check (the host name for the load balancer (base and FQDN) and that of the server itself (base and FQDN).  </p>""",azure-virtual-machine
51391197,"Azure web app very slow after publish or restart <p>When I publish or restart my web app it loads very slowly the first time  then when I refresh with F5 it is ok again. what could it be?<a href=\https://i.stack.imgur.com/FFHbR.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/FFHbR.png\"" alt=\""Average response time\""></a></p>""",azure-web-app-service
46556031,Azure Function Context <p>I am looking to use <code>Microsoft.Azure.WebJobs.ExecutionContext</code> to get the <code>InvocationId</code> while a function is running  but is there a way to get this while outside of the actual function call. </p>  <p>So if a calling class needs to have some kind of context it can use this. Is it possible?</p>,azure-functions
24497580,"Azure ReservedIP endpoints <p>I'm trying to provision a new Azure VM from an image via PowerShell and I need to use ReservedIP (which is why I'm using PowerShell - ReservedIP functionality isn't available from the management portal).</p>  <p>I'm running the following command:</p>  <pre><code>New-AzureVMConfig -Name \myName\"" -InstanceSize Small -ImageName \""imageName\"" | New-AzureVM -ServiceName \""serviceName\"" -ReservedIPName \""IP Name\"" -AffinityGroup \""myAffinityGroup\"" </code></pre>  <p>But I get the following error:</p>  <pre><code>New-AzureVM : BadRequest: Deployment serviceName uses ReservedIP IP Name but does not contain any endpoints. Deployment must contain at least one endpoint in order to use a ReservedIP. </code></pre>  <p>I can see that the cloud instance gets created  but it doesn't have any VM instance in it. Other Stack Overflow posts seem to imply that the above pshell commands should just work. None of the documentation addresses the need to add an endpoint and the VM doesn't even get created  so I don't know where I'd be able to add one.</p>  <p>Any help would be much appreciated. Thanks!</p>""",azure-virtual-machine
56474058,"Azure service principal unable to assign permissions to resource groups <p>I am trying to build a azure web app to create a azure resource group and assign contributor permission for a specific user. I am using a powershell script to do this. when i run it in my local it does what it supposed to do. where as when i execute it on azure web app it throws the following error.</p>  <p>The service principal has owner permission on the subscription also it has the directory permission.  </p>  <pre><code>#Login to Azure using Service Principal Login-AzureRmAccount -ServicePrincipal  -Credential $SPcred -TenantId \XXXXX-xxxx-xxxxxxx\""  #Create resource group New-AzureRmResourceGroup -Name $Name -Location $Location -Force    if((Get-AzureRmResourceGroup -Name $Name).ProvisioningState = \""Succeeded\"") {      New-AzureRmRoleAssignment -ResourceGroupName $Name -SignInName XXXXXX -RoleDefinitionName Contributor } </code></pre>  <p><strong>Error Message:</strong></p>  <blockquote>   <p>The provided information does not map to an AD object id azure</p> </blockquote>""",azure-web-app-service
39400938,"Azure Web App Deploy. Transforming the webconfig <p>I am trying to chance some appsettings and the ConnectionString of an application in a certain slot in my Azure Web App.</p>  <p>When I try to change the config via the Application Settings on Azure portal  nothing happens.</p>  <p>So I found this post:</p>  <blockquote>   <p><a href=\http://brian.vallelunga.com/blog/chaining-azure-web-config-transforms-when-deploying-from-source-control\"" rel=\""nofollow\"">http://brian.vallelunga.com/blog/chaining-azure-web-config-transforms-when-deploying-from-source-control</a></p> </blockquote>  <p>Ok  I done what the tutorial tells me to do and I got success on some deploys (I am using Kudu for auto deploy from GitHub).</p>  <p>But suddenly (without any change of config) the deploys are using the Release transform  instead of the dev one.</p>  <p>Via <code>Kudu</code> console  I saw in deployment folder  in some moment <code>Kudu</code> transformed my web.config in right one  and after transforms it again into the release version. Someone have any idea what I can do?</p>  <p>Oh. My solution have more than one web project. I am using the <code>\""Project\""</code> Key on Azure application config page and that one works.</p>  <p>Thanks </p>""",azure-web-app-service
54259566,Azure Devops requiring password every time I push from local to remote repository <p>Relatively new git and azure-devops user here. </p>  <p>I am currently working on a project locally that I wish to push to my private azure-devops repository called 'Hello_World'. </p>  <p>So locally  I did the following:</p>  <pre><code>git remote add origin https://dkennetz@dev.azure.com/dkennetz/Hello_World/_git/Hello_World </code></pre>  <p>Then I wanted to push all my local code to the remote repo  so I simply did:</p>  <pre><code>git push -u origin --all </code></pre>  <p>and I was prompted:</p>  <pre><code>[dkennetz@nodecn204  Hello_World]$ git push -u origin --all Password for 'https://dkennetz@dev.azure.com': </code></pre>  <p>Which is fine. I entered the token the first time and I thought all things would be handled accordingly for future pushes. I was wrong. Every time after this  I still have to enter my password for pushes. </p>  <p>I am doing this as a simple test case to try out azure-devops but I can see this becoming a serious issue if each user in a project has to enter username and password for CI/CD every time a user wants to push code to a repo. </p>  <p>I thought maybe I could add something to my config to handle this  but I am not sure. </p>  <p>If I run:</p>  <pre><code>git config --list </code></pre>  <p>I get (the space is because of code formatting issues):</p>  <pre><code>user.name=Dennis Kennetz user.email=funkyman@funky.org core.repositoryformatversion=0 core.filemode=true core.bare=false core.logallrefupdates=true </code></pre>  <p><code>remote.origin.url=https://dkennetz@dev.azure.com/dkennetz/Hello_World/_git/Hello_World</code></p>  <pre><code>remote.origin.fetch=+refs/heads/*:refs/remotes/origin/* branch.master.remote=origin branch.master.merge=refs/heads/master </code></pre>  <p>Thanks for the help!</p>,azure-devops
35778323,"Can i put vm into another resource group than availabilitySet? <p>I would like to keep each VM in separate resource group for ease for lifecycle management. I have a cluster containing n VLMs.</p>  <p>So I create one resource group for common things like public IP  load balancer and put availabilitySet declaration into it because is also must be shared between VMs. Then I create VM in separate resource group and reference to availabilitySet with      \availabilitySet\"": {           \""id\"": \""[resourceId('Microsoft.Compute/availabilitySets' variables('availabilitySetName'))]\""         }  Of cause 'availabilitySetName' is defined.</p>  <p>When I deploy my template I get an error saying</p>  <blockquote>   <p>{\""error\"":{\""code\"":\""BadRequest\"" \""message\"":\""Entity resourceGroupName in resource reference id /subscriptions/a719381f-1fa0-4b06-8e29-ad6ea7d3c90b/resourceGroups/TB_PIP_OPSRV_UAT/providers/Microsoft.Compute/availabilitySets/tb_avlbs_opsrv_uat is invalid.\""}}</p> </blockquote>  <p>I double checked that resource and availability set name are specified correctly. </p>  <p>Does it mean that I can't put a set in separate resource group from VM? </p>""",azure-virtual-machine
56816900,.trx test file generation in ng run test for sonar cloud code coverage <p>I am facing issues to get code coverage report via sonar cloud in my angular project.</p>  <p>I have configured karma tool to get the test report. Output file is generating test report in .xml format. I configured the test report path in sonar as well:</p>  <pre><code>sonar.cs.vscoveragexml.reportsPaths=$(Agent.BuildDirectory)/TestResults/*.xml </code></pre>  <p>But sonar cloud is searching for .trx extension test report.Below is the error log.</p>  <pre><code>06:16:44.724  Looking for TRX files in: D:\a\1\TestResults 06:16:44.724  No test results files found 06:16:45.083  Did not find any binary coverage files in the expected location. 06:16:45.083  Falling back on locating coverage files in the agent temp directory. 06:16:45.083  Searching for coverage files in D:\a\_temp </code></pre>  <p>Requesting to help me to resolve the same.</p>,azure-devops
52031745,"VSTS Build failed when associated with Hockey App <p>I am trying to associate my UWP App build with the Hockey App but it's getting failed.</p>  <p>Below are the configurations I have set:</p>  <p>For Build:</p>  <p><strong>MSBuild Arguments:</strong></p>  <blockquote>   <p>/p:AppxBundlePlatforms=\$(BuildPlatform)\""   /p:AppxPackageDir=\""$(Build.ArtifactStagingDirectory)\\AppxPackages\\\""   /p:AppxBundle=Always /p:UapAppxPackageBuildMode=StoreUpload</p> </blockquote>  <p>For Hockey App:</p>  <p><strong>Binary Path:</strong></p>  <p><code>$(Build.ArtifactStagingDirectory)\\AppxPackages\\UWPVSTSBuild_$(AppxVersion)_Test\\UWPVSTSBuild_$(AppxVersion)_x86_x64_ARM.appxbundle</code></p>  <p>Error that I am getting after build process:</p>  <pre><code>Error: Not found binaryPath:   D:\\a\\1\\a\\AppxPackages\\UWPVSTSBuild_$(AppxVersion)_Test\\UWPVSTSBuild_$(AppxVersion)_x86_x64_ARM.appxbundle </code></pre>  <p>Is there anything that I am missing in the parameter?</p>""",azure-devops
54390868,Pass build variables to powerhshell inline script in Azure DevOps <p>I have set build variable which I would like to consume in my inline powershell script. </p>  <p>I tried $($myvariable) but this comes out blank</p>,azure-devops
46123786,"Config files and retrieving in Azure-Functions <p>I've been experimenting with .config files in Azure-Functions.</p>  <p>If I write this function</p>  <pre><code>using System; using System.Configuration; using System.Net; using System.Net.Http; using System.Threading.Tasks;  using Microsoft.Azure.WebJobs; using Microsoft.Azure.WebJobs.Extensions.Http; using Microsoft.Azure.WebJobs.Host;   namespace GranadaCoder.AzurePoc.AzureFunctionsOne {     public static class AppSettingsTestOne     {         [FunctionName(\AppSettingsTestOneFunctionName\"")]         public static async Task&lt;HttpResponseMessage&gt; Run([HttpTrigger(AuthorizationLevel.Function  \""post\""  Route = null)]HttpRequestMessage req  TraceWriter log)         {              try             {                  string rootDirectory = string.Empty;                 if (!string.IsNullOrEmpty(Environment.GetEnvironmentVariable(\""HOME\"")))                 {                     /* running in azure */                     rootDirectory = Environment.GetEnvironmentVariable(\""HOME\"") + \""\\\\site\\\\wwwroot\"";                 }                 else                 {                     /* in visual studio  local debugging */                     rootDirectory = \"".\"";                 }                 string path = rootDirectory + @\""\\CustomConfigFiles\\CustomAppSettings.config\"";                  if (!System.IO.File.Exists(path))                 {                     throw new System.IO.FileNotFoundException(string.Format(\""NOT FOUND!!! ('{0}')\""  path));                 }                 else                 {                     log.Info(string.Format(\""File exists='{0}'\""  path));                 }                  ExeConfigurationFileMap map = new ExeConfigurationFileMap { ExeConfigFilename = path };                 Configuration config = ConfigurationManager.OpenMappedExeConfiguration(map  ConfigurationUserLevel.None);                  Configuration fileConfig = ConfigurationManager.OpenExeConfiguration(path); /* does NOT work */                 string val1 = config.AppSettings.Settings[\""KeyOne\""].Value;                 string val2 = config.AppSettings.Settings[\""KeyTwo\""].Value;                 string val3 = config.AppSettings.Settings[\""KeyThree\""].Value;                  string msg = string.Join(\"" \""  val1  val2  val3);                  return req.CreateResponse(HttpStatusCode.OK  msg);             }             catch (Exception ex)             {                 string errorMsg = ex.Message; //  ExceptionHelper.GenerateFullFlatMessage(ex);                 log.Error(errorMsg);                 return req.CreateResponse(HttpStatusCode.BadRequest  errorMsg);             }         }     } } </code></pre>  <p>with this .config file (CustomAppSettings.config)</p>  <pre><code>&lt;?xml version=\""1.0\"" encoding=\""utf-8\""?&gt; &lt;configuration&gt;   &lt;appSettings&gt;     &lt;add key=\""KeyOne\"" value=\""ValueOne\"" /&gt;     &lt;add key=\""KeyTwo\"" value=\""ValueTwo\"" /&gt;     &lt;add key=\""KeyThree\"" value=\""ValueThree\"" /&gt;   &lt;/appSettings&gt; &lt;/configuration&gt; </code></pre>  <p>It works as anticipated.</p>  <p>If I use this function:</p>  <pre><code>using System; using System.Collections.Specialized; using System.Configuration; using System.IO; using System.Linq; using System.Net; using System.Net.Http; using System.Threading.Tasks; using System.Xml;  using Microsoft.Azure.WebJobs; using Microsoft.Azure.WebJobs.Extensions.Http; using Microsoft.Azure.WebJobs.Host;   namespace GranadaCoder.AzurePoc.AzureFunctionsOne {     public static class NameValuePairAppSettingsTest     {         [FunctionName(\""NameValuePairAppSettingsTestFunctionName\"")]         public static async Task&lt;HttpResponseMessage&gt; Run([HttpTrigger(AuthorizationLevel.Function  \""post\""  Route = null)]HttpRequestMessage req  TraceWriter log)         {              try             {                 string rootDirectory = string.Empty;                 if (!string.IsNullOrEmpty(Environment.GetEnvironmentVariable(\""HOME\"")))                 {                     /* running in azure */                     rootDirectory = Environment.GetEnvironmentVariable(\""HOME\"") + \""\\\\site\\\\wwwroot\"";                 }                 else                 {                     /* in visual studio  local debugging */                     rootDirectory = \"".\"";                 }                 string path = rootDirectory + @\""\\CustomConfigFiles\\NameValuePairSettings.config\"";                   if (!System.IO.File.Exists(path))                 {                     throw new System.IO.FileNotFoundException(string.Format(\""NOT FOUND!!! ('{0}')\""  path));                 }                 else                 {                     log.Info(string.Format(\""file exists='{0}'\""  path));                 }                  ExeConfigurationFileMap map = new ExeConfigurationFileMap { ExeConfigFilename = path };                 Configuration config = ConfigurationManager.OpenMappedExeConfiguration(map  ConfigurationUserLevel.None);                  //NameValueCollection nvc = (NameValueCollection)config.GetSection(\""myLittleArea\""); /* does not work */                  ConfigurationSection myParamsSection = config.GetSection(\""myLittleArea\"");                 /* see https://stackoverflow.com/questions/13825323/how-do-i-get-the-values-from-a-configsection-defined-as-namevaluesectionhandler */                 string myParamsSectionRawXml = myParamsSection.SectionInformation.GetRawXml();                 XmlDocument sectionXmlDoc = new XmlDocument();                 sectionXmlDoc.Load(new StringReader(myParamsSectionRawXml));                 NameValueSectionHandler handler = new NameValueSectionHandler();                 NameValueCollection nvc = handler.Create(null  null  sectionXmlDoc.DocumentElement) as NameValueCollection;                  var items = nvc.AllKeys.SelectMany(nvc.GetValues  (k  v) =&gt; new { key = k  value = v });                 ////////foreach (var item in items)                 ////////{                 ////////    Console.WriteLine(\""{0} {1}\""  item.key  item.value);                 ////////}                  string msg = string.Join(\"" \""  items.ToList());                  return req.CreateResponse(HttpStatusCode.OK  msg);             }             catch (Exception ex)             {                 string errorMsg = ex.Message; //  ExceptionHelper.GenerateFullFlatMessage(ex);                 log.Error(errorMsg);                 return req.CreateResponse(HttpStatusCode.BadRequest  errorMsg);             }         }     } } </code></pre>  <p>with this .config file (NameValuePairSettings.config)</p>  <pre><code>&lt;?xml version=\""1.0\"" encoding=\""utf-8\""?&gt; &lt;configuration&gt;   &lt;configSections&gt;     &lt;section name=\""myLittleArea\"" type=\""System.Configuration.NameValueSectionHandler  System  Version=1.0.5000.0 Culture=neutral  PublicKeyToken=b77a5c561934e089\"" /&gt;   &lt;/configSections&gt;    &lt;myLittleArea&gt;     &lt;add key=\""color\"" value=\""red\""/&gt;     &lt;add key=\""street\"" value=\""main\""/&gt;     &lt;add key=\""month\"" value=\""july\""/&gt;     &lt;add key=\""candy\"" value=\""snickers\""/&gt;   &lt;/myLittleArea&gt;  &lt;/configuration&gt; </code></pre>  <p>Everything works ok.</p>  <p>(Drum Roll).</p>  <p>If I create a custom configuration section.</p>  <pre><code>using System.Configuration;  namespace GranadaCoder.AzurePoc.ConfigurationLibrary.MyCustomConfigurationSettings {     public static class MyCustomConfigurationSettingsConfigurationRetriever     {         public static readonly string ConfigurationSectionName = \""MyCustomConfigurationSettingsConfigurationSectionName\"";          /*         public static MyCustomConfigurationSettingsConfigurationSection GetMyCustomConfigurationSettings()         {             MyCustomConfigurationSettingsConfigurationSection returnSection = (MyCustomConfigurationSettingsConfigurationSection)ConfigurationManager.GetSection(ConfigurationSectionName);             if (returnSection != null)             {                 return returnSection;             }              return null;         }         */          public static MyCustomConfigurationSettingsConfigurationSection GetMyCustomConfigurationSettings(System.Configuration.Configuration cfg)         {             MyCustomConfigurationSettingsConfigurationSection returnSection = (MyCustomConfigurationSettingsConfigurationSection)cfg.GetSection(ConfigurationSectionName);             if (returnSection != null)             {                 return returnSection;             }              return null;         }     } } </code></pre>  <p>and</p>  <pre><code>using System.Configuration;  namespace GranadaCoder.AzurePoc.ConfigurationLibrary.MyCustomConfigurationSettings {     public class MyCustomConfigurationSettingsConfigurationSection : ConfigurationSection     {         private const string FavoriteNumberPropertyName = \""FavoriteNumber\"";         private const string FavoriteColorPropertyName = \""FavoriteColor\"";          [ConfigurationProperty(FavoriteNumberPropertyName  IsRequired = true  DefaultValue = 100)]         public int FavoriteNumber         {             get             {                 return (int)this[FavoriteNumberPropertyName];             }         }          [ConfigurationProperty(FavoriteColorPropertyName  IsRequired = true  DefaultValue = \"" \"")]         public string FavoriteColor         {             get             {                 return (string)this[FavoriteColorPropertyName];             }         }     } } </code></pre>  <p>and .config (MyCustomConfigurationSettings.config)</p>  <pre><code>&lt;?xml version=\""1.0\"" encoding=\""utf-8\""?&gt; &lt;configuration&gt;   &lt;configSections&gt;     &lt;section name =\""MyCustomConfigurationSettingsConfigurationSectionName\"" type=\""GranadaCoder.AzurePoc.ConfigurationLibrary.MyCustomConfigurationSettings.MyCustomConfigurationSettingsConfigurationSection  GranadaCoder.AzurePoc.ConfigurationLibrary\"" /&gt;   &lt;/configSections&gt;   &lt;MyCustomConfigurationSettingsConfigurationSectionName     FavoriteNumber=\""333\""     FavoriteColor=\""Green\""   &gt;   &lt;/MyCustomConfigurationSettingsConfigurationSectionName&gt; &lt;/configuration&gt; </code></pre>  <p>and azure function code</p>  <pre><code>using System; using System.Configuration; using System.Net; using System.Net.Http; using System.Threading.Tasks;  using Microsoft.Azure.WebJobs; using Microsoft.Azure.WebJobs.Extensions.Http; using Microsoft.Azure.WebJobs.Host;  using GranadaCoder.AzurePoc.ConfigurationLibrary.MyCustomConfigurationSettings;    namespace GranadaCoder.AzurePoc.AzureFunctionsOne {     public static class CustomConfigurationTest     {         [FunctionName(\""CustomConfigurationTestFunctionName\"")]         public static async Task&lt;HttpResponseMessage&gt; Run([HttpTrigger(AuthorizationLevel.Function  \""post\""  Route = null)]HttpRequestMessage req  TraceWriter log)         {             try             {                 string rootDirectory = string.Empty;                 if (!string.IsNullOrEmpty(Environment.GetEnvironmentVariable(\""HOME\"")))                 {                     /* running in azure */                     rootDirectory = Environment.GetEnvironmentVariable(\""HOME\"") + \""\\\\site\\\\wwwroot\"";                 }                 else                 {                     /* in visual studio  local debugging */                     rootDirectory = \"".\"";                 }                 string path = rootDirectory + @\""\\CustomConfigFiles\\MyCustomConfigurationSettings.config\"";                  log.Info(string.Format(\""CustomConfigurationTestFunctionName HostingEnvironment.ApplicationPhysicalPath='{0}'\""  System.Web.Hosting.HostingEnvironment.ApplicationPhysicalPath));                  if (!System.IO.File.Exists(path))                 {                     throw new System.IO.FileNotFoundException(string.Format(\""NOT FOUND!!! ('{0}')\""  path));                 }                 else                 {                     log.Info(string.Format(\""File exists='{0}'\""  path));                 }                  ExeConfigurationFileMap map = new ExeConfigurationFileMap { ExeConfigFilename = path };                 Configuration config = ConfigurationManager.OpenMappedExeConfiguration(map  ConfigurationUserLevel.None);                  MyCustomConfigurationSettingsConfigurationSection customSection = MyCustomConfigurationSettingsConfigurationRetriever.GetMyCustomConfigurationSettings(config);                  string msg = string.Join(\"" \""  customSection.FavoriteNumber.ToString()  customSection.FavoriteColor);                  return req.CreateResponse(HttpStatusCode.OK  msg);             }             catch (Exception ex)             {                 string errorMsg = ex.Message; //  ExceptionHelper.GenerateFullFlatMessage(ex);                 log.Error(errorMsg);                 return req.CreateResponse(HttpStatusCode.BadRequest  errorMsg);             }         }     } } </code></pre>  <p>The above does not work.</p>  <p>I get an error</p>  <p>\""An error occurred creating the configuration section handler for MyCustomConfigurationSettingsConfigurationSectionName: Could not load file or assembly 'GranadaCoder.AzurePoc.ConfigurationLibrary' or one of its dependencies. The system cannot find the file specified. (C:\\blah\\blah\\blah\\bin\\Debug\\net461\\CustomConfigFiles\\MyCustomConfigurationSettings.config line 4)\""</p>  <p>The file IS THERE (see image)</p>  <p>Any idea why the custom configuration does not work?</p>  <p><a href=\""https://i.stack.imgur.com/oJxeq.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/oJxeq.png\"" alt=\""enter image description here\""></a></p>""",azure-functions
53537056,Azure DevOps fails executing EF Core Migration scripts <p>​I have been deploying my code first migrations until now by creating the ef core migration script during my build and running them against the database. They look like this:</p>  <pre><code>IF NOT EXISTS(SELECT * FROM [__EFMigrationsHistory] WHERE [MigrationId] = N'20181106170338_Add FK To user from news')  BEGIN      UPDATE News SET News.UserId = AspNetUsers.Id FROM AspNetUsers where AspNetUsers.UserName = News.Username END;  GO  </code></pre>  <p>In a later migration I droped the column News.Username. I have created many releases since then and they worked. Now I get an error saying Username column does not exist. But even if I go back now an execute an older migration it fails with this message since this morning event though it worked for example last night.</p>,azure-devops
56208849,"Issue with Team Explorer Everywhere on MAC OS <p>I am trying to use TFS for code checkin and checkout on MAC using Eclipse. I have recently moved to a new MAC system with <code>Mojave</code>  older one used to work fine with <code>Team Explorer Everywhere</code> and <code>Eclipse Neon 3</code>.</p>  <p>I am using the following version of Eclipse and using the latest version of <code>Team Explorer Everywhere 14.134.0</code> plugin.</p>  <pre><code>Eclipse IDE for Java Developers  Version: 2019-03 (4.11.0) Build id: 20190314-1200 </code></pre>  <p>I get the following error when I try to open the TEE  <code>Plug-in \com.microsoft.tfs.client.common.ui\"" was unable to instantiate class \""com.microsoft.tfs.client.common.ui.views.TeamExplorerView\""</code></p>  <p>I have the JAVA Version <code>java version \""12.0.1\"" 2019-04-16</code></p>  <p>Can someone help ?</p>""",azure-devops
32391347,"How to deploy an asp.net mvc app to IIS 8 on azure virtual machine <p>Trying to deploy an asp.net mvc application with IIS 8 on azure virtual machine but Im getting the following error:</p>  <p><a href=\https://i.stack.imgur.com/Kwfj5.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/Kwfj5.png\"" alt=\""enter image description here\""></a></p>  <p>This is what ive done so far in azure Virtual machine:</p>  <ol> <li>Installed IIS </li> <li>Installed Web deploy 3.6  web deploy for hosting server  web deploy tools 2.1  web deploy without sql bundled support In IIS azure Virtual machine:</li> <li>Created a website \""Nextix\"" in IIS</li> <li>Disabled Default Web site in IIS</li> <li>In my Visual Studio 2013 (asp.net mvc project)  selected publish -> web deploy package</li> <li>Copied the deployed package to the virtual machine</li> <li>In IIS  clicked website \""Nextix\"" and selected import application </li> <li>Followed all instructions in Import Application Package Wizard to install Web deploy package</li> <li>I also installed ASP.net 4 in iis by following the instruction in the link <a href=\""https://stackoverflow.com/questions/2374957/asp-net-mvc-on-iis-7-5\"">ASP.NET MVC on IIS 7.5</a></li> </ol>  <p>After the steps I did  this is how my IIS application pools looks like: <a href=\""https://i.stack.imgur.com/nSlMY.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/nSlMY.png\"" alt=\""enter image description here\""></a></p>  <p>And how the advance settings of my nextix website looks like: <a href=\""https://i.stack.imgur.com/t0gHT.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/t0gHT.png\"" alt=\""enter image description here\""></a></p>  <p>Is there something else I need to check or do? Im still getting the above error message screen.</p>""",azure-virtual-machine
14800651,"May I lose Drive D: if I add new storage to my Azure VM? <p>I had a bad experience when I tried to promote my VM from a smaller size to a bigger one  in that case I lost alla data on the \Temporary Drive D:\"". Now I need to add a persistent drive to my VM  would this addition result in cancelling the drive D:?</p>""",azure-storage
39345873,Installing Azure SDK without Emulators <p>Is it possible to install the Azure SDK (specifically VS 2015) without installing the associated emulators. </p>  <p>Simply I just never use them  and it would be good to not install them! </p>,azure-storage
52320445,"V2 Azure Function ServiceBusTrigger Not Working <p>I have a .NET Standard 2.0 project that defines Azure functions. I have a couple of BlobTrigger and QueueTrigger functions which work as expected. I am trying to replace the storage account QueueTrigger functions with ServiceBus topic trigger functions:</p>  <pre><code>[FunctionName(\CommandConsumer\"")] public static async Task RunAsync([ServiceBusTrigger(\""commands\""  \""active\""  Connection = \""ServiceBus\"")]string commandJson  TraceWriter log) {     log.Info($\""C# ServiceBus topic trigger function processed message: {commandJson}\""); } </code></pre>  <p>This function never gets triggered even though upstream functions add messages to the topic successfully (I can see that I have 25 messages on the topic right now)  and my console window shows a lot of messages like these:</p>  <pre><code>[9/13/2018 7:13:29 PM] MessageReceiver error (Action=Receive  ClientId=MessageReceiver1commands/Subscriptions/active  EntityPath=commands/Subscriptions/active  Endpoint=p.servicebus.windows.net) [9/13/2018 7:14:06 PM] MessageReceiver error (Action=Receive  ClientId=MessageReceiver1commands/Subscriptions/active  EntityPath=commands/Subscriptions/active  Endpoint=p.servicebus.windows.net) [9/13/2018 7:14:42 PM] MessageReceiver error (Action=Receive  ClientId=MessageReceiver1commands/Subscriptions/active  EntityPath=commands/Subscriptions/active  Endpoint=p.servicebus.windows.net) </code></pre>  <p>I've set the tracing to Verbose but I can't get any more details about this MessageReceiver error.</p>  <p>Thank you in advance!</p>  <p>Edit: here are the project's relevant package references:</p>  <pre><code>&lt;PackageReference Include=\""Microsoft.Azure.ServiceBus\"" Version=\""3.1.0\"" /&gt; &lt;PackageReference Include=\""Microsoft.Azure.WebJobs.Extensions.Storage\"" Version=\""3.0.0-beta8\"" /&gt; &lt;PackageReference Include=\""Microsoft.Azure.WebJobs.ServiceBus\"" Version=\""3.0.0-beta8\"" /&gt; &lt;PackageReference Include=\""Microsoft.NET.Sdk.Functions\"" Version=\""1.0.19\"" /&gt; </code></pre>""",azure-functions
54021522,"How to debug in-process hosted ASP.Net Core apps with WinDBG and SOS? <p>I have an ASP.Net Core 2.2 app  targeted to .Net Core 2.2. I host it on Azure App Service using the new <a href=\https://docs.microsoft.com/en-us/aspnet/core/host-and-deploy/aspnet-core-module?view=aspnetcore-2.2\"" rel=\""nofollow noreferrer\"">in-process hosting model</a>. Then I create a memory dump via App Service diagnostic tools. Open it using Visual Studio  and I see two CLR versions: 4.7.3190.0; 4.6.27110.4. I can tell that 4.7.3190.0 is for .Net Framework  and 4.6.27110.4 is for .Net Core. <a href=\""https://i.stack.imgur.com/pfgn4.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/pfgn4.png\"" alt=\""enter image description here\""></a> If I open the dump in WinDBG  it keeps loading the mscordacwks DLL for 4.7.3190.0. I have no way to make it load the mscordaccore DLL for 4.6.27110.4. And thus a simple SOS command such as <code>!Threads</code> leads to error <code>Failed to request ThreadStore</code>.</p>  <p>How can I debug my managed code (the .Net Core part) using WinDBG and SOS?</p>  <p>You can get the sample memory dump <a href=\""https://media.githubusercontent.com/media/zhiliangxu/DebugAspNetCore/master/RD0003FF588DD0_w3wp_7900.dmp\"" rel=\""nofollow noreferrer\"">here</a>.</p>  <h2>Update</h2>  <p>Thanks for the GREAT help from <a href=\""https://stackoverflow.com/users/480982/thomas-weller\"">Thomas Weller</a>! The solution to this case is to run <code>.cordll -u -I coreclr -l -lp \""C:\\Program Files\\dotnet\\shared\\Microsoft.NETCore.App\\2.2.0\\\""</code>. I must unload (<code>-u</code>) CLR DAC and load (<code>-l</code>) the <strong>Core</strong> CLR DAC in one command.</p>  <p>The successful commands and logs are <a href=\""https://github.com/zhiliangxu/DebugAspNetCore/blob/master/success.log\"" rel=\""nofollow noreferrer\"">here</a>.</p>""",azure-web-app-service
41559854,Azure Load Balancer + NSG Rules - Remove Access Directly <p>I've got a networking question for one of my customers servers in the cloud.</p>  <p>We are using just a standard 2012R2 VM with a few endpoints set up through the NSG Firewall  and we have a LoadBalancer infront of the network with a few ports forwarded to the same VPC.</p>  <p>The reason we are using a load balancer with port forwarding is because I'm finding countless records of bots trying to hit 3389 and 21 with attempts to break in.</p>  <p>So I have tried to change the source setting in the NSG rule to AzureLoadBalancer with the hope that it will only allow access to traffic that has come via the LoadBalancer on the external ports.</p>  <p>But for some reason this is not the case? Is there a proper procedure for restricting traffic to a VM via the NSG from a LoadBalancer?</p>  <p>Any help with this is greatly appreciated.</p>  <p>Thanks</p>,azure-virtual-machine
48634002,"Azure Webapp Ruby Deployment <p>After carefully read all Azure tutorials I wasn't able to deploy my application.</p>  <p>I used the follow steps:</p>  <ol> <li>Create a new Web App from Azure Portal Linux with Ruby 2.3 container</li> <li>Configure local git repository with username and password</li> <li>Fork a hello-workd from Microsoft  from this <a href=\https://docs.microsoft.com/pt-br/azure/app-service/containers/quickstart-ruby\"" rel=\""nofollow noreferrer\"">tutorial</a> and from this <a href=\""https://github.com/Azure-Samples/ruby-docs-hello-world\"" rel=\""nofollow noreferrer\"">repo</a> </li> <li><p>After restart the Web App I got the message:</p>  <pre><code>Service Unavailable </code></pre></li> </ol>  <p>I can't connect using SSH  but  using Kudu  I was able to check the log files. Apparently  the problem is regard with Ruby dependencies  but I have no idea how to solve. </p>  <pre><code>2018-02-06 00:54:43.965 INFO  - Logging is not enabled for this container. Please use https://aka.ms/linux-diagnostics to enable logging to see container logs here. 2018-02-06 00:54:48.292 INFO  - Container logs 2018-02-06T00:54:45.106381390Z Starting OpenBSD Secure Shell server: sshd. 2018-02-06T00:54:45.313181989Z Bundle install with no 'without' options 2018-02-06T00:54:45.313337691Z Defaulting gem installation directory to /tmp/bundle 2018-02-06T00:54:45.313459292Z Defaulting site config directory to /home/site/config 2018-02-06T00:54:45.313575793Z Generating a secret key base 2018-02-06T00:54:45.641497487Z RAILS_ENV set to production 2018-02-06T00:54:45.641616888Z Removing any leftover pids if present 2018-02-06T00:54:45.649293251Z Running bundle check 2018-02-06T00:54:45.649606153Z /opt/startup.sh: line 67: [: : integer expression expected 2018-02-06T00:54:46.700604188Z You are replacing the current local value of path  which is currently \""/home/site/wwwroot/vendor/bundle\"" 2018-02-06T00:54:47.793612367Z missing dependencies  try redeploying  2018-02-06 00:54:48.293 ERROR - Container xxx for site xxx has exited  failing site start </code></pre>  <p>Anyone did go thru on this? I suspect maybe is related to some app configurations  but as far I read  it's optional.</p>""",azure-web-app-service
47394160,Wildcard SSL mapping multiple Azure App Service apps <p>I have domain.com  a.domain.com  b.domain.com  and c.domain.com to be mapped to x.azurewebsites.net a.azurewebsites.net  a.azurewebsites.net and a.azurewebsites.net</p>  <p>I am able to set the following</p>  <p><code>A record pointing to IP address of x.azurewebsites.net</code> and </p>  <pre><code>CNAME www.domain.com pointed to x.azurewebsites.net </code></pre>  <p>And update SSL  it works for https works for domain.com and www.domain.com</p>  <p>When I am setting up a.domain.com to a.azurewebsites.net</p>  <p>I cannot set A record  So I set CNAME</p>  <pre><code>CNAME a.domain.com pointed to a.azurewebsites.net  </code></pre>  <p>How can I fix DNS configuration for this scenario?</p>,azure-web-app-service
46472805,Execute PowerShell on Azure VM from TFS via AzureRM <p>I have a number of VMs provisioned in my Azure subscription  protected by an NSG  so I don't have WinRM available remotely.</p>  <p>I'd like to execute a PowerShell script on these VMs as part of my TFS release definition.</p>  <p>Is there any way to execute arbitrary PowerShell scripts on Azure VM resources?</p>  <p>I'm aware of the Custom Script extension for Azure VM resources  but I don't know if this is what I'm after  or if it plays nicely with TFS.</p>,azure-virtual-machine
47400751,How to assign two IP address to single virtual machine in Azure <p>I installed a software called Postal on my azure virtual machine  now I have 1 public IP address but the application requires an another IP so that it can enable fast_server and use that new IP to track all links.</p>  <p>I tried adding new ip by</p>  <ol> <li>Open Network Interface of that Virtual Machine </li> <li>Click on IP   Configuration</li> <li>Click on Add button and add that IP as secondary</li> </ol>  <p>I have got the secondary IP but It's not properly working or responding.</p>  <p>Do I have to enable any inbound rule for that IP?</p>,azure-virtual-machine
48035044,Web App Service - How often should it be restarted? <p>I deployed an Azure web app back in July and it's been running flawlessly up until about three weeks ago. At that time  I would notice my CPU utilization constantly between 80% to 100%  with no corresponding increase in traffic. The first time I saw this  after concluding it wasn't my app  or increased traffic  causing this  I restarted the web app service and the CPU utilization returned to its normal 5% to 15%. Then after a couple days it started to do it again. And  again  a restart solved the issue. </p>  <p>My question is this. Is this normal to have to restart the web service every day or so? And  if so  why?</p>,azure-web-app-service
52858016,"Investigating memory issue and determining if the finalizer thread is blocked <p>I am trying to investigate a suspected memory issue in one of our APIs deployed on azure as app service.We see during certain long-running operations memory continuously increases over a period of time and the application becomes too slow.</p>  <p>I collected a couple of memory dumps while the operation was running using azure memory dump tool and noticed that number of object ready for finalization are continuously increasing (15K 25k 28 K and the one which took after the whole process completed showed 100K). With my limited knowledge  I suspect this could be a case of blocked finalizer thread. </p>  <p>When I look at the call stack of finalizer thread for all the dumps   one thing is common that the last entry is always \ntdll!NtWaitForMultipleObjects\"" .</p>  <p>Does this mean that my finalizer thread is blocked? Or is this normal? </p>  <p>Below is the screenshot from one of the dumps showing the full call stack for the finalizer thread.</p>  <p><a href=\""https://i.stack.imgur.com/FIAIi.png\"" rel=\""nofollow noreferrer\""><img src=\""https://i.stack.imgur.com/FIAIi.png\"" alt=\""enter image description here\""></a></p>""",azure-web-app-service
14723203,Can You Remotely Install Visual Studio Team Foundation Server 2012? <p>Is it possible to remotely install visual studio team foundation 2012?</p>  <p>If anyone can link to a tutorial or information guide that would be great if there is one available.</p>,azure-devops
